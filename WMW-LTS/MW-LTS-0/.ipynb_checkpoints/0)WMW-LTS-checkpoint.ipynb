{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import tensorflow package for modeling\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Initializing module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "## Copy module\n",
    "import copy\n",
    "\n",
    "## Used to calculate the training time\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "## Set the GUP environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the display\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control memory usage space for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前設備： 0\n",
      "目前設備名： GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "## 查詢有無可用 GPU\n",
    "torch.cuda.is_available()\n",
    "## 查詢可用 GPU 的數量\n",
    "torch.cuda.device_count()\n",
    "##目前設備\n",
    "print(\"目前設備：\",torch.cuda.current_device())\n",
    "## 目前設備名\n",
    "print(\"目前設備名：\",torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cacl(pred_value, actual_value):\n",
    "    \n",
    "#     yo, loss, tape = network.forward()\n",
    "    performance = []\n",
    "    performance.append(torch.mean(torch.abs(pred_value - actual_value)))\n",
    "    performance.append(torch.mean(torch.abs((pred_value - actual_value) / actual_value))) \n",
    "    performance.append(torch.sqrt(torch.mean((pred_value - actual_value)**2)))\n",
    "    \n",
    "    for i in range(2000,3001,1000):\n",
    "        correct_times = torch.nonzero(torch.abs(pred_value - actual_value) <= i)\n",
    "        accuracy = correct_times.shape[0]/pred_value.shape[0]\n",
    "        performance.append(accuracy)\n",
    "    \n",
    "    performance.append(torch.max(torch.abs(pred_value - actual_value)))\n",
    "    performance.append(torch.min(torch.abs(pred_value - actual_value)))\n",
    "    \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(name, pred_value, actual_value,block_index):\n",
    "    \n",
    "#     fig, ax = plt.subplots(2,2,figsize=(20,10), sharex=True, sharey=True)\n",
    "    fig, ax = plt.subplots(1,figsize=(20,10), sharex=True, sharey=True)\n",
    "#     ax.set_xlim(0,pred_value.shape[0])  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.plot(pred_value, label=\"LLAAT\")\n",
    "    ax.plot(actual_value, label=\"Actual\")\n",
    "    ax.set_title(\"Forecasted performance for l=%d\" %(1))\n",
    "    ax.legend()\n",
    "        \n",
    "    #fig.text(0.5, 0, \"Stage of training\", ha='center', fontsize=20)\n",
    "    #fig.text(0, 0.5, \"Copper price value\", va='center', rotation='vertical')\n",
    "\n",
    "    fig.suptitle(\"In the %s process in the M=%d window\"%(name, block_index))\n",
    "    fig.tight_layout()\n",
    "#     fig.savefig(\"In the %s process in the M=%d window.png\"%(name, block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adopted_node(network,block_index):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "#     ax.set_xticklabels([i for i in range(network.nb_node_acceptable.shape[0]+5)])\n",
    "    \n",
    "    ax.set_title(\"Total amount of adopted hidden nodes in the training process in the M=%d window\"%(block_index))\n",
    "    ax.plot(network.nb_node_acceptable,\"-o\")\n",
    "\n",
    "    ax.set_xlabel(\"Stage of training\")\n",
    "    ax.set_ylabel(\"Hidden nodes\")\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#     fig.savefig(\"hidden nodes in the training process in the M=%d window\"%(block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_table(evaluation_results, block_index, name, performance, nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node):\n",
    "\n",
    "    print(performance[3])\n",
    "    print(type(performance[3]))\n",
    "    \n",
    "    new_result = pd.DataFrame({\n",
    "\n",
    "        \"Window_index\":block_index,\n",
    "        \"Stage\":name,\n",
    "        \"MAE\" : round(performance[0].item(),2),\n",
    "        \"MAPE\" : \"%.2f\"%(performance[1]*100).item(),\n",
    "        \"RMSE\" : round(performance[2].item(),2),\n",
    "        \"Accuracy(2000)\" : [round(performance[3]*100,2)],\n",
    "        \"Accuracy(3000)\" : [round(performance[4]*100,2)],\n",
    "        \"Maximum error\" : round(performance[5].item(),2),\n",
    "        \"Minimum error\" : round(performance[6].item(),2),\n",
    "        \"Step4\":nb_step4,\n",
    "        \"Step6.1\":nb_step6_1,\n",
    "        \"Step6.2\":nb_step6_2,\n",
    "        \"Time\":time,\n",
    "        \"Adopted_hidden_node\":adopted_hidden_node\n",
    "    })\n",
    "\n",
    "    evaluation_results = evaluation_results.append(new_result, ignore_index=True)\n",
    "    \n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(last_date, network, nb_step4, nb_step6_1, nb_step6_2, x_train_scaled, y_train_scaled, x_test, y_test, start, end, block_index, evaluation_results_train, evaluation_results_test,forecasted_price):\n",
    "\n",
    "    ## Training_Step\n",
    "    print(\"<<Training step>>\")\n",
    "    print(\"The training time(s):\",end - start)\n",
    "    time = end - start\n",
    "    yo, loss= network.forward()\n",
    "    \n",
    "    ## N - outlier\n",
    "    pre_train = yo.data.cpu()\n",
    "    true_train = network.y.data.cpu()\n",
    "    \n",
    "    pred_value_train = torch.FloatTensor(sc.inverse_transform(pre_train))\n",
    "    actual_value_train = torch.FloatTensor(sc.inverse_transform(true_train))\n",
    "    accuracy_train = accuracy_cacl(pred_value_train,actual_value_train)\n",
    "\n",
    "    ## Outlier\n",
    "#     pre_outlier = torch.FloatTensor(sc.inverse_transform(network.forecast(x_train_scaled).data.cpu()))\n",
    "#     actual_outlier = torch.FloatTensor(sc.inverse_transform(y_train_scaled))\n",
    "#     accuracy_outlier = accuracy_cacl(pre_outlier,actual_outlier)\n",
    "    \n",
    "    ## B\n",
    "    pred_value_test = torch.FloatTensor(sc.inverse_transform(network.forecast(x_test).data.cpu()))\n",
    "    accuracy_test = accuracy_cacl(pred_value_test, y_test)\n",
    "    \n",
    "    total_time = nb_step4 + nb_step6_1 + nb_step6_2\n",
    "    print(\"<<The percentage of each step>>\")\n",
    "    print(\"Step 4: %.2f%%\"%((nb_step4/total_time)*100))\n",
    "    print(\"Step 6.1: %.2f%%\"%((nb_step6_1/total_time)*100))\n",
    "    print(\"Step 6.2: %.2f%%\"%((nb_step6_2/total_time)*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"Total frequency of cramming occurrences:\",nb_step6_2)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of hidden node that be pruned:\",network.nb_node_pruned)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    adopted_hidden_node = network.nb_node_acceptable[-1].item()\n",
    "    print(\"The amount of adopted hidden nodes:\",network.nb_node_acceptable[-1].item())\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in training step>>\")\n",
    "    print(\"The MAE for l = 1: %.2f\" %(accuracy_train[0]))\n",
    "    print(\"The MAPE for l = 1: %.2f%%\" %(accuracy_train[1]))\n",
    "    print(\"The RMSE for l = 1: %.2f\" %(accuracy_train[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.2f%%\" %(accuracy_train[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.2f%%\" %(accuracy_train[4]*100))\n",
    "    print(\"The maximum error:\", accuracy_train[5])\n",
    "    print(\"The minimum error:\", accuracy_train[6])\n",
    "#     print(\"The accuracy for l = 2: %.1f%%\" %(accuracy_train[1]*100))\n",
    "#     print(\"The accuracy for l = 3: %.1f%%\" %(accuracy_train[2]*100))\n",
    "#     print(\"The accuracy for l = 4: %.1f%%\" %(accuracy_train[3]*100))\n",
    "\n",
    "#     print(\"-\"*60)\n",
    "#     print(\"<<Accuracy in toutlier>>\")\n",
    "#     print(\"The MAE for l = 1: %.2f\" %(accuracy_outlier[0]))\n",
    "#     print(\"The MAPE for l = 1: %.2f%%\" %(accuracy_outlier[1]))\n",
    "#     print(\"The RMSE for l = 1: %.2f\" %(accuracy_outlier[2]))\n",
    "#     print(\"The accuracy(2000) for l = 1: %.2f%%\" %(accuracy_outlier[3]*100))\n",
    "#     print(\"The accuracy(3000) for l = 1: %.2f%%\" %(accuracy_outlier[4]*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in inferencing step>>\")\n",
    "    print(\"The MAE for l = 1: %.1f\" %(accuracy_test[0]))\n",
    "    print(\"The MAPE for l = 1: %.1f%%\" %(accuracy_test[1]))\n",
    "    print(\"The RMSE for l = 1: %.1f\" %(accuracy_test[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.1f%%\" %(accuracy_test[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.1f%%\" %(accuracy_test[4]*100))\n",
    "    print(\"The maximum error:\", accuracy_test[5].item())\n",
    "    print(\"The minimum error:\", accuracy_test[6].item())\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    y_test = np.round_(y_test, decimals = 2) \n",
    "    \n",
    "    for i in range(pred_value_test.shape[0]):\n",
    "        \n",
    "        record = pd.DataFrame({\n",
    "            \n",
    "            \"Date\": [datetime.date(last_date[0]+timedelta(days=28+7*i))],\n",
    "            \"Actual\": y_test[i],\n",
    "            \"Forecasted_price\": round(pred_value_test[i].item(),2)\n",
    "        })\n",
    "    \n",
    "        forecasted_price = forecasted_price.append(record)\n",
    "    \n",
    "    evaluation_table_train = evaluation_table(evaluation_results_train, block_index, \"Training\", accuracy_train,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "#     evaluation_table_outlier = evaluation_table(evaluation_results_outlier, block_index, \"Outlier\", accuracy_outlier,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    evaluation_table_test = evaluation_table(evaluation_results_test, block_index, \"Inferencing\", accuracy_test,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    pre_LDSS = sc.inverse_transform(network.forecast(x_test).data.cpu())\n",
    "#     pd.DataFrame(pre_LDSS).to_csv(\"pre_LDSS_%d.csv\"%(block_index), index=False)\n",
    "    \n",
    "#     if block_index%5==0:\n",
    "    plot_result(\"training\",pred_value_train, actual_value_train,block_index)\n",
    "    plot_result(\"inferencing\",pred_value_test, y_test,block_index)\n",
    "    plot_adopted_node(network,block_index)\n",
    "    \n",
    "    return(evaluation_table_train, evaluation_table_test, forecasted_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=4, futureWeek=4, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek+1):\n",
    "        \n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use min-max normalization to scale the data to the range from 1 to 0\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design get_data() to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(futureWeek):\n",
    "    \n",
    "    ## Read weekly copper price data\n",
    "    path = \"WeeklyFinalData.csv\"\n",
    "    data = read(path)\n",
    "    \n",
    "    date = pd.DataFrame(data[\"Date\"][3:])\n",
    "    date[\"Date\"] = pd.to_datetime(date[\"Date\"], format=\"%Y/%m/%d\")\n",
    "    data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "    ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "    x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "\n",
    "\n",
    "    return (date, x_data, y_data)\n",
    "\n",
    "#     return (x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_neuro, x_train_scaled, y_train_scaled):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(x_train_scaled.shape[1], nb_neuro).cuda()\n",
    "        self.linear2 = torch.nn.Linear(nb_neuro, 1).cuda()\n",
    "        \n",
    "        \n",
    "        # Stop criteria - threshold\n",
    "        self.threshold_for_error = 0.12\n",
    "        self.threshold_for_lr = 1e-4\n",
    "        \n",
    "        # Input data \n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = 1e-3\n",
    "        \n",
    "        # Whether the network is acceptable, default as False\n",
    "        self.acceptable = False\n",
    "        \n",
    "        # Some record for experiment\n",
    "        self.nb_node_pruned = 0\n",
    "        self.nb_node_acceptable=torch.IntTensor([nb_neuro])\n",
    "        \n",
    "        self.limit = nb_neuro\n",
    "        \n",
    "    ## Forecast the test data\n",
    "    def forecast(self, x_test):\n",
    "    \n",
    "        x_test = torch.FloatTensor(x_test).cuda()\n",
    "        activation_value = self.linear1(x_test).clamp(min=0)\n",
    "        forecast_value = self.linear2(activation_value)\n",
    "       \n",
    "        return forecast_value\n",
    "\n",
    "    ## Reset the x and y data\n",
    "    def setData(self, x_train_scaled, y_train_scaled):\n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "    \n",
    "    ## Add the new data to the x and y data\n",
    "    def addData(self, new_x_train, new_y_train):\n",
    "\n",
    "        self.x = torch.cat([self.x, new_x_train.reshape(1,-1).cuda()],0)\n",
    "        self.y = torch.cat([self.y, new_y_train.reshape(-1,1).cuda()],0)\n",
    "    \n",
    "    ## forward operation\n",
    "    def forward(self, reg_strength=0):\n",
    "       \n",
    "        y1 = self.linear1(self.x).clamp(min=0)\n",
    "        yo = self.linear2(y1)\n",
    "\n",
    "        # performance measure\n",
    "        param_val= torch.sum(torch.pow(self.linear2.bias.data,2))+torch.sum(torch.pow(self.linear2.weight.data,2))+torch.sum(torch.pow(self.linear1.bias.data,2))+torch.sum(torch.pow(self.linear1.weight.data,2))\n",
    "        reg_term= reg_strength/((self.linear2.bias.data.shape[0]*(self.linear2.weight.data.shape[1]+1)) +(self.linear1.bias.data.shape[0]*(self.linear1.weight.data.shape[1]+1)))*param_val\n",
    "        loss = torch.nn.functional.mse_loss(yo,self.y)+reg_term\n",
    "        loss = loss.cuda()\n",
    "        return(yo, loss)\n",
    "\n",
    "    # backward operation\n",
    "    def backward_Adadelta(self,loss):    \n",
    "\n",
    "        optimizer = optim.Adadelta(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing(network, initial_x, initial_y):\n",
    "    print(\"Initializing module\")\n",
    "    ## Find each minimum output value y\n",
    "    min_y = torch.min(initial_y, axis=0)\n",
    "    ## Subtract min_y from each y\n",
    "    res_y = initial_y-min_y.values\n",
    "    \n",
    "    ## Use linear regression to find the initial W1,b1,Wo,bo\n",
    "    reg = LinearRegression().fit(initial_x, res_y)\n",
    "    \n",
    "    ## Set up the initial parameter of the network\n",
    "    network.linear1.weight = torch.nn.Parameter(torch.FloatTensor(reg.coef_).cuda())\n",
    "    network.linear1.bias = torch.nn.Parameter(torch.FloatTensor(reg.intercept_).cuda())\n",
    "    network.linear2.weight=torch.nn.Parameter(torch.FloatTensor([[1]]).cuda())\n",
    "    network.linear2.bias = torch.nn.Parameter(torch.FloatTensor(min_y.values).cuda())\n",
    "    \n",
    "#     print(reg.coef_)\n",
    "#     print(reg.intercept_)\n",
    "\n",
    "    ## Set up the acceptable of the initial network as True\n",
    "    network.acceptable =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(network, x_train_scaled, y_train_scaled):\n",
    "    \n",
    "    print(\"<<Selecting module>>\")\n",
    "    loss = []\n",
    "    temp_network = copy.deepcopy(network)\n",
    "    \n",
    "    ## Put each data into network to calculate the loss value\n",
    "    for i in range(x_train_scaled.shape[0]):\n",
    "        temp_network.setData(x_train_scaled[i].reshape(1,-1), y_train_scaled[i].reshape(-1,1))\n",
    "        loss.append((temp_network.forward()[1].item(),i))\n",
    "#         print(network.state_dict())\n",
    "#         print(temp_network.y)\n",
    "#         print(\"-\"*20)\n",
    "#         print(temp_network.forward()[1])\n",
    "#         print(\"-\"*20)\n",
    "#     ## Sort the data according to the loss value from smallest to largest, and save the data index in sorted_index\n",
    "    sorted_index = [sorted_data[1] for sorted_data in sorted(loss, key = lambda x:x[0])]\n",
    "    \n",
    "    \n",
    "    ## Print out some info for debug\n",
    "    print(\"The loss value of k:\",loss[sorted_index[0]])\n",
    "#     print(\"The second_loss value of k:\",loss[sorted_index[1]])\n",
    "    print(\"Selecting module finish!\")\n",
    "#     print(\"Loss\",loss)\n",
    "#     print(network.state_dict())\n",
    "    \n",
    "    return sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matching(network):\n",
    "\n",
    "#     times_enlarge=0\n",
    "#     times_shrink=0\n",
    "    \n",
    "#     print(\"<<Matching module>>\")\n",
    "#     print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "#     ## Set up the learning rate of the network\n",
    "#     network.learning_rate = 1e-3\n",
    "#     network.acceptable = False\n",
    "#     initial_network = copy.deepcopy(network)\n",
    "\n",
    "#     yo, loss = network.forward()\n",
    "    \n",
    "#     if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "#         print(\"Matching finished (firstly) - the network is acceptable\")\n",
    "#         network.acceptable = True\n",
    "# #         print(\"Matching firstly finished - the network is acceptable\")\n",
    "#         print(\"Number of enlarge:\",times_enlarge)\n",
    "#         print(\"Number of shrink:\",times_shrink)\n",
    "#         return(network)\n",
    "    \n",
    "#     else:\n",
    "    \n",
    "#         while True:\n",
    "\n",
    "#             yo, loss = network.forward()\n",
    "#             network_pre = copy.deepcopy(network)\n",
    "#             loss_pre = loss\n",
    "            \n",
    "#             # Backward and check the loss performance of the network with new learning rate\n",
    "#             network.backward_Adadelta(loss)\n",
    "#             yo, loss = network.forward()\n",
    "\n",
    "#             # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "#             if loss <= loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "       \n",
    "#                 network.acceptable = True\n",
    "#                 print(\"Matching finished - the network is acceptable\")\n",
    "#                 print(\"Number of enlarge:\",times_enlarge)\n",
    "#                 print(\"Number of shrink:\",times_shrink)\n",
    "#                 return(network)\n",
    "\n",
    "#             elif loss <= loss_pre:\n",
    "                \n",
    "#                 times_enlarge+=1\n",
    "#                 network.learning_rate *= 1.2\n",
    "\n",
    "#             else:         \n",
    "\n",
    "#                 # Identify whether the current learning rate is less than the threshold\n",
    "#                 if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "#                     # If true, set the acceptable of the network as false and return it\n",
    "#                     network.acceptable = False\n",
    "#                     print(\"Matching finished - the network is Unacceptable\")\n",
    "#                     print(\"Number of enlarge:\",times_enlarge)\n",
    "#                     print(\"Number of shrink:\",times_shrink)\n",
    "#                     return(initial_network)\n",
    "\n",
    "#                 # On the contrary, restore w and adjust the learning rate\n",
    "#                 else:\n",
    "                    \n",
    "#                     # Restore the papameter of the network\n",
    "#                     network = copy.deepcopy(network_pre)\n",
    "#                     times_shrink+=1\n",
    "#                     network.learning_rate *= 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(10000):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "#             print(\"<前Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "#             print(\"<後Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "#                 print(\"*1.2\")\n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "#                     print(\"*0.7\")\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching for reorganizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_for_reorganizing(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module for reorganizing>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(500):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "#             print(\"<前Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "#             print(\"<後Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished(o) - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "#                 print(\"*1.2\")\n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished(o) - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "#                     print(\"*0.7\")\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramming module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramming(network):\n",
    "    \n",
    "    torch.random.manual_seed(0)\n",
    "    print(\"<<Cramming module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Find unsatisfied data:K\n",
    "    yo, loss = network.forward()\n",
    "    undesired_index = torch.nonzero(torch.abs(yo-network.y) > network.threshold_for_error+0.001, as_tuple =False)\n",
    "\n",
    "    ## Print out the undesired_index for debug\n",
    "    print(\"不滿足個數：\",undesired_index.shape[0])\n",
    "    print(\"The index of the undesired data:\",undesired_index)\n",
    "\n",
    "    \n",
    "    if undesired_index.shape[0] == 1:\n",
    "        \n",
    "        # Unsatisfied situation\n",
    "        ## Find the index of the unsatisfied data\n",
    "        k_data_num = undesired_index[0][0]\n",
    "\n",
    "        undesired_data = torch.reshape(network.x[k_data_num,:], [1,-1])\n",
    "\n",
    "        ## Remove the data that does not meet the error term\n",
    "        left_data = network.x[:k_data_num,:]\n",
    "        right_data = network.x[k_data_num+1:,:]\n",
    "        remain_tensor = torch.cat([left_data, right_data], 0)\n",
    "\n",
    "\n",
    "        ## Use the random method to find out the gamma and zeta\n",
    "        while True:\n",
    "\n",
    "            ## Find m-vector gamma: r\n",
    "            ## Use the random method to generate the gamma that can make the conditions met\n",
    "            gamma = torch.rand(size=[1,network.x.shape[1]]).cuda()\n",
    "            subtract_undesired_data = torch.sub(remain_tensor, undesired_data)\n",
    "            matmul_value = torch.mm(gamma,torch.t(subtract_undesired_data))\n",
    "\n",
    "            if torch.all(matmul_value != 0):\n",
    "                break\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## Find the tiny value: zeta\n",
    "            ## Use the random method to generate the zeta that can make the conditions met\n",
    "            zeta = torch.rand(size=[1]).cuda()\n",
    "\n",
    "            if torch.all(torch.mul(torch.add(zeta,matmul_value),torch.sub(zeta,matmul_value))<0):\n",
    "                break\n",
    "\n",
    "       \n",
    "\n",
    "        k_l = undesired_index[0][1]\n",
    "        \n",
    "        ## The weight of input layer to hidden layer I\n",
    "        w10 = gamma\n",
    "        w11 = gamma\n",
    "        w12 = gamma\n",
    "\n",
    "        W1_new = torch.cat([w10,w11,w12],0)\n",
    "        \n",
    "\n",
    "        ## The bias of input layer to hidden layer I\n",
    "        matual_value = torch.mm(gamma,torch.t(undesired_data))\n",
    "       \n",
    "        \n",
    "        b10 = torch.sub(zeta,matual_value)\n",
    "        b11 = -1*matual_value\n",
    "        b12 = torch.sub(-1*zeta,matual_value)\n",
    "\n",
    "        b1_new = torch.reshape(torch.cat([b10,b11,b12],0),[3])\n",
    "        \n",
    "#         print(\"b1_new\",b1_new)\n",
    "\n",
    "\n",
    "        ## The weight of hidden layer I to output layer\n",
    "        gap = network.y[k_data_num, k_l]-yo[k_data_num, k_l]\n",
    "#         print(\"gap:\",gap)\n",
    "\n",
    "        wo0_value = gap/zeta\n",
    "        wo1_value = (-2*gap)/zeta\n",
    "        wo2_value = gap/zeta\n",
    "\n",
    "        Wo_new = torch.reshape(torch.cat([wo0_value,wo1_value,wo2_value],0),[1,-1])\n",
    "\n",
    "        ## Add new neuroes to the network\n",
    "        network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight.data, W1_new]))\n",
    "        network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias.data, b1_new]))\n",
    "        network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight.data, Wo_new],1))\n",
    "\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        \n",
    "        ## Determine if cramming is successful and print out the corresponding information\n",
    "        if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            network.acceptable = True \n",
    "            print(\"Cramming success!\")\n",
    "\n",
    "        else:\n",
    "            print(\"Cramming failed!\")\n",
    "    \n",
    "    else:\n",
    "        print(\"條件不合，不能Cramming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizing(network):\n",
    "\n",
    "    print(\"<<Regularizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Record the number of executions\n",
    "    times_enlarge = 0\n",
    "    times_shrink = 0\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "\n",
    "    ## Set epoch to 0\n",
    "    for i in range(0):\n",
    "\n",
    "        ## Store the parameter of the network\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"調整前的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "        \n",
    "        ## Backward operation to obtain w'\n",
    "        network.backward_Adadelta(loss)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "#         print(\"調整後的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "         # Confirm whether the adjusted loss value is smaller than the current one\n",
    "        if loss <= loss_pre:\n",
    "            \n",
    "            ## Identify that all forecast value has met the error term\n",
    "            if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "                \n",
    "                ## If true, multiply the learning rate by 1.2\n",
    "#                 print(\"*1.2\")\n",
    "                network.learning_rate *= 1.2\n",
    "                times_enlarge += 1\n",
    "#                 print(\"Regularizing %d process - Enlarge\"%i)\n",
    "#                 print(\"第\\\"%d\\\"回合是成功執行regularizing\"%(i+1))\n",
    "#                 print(\"差異\")\n",
    "#                 print(torch.abs(yo-network.y))\n",
    "\n",
    "            else:\n",
    "\n",
    "                ## Else, restore w and end the process\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-因為沒有顧好預測誤差\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Unable to meet the error term\")\n",
    "                return(network)\n",
    "\n",
    "        # If the adjusted loss value is not smaller than the current one\n",
    "        else:\n",
    "\n",
    "            ## If the learning rate is greater than the threshold for learning rate\n",
    "            if network.learning_rate > network.threshold_for_lr:\n",
    "                \n",
    "                ## Restore the w and multiply the learning rate by 0.7\n",
    "                network = copy.deepcopy(network_pre)\n",
    "#                 print(\"*0.7\")\n",
    "                network.learning_rate *= 0.7\n",
    "                times_shrink += 1\n",
    "#                 print(\"把Learning rate變小\")\n",
    "#                 print(\"Regularizing %d process - Shrink\"%i)\n",
    "             ## If the learning rate is smaller than the threshold for learning rate\n",
    "            else:\n",
    "                \n",
    "                ## Restore the w\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-Learning不能這麼小\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Less than the epsilon for the learning rate\")\n",
    "                return(network)\n",
    "\n",
    "    print(\"第\\\"%d\\\"回合Regularizing module完畢\"%(i+1))\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganizing(network):\n",
    "    print(\"<<Reorganizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    limit = 4\n",
    "    if network.linear1.bias.shape[0] <= limit:\n",
    "#         network = regularizing(network)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        ## Set up the k = 1, and p = the number of hidden node\n",
    "        k = 1\n",
    "    #     p = network.W1.shape[1]\n",
    "        p = network.linear1.weight.data.shape[0]\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## If k > p, end of Process\n",
    "            if k > p or p<=limit:\n",
    "\n",
    "                print(\"Reorganizing result: The final number of neuro is \",p)\n",
    "                return(network)\n",
    "\n",
    "            ## Else, Process is ongoing\n",
    "            else:\n",
    "\n",
    "                ## Using the regularizing module to adjust the network\n",
    "#                 network = regularizing(network)\n",
    "\n",
    "                ## Store the network and w\n",
    "                network_pre = copy.deepcopy(network)\n",
    "\n",
    "                ## Set up the acceptable of the network as false\n",
    "                network.acceptable = False\n",
    "                \n",
    "            \n",
    "                ## Ignore the K hidden node\n",
    "                network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight[:k-1],network.linear1.weight[k:]],0))\n",
    "                network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias[:k-1],network.linear1.bias[k:]]))\n",
    "                network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight[:,:k-1],network.linear2.weight[:,k:]],1))\n",
    "\n",
    "                \n",
    "                ## Using the matching module to adjust the network\n",
    "                network = matching_for_reorganizing(network)\n",
    "\n",
    "                print(\"是不是可以不要這個hidden node:\",network.acceptable)\n",
    "\n",
    "                ## If the resulting network is acceptable, this means that the k hidden node can be removed\n",
    "                if network.acceptable:\n",
    "\n",
    "                    print(\"Drop out the nero number: %d / %d\" %(k, p))\n",
    "                    network.nb_node_pruned += 1\n",
    "                    ## p--\n",
    "                    p-=1\n",
    "\n",
    "                ## Else, it means that the k hidden node cannot be removed\n",
    "                else:\n",
    "\n",
    "                    ## Restore the network and w\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    print(\"Cannot drop out the nero number: %d / %d\" %(k, p))\n",
    "\n",
    "                    ## k++\n",
    "                    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The <<1>> Block\n",
      "初始值 torch.Size([20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing module\n",
      "<<Initializing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "現在訓練到第幾筆資料: 20\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49] 數值 torch.Size([20, 1])\n",
      "目前模型的Data狀態 torch.Size([20, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.2917094230651855\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 21\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56] 數值 torch.Size([21, 1])\n",
      "目前模型的Data狀態 torch.Size([21, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.3544676303863525\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 22\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97] 數值 torch.Size([22, 1])\n",
      "目前模型的Data狀態 torch.Size([22, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.418060302734375\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 23\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27] 數值 torch.Size([23, 1])\n",
      "目前模型的Data狀態 torch.Size([23, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.4830634593963623\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 24\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57] 數值 torch.Size([24, 1])\n",
      "目前模型的Data狀態 torch.Size([24, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.5467886924743652\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 25\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55] 數值 torch.Size([25, 1])\n",
      "目前模型的Data狀態 torch.Size([25, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.6108791828155518\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 26\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34] 數值 torch.Size([26, 1])\n",
      "目前模型的Data狀態 torch.Size([26, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.6752853393554688\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 27\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36] 數值 torch.Size([27, 1])\n",
      "目前模型的Data狀態 torch.Size([27, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.7398762702941895\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 28\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35] 數值 torch.Size([28, 1])\n",
      "目前模型的Data狀態 torch.Size([28, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.8042330741882324\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 29\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33] 數值 torch.Size([29, 1])\n",
      "目前模型的Data狀態 torch.Size([29, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.8683981895446777\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 30\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28] 數值 torch.Size([30, 1])\n",
      "目前模型的Data狀態 torch.Size([30, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.9346134662628174\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 31\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98] 數值 torch.Size([31, 1])\n",
      "目前模型的Data狀態 torch.Size([31, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(    0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.9998722076416016\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 32\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78] 數值 torch.Size([32, 1])\n",
      "目前模型的Data狀態 torch.Size([32, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.0656137466430664\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 33\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37] 數值 torch.Size([33, 1])\n",
      "目前模型的Data狀態 torch.Size([33, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.1316323280334473\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 34\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99] 數值 torch.Size([34, 1])\n",
      "目前模型的Data狀態 torch.Size([34, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.1968321800231934\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 35\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53] 數值 torch.Size([35, 1])\n",
      "目前模型的Data狀態 torch.Size([35, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.262054443359375\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 36\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32] 數值 torch.Size([36, 1])\n",
      "目前模型的Data狀態 torch.Size([36, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.328385591506958\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 37\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62] 數值 torch.Size([37, 1])\n",
      "目前模型的Data狀態 torch.Size([37, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.394728422164917\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 38\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47] 數值 torch.Size([38, 1])\n",
      "目前模型的Data狀態 torch.Size([38, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.4599997997283936\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 39\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26] 數值 torch.Size([39, 1])\n",
      "目前模型的Data狀態 torch.Size([39, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.5254476070404053\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 40\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63] 數值 torch.Size([40, 1])\n",
      "目前模型的Data狀態 torch.Size([40, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.59233021736145\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 41\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48] 數值 torch.Size([41, 1])\n",
      "目前模型的Data狀態 torch.Size([41, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.6583425998687744\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 42\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101] 數值 torch.Size([42, 1])\n",
      "目前模型的Data狀態 torch.Size([42, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.7242865562438965\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 43\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61] 數值 torch.Size([43, 1])\n",
      "目前模型的Data狀態 torch.Size([43, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.7914037704467773\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 44\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30] 數值 torch.Size([44, 1])\n",
      "目前模型的Data狀態 torch.Size([44, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.8583600521087646\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 45\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29] 數值 torch.Size([45, 1])\n",
      "目前模型的Data狀態 torch.Size([45, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.9253201484680176\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 46\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100] 數值 torch.Size([46, 1])\n",
      "目前模型的Data狀態 torch.Size([46, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.9927656650543213\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 47\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52] 數值 torch.Size([47, 1])\n",
      "目前模型的Data狀態 torch.Size([47, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.059941291809082\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 48\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51] 數值 torch.Size([48, 1])\n",
      "目前模型的Data狀態 torch.Size([48, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.1268749237060547\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 49\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54] 數值 torch.Size([49, 1])\n",
      "目前模型的Data狀態 torch.Size([49, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.195371150970459\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 50\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58] 數值 torch.Size([50, 1])\n",
      "目前模型的Data狀態 torch.Size([50, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.262935161590576\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 51\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24] 數值 torch.Size([51, 1])\n",
      "目前模型的Data狀態 torch.Size([51, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.330092668533325\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 52\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70] 數值 torch.Size([52, 1])\n",
      "目前模型的Data狀態 torch.Size([52, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.398404359817505\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 53\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31] 數值 torch.Size([53, 1])\n",
      "目前模型的Data狀態 torch.Size([53, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.4662530422210693\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 54\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67] 數值 torch.Size([54, 1])\n",
      "目前模型的Data狀態 torch.Size([54, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.5342557430267334\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 55\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85] 數值 torch.Size([55, 1])\n",
      "目前模型的Data狀態 torch.Size([55, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.603581666946411\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 56\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71] 數值 torch.Size([56, 1])\n",
      "目前模型的Data狀態 torch.Size([56, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.67169189453125\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 57\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25] 數值 torch.Size([57, 1])\n",
      "目前模型的Data狀態 torch.Size([57, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.7402429580688477\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 58\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102] 數值 torch.Size([58, 1])\n",
      "目前模型的Data狀態 torch.Size([58, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.809617519378662\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 59\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103] 數值 torch.Size([59, 1])\n",
      "目前模型的Data狀態 torch.Size([59, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.8781349658966064\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 60\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46] 數值 torch.Size([60, 1])\n",
      "目前模型的Data狀態 torch.Size([60, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.9465951919555664\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 61\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50] 數值 torch.Size([61, 1])\n",
      "目前模型的Data狀態 torch.Size([61, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.016645669937134\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 62\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0] 數值 torch.Size([62, 1])\n",
      "目前模型的Data狀態 torch.Size([62, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.086156129837036\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 63\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64] 數值 torch.Size([63, 1])\n",
      "目前模型的Data狀態 torch.Size([63, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.1557512283325195\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 64\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60] 數值 torch.Size([64, 1])\n",
      "目前模型的Data狀態 torch.Size([64, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.225924015045166\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 65\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59] 數值 torch.Size([65, 1])\n",
      "目前模型的Data狀態 torch.Size([65, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.295565128326416\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 66\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23] 數值 torch.Size([66, 1])\n",
      "目前模型的Data狀態 torch.Size([66, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.365134000778198\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 67\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1] 數值 torch.Size([67, 1])\n",
      "目前模型的Data狀態 torch.Size([67, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.435583591461182\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 68\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68] 數值 torch.Size([68, 1])\n",
      "目前模型的Data狀態 torch.Size([68, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.505757570266724\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 69\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65] 數值 torch.Size([69, 1])\n",
      "目前模型的Data狀態 torch.Size([69, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.576012849807739\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 70\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83] 數值 torch.Size([70, 1])\n",
      "目前模型的Data狀態 torch.Size([70, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.6474363803863525\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 71\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22] 數值 torch.Size([71, 1])\n",
      "目前模型的Data狀態 torch.Size([71, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.717667818069458\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 72\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104] 數值 torch.Size([72, 1])\n",
      "目前模型的Data狀態 torch.Size([72, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.788123607635498\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 73\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66] 數值 torch.Size([73, 1])\n",
      "目前模型的Data狀態 torch.Size([73, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.859795093536377\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 74\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38] 數值 torch.Size([74, 1])\n",
      "目前模型的Data狀態 torch.Size([74, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.9303319454193115\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 75\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2] 數值 torch.Size([75, 1])\n",
      "目前模型的Data狀態 torch.Size([75, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.001227617263794\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 76\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106] 數值 torch.Size([76, 1])\n",
      "目前模型的Data狀態 torch.Size([76, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.073295593261719\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 77\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3] 數值 torch.Size([77, 1])\n",
      "目前模型的Data狀態 torch.Size([77, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.144341230392456\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 78\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41] 數值 torch.Size([78, 1])\n",
      "目前模型的Data狀態 torch.Size([78, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.215479373931885\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 79\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107] 數值 torch.Size([79, 1])\n",
      "目前模型的Data狀態 torch.Size([79, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.287047624588013\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 80\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21] 數值 torch.Size([80, 1])\n",
      "目前模型的Data狀態 torch.Size([80, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.358785390853882\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 81\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80] 數值 torch.Size([81, 1])\n",
      "目前模型的Data狀態 torch.Size([81, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.430878639221191\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 82\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108] 數值 torch.Size([82, 1])\n",
      "目前模型的Data狀態 torch.Size([82, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.503741264343262\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 83\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44] 數值 torch.Size([83, 1])\n",
      "目前模型的Data狀態 torch.Size([83, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.575717926025391\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 84\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42] 數值 torch.Size([84, 1])\n",
      "目前模型的Data狀態 torch.Size([84, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.648107528686523\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 85\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105] 數值 torch.Size([85, 1])\n",
      "目前模型的Data狀態 torch.Size([85, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.721282482147217\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 86\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82] 數值 torch.Size([86, 1])\n",
      "目前模型的Data狀態 torch.Size([86, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.793673515319824\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 87\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84] 數值 torch.Size([87, 1])\n",
      "目前模型的Data狀態 torch.Size([87, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.865652561187744\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 88\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81] 數值 torch.Size([88, 1])\n",
      "目前模型的Data狀態 torch.Size([88, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.939344644546509\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 89\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17] 數值 torch.Size([89, 1])\n",
      "目前模型的Data狀態 torch.Size([89, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.012258052825928\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 90\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39] 數值 torch.Size([90, 1])\n",
      "目前模型的Data狀態 torch.Size([90, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.085195064544678\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 91\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40] 數值 torch.Size([91, 1])\n",
      "目前模型的Data狀態 torch.Size([91, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.158968925476074\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 92\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43] 數值 torch.Size([92, 1])\n",
      "目前模型的Data狀態 torch.Size([92, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.231560230255127\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 93\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8] 數值 torch.Size([93, 1])\n",
      "目前模型的Data狀態 torch.Size([93, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.304863452911377\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 94\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9] 數值 torch.Size([94, 1])\n",
      "目前模型的Data狀態 torch.Size([94, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.37915301322937\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 95\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109] 數值 torch.Size([95, 1])\n",
      "目前模型的Data狀態 torch.Size([95, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.45275092124939\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 96\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18] 數值 torch.Size([96, 1])\n",
      "目前模型的Data狀態 torch.Size([96, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.526774168014526\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 97\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20] 數值 torch.Size([97, 1])\n",
      "目前模型的Data狀態 torch.Size([97, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.601890563964844\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 98\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4] 數值 torch.Size([98, 1])\n",
      "目前模型的Data狀態 torch.Size([98, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.675366163253784\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 99\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19] 數值 torch.Size([99, 1])\n",
      "目前模型的Data狀態 torch.Size([99, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.748903036117554\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 100\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16] 數值 torch.Size([100, 1])\n",
      "目前模型的Data狀態 torch.Size([100, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.8250768184661865\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 101\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7] 數值 torch.Size([101, 1])\n",
      "目前模型的Data狀態 torch.Size([101, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.899319171905518\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 102\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15] 數值 torch.Size([102, 1])\n",
      "目前模型的Data狀態 torch.Size([102, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.973714590072632\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 103\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10] 數值 torch.Size([103, 1])\n",
      "目前模型的Data狀態 torch.Size([103, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.049311876296997\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 104\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11] 數值 torch.Size([104, 1])\n",
      "目前模型的Data狀態 torch.Size([104, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.124011516571045\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 105\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14] 數值 torch.Size([105, 1])\n",
      "目前模型的Data狀態 torch.Size([105, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.198715686798096\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 106\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110] 數值 torch.Size([106, 1])\n",
      "目前模型的Data狀態 torch.Size([106, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.274209260940552\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 107\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6] 數值 torch.Size([107, 1])\n",
      "目前模型的Data狀態 torch.Size([107, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.3491270542144775\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 108\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79] 數值 torch.Size([108, 1])\n",
      "目前模型的Data狀態 torch.Size([108, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.42429256439209\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 109\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79, 13] 數值 torch.Size([109, 1])\n",
      "目前模型的Data狀態 torch.Size([109, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482],\n",
      "        [0.6941]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.5004847049713135\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 110\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79, 13, 112] 數值 torch.Size([110, 1])\n",
      "目前模型的Data狀態 torch.Size([110, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482],\n",
      "        [0.6941],\n",
      "        [0.9269]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.576246023178101\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 111\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79, 13, 112, 5] 數值 torch.Size([111, 1])\n",
      "目前模型的Data狀態 torch.Size([111, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482],\n",
      "        [0.6941],\n",
      "        [0.9269],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.6517205238342285\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 112\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79, 13, 112, 5, 125] 數值 torch.Size([112, 1])\n",
      "目前模型的Data狀態 torch.Size([112, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482],\n",
      "        [0.6941],\n",
      "        [0.9269],\n",
      "        [0.6914],\n",
      "        [0.9177]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.7287538051605225\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 113\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79, 13, 112, 5, 125, 130] 數值 torch.Size([113, 1])\n",
      "目前模型的Data狀態 torch.Size([113, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482],\n",
      "        [0.6941],\n",
      "        [0.9269],\n",
      "        [0.6914],\n",
      "        [0.9177],\n",
      "        [0.8807]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938],\n",
      "        [    0.3000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938],\n",
      "        [    0.3000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.804614782333374\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 114\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79, 13, 112, 5, 125, 130, 111] 數值 torch.Size([114, 1])\n",
      "目前模型的Data狀態 torch.Size([114, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482],\n",
      "        [0.6941],\n",
      "        [0.9269],\n",
      "        [0.6914],\n",
      "        [0.9177],\n",
      "        [0.8807],\n",
      "        [0.9479]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938],\n",
      "        [    0.3000],\n",
      "        [    0.3026]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938],\n",
      "        [    0.3000],\n",
      "        [    0.3026]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.8807525634765625\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 115\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79, 13, 112, 5, 125, 130, 111, 12] 數值 torch.Size([115, 1])\n",
      "目前模型的Data狀態 torch.Size([115, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482],\n",
      "        [0.6941],\n",
      "        [0.9269],\n",
      "        [0.6914],\n",
      "        [0.9177],\n",
      "        [0.8807],\n",
      "        [0.9479],\n",
      "        [0.6914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938],\n",
      "        [    0.3000],\n",
      "        [    0.3026],\n",
      "        [    0.3058]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938],\n",
      "        [    0.3000],\n",
      "        [    0.3026],\n",
      "        [    0.3058]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.957886219024658\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 116\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 72)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [72, 91, 93, 75, 87, 90, 94, 95, 73, 76, 86, 88, 92, 45, 69, 74, 77, 89, 96, 49, 56, 97, 27, 57, 55, 34, 36, 35, 33, 28, 98, 78, 37, 99, 53, 32, 62, 47, 26, 63, 48, 101, 61, 30, 29, 100, 52, 51, 54, 58, 24, 70, 31, 67, 85, 71, 25, 102, 103, 46, 50, 0, 64, 60, 59, 23, 1, 68, 65, 83, 22, 104, 66, 38, 2, 106, 3, 41, 107, 21, 80, 108, 44, 42, 105, 82, 84, 81, 17, 39, 40, 43, 8, 9, 109, 18, 20, 4, 19, 16, 7, 15, 10, 11, 14, 110, 6, 79, 13, 112, 5, 125, 130, 111, 12, 126] 數值 torch.Size([116, 1])\n",
      "目前模型的Data狀態 torch.Size([116, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.7461],\n",
      "        [0.6914],\n",
      "        [0.7161],\n",
      "        [0.7463],\n",
      "        [0.7355],\n",
      "        [0.7034],\n",
      "        [0.7078],\n",
      "        [0.7050],\n",
      "        [0.7455],\n",
      "        [0.7586],\n",
      "        [0.7168],\n",
      "        [0.7342],\n",
      "        [0.7056],\n",
      "        [0.7079],\n",
      "        [0.7038],\n",
      "        [0.7606],\n",
      "        [0.7218],\n",
      "        [0.7118],\n",
      "        [0.6950],\n",
      "        [0.8462],\n",
      "        [0.8996],\n",
      "        [0.6914],\n",
      "        [0.8130],\n",
      "        [0.9105],\n",
      "        [0.8993],\n",
      "        [0.8284],\n",
      "        [0.8582],\n",
      "        [0.8228],\n",
      "        [0.8020],\n",
      "        [0.8284],\n",
      "        [0.7029],\n",
      "        [0.6914],\n",
      "        [0.8347],\n",
      "        [0.6914],\n",
      "        [0.9005],\n",
      "        [0.7756],\n",
      "        [0.8467],\n",
      "        [0.7898],\n",
      "        [0.7899],\n",
      "        [0.8197],\n",
      "        [0.8042],\n",
      "        [0.6914],\n",
      "        [0.8707],\n",
      "        [0.9011],\n",
      "        [0.8826],\n",
      "        [0.6914],\n",
      "        [0.9396],\n",
      "        [0.9594],\n",
      "        [0.9558],\n",
      "        [0.8664],\n",
      "        [0.7217],\n",
      "        [0.7226],\n",
      "        [0.8778],\n",
      "        [0.7189],\n",
      "        [0.7365],\n",
      "        [0.7346],\n",
      "        [0.7290],\n",
      "        [0.7227],\n",
      "        [0.7448],\n",
      "        [0.7538],\n",
      "        [0.9899],\n",
      "        [0.6914],\n",
      "        [0.7609],\n",
      "        [0.8399],\n",
      "        [0.8432],\n",
      "        [0.7249],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6963],\n",
      "        [0.7958],\n",
      "        [0.7134],\n",
      "        [0.8024],\n",
      "        [0.6914],\n",
      "        [0.8032],\n",
      "        [0.6914],\n",
      "        [0.8489],\n",
      "        [0.6914],\n",
      "        [0.8081],\n",
      "        [0.8515],\n",
      "        [0.6914],\n",
      "        [0.7844],\n",
      "        [0.8540],\n",
      "        [0.7300],\n",
      "        [0.7949],\n",
      "        [0.8537],\n",
      "        [0.8114],\n",
      "        [0.8117],\n",
      "        [0.8078],\n",
      "        [0.6914],\n",
      "        [0.8023],\n",
      "        [0.7699],\n",
      "        [0.7465],\n",
      "        [0.7693],\n",
      "        [0.7586],\n",
      "        [0.8935],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.6914],\n",
      "        [0.7466],\n",
      "        [0.7069],\n",
      "        [0.7305],\n",
      "        [0.7109],\n",
      "        [0.7061],\n",
      "        [0.9192],\n",
      "        [0.6959],\n",
      "        [0.7482],\n",
      "        [0.6941],\n",
      "        [0.9269],\n",
      "        [0.6914],\n",
      "        [0.9177],\n",
      "        [0.8807],\n",
      "        [0.9479],\n",
      "        [0.6914],\n",
      "        [0.9310]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0062],\n",
      "        [    0.0063],\n",
      "        [    0.0079],\n",
      "        [    0.0094],\n",
      "        [    0.0094],\n",
      "        [    0.0103],\n",
      "        [    0.0140],\n",
      "        [    0.0156],\n",
      "        [    0.0172],\n",
      "        [    0.0180],\n",
      "        [    0.0208],\n",
      "        [    0.0257],\n",
      "        [    0.0284],\n",
      "        [    0.0288],\n",
      "        [    0.0317],\n",
      "        [    0.0331],\n",
      "        [    0.0338],\n",
      "        [    0.0366],\n",
      "        [    0.0399],\n",
      "        [    0.0417],\n",
      "        [    0.0419],\n",
      "        [    0.0421],\n",
      "        [    0.0440],\n",
      "        [    0.0496],\n",
      "        [    0.0515],\n",
      "        [    0.0531],\n",
      "        [    0.0561],\n",
      "        [    0.0561],\n",
      "        [    0.0616],\n",
      "        [    0.0632],\n",
      "        [    0.0690],\n",
      "        [    0.0712],\n",
      "        [    0.0734],\n",
      "        [    0.0735],\n",
      "        [    0.0747],\n",
      "        [    0.0754],\n",
      "        [    0.0761],\n",
      "        [    0.0776],\n",
      "        [    0.0815],\n",
      "        [    0.0857],\n",
      "        [    0.0894],\n",
      "        [    0.1007],\n",
      "        [    0.1125],\n",
      "        [    0.1134],\n",
      "        [    0.1154],\n",
      "        [    0.1162],\n",
      "        [    0.1206],\n",
      "        [    0.1221],\n",
      "        [    0.1252],\n",
      "        [    0.1393],\n",
      "        [    0.1405],\n",
      "        [    0.1413],\n",
      "        [    0.1435],\n",
      "        [    0.1441],\n",
      "        [    0.1498],\n",
      "        [    0.1507],\n",
      "        [    0.1523],\n",
      "        [    0.1533],\n",
      "        [    0.1601],\n",
      "        [    0.1607],\n",
      "        [    0.1619],\n",
      "        [    0.1631],\n",
      "        [    0.1648],\n",
      "        [    0.1718],\n",
      "        [    0.1720],\n",
      "        [    0.1742],\n",
      "        [    0.1779],\n",
      "        [    0.1881],\n",
      "        [    0.1935],\n",
      "        [    0.1975],\n",
      "        [    0.1977],\n",
      "        [    0.1986],\n",
      "        [    0.2057],\n",
      "        [    0.2073],\n",
      "        [    0.2169],\n",
      "        [    0.2215],\n",
      "        [    0.2227],\n",
      "        [    0.2245],\n",
      "        [    0.2376],\n",
      "        [    0.2452],\n",
      "        [    0.2524],\n",
      "        [    0.2528],\n",
      "        [    0.2605],\n",
      "        [    0.2622],\n",
      "        [    0.2681],\n",
      "        [    0.2739],\n",
      "        [    0.2776],\n",
      "        [    0.2788],\n",
      "        [    0.2870],\n",
      "        [    0.2893],\n",
      "        [    0.2905],\n",
      "        [    0.2907],\n",
      "        [    0.2938],\n",
      "        [    0.3000],\n",
      "        [    0.3026],\n",
      "        [    0.3058],\n",
      "        [    0.3139]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.31\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.31\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 38\n",
      "Number of shrink: 0\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0165],\n",
      "        [0.0030],\n",
      "        [0.0075],\n",
      "        [0.0068],\n",
      "        [0.0138],\n",
      "        [0.0089],\n",
      "        [0.0070],\n",
      "        [0.0071],\n",
      "        [0.0147],\n",
      "        [0.0013],\n",
      "        [0.0160],\n",
      "        [0.0139],\n",
      "        [0.0112],\n",
      "        [0.0462],\n",
      "        [0.0242],\n",
      "        [0.0088],\n",
      "        [0.0008],\n",
      "        [0.0127],\n",
      "        [0.0006],\n",
      "        [0.0349],\n",
      "        [0.0301],\n",
      "        [0.0109],\n",
      "        [0.0401],\n",
      "        [0.0275],\n",
      "        [0.0240],\n",
      "        [0.0409],\n",
      "        [0.0422],\n",
      "        [0.0105],\n",
      "        [0.0112],\n",
      "        [0.0084],\n",
      "        [0.0173],\n",
      "        [0.0314],\n",
      "        [0.0022],\n",
      "        [0.0347],\n",
      "        [0.0652],\n",
      "        [0.0025],\n",
      "        [0.0055],\n",
      "        [0.0054],\n",
      "        [0.0081],\n",
      "        [0.0101],\n",
      "        [0.0051],\n",
      "        [0.0470],\n",
      "        [0.0181],\n",
      "        [0.0789],\n",
      "        [0.0810],\n",
      "        [0.0591],\n",
      "        [0.0872],\n",
      "        [0.0946],\n",
      "        [0.0958],\n",
      "        [0.0306],\n",
      "        [0.0334],\n",
      "        [0.0919],\n",
      "        [0.1016],\n",
      "        [0.0432],\n",
      "        [0.0623],\n",
      "        [0.0934],\n",
      "        [0.0409],\n",
      "        [0.0711],\n",
      "        [0.0761],\n",
      "        [0.0416],\n",
      "        [0.1355],\n",
      "        [0.1095],\n",
      "        [0.0811],\n",
      "        [0.0847],\n",
      "        [0.0832],\n",
      "        [0.0824],\n",
      "        [0.1191],\n",
      "        [0.0998],\n",
      "        [0.1080],\n",
      "        [0.1356],\n",
      "        [0.1032],\n",
      "        [0.1332],\n",
      "        [0.1115],\n",
      "        [0.1222],\n",
      "        [0.1477],\n",
      "        [0.1375],\n",
      "        [0.1502],\n",
      "        [0.1314],\n",
      "        [0.1445],\n",
      "        [0.1336],\n",
      "        [0.1621],\n",
      "        [0.1474],\n",
      "        [0.1295],\n",
      "        [0.1398],\n",
      "        [0.1620],\n",
      "        [0.1731],\n",
      "        [0.1783],\n",
      "        [0.1898],\n",
      "        [0.1945],\n",
      "        [0.1694],\n",
      "        [0.1688],\n",
      "        [0.1695],\n",
      "        [0.1735],\n",
      "        [0.1785],\n",
      "        [0.2043],\n",
      "        [0.2173],\n",
      "        [0.1885],\n",
      "        [0.2345],\n",
      "        [0.2244],\n",
      "        [0.2355],\n",
      "        [0.2169],\n",
      "        [0.2111],\n",
      "        [0.2181],\n",
      "        [0.2199],\n",
      "        [0.2223],\n",
      "        [0.2618],\n",
      "        [0.2420],\n",
      "        [0.2893],\n",
      "        [0.2371],\n",
      "        [0.2739],\n",
      "        [0.2876],\n",
      "        [0.2789],\n",
      "        [0.2944],\n",
      "        [0.2866],\n",
      "        [0.2823],\n",
      "        [0.3025]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.31335684]\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0165],\n",
      "        [0.0030],\n",
      "        [0.0075],\n",
      "        [0.0068],\n",
      "        [0.0138],\n",
      "        [0.0089],\n",
      "        [0.0070],\n",
      "        [0.0071],\n",
      "        [0.0147],\n",
      "        [0.0013],\n",
      "        [0.0160],\n",
      "        [0.0139],\n",
      "        [0.0112],\n",
      "        [0.0462],\n",
      "        [0.0242],\n",
      "        [0.0088],\n",
      "        [0.0008],\n",
      "        [0.0127],\n",
      "        [0.0006],\n",
      "        [0.0349],\n",
      "        [0.0301],\n",
      "        [0.0109],\n",
      "        [0.0401],\n",
      "        [0.0275],\n",
      "        [0.0240],\n",
      "        [0.0409],\n",
      "        [0.0422],\n",
      "        [0.0105],\n",
      "        [0.0112],\n",
      "        [0.0084],\n",
      "        [0.0173],\n",
      "        [0.0314],\n",
      "        [0.0022],\n",
      "        [0.0347],\n",
      "        [0.0652],\n",
      "        [0.0025],\n",
      "        [0.0055],\n",
      "        [0.0054],\n",
      "        [0.0081],\n",
      "        [0.0101],\n",
      "        [0.0051],\n",
      "        [0.0470],\n",
      "        [0.0181],\n",
      "        [0.0789],\n",
      "        [0.0810],\n",
      "        [0.0591],\n",
      "        [0.0872],\n",
      "        [0.0946],\n",
      "        [0.0958],\n",
      "        [0.0306],\n",
      "        [0.0334],\n",
      "        [0.0919],\n",
      "        [0.1016],\n",
      "        [0.0432],\n",
      "        [0.0623],\n",
      "        [0.0934],\n",
      "        [0.0409],\n",
      "        [0.0711],\n",
      "        [0.0761],\n",
      "        [0.0416],\n",
      "        [0.1355],\n",
      "        [0.1095],\n",
      "        [0.0811],\n",
      "        [0.0847],\n",
      "        [0.0832],\n",
      "        [0.0824],\n",
      "        [0.1191],\n",
      "        [0.0998],\n",
      "        [0.1080],\n",
      "        [0.1356],\n",
      "        [0.1032],\n",
      "        [0.1332],\n",
      "        [0.1115],\n",
      "        [0.1222],\n",
      "        [0.1477],\n",
      "        [0.1375],\n",
      "        [0.1502],\n",
      "        [0.1314],\n",
      "        [0.1445],\n",
      "        [0.1336],\n",
      "        [0.1621],\n",
      "        [0.1474],\n",
      "        [0.1295],\n",
      "        [0.1398],\n",
      "        [0.1620],\n",
      "        [0.1731],\n",
      "        [0.1783],\n",
      "        [0.1898],\n",
      "        [0.1945],\n",
      "        [0.1694],\n",
      "        [0.1688],\n",
      "        [0.1695],\n",
      "        [0.1735],\n",
      "        [0.1785],\n",
      "        [0.2043],\n",
      "        [0.2173],\n",
      "        [0.1885],\n",
      "        [0.2345],\n",
      "        [0.2244],\n",
      "        [0.2355],\n",
      "        [0.2169],\n",
      "        [0.2111],\n",
      "        [0.2181],\n",
      "        [0.2199],\n",
      "        [0.2223],\n",
      "        [0.2618],\n",
      "        [0.2420],\n",
      "        [0.2893],\n",
      "        [0.2371],\n",
      "        [0.2739],\n",
      "        [0.2876],\n",
      "        [0.2789],\n",
      "        [0.2944],\n",
      "        [0.2866],\n",
      "        [0.2823],\n",
      "        [0.3025]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.119563341140747\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 117\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (3.0866345923641347e-07, 96)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [96, 77, 76, 37, 32, 91, 48, 47, 62, 75, 94, 95, 93, 26, 28, 74, 90, 63, 35, 97, 33, 92, 89, 87, 88, 73, 86, 72, 98, 61, 55, 69, 57, 56, 58, 78, 24, 99, 49, 27, 34, 25, 46, 36, 67, 45, 101, 100, 85, 53, 102, 103, 30, 29, 64, 23, 59, 60, 52, 70, 71, 51, 54, 68, 31, 22, 65, 0, 66, 1, 38, 44, 41, 104, 21, 50, 83, 106, 42, 107, 108, 2, 3, 105, 80, 40, 39, 43, 82, 8, 84, 9, 20, 81, 17, 109, 15, 7, 18, 10, 11, 14, 19, 4, 16, 13, 6, 110, 112, 125, 12, 111, 5, 79, 130, 126, 113] 數值 torch.Size([117, 1])\n",
      "目前模型的Data狀態 torch.Size([117, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.6945],\n",
      "        [0.7225],\n",
      "        [0.7573],\n",
      "        [0.8613],\n",
      "        [0.8069],\n",
      "        [0.6945],\n",
      "        [0.8514],\n",
      "        [0.8351],\n",
      "        [0.8778],\n",
      "        [0.7531],\n",
      "        [0.7008],\n",
      "        [0.6980],\n",
      "        [0.7086],\n",
      "        [0.8234],\n",
      "        [0.8576],\n",
      "        [0.7694],\n",
      "        [0.6945],\n",
      "        [0.8516],\n",
      "        [0.8505],\n",
      "        [0.6945],\n",
      "        [0.8311],\n",
      "        [0.6945],\n",
      "        [0.6990],\n",
      "        [0.7217],\n",
      "        [0.7203],\n",
      "        [0.7602],\n",
      "        [0.7008],\n",
      "        [0.7626],\n",
      "        [0.6945],\n",
      "        [0.9022],\n",
      "        [0.9336],\n",
      "        [0.7281],\n",
      "        [0.9475],\n",
      "        [0.9360],\n",
      "        [0.9048],\n",
      "        [0.6945],\n",
      "        [0.7595],\n",
      "        [0.6945],\n",
      "        [0.8873],\n",
      "        [0.8438],\n",
      "        [0.8553],\n",
      "        [0.7656],\n",
      "        [0.8016],\n",
      "        [0.8848],\n",
      "        [0.7504],\n",
      "        [0.7541],\n",
      "        [0.6945],\n",
      "        [0.6945],\n",
      "        [0.7233],\n",
      "        [0.9326],\n",
      "        [0.7123],\n",
      "        [0.7352],\n",
      "        [0.9285],\n",
      "        [0.9105],\n",
      "        [0.7932],\n",
      "        [0.7630],\n",
      "        [0.8762],\n",
      "        [0.8705],\n",
      "        [0.9706],\n",
      "        [0.7411],\n",
      "        [0.7519],\n",
      "        [0.9924],\n",
      "        [0.9884],\n",
      "        [0.7168],\n",
      "        [0.9059],\n",
      "        [0.7516],\n",
      "        [0.7277],\n",
      "        [0.6945],\n",
      "        [0.7240],\n",
      "        [0.6945],\n",
      "        [0.8308],\n",
      "        [0.7723],\n",
      "        [0.8367],\n",
      "        [0.7921],\n",
      "        [0.7197],\n",
      "        [1.0248],\n",
      "        [0.7909],\n",
      "        [0.8341],\n",
      "        [0.8271],\n",
      "        [0.8352],\n",
      "        [0.8366],\n",
      "        [0.6945],\n",
      "        [0.6945],\n",
      "        [0.8414],\n",
      "        [0.7834],\n",
      "        [0.7996],\n",
      "        [0.8306],\n",
      "        [0.7826],\n",
      "        [0.8066],\n",
      "        [0.8031],\n",
      "        [0.8019],\n",
      "        [0.7970],\n",
      "        [0.7274],\n",
      "        [0.8041],\n",
      "        [0.6945],\n",
      "        [0.8764],\n",
      "        [0.7562],\n",
      "        [0.7825],\n",
      "        [0.6968],\n",
      "        [0.7746],\n",
      "        [0.7592],\n",
      "        [0.7577],\n",
      "        [0.7123],\n",
      "        [0.6945],\n",
      "        [0.7083],\n",
      "        [0.7463],\n",
      "        [0.7327],\n",
      "        [0.9034],\n",
      "        [0.9103],\n",
      "        [0.9028],\n",
      "        [0.7150],\n",
      "        [0.9320],\n",
      "        [0.6945],\n",
      "        [0.7504],\n",
      "        [0.8751],\n",
      "        [0.9196],\n",
      "        [0.9441]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0006],\n",
      "        [0.0008],\n",
      "        [0.0013],\n",
      "        [0.0022],\n",
      "        [0.0025],\n",
      "        [0.0030],\n",
      "        [0.0051],\n",
      "        [0.0054],\n",
      "        [0.0055],\n",
      "        [0.0068],\n",
      "        [0.0070],\n",
      "        [0.0071],\n",
      "        [0.0075],\n",
      "        [0.0081],\n",
      "        [0.0084],\n",
      "        [0.0088],\n",
      "        [0.0089],\n",
      "        [0.0101],\n",
      "        [0.0105],\n",
      "        [0.0109],\n",
      "        [0.0112],\n",
      "        [0.0112],\n",
      "        [0.0127],\n",
      "        [0.0138],\n",
      "        [0.0139],\n",
      "        [0.0147],\n",
      "        [0.0160],\n",
      "        [0.0165],\n",
      "        [0.0173],\n",
      "        [0.0181],\n",
      "        [0.0240],\n",
      "        [0.0242],\n",
      "        [0.0275],\n",
      "        [0.0301],\n",
      "        [0.0306],\n",
      "        [0.0314],\n",
      "        [0.0334],\n",
      "        [0.0347],\n",
      "        [0.0349],\n",
      "        [0.0401],\n",
      "        [0.0409],\n",
      "        [0.0409],\n",
      "        [0.0416],\n",
      "        [0.0422],\n",
      "        [0.0432],\n",
      "        [0.0462],\n",
      "        [0.0470],\n",
      "        [0.0591],\n",
      "        [0.0623],\n",
      "        [0.0652],\n",
      "        [0.0711],\n",
      "        [0.0761],\n",
      "        [0.0789],\n",
      "        [0.0810],\n",
      "        [0.0811],\n",
      "        [0.0824],\n",
      "        [0.0832],\n",
      "        [0.0847],\n",
      "        [0.0872],\n",
      "        [0.0919],\n",
      "        [0.0934],\n",
      "        [0.0946],\n",
      "        [0.0958],\n",
      "        [0.0998],\n",
      "        [0.1016],\n",
      "        [0.1032],\n",
      "        [0.1080],\n",
      "        [0.1095],\n",
      "        [0.1115],\n",
      "        [0.1191],\n",
      "        [0.1222],\n",
      "        [0.1295],\n",
      "        [0.1314],\n",
      "        [0.1332],\n",
      "        [0.1336],\n",
      "        [0.1355],\n",
      "        [0.1356],\n",
      "        [0.1375],\n",
      "        [0.1398],\n",
      "        [0.1445],\n",
      "        [0.1474],\n",
      "        [0.1477],\n",
      "        [0.1502],\n",
      "        [0.1620],\n",
      "        [0.1621],\n",
      "        [0.1688],\n",
      "        [0.1694],\n",
      "        [0.1695],\n",
      "        [0.1731],\n",
      "        [0.1735],\n",
      "        [0.1783],\n",
      "        [0.1785],\n",
      "        [0.1885],\n",
      "        [0.1898],\n",
      "        [0.1945],\n",
      "        [0.2043],\n",
      "        [0.2111],\n",
      "        [0.2169],\n",
      "        [0.2173],\n",
      "        [0.2181],\n",
      "        [0.2199],\n",
      "        [0.2223],\n",
      "        [0.2244],\n",
      "        [0.2345],\n",
      "        [0.2355],\n",
      "        [0.2371],\n",
      "        [0.2420],\n",
      "        [0.2618],\n",
      "        [0.2739],\n",
      "        [0.2789],\n",
      "        [0.2823],\n",
      "        [0.2866],\n",
      "        [0.2876],\n",
      "        [0.2893],\n",
      "        [0.2944],\n",
      "        [0.3025],\n",
      "        [0.3081]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0006],\n",
      "        [0.0008],\n",
      "        [0.0013],\n",
      "        [0.0022],\n",
      "        [0.0025],\n",
      "        [0.0030],\n",
      "        [0.0051],\n",
      "        [0.0054],\n",
      "        [0.0055],\n",
      "        [0.0068],\n",
      "        [0.0070],\n",
      "        [0.0071],\n",
      "        [0.0075],\n",
      "        [0.0081],\n",
      "        [0.0084],\n",
      "        [0.0088],\n",
      "        [0.0089],\n",
      "        [0.0101],\n",
      "        [0.0105],\n",
      "        [0.0109],\n",
      "        [0.0112],\n",
      "        [0.0112],\n",
      "        [0.0127],\n",
      "        [0.0138],\n",
      "        [0.0139],\n",
      "        [0.0147],\n",
      "        [0.0160],\n",
      "        [0.0165],\n",
      "        [0.0173],\n",
      "        [0.0181],\n",
      "        [0.0240],\n",
      "        [0.0242],\n",
      "        [0.0275],\n",
      "        [0.0301],\n",
      "        [0.0306],\n",
      "        [0.0314],\n",
      "        [0.0334],\n",
      "        [0.0347],\n",
      "        [0.0349],\n",
      "        [0.0401],\n",
      "        [0.0409],\n",
      "        [0.0409],\n",
      "        [0.0416],\n",
      "        [0.0422],\n",
      "        [0.0432],\n",
      "        [0.0462],\n",
      "        [0.0470],\n",
      "        [0.0591],\n",
      "        [0.0623],\n",
      "        [0.0652],\n",
      "        [0.0711],\n",
      "        [0.0761],\n",
      "        [0.0789],\n",
      "        [0.0810],\n",
      "        [0.0811],\n",
      "        [0.0824],\n",
      "        [0.0832],\n",
      "        [0.0847],\n",
      "        [0.0872],\n",
      "        [0.0919],\n",
      "        [0.0934],\n",
      "        [0.0946],\n",
      "        [0.0958],\n",
      "        [0.0998],\n",
      "        [0.1016],\n",
      "        [0.1032],\n",
      "        [0.1080],\n",
      "        [0.1095],\n",
      "        [0.1115],\n",
      "        [0.1191],\n",
      "        [0.1222],\n",
      "        [0.1295],\n",
      "        [0.1314],\n",
      "        [0.1332],\n",
      "        [0.1336],\n",
      "        [0.1355],\n",
      "        [0.1356],\n",
      "        [0.1375],\n",
      "        [0.1398],\n",
      "        [0.1445],\n",
      "        [0.1474],\n",
      "        [0.1477],\n",
      "        [0.1502],\n",
      "        [0.1620],\n",
      "        [0.1621],\n",
      "        [0.1688],\n",
      "        [0.1694],\n",
      "        [0.1695],\n",
      "        [0.1731],\n",
      "        [0.1735],\n",
      "        [0.1783],\n",
      "        [0.1785],\n",
      "        [0.1885],\n",
      "        [0.1898],\n",
      "        [0.1945],\n",
      "        [0.2043],\n",
      "        [0.2111],\n",
      "        [0.2169],\n",
      "        [0.2173],\n",
      "        [0.2181],\n",
      "        [0.2199],\n",
      "        [0.2223],\n",
      "        [0.2244],\n",
      "        [0.2345],\n",
      "        [0.2355],\n",
      "        [0.2371],\n",
      "        [0.2420],\n",
      "        [0.2618],\n",
      "        [0.2739],\n",
      "        [0.2789],\n",
      "        [0.2823],\n",
      "        [0.2866],\n",
      "        [0.2876],\n",
      "        [0.2893],\n",
      "        [0.2944],\n",
      "        [0.3025],\n",
      "        [0.3081]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.196669101715088\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 118\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (3.0866345923641347e-07, 96)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [96, 77, 76, 37, 32, 91, 48, 47, 62, 75, 94, 95, 93, 26, 28, 74, 90, 63, 35, 97, 33, 92, 89, 87, 88, 73, 86, 72, 98, 61, 55, 69, 57, 56, 58, 78, 24, 99, 49, 27, 34, 25, 46, 36, 67, 45, 101, 100, 85, 53, 102, 103, 30, 29, 64, 23, 59, 60, 52, 70, 71, 51, 54, 68, 31, 22, 65, 0, 66, 1, 38, 44, 41, 104, 21, 50, 83, 106, 42, 107, 108, 2, 3, 105, 80, 40, 39, 43, 82, 8, 84, 9, 20, 81, 17, 109, 15, 7, 18, 10, 11, 14, 19, 4, 16, 13, 6, 110, 112, 125, 12, 111, 5, 79, 130, 126, 113, 133] 數值 torch.Size([118, 1])\n",
      "目前模型的Data狀態 torch.Size([118, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.6945],\n",
      "        [0.7225],\n",
      "        [0.7573],\n",
      "        [0.8613],\n",
      "        [0.8069],\n",
      "        [0.6945],\n",
      "        [0.8514],\n",
      "        [0.8351],\n",
      "        [0.8778],\n",
      "        [0.7531],\n",
      "        [0.7008],\n",
      "        [0.6980],\n",
      "        [0.7086],\n",
      "        [0.8234],\n",
      "        [0.8576],\n",
      "        [0.7694],\n",
      "        [0.6945],\n",
      "        [0.8516],\n",
      "        [0.8505],\n",
      "        [0.6945],\n",
      "        [0.8311],\n",
      "        [0.6945],\n",
      "        [0.6990],\n",
      "        [0.7217],\n",
      "        [0.7203],\n",
      "        [0.7602],\n",
      "        [0.7008],\n",
      "        [0.7626],\n",
      "        [0.6945],\n",
      "        [0.9022],\n",
      "        [0.9336],\n",
      "        [0.7281],\n",
      "        [0.9475],\n",
      "        [0.9360],\n",
      "        [0.9048],\n",
      "        [0.6945],\n",
      "        [0.7595],\n",
      "        [0.6945],\n",
      "        [0.8873],\n",
      "        [0.8438],\n",
      "        [0.8553],\n",
      "        [0.7656],\n",
      "        [0.8016],\n",
      "        [0.8848],\n",
      "        [0.7504],\n",
      "        [0.7541],\n",
      "        [0.6945],\n",
      "        [0.6945],\n",
      "        [0.7233],\n",
      "        [0.9326],\n",
      "        [0.7123],\n",
      "        [0.7352],\n",
      "        [0.9285],\n",
      "        [0.9105],\n",
      "        [0.7932],\n",
      "        [0.7630],\n",
      "        [0.8762],\n",
      "        [0.8705],\n",
      "        [0.9706],\n",
      "        [0.7411],\n",
      "        [0.7519],\n",
      "        [0.9924],\n",
      "        [0.9884],\n",
      "        [0.7168],\n",
      "        [0.9059],\n",
      "        [0.7516],\n",
      "        [0.7277],\n",
      "        [0.6945],\n",
      "        [0.7240],\n",
      "        [0.6945],\n",
      "        [0.8308],\n",
      "        [0.7723],\n",
      "        [0.8367],\n",
      "        [0.7921],\n",
      "        [0.7197],\n",
      "        [1.0248],\n",
      "        [0.7909],\n",
      "        [0.8341],\n",
      "        [0.8271],\n",
      "        [0.8352],\n",
      "        [0.8366],\n",
      "        [0.6945],\n",
      "        [0.6945],\n",
      "        [0.8414],\n",
      "        [0.7834],\n",
      "        [0.7996],\n",
      "        [0.8306],\n",
      "        [0.7826],\n",
      "        [0.8066],\n",
      "        [0.8031],\n",
      "        [0.8019],\n",
      "        [0.7970],\n",
      "        [0.7274],\n",
      "        [0.8041],\n",
      "        [0.6945],\n",
      "        [0.8764],\n",
      "        [0.7562],\n",
      "        [0.7825],\n",
      "        [0.6968],\n",
      "        [0.7746],\n",
      "        [0.7592],\n",
      "        [0.7577],\n",
      "        [0.7123],\n",
      "        [0.6945],\n",
      "        [0.7083],\n",
      "        [0.7463],\n",
      "        [0.7327],\n",
      "        [0.9034],\n",
      "        [0.9103],\n",
      "        [0.9028],\n",
      "        [0.7150],\n",
      "        [0.9320],\n",
      "        [0.6945],\n",
      "        [0.7504],\n",
      "        [0.8751],\n",
      "        [0.9196],\n",
      "        [0.9441],\n",
      "        [0.9892]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0006],\n",
      "        [0.0008],\n",
      "        [0.0013],\n",
      "        [0.0022],\n",
      "        [0.0025],\n",
      "        [0.0030],\n",
      "        [0.0051],\n",
      "        [0.0054],\n",
      "        [0.0055],\n",
      "        [0.0068],\n",
      "        [0.0070],\n",
      "        [0.0071],\n",
      "        [0.0075],\n",
      "        [0.0081],\n",
      "        [0.0084],\n",
      "        [0.0088],\n",
      "        [0.0089],\n",
      "        [0.0101],\n",
      "        [0.0105],\n",
      "        [0.0109],\n",
      "        [0.0112],\n",
      "        [0.0112],\n",
      "        [0.0127],\n",
      "        [0.0138],\n",
      "        [0.0139],\n",
      "        [0.0147],\n",
      "        [0.0160],\n",
      "        [0.0165],\n",
      "        [0.0173],\n",
      "        [0.0181],\n",
      "        [0.0240],\n",
      "        [0.0242],\n",
      "        [0.0275],\n",
      "        [0.0301],\n",
      "        [0.0306],\n",
      "        [0.0314],\n",
      "        [0.0334],\n",
      "        [0.0347],\n",
      "        [0.0349],\n",
      "        [0.0401],\n",
      "        [0.0409],\n",
      "        [0.0409],\n",
      "        [0.0416],\n",
      "        [0.0422],\n",
      "        [0.0432],\n",
      "        [0.0462],\n",
      "        [0.0470],\n",
      "        [0.0591],\n",
      "        [0.0623],\n",
      "        [0.0652],\n",
      "        [0.0711],\n",
      "        [0.0761],\n",
      "        [0.0789],\n",
      "        [0.0810],\n",
      "        [0.0811],\n",
      "        [0.0824],\n",
      "        [0.0832],\n",
      "        [0.0847],\n",
      "        [0.0872],\n",
      "        [0.0919],\n",
      "        [0.0934],\n",
      "        [0.0946],\n",
      "        [0.0958],\n",
      "        [0.0998],\n",
      "        [0.1016],\n",
      "        [0.1032],\n",
      "        [0.1080],\n",
      "        [0.1095],\n",
      "        [0.1115],\n",
      "        [0.1191],\n",
      "        [0.1222],\n",
      "        [0.1295],\n",
      "        [0.1314],\n",
      "        [0.1332],\n",
      "        [0.1336],\n",
      "        [0.1355],\n",
      "        [0.1356],\n",
      "        [0.1375],\n",
      "        [0.1398],\n",
      "        [0.1445],\n",
      "        [0.1474],\n",
      "        [0.1477],\n",
      "        [0.1502],\n",
      "        [0.1620],\n",
      "        [0.1621],\n",
      "        [0.1688],\n",
      "        [0.1694],\n",
      "        [0.1695],\n",
      "        [0.1731],\n",
      "        [0.1735],\n",
      "        [0.1783],\n",
      "        [0.1785],\n",
      "        [0.1885],\n",
      "        [0.1898],\n",
      "        [0.1945],\n",
      "        [0.2043],\n",
      "        [0.2111],\n",
      "        [0.2169],\n",
      "        [0.2173],\n",
      "        [0.2181],\n",
      "        [0.2199],\n",
      "        [0.2223],\n",
      "        [0.2244],\n",
      "        [0.2345],\n",
      "        [0.2355],\n",
      "        [0.2371],\n",
      "        [0.2420],\n",
      "        [0.2618],\n",
      "        [0.2739],\n",
      "        [0.2789],\n",
      "        [0.2823],\n",
      "        [0.2866],\n",
      "        [0.2876],\n",
      "        [0.2893],\n",
      "        [0.2944],\n",
      "        [0.3025],\n",
      "        [0.3081],\n",
      "        [0.3175]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.31\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.31\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 36\n",
      "Number of shrink: 0\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0104],\n",
      "        [0.0060],\n",
      "        [0.0097],\n",
      "        [0.0082],\n",
      "        [0.0117],\n",
      "        [0.0068],\n",
      "        [0.0298],\n",
      "        [0.0292],\n",
      "        [0.0087],\n",
      "        [0.0031],\n",
      "        [0.0194],\n",
      "        [0.0196],\n",
      "        [0.0200],\n",
      "        [0.0077],\n",
      "        [0.0215],\n",
      "        [0.0069],\n",
      "        [0.0187],\n",
      "        [0.0050],\n",
      "        [0.0218],\n",
      "        [0.0011],\n",
      "        [0.0241],\n",
      "        [0.0210],\n",
      "        [0.0271],\n",
      "        [0.0309],\n",
      "        [0.0312],\n",
      "        [0.0168],\n",
      "        [0.0321],\n",
      "        [0.0203],\n",
      "        [0.0075],\n",
      "        [0.0036],\n",
      "        [0.0404],\n",
      "        [0.0339],\n",
      "        [0.0458],\n",
      "        [0.0477],\n",
      "        [0.0115],\n",
      "        [0.0216],\n",
      "        [0.0138],\n",
      "        [0.0249],\n",
      "        [0.0546],\n",
      "        [0.0541],\n",
      "        [0.0524],\n",
      "        [0.0224],\n",
      "        [0.0162],\n",
      "        [0.0527],\n",
      "        [0.0286],\n",
      "        [0.0708],\n",
      "        [0.0372],\n",
      "        [0.0493],\n",
      "        [0.0452],\n",
      "        [0.0798],\n",
      "        [0.0568],\n",
      "        [0.0622],\n",
      "        [0.0907],\n",
      "        [0.0931],\n",
      "        [0.0659],\n",
      "        [0.0626],\n",
      "        [0.0674],\n",
      "        [0.0705],\n",
      "        [0.1010],\n",
      "        [0.0971],\n",
      "        [0.0976],\n",
      "        [0.1092],\n",
      "        [0.1109],\n",
      "        [0.0877],\n",
      "        [0.1136],\n",
      "        [0.0838],\n",
      "        [0.0935],\n",
      "        [0.1193],\n",
      "        [0.0950],\n",
      "        [0.1289],\n",
      "        [0.1110],\n",
      "        [0.1071],\n",
      "        [0.1191],\n",
      "        [0.1185],\n",
      "        [0.1116],\n",
      "        [0.1511],\n",
      "        [0.1236],\n",
      "        [0.1197],\n",
      "        [0.1248],\n",
      "        [0.1258],\n",
      "        [0.1279],\n",
      "        [0.1575],\n",
      "        [0.1601],\n",
      "        [0.1460],\n",
      "        [0.1539],\n",
      "        [0.1560],\n",
      "        [0.1574],\n",
      "        [0.1512],\n",
      "        [0.1620],\n",
      "        [0.1554],\n",
      "        [0.1632],\n",
      "        [0.1565],\n",
      "        [0.1641],\n",
      "        [0.1796],\n",
      "        [0.1775],\n",
      "        [0.1850],\n",
      "        [0.1832],\n",
      "        [0.1976],\n",
      "        [0.1901],\n",
      "        [0.1922],\n",
      "        [0.1914],\n",
      "        [0.1931],\n",
      "        [0.1977],\n",
      "        [0.2443],\n",
      "        [0.2057],\n",
      "        [0.2069],\n",
      "        [0.2223],\n",
      "        [0.2432],\n",
      "        [0.2545],\n",
      "        [0.2597],\n",
      "        [0.2514],\n",
      "        [0.2679],\n",
      "        [0.2975],\n",
      "        [0.2833],\n",
      "        [0.2820],\n",
      "        [0.2854],\n",
      "        [0.2887],\n",
      "        [0.3068]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.31335684]\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0104],\n",
      "        [0.0060],\n",
      "        [0.0097],\n",
      "        [0.0082],\n",
      "        [0.0117],\n",
      "        [0.0068],\n",
      "        [0.0298],\n",
      "        [0.0292],\n",
      "        [0.0087],\n",
      "        [0.0031],\n",
      "        [0.0194],\n",
      "        [0.0196],\n",
      "        [0.0200],\n",
      "        [0.0077],\n",
      "        [0.0215],\n",
      "        [0.0069],\n",
      "        [0.0187],\n",
      "        [0.0050],\n",
      "        [0.0218],\n",
      "        [0.0011],\n",
      "        [0.0241],\n",
      "        [0.0210],\n",
      "        [0.0271],\n",
      "        [0.0309],\n",
      "        [0.0312],\n",
      "        [0.0168],\n",
      "        [0.0321],\n",
      "        [0.0203],\n",
      "        [0.0075],\n",
      "        [0.0036],\n",
      "        [0.0404],\n",
      "        [0.0339],\n",
      "        [0.0458],\n",
      "        [0.0477],\n",
      "        [0.0115],\n",
      "        [0.0216],\n",
      "        [0.0138],\n",
      "        [0.0249],\n",
      "        [0.0546],\n",
      "        [0.0541],\n",
      "        [0.0524],\n",
      "        [0.0224],\n",
      "        [0.0162],\n",
      "        [0.0527],\n",
      "        [0.0286],\n",
      "        [0.0708],\n",
      "        [0.0372],\n",
      "        [0.0493],\n",
      "        [0.0452],\n",
      "        [0.0798],\n",
      "        [0.0568],\n",
      "        [0.0622],\n",
      "        [0.0907],\n",
      "        [0.0931],\n",
      "        [0.0659],\n",
      "        [0.0626],\n",
      "        [0.0674],\n",
      "        [0.0705],\n",
      "        [0.1010],\n",
      "        [0.0971],\n",
      "        [0.0976],\n",
      "        [0.1092],\n",
      "        [0.1109],\n",
      "        [0.0877],\n",
      "        [0.1136],\n",
      "        [0.0838],\n",
      "        [0.0935],\n",
      "        [0.1193],\n",
      "        [0.0950],\n",
      "        [0.1289],\n",
      "        [0.1110],\n",
      "        [0.1071],\n",
      "        [0.1191],\n",
      "        [0.1185],\n",
      "        [0.1116],\n",
      "        [0.1511],\n",
      "        [0.1236],\n",
      "        [0.1197],\n",
      "        [0.1248],\n",
      "        [0.1258],\n",
      "        [0.1279],\n",
      "        [0.1575],\n",
      "        [0.1601],\n",
      "        [0.1460],\n",
      "        [0.1539],\n",
      "        [0.1560],\n",
      "        [0.1574],\n",
      "        [0.1512],\n",
      "        [0.1620],\n",
      "        [0.1554],\n",
      "        [0.1632],\n",
      "        [0.1565],\n",
      "        [0.1641],\n",
      "        [0.1796],\n",
      "        [0.1775],\n",
      "        [0.1850],\n",
      "        [0.1832],\n",
      "        [0.1976],\n",
      "        [0.1901],\n",
      "        [0.1922],\n",
      "        [0.1914],\n",
      "        [0.1931],\n",
      "        [0.1977],\n",
      "        [0.2443],\n",
      "        [0.2057],\n",
      "        [0.2069],\n",
      "        [0.2223],\n",
      "        [0.2432],\n",
      "        [0.2545],\n",
      "        [0.2597],\n",
      "        [0.2514],\n",
      "        [0.2679],\n",
      "        [0.2975],\n",
      "        [0.2833],\n",
      "        [0.2820],\n",
      "        [0.2854],\n",
      "        [0.2887],\n",
      "        [0.3068]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.352966785430908\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 119\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1.156200823970721e-06, 97)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [97, 75, 61, 63, 77, 91, 74, 98, 26, 37, 62, 76, 96, 58, 32, 24, 46, 73, 90, 94, 95, 93, 72, 92, 28, 78, 35, 25, 33, 99, 89, 67, 47, 48, 87, 88, 86, 69, 101, 55, 85, 57, 56, 100, 34, 36, 27, 49, 102, 103, 23, 64, 59, 60, 45, 53, 22, 68, 30, 29, 65, 66, 70, 71, 52, 44, 51, 54, 38, 21, 31, 104, 41, 0, 106, 83, 42, 107, 108, 1, 105, 50, 43, 80, 8, 40, 9, 39, 2, 3, 82, 84, 20, 17, 81, 15, 109, 18, 11, 10, 14, 7, 19, 16, 13, 6, 110, 4, 12, 112, 125, 111, 130, 79, 126, 113, 5, 131, 133] 數值 torch.Size([119, 1])\n",
      "目前模型的Data狀態 torch.Size([119, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.6846],\n",
      "        [0.7494],\n",
      "        [0.9167],\n",
      "        [0.8666],\n",
      "        [0.7158],\n",
      "        [0.6846],\n",
      "        [0.7675],\n",
      "        [0.6846],\n",
      "        [0.8392],\n",
      "        [0.8717],\n",
      "        [0.8920],\n",
      "        [0.7489],\n",
      "        [0.6846],\n",
      "        [0.9240],\n",
      "        [0.8212],\n",
      "        [0.7791],\n",
      "        [0.8271],\n",
      "        [0.7624],\n",
      "        [0.6846],\n",
      "        [0.6884],\n",
      "        [0.6854],\n",
      "        [0.6960],\n",
      "        [0.7664],\n",
      "        [0.6846],\n",
      "        [0.8707],\n",
      "        [0.6846],\n",
      "        [0.8618],\n",
      "        [0.7841],\n",
      "        [0.8441],\n",
      "        [0.6846],\n",
      "        [0.6846],\n",
      "        [0.7651],\n",
      "        [0.8588],\n",
      "        [0.8761],\n",
      "        [0.7046],\n",
      "        [0.7030],\n",
      "        [0.6846],\n",
      "        [0.7378],\n",
      "        [0.6846],\n",
      "        [0.9500],\n",
      "        [0.7063],\n",
      "        [0.9658],\n",
      "        [0.9536],\n",
      "        [0.6846],\n",
      "        [0.8669],\n",
      "        [0.8953],\n",
      "        [0.8577],\n",
      "        [0.9070],\n",
      "        [0.6979],\n",
      "        [0.7214],\n",
      "        [0.7828],\n",
      "        [0.8085],\n",
      "        [0.8920],\n",
      "        [0.8847],\n",
      "        [0.7787],\n",
      "        [0.9473],\n",
      "        [0.7710],\n",
      "        [0.7289],\n",
      "        [0.9402],\n",
      "        [0.9227],\n",
      "        [0.7422],\n",
      "        [0.7405],\n",
      "        [0.7464],\n",
      "        [0.7561],\n",
      "        [0.9844],\n",
      "        [0.7947],\n",
      "        [1.0070],\n",
      "        [1.0034],\n",
      "        [0.8420],\n",
      "        [0.7418],\n",
      "        [0.9179],\n",
      "        [0.7775],\n",
      "        [0.8491],\n",
      "        [0.6846],\n",
      "        [0.8163],\n",
      "        [0.7789],\n",
      "        [0.8422],\n",
      "        [0.8165],\n",
      "        [0.8172],\n",
      "        [0.6846],\n",
      "        [0.8254],\n",
      "        [1.0403],\n",
      "        [0.8009],\n",
      "        [0.7753],\n",
      "        [0.8213],\n",
      "        [0.8125],\n",
      "        [0.8190],\n",
      "        [0.8426],\n",
      "        [0.6846],\n",
      "        [0.6846],\n",
      "        [0.7955],\n",
      "        [0.7867],\n",
      "        [0.7518],\n",
      "        [0.7114],\n",
      "        [0.7940],\n",
      "        [0.7841],\n",
      "        [0.8570],\n",
      "        [0.7240],\n",
      "        [0.7876],\n",
      "        [0.8005],\n",
      "        [0.7870],\n",
      "        [0.8018],\n",
      "        [0.7389],\n",
      "        [0.7381],\n",
      "        [0.7764],\n",
      "        [0.7525],\n",
      "        [0.8848],\n",
      "        [0.6846],\n",
      "        [0.7459],\n",
      "        [0.8909],\n",
      "        [0.8836],\n",
      "        [0.9133],\n",
      "        [0.8626],\n",
      "        [0.7444],\n",
      "        [0.9025],\n",
      "        [0.9247],\n",
      "        [0.6846],\n",
      "        [0.9373],\n",
      "        [0.9785]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0011],\n",
      "        [0.0031],\n",
      "        [0.0036],\n",
      "        [0.0050],\n",
      "        [0.0060],\n",
      "        [0.0068],\n",
      "        [0.0069],\n",
      "        [0.0075],\n",
      "        [0.0077],\n",
      "        [0.0082],\n",
      "        [0.0087],\n",
      "        [0.0097],\n",
      "        [0.0104],\n",
      "        [0.0115],\n",
      "        [0.0117],\n",
      "        [0.0138],\n",
      "        [0.0162],\n",
      "        [0.0168],\n",
      "        [0.0187],\n",
      "        [0.0194],\n",
      "        [0.0196],\n",
      "        [0.0200],\n",
      "        [0.0203],\n",
      "        [0.0210],\n",
      "        [0.0215],\n",
      "        [0.0216],\n",
      "        [0.0218],\n",
      "        [0.0224],\n",
      "        [0.0241],\n",
      "        [0.0249],\n",
      "        [0.0271],\n",
      "        [0.0286],\n",
      "        [0.0292],\n",
      "        [0.0298],\n",
      "        [0.0309],\n",
      "        [0.0312],\n",
      "        [0.0321],\n",
      "        [0.0339],\n",
      "        [0.0372],\n",
      "        [0.0404],\n",
      "        [0.0452],\n",
      "        [0.0458],\n",
      "        [0.0477],\n",
      "        [0.0493],\n",
      "        [0.0524],\n",
      "        [0.0527],\n",
      "        [0.0541],\n",
      "        [0.0546],\n",
      "        [0.0568],\n",
      "        [0.0622],\n",
      "        [0.0626],\n",
      "        [0.0659],\n",
      "        [0.0674],\n",
      "        [0.0705],\n",
      "        [0.0708],\n",
      "        [0.0798],\n",
      "        [0.0838],\n",
      "        [0.0877],\n",
      "        [0.0907],\n",
      "        [0.0931],\n",
      "        [0.0935],\n",
      "        [0.0950],\n",
      "        [0.0971],\n",
      "        [0.0976],\n",
      "        [0.1010],\n",
      "        [0.1071],\n",
      "        [0.1092],\n",
      "        [0.1109],\n",
      "        [0.1110],\n",
      "        [0.1116],\n",
      "        [0.1136],\n",
      "        [0.1185],\n",
      "        [0.1191],\n",
      "        [0.1193],\n",
      "        [0.1197],\n",
      "        [0.1236],\n",
      "        [0.1248],\n",
      "        [0.1258],\n",
      "        [0.1279],\n",
      "        [0.1289],\n",
      "        [0.1460],\n",
      "        [0.1511],\n",
      "        [0.1512],\n",
      "        [0.1539],\n",
      "        [0.1554],\n",
      "        [0.1560],\n",
      "        [0.1565],\n",
      "        [0.1574],\n",
      "        [0.1575],\n",
      "        [0.1601],\n",
      "        [0.1620],\n",
      "        [0.1632],\n",
      "        [0.1641],\n",
      "        [0.1775],\n",
      "        [0.1796],\n",
      "        [0.1832],\n",
      "        [0.1850],\n",
      "        [0.1901],\n",
      "        [0.1914],\n",
      "        [0.1922],\n",
      "        [0.1931],\n",
      "        [0.1976],\n",
      "        [0.1977],\n",
      "        [0.2057],\n",
      "        [0.2069],\n",
      "        [0.2223],\n",
      "        [0.2432],\n",
      "        [0.2443],\n",
      "        [0.2514],\n",
      "        [0.2545],\n",
      "        [0.2597],\n",
      "        [0.2679],\n",
      "        [0.2820],\n",
      "        [0.2833],\n",
      "        [0.2854],\n",
      "        [0.2887],\n",
      "        [0.2975],\n",
      "        [0.3067],\n",
      "        [0.3068]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0011],\n",
      "        [0.0031],\n",
      "        [0.0036],\n",
      "        [0.0050],\n",
      "        [0.0060],\n",
      "        [0.0068],\n",
      "        [0.0069],\n",
      "        [0.0075],\n",
      "        [0.0077],\n",
      "        [0.0082],\n",
      "        [0.0087],\n",
      "        [0.0097],\n",
      "        [0.0104],\n",
      "        [0.0115],\n",
      "        [0.0117],\n",
      "        [0.0138],\n",
      "        [0.0162],\n",
      "        [0.0168],\n",
      "        [0.0187],\n",
      "        [0.0194],\n",
      "        [0.0196],\n",
      "        [0.0200],\n",
      "        [0.0203],\n",
      "        [0.0210],\n",
      "        [0.0215],\n",
      "        [0.0216],\n",
      "        [0.0218],\n",
      "        [0.0224],\n",
      "        [0.0241],\n",
      "        [0.0249],\n",
      "        [0.0271],\n",
      "        [0.0286],\n",
      "        [0.0292],\n",
      "        [0.0298],\n",
      "        [0.0309],\n",
      "        [0.0312],\n",
      "        [0.0321],\n",
      "        [0.0339],\n",
      "        [0.0372],\n",
      "        [0.0404],\n",
      "        [0.0452],\n",
      "        [0.0458],\n",
      "        [0.0477],\n",
      "        [0.0493],\n",
      "        [0.0524],\n",
      "        [0.0527],\n",
      "        [0.0541],\n",
      "        [0.0546],\n",
      "        [0.0568],\n",
      "        [0.0622],\n",
      "        [0.0626],\n",
      "        [0.0659],\n",
      "        [0.0674],\n",
      "        [0.0705],\n",
      "        [0.0708],\n",
      "        [0.0798],\n",
      "        [0.0838],\n",
      "        [0.0877],\n",
      "        [0.0907],\n",
      "        [0.0931],\n",
      "        [0.0935],\n",
      "        [0.0950],\n",
      "        [0.0971],\n",
      "        [0.0976],\n",
      "        [0.1010],\n",
      "        [0.1071],\n",
      "        [0.1092],\n",
      "        [0.1109],\n",
      "        [0.1110],\n",
      "        [0.1116],\n",
      "        [0.1136],\n",
      "        [0.1185],\n",
      "        [0.1191],\n",
      "        [0.1193],\n",
      "        [0.1197],\n",
      "        [0.1236],\n",
      "        [0.1248],\n",
      "        [0.1258],\n",
      "        [0.1279],\n",
      "        [0.1289],\n",
      "        [0.1460],\n",
      "        [0.1511],\n",
      "        [0.1512],\n",
      "        [0.1539],\n",
      "        [0.1554],\n",
      "        [0.1560],\n",
      "        [0.1565],\n",
      "        [0.1574],\n",
      "        [0.1575],\n",
      "        [0.1601],\n",
      "        [0.1620],\n",
      "        [0.1632],\n",
      "        [0.1641],\n",
      "        [0.1775],\n",
      "        [0.1796],\n",
      "        [0.1832],\n",
      "        [0.1850],\n",
      "        [0.1901],\n",
      "        [0.1914],\n",
      "        [0.1922],\n",
      "        [0.1931],\n",
      "        [0.1976],\n",
      "        [0.1977],\n",
      "        [0.2057],\n",
      "        [0.2069],\n",
      "        [0.2223],\n",
      "        [0.2432],\n",
      "        [0.2443],\n",
      "        [0.2514],\n",
      "        [0.2545],\n",
      "        [0.2597],\n",
      "        [0.2679],\n",
      "        [0.2820],\n",
      "        [0.2833],\n",
      "        [0.2854],\n",
      "        [0.2887],\n",
      "        [0.2975],\n",
      "        [0.3067],\n",
      "        [0.3068]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.430915117263794\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 120\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1.156200823970721e-06, 97)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [97, 75, 61, 63, 77, 91, 74, 98, 26, 37, 62, 76, 96, 58, 32, 24, 46, 73, 90, 94, 95, 93, 72, 92, 28, 78, 35, 25, 33, 99, 89, 67, 47, 48, 87, 88, 86, 69, 101, 55, 85, 57, 56, 100, 34, 36, 27, 49, 102, 103, 23, 64, 59, 60, 45, 53, 22, 68, 30, 29, 65, 66, 70, 71, 52, 44, 51, 54, 38, 21, 31, 104, 41, 0, 106, 83, 42, 107, 108, 1, 105, 50, 43, 80, 8, 40, 9, 39, 2, 3, 82, 84, 20, 17, 81, 15, 109, 18, 11, 10, 14, 7, 19, 16, 13, 6, 110, 4, 12, 112, 125, 111, 130, 79, 126, 113, 5, 131, 133, 127] 數值 torch.Size([120, 1])\n",
      "目前模型的Data狀態 torch.Size([120, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.6846],\n",
      "        [0.7494],\n",
      "        [0.9167],\n",
      "        [0.8666],\n",
      "        [0.7158],\n",
      "        [0.6846],\n",
      "        [0.7675],\n",
      "        [0.6846],\n",
      "        [0.8392],\n",
      "        [0.8717],\n",
      "        [0.8920],\n",
      "        [0.7489],\n",
      "        [0.6846],\n",
      "        [0.9240],\n",
      "        [0.8212],\n",
      "        [0.7791],\n",
      "        [0.8271],\n",
      "        [0.7624],\n",
      "        [0.6846],\n",
      "        [0.6884],\n",
      "        [0.6854],\n",
      "        [0.6960],\n",
      "        [0.7664],\n",
      "        [0.6846],\n",
      "        [0.8707],\n",
      "        [0.6846],\n",
      "        [0.8618],\n",
      "        [0.7841],\n",
      "        [0.8441],\n",
      "        [0.6846],\n",
      "        [0.6846],\n",
      "        [0.7651],\n",
      "        [0.8588],\n",
      "        [0.8761],\n",
      "        [0.7046],\n",
      "        [0.7030],\n",
      "        [0.6846],\n",
      "        [0.7378],\n",
      "        [0.6846],\n",
      "        [0.9500],\n",
      "        [0.7063],\n",
      "        [0.9658],\n",
      "        [0.9536],\n",
      "        [0.6846],\n",
      "        [0.8669],\n",
      "        [0.8953],\n",
      "        [0.8577],\n",
      "        [0.9070],\n",
      "        [0.6979],\n",
      "        [0.7214],\n",
      "        [0.7828],\n",
      "        [0.8085],\n",
      "        [0.8920],\n",
      "        [0.8847],\n",
      "        [0.7787],\n",
      "        [0.9473],\n",
      "        [0.7710],\n",
      "        [0.7289],\n",
      "        [0.9402],\n",
      "        [0.9227],\n",
      "        [0.7422],\n",
      "        [0.7405],\n",
      "        [0.7464],\n",
      "        [0.7561],\n",
      "        [0.9844],\n",
      "        [0.7947],\n",
      "        [1.0070],\n",
      "        [1.0034],\n",
      "        [0.8420],\n",
      "        [0.7418],\n",
      "        [0.9179],\n",
      "        [0.7775],\n",
      "        [0.8491],\n",
      "        [0.6846],\n",
      "        [0.8163],\n",
      "        [0.7789],\n",
      "        [0.8422],\n",
      "        [0.8165],\n",
      "        [0.8172],\n",
      "        [0.6846],\n",
      "        [0.8254],\n",
      "        [1.0403],\n",
      "        [0.8009],\n",
      "        [0.7753],\n",
      "        [0.8213],\n",
      "        [0.8125],\n",
      "        [0.8190],\n",
      "        [0.8426],\n",
      "        [0.6846],\n",
      "        [0.6846],\n",
      "        [0.7955],\n",
      "        [0.7867],\n",
      "        [0.7518],\n",
      "        [0.7114],\n",
      "        [0.7940],\n",
      "        [0.7841],\n",
      "        [0.8570],\n",
      "        [0.7240],\n",
      "        [0.7876],\n",
      "        [0.8005],\n",
      "        [0.7870],\n",
      "        [0.8018],\n",
      "        [0.7389],\n",
      "        [0.7381],\n",
      "        [0.7764],\n",
      "        [0.7525],\n",
      "        [0.8848],\n",
      "        [0.6846],\n",
      "        [0.7459],\n",
      "        [0.8909],\n",
      "        [0.8836],\n",
      "        [0.9133],\n",
      "        [0.8626],\n",
      "        [0.7444],\n",
      "        [0.9025],\n",
      "        [0.9247],\n",
      "        [0.6846],\n",
      "        [0.9373],\n",
      "        [0.9785],\n",
      "        [0.9276]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0011],\n",
      "        [0.0031],\n",
      "        [0.0036],\n",
      "        [0.0050],\n",
      "        [0.0060],\n",
      "        [0.0068],\n",
      "        [0.0069],\n",
      "        [0.0075],\n",
      "        [0.0077],\n",
      "        [0.0082],\n",
      "        [0.0087],\n",
      "        [0.0097],\n",
      "        [0.0104],\n",
      "        [0.0115],\n",
      "        [0.0117],\n",
      "        [0.0138],\n",
      "        [0.0162],\n",
      "        [0.0168],\n",
      "        [0.0187],\n",
      "        [0.0194],\n",
      "        [0.0196],\n",
      "        [0.0200],\n",
      "        [0.0203],\n",
      "        [0.0210],\n",
      "        [0.0215],\n",
      "        [0.0216],\n",
      "        [0.0218],\n",
      "        [0.0224],\n",
      "        [0.0241],\n",
      "        [0.0249],\n",
      "        [0.0271],\n",
      "        [0.0286],\n",
      "        [0.0292],\n",
      "        [0.0298],\n",
      "        [0.0309],\n",
      "        [0.0312],\n",
      "        [0.0321],\n",
      "        [0.0339],\n",
      "        [0.0372],\n",
      "        [0.0404],\n",
      "        [0.0452],\n",
      "        [0.0458],\n",
      "        [0.0477],\n",
      "        [0.0493],\n",
      "        [0.0524],\n",
      "        [0.0527],\n",
      "        [0.0541],\n",
      "        [0.0546],\n",
      "        [0.0568],\n",
      "        [0.0622],\n",
      "        [0.0626],\n",
      "        [0.0659],\n",
      "        [0.0674],\n",
      "        [0.0705],\n",
      "        [0.0708],\n",
      "        [0.0798],\n",
      "        [0.0838],\n",
      "        [0.0877],\n",
      "        [0.0907],\n",
      "        [0.0931],\n",
      "        [0.0935],\n",
      "        [0.0950],\n",
      "        [0.0971],\n",
      "        [0.0976],\n",
      "        [0.1010],\n",
      "        [0.1071],\n",
      "        [0.1092],\n",
      "        [0.1109],\n",
      "        [0.1110],\n",
      "        [0.1116],\n",
      "        [0.1136],\n",
      "        [0.1185],\n",
      "        [0.1191],\n",
      "        [0.1193],\n",
      "        [0.1197],\n",
      "        [0.1236],\n",
      "        [0.1248],\n",
      "        [0.1258],\n",
      "        [0.1279],\n",
      "        [0.1289],\n",
      "        [0.1460],\n",
      "        [0.1511],\n",
      "        [0.1512],\n",
      "        [0.1539],\n",
      "        [0.1554],\n",
      "        [0.1560],\n",
      "        [0.1565],\n",
      "        [0.1574],\n",
      "        [0.1575],\n",
      "        [0.1601],\n",
      "        [0.1620],\n",
      "        [0.1632],\n",
      "        [0.1641],\n",
      "        [0.1775],\n",
      "        [0.1796],\n",
      "        [0.1832],\n",
      "        [0.1850],\n",
      "        [0.1901],\n",
      "        [0.1914],\n",
      "        [0.1922],\n",
      "        [0.1931],\n",
      "        [0.1976],\n",
      "        [0.1977],\n",
      "        [0.2057],\n",
      "        [0.2069],\n",
      "        [0.2223],\n",
      "        [0.2432],\n",
      "        [0.2443],\n",
      "        [0.2514],\n",
      "        [0.2545],\n",
      "        [0.2597],\n",
      "        [0.2679],\n",
      "        [0.2820],\n",
      "        [0.2833],\n",
      "        [0.2854],\n",
      "        [0.2887],\n",
      "        [0.2975],\n",
      "        [0.3067],\n",
      "        [0.3068],\n",
      "        [0.3089]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0011],\n",
      "        [0.0031],\n",
      "        [0.0036],\n",
      "        [0.0050],\n",
      "        [0.0060],\n",
      "        [0.0068],\n",
      "        [0.0069],\n",
      "        [0.0075],\n",
      "        [0.0077],\n",
      "        [0.0082],\n",
      "        [0.0087],\n",
      "        [0.0097],\n",
      "        [0.0104],\n",
      "        [0.0115],\n",
      "        [0.0117],\n",
      "        [0.0138],\n",
      "        [0.0162],\n",
      "        [0.0168],\n",
      "        [0.0187],\n",
      "        [0.0194],\n",
      "        [0.0196],\n",
      "        [0.0200],\n",
      "        [0.0203],\n",
      "        [0.0210],\n",
      "        [0.0215],\n",
      "        [0.0216],\n",
      "        [0.0218],\n",
      "        [0.0224],\n",
      "        [0.0241],\n",
      "        [0.0249],\n",
      "        [0.0271],\n",
      "        [0.0286],\n",
      "        [0.0292],\n",
      "        [0.0298],\n",
      "        [0.0309],\n",
      "        [0.0312],\n",
      "        [0.0321],\n",
      "        [0.0339],\n",
      "        [0.0372],\n",
      "        [0.0404],\n",
      "        [0.0452],\n",
      "        [0.0458],\n",
      "        [0.0477],\n",
      "        [0.0493],\n",
      "        [0.0524],\n",
      "        [0.0527],\n",
      "        [0.0541],\n",
      "        [0.0546],\n",
      "        [0.0568],\n",
      "        [0.0622],\n",
      "        [0.0626],\n",
      "        [0.0659],\n",
      "        [0.0674],\n",
      "        [0.0705],\n",
      "        [0.0708],\n",
      "        [0.0798],\n",
      "        [0.0838],\n",
      "        [0.0877],\n",
      "        [0.0907],\n",
      "        [0.0931],\n",
      "        [0.0935],\n",
      "        [0.0950],\n",
      "        [0.0971],\n",
      "        [0.0976],\n",
      "        [0.1010],\n",
      "        [0.1071],\n",
      "        [0.1092],\n",
      "        [0.1109],\n",
      "        [0.1110],\n",
      "        [0.1116],\n",
      "        [0.1136],\n",
      "        [0.1185],\n",
      "        [0.1191],\n",
      "        [0.1193],\n",
      "        [0.1197],\n",
      "        [0.1236],\n",
      "        [0.1248],\n",
      "        [0.1258],\n",
      "        [0.1279],\n",
      "        [0.1289],\n",
      "        [0.1460],\n",
      "        [0.1511],\n",
      "        [0.1512],\n",
      "        [0.1539],\n",
      "        [0.1554],\n",
      "        [0.1560],\n",
      "        [0.1565],\n",
      "        [0.1574],\n",
      "        [0.1575],\n",
      "        [0.1601],\n",
      "        [0.1620],\n",
      "        [0.1632],\n",
      "        [0.1641],\n",
      "        [0.1775],\n",
      "        [0.1796],\n",
      "        [0.1832],\n",
      "        [0.1850],\n",
      "        [0.1901],\n",
      "        [0.1914],\n",
      "        [0.1922],\n",
      "        [0.1931],\n",
      "        [0.1976],\n",
      "        [0.1977],\n",
      "        [0.2057],\n",
      "        [0.2069],\n",
      "        [0.2223],\n",
      "        [0.2432],\n",
      "        [0.2443],\n",
      "        [0.2514],\n",
      "        [0.2545],\n",
      "        [0.2597],\n",
      "        [0.2679],\n",
      "        [0.2820],\n",
      "        [0.2833],\n",
      "        [0.2854],\n",
      "        [0.2887],\n",
      "        [0.2975],\n",
      "        [0.3067],\n",
      "        [0.3068],\n",
      "        [0.3089]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.507915258407593\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 121\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1.156200823970721e-06, 97)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引: [97, 75, 61, 63, 77, 91, 74, 98, 26, 37, 62, 76, 96, 58, 32, 24, 46, 73, 90, 94, 95, 93, 72, 92, 28, 78, 35, 25, 33, 99, 89, 67, 47, 48, 87, 88, 86, 69, 101, 55, 85, 57, 56, 100, 34, 36, 27, 49, 102, 103, 23, 64, 59, 60, 45, 53, 22, 68, 30, 29, 65, 66, 70, 71, 52, 44, 51, 54, 38, 21, 31, 104, 41, 0, 106, 83, 42, 107, 108, 1, 105, 50, 43, 80, 8, 40, 9, 39, 2, 3, 82, 84, 20, 17, 81, 15, 109, 18, 11, 10, 14, 7, 19, 16, 13, 6, 110, 4, 12, 112, 125, 111, 130, 79, 126, 113, 5, 131, 133, 127, 132] 數值 torch.Size([121, 1])\n",
      "目前模型的Data狀態 torch.Size([121, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.6846],\n",
      "        [0.7494],\n",
      "        [0.9167],\n",
      "        [0.8666],\n",
      "        [0.7158],\n",
      "        [0.6846],\n",
      "        [0.7675],\n",
      "        [0.6846],\n",
      "        [0.8392],\n",
      "        [0.8717],\n",
      "        [0.8920],\n",
      "        [0.7489],\n",
      "        [0.6846],\n",
      "        [0.9240],\n",
      "        [0.8212],\n",
      "        [0.7791],\n",
      "        [0.8271],\n",
      "        [0.7624],\n",
      "        [0.6846],\n",
      "        [0.6884],\n",
      "        [0.6854],\n",
      "        [0.6960],\n",
      "        [0.7664],\n",
      "        [0.6846],\n",
      "        [0.8707],\n",
      "        [0.6846],\n",
      "        [0.8618],\n",
      "        [0.7841],\n",
      "        [0.8441],\n",
      "        [0.6846],\n",
      "        [0.6846],\n",
      "        [0.7651],\n",
      "        [0.8588],\n",
      "        [0.8761],\n",
      "        [0.7046],\n",
      "        [0.7030],\n",
      "        [0.6846],\n",
      "        [0.7378],\n",
      "        [0.6846],\n",
      "        [0.9500],\n",
      "        [0.7063],\n",
      "        [0.9658],\n",
      "        [0.9536],\n",
      "        [0.6846],\n",
      "        [0.8669],\n",
      "        [0.8953],\n",
      "        [0.8577],\n",
      "        [0.9070],\n",
      "        [0.6979],\n",
      "        [0.7214],\n",
      "        [0.7828],\n",
      "        [0.8085],\n",
      "        [0.8920],\n",
      "        [0.8847],\n",
      "        [0.7787],\n",
      "        [0.9473],\n",
      "        [0.7710],\n",
      "        [0.7289],\n",
      "        [0.9402],\n",
      "        [0.9227],\n",
      "        [0.7422],\n",
      "        [0.7405],\n",
      "        [0.7464],\n",
      "        [0.7561],\n",
      "        [0.9844],\n",
      "        [0.7947],\n",
      "        [1.0070],\n",
      "        [1.0034],\n",
      "        [0.8420],\n",
      "        [0.7418],\n",
      "        [0.9179],\n",
      "        [0.7775],\n",
      "        [0.8491],\n",
      "        [0.6846],\n",
      "        [0.8163],\n",
      "        [0.7789],\n",
      "        [0.8422],\n",
      "        [0.8165],\n",
      "        [0.8172],\n",
      "        [0.6846],\n",
      "        [0.8254],\n",
      "        [1.0403],\n",
      "        [0.8009],\n",
      "        [0.7753],\n",
      "        [0.8213],\n",
      "        [0.8125],\n",
      "        [0.8190],\n",
      "        [0.8426],\n",
      "        [0.6846],\n",
      "        [0.6846],\n",
      "        [0.7955],\n",
      "        [0.7867],\n",
      "        [0.7518],\n",
      "        [0.7114],\n",
      "        [0.7940],\n",
      "        [0.7841],\n",
      "        [0.8570],\n",
      "        [0.7240],\n",
      "        [0.7876],\n",
      "        [0.8005],\n",
      "        [0.7870],\n",
      "        [0.8018],\n",
      "        [0.7389],\n",
      "        [0.7381],\n",
      "        [0.7764],\n",
      "        [0.7525],\n",
      "        [0.8848],\n",
      "        [0.6846],\n",
      "        [0.7459],\n",
      "        [0.8909],\n",
      "        [0.8836],\n",
      "        [0.9133],\n",
      "        [0.8626],\n",
      "        [0.7444],\n",
      "        [0.9025],\n",
      "        [0.9247],\n",
      "        [0.6846],\n",
      "        [0.9373],\n",
      "        [0.9785],\n",
      "        [0.9276],\n",
      "        [0.9947]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0011],\n",
      "        [0.0031],\n",
      "        [0.0036],\n",
      "        [0.0050],\n",
      "        [0.0060],\n",
      "        [0.0068],\n",
      "        [0.0069],\n",
      "        [0.0075],\n",
      "        [0.0077],\n",
      "        [0.0082],\n",
      "        [0.0087],\n",
      "        [0.0097],\n",
      "        [0.0104],\n",
      "        [0.0115],\n",
      "        [0.0117],\n",
      "        [0.0138],\n",
      "        [0.0162],\n",
      "        [0.0168],\n",
      "        [0.0187],\n",
      "        [0.0194],\n",
      "        [0.0196],\n",
      "        [0.0200],\n",
      "        [0.0203],\n",
      "        [0.0210],\n",
      "        [0.0215],\n",
      "        [0.0216],\n",
      "        [0.0218],\n",
      "        [0.0224],\n",
      "        [0.0241],\n",
      "        [0.0249],\n",
      "        [0.0271],\n",
      "        [0.0286],\n",
      "        [0.0292],\n",
      "        [0.0298],\n",
      "        [0.0309],\n",
      "        [0.0312],\n",
      "        [0.0321],\n",
      "        [0.0339],\n",
      "        [0.0372],\n",
      "        [0.0404],\n",
      "        [0.0452],\n",
      "        [0.0458],\n",
      "        [0.0477],\n",
      "        [0.0493],\n",
      "        [0.0524],\n",
      "        [0.0527],\n",
      "        [0.0541],\n",
      "        [0.0546],\n",
      "        [0.0568],\n",
      "        [0.0622],\n",
      "        [0.0626],\n",
      "        [0.0659],\n",
      "        [0.0674],\n",
      "        [0.0705],\n",
      "        [0.0708],\n",
      "        [0.0798],\n",
      "        [0.0838],\n",
      "        [0.0877],\n",
      "        [0.0907],\n",
      "        [0.0931],\n",
      "        [0.0935],\n",
      "        [0.0950],\n",
      "        [0.0971],\n",
      "        [0.0976],\n",
      "        [0.1010],\n",
      "        [0.1071],\n",
      "        [0.1092],\n",
      "        [0.1109],\n",
      "        [0.1110],\n",
      "        [0.1116],\n",
      "        [0.1136],\n",
      "        [0.1185],\n",
      "        [0.1191],\n",
      "        [0.1193],\n",
      "        [0.1197],\n",
      "        [0.1236],\n",
      "        [0.1248],\n",
      "        [0.1258],\n",
      "        [0.1279],\n",
      "        [0.1289],\n",
      "        [0.1460],\n",
      "        [0.1511],\n",
      "        [0.1512],\n",
      "        [0.1539],\n",
      "        [0.1554],\n",
      "        [0.1560],\n",
      "        [0.1565],\n",
      "        [0.1574],\n",
      "        [0.1575],\n",
      "        [0.1601],\n",
      "        [0.1620],\n",
      "        [0.1632],\n",
      "        [0.1641],\n",
      "        [0.1775],\n",
      "        [0.1796],\n",
      "        [0.1832],\n",
      "        [0.1850],\n",
      "        [0.1901],\n",
      "        [0.1914],\n",
      "        [0.1922],\n",
      "        [0.1931],\n",
      "        [0.1976],\n",
      "        [0.1977],\n",
      "        [0.2057],\n",
      "        [0.2069],\n",
      "        [0.2223],\n",
      "        [0.2432],\n",
      "        [0.2443],\n",
      "        [0.2514],\n",
      "        [0.2545],\n",
      "        [0.2597],\n",
      "        [0.2679],\n",
      "        [0.2820],\n",
      "        [0.2833],\n",
      "        [0.2854],\n",
      "        [0.2887],\n",
      "        [0.2975],\n",
      "        [0.3067],\n",
      "        [0.3068],\n",
      "        [0.3089],\n",
      "        [0.3180]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "Loss值\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.31\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.31\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 25\n",
      "Number of shrink: 0\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0006],\n",
      "        [    0.0041],\n",
      "        [    0.0098],\n",
      "        [    0.0012],\n",
      "        [    0.0133],\n",
      "        [    0.0085],\n",
      "        [    0.0002],\n",
      "        [    0.0058],\n",
      "        [    0.0014],\n",
      "        [    0.0023],\n",
      "        [    0.0025],\n",
      "        [    0.0173],\n",
      "        [    0.0121],\n",
      "        [    0.0171],\n",
      "        [    0.0061],\n",
      "        [    0.0198],\n",
      "        [    0.0214],\n",
      "        [    0.0099],\n",
      "        [    0.0204],\n",
      "        [    0.0248],\n",
      "        [    0.0221],\n",
      "        [    0.0284],\n",
      "        [    0.0134],\n",
      "        [    0.0227],\n",
      "        [    0.0154],\n",
      "        [    0.0199],\n",
      "        [    0.0159],\n",
      "        [    0.0286],\n",
      "        [    0.0183],\n",
      "        [    0.0232],\n",
      "        [    0.0288],\n",
      "        [    0.0352],\n",
      "        [    0.0237],\n",
      "        [    0.0245],\n",
      "        [    0.0392],\n",
      "        [    0.0395],\n",
      "        [    0.0338],\n",
      "        [    0.0273],\n",
      "        [    0.0355],\n",
      "        [    0.0349],\n",
      "        [    0.0371],\n",
      "        [    0.0402],\n",
      "        [    0.0422],\n",
      "        [    0.0476],\n",
      "        [    0.0465],\n",
      "        [    0.0469],\n",
      "        [    0.0478],\n",
      "        [    0.0491],\n",
      "        [    0.0486],\n",
      "        [    0.0540],\n",
      "        [    0.0687],\n",
      "        [    0.0721],\n",
      "        [    0.0734],\n",
      "        [    0.0767],\n",
      "        [    0.0657],\n",
      "        [    0.0743],\n",
      "        [    0.0900],\n",
      "        [    0.0943],\n",
      "        [    0.0847],\n",
      "        [    0.0870],\n",
      "        [    0.1000],\n",
      "        [    0.1015],\n",
      "        [    0.0903],\n",
      "        [    0.0906],\n",
      "        [    0.0955],\n",
      "        [    0.1122],\n",
      "        [    0.1037],\n",
      "        [    0.1054],\n",
      "        [    0.1166],\n",
      "        [    0.1176],\n",
      "        [    0.1079],\n",
      "        [    0.1103],\n",
      "        [    0.1247],\n",
      "        [    0.1210],\n",
      "        [    0.1113],\n",
      "        [    0.1156],\n",
      "        [    0.1303],\n",
      "        [    0.1174],\n",
      "        [    0.1194],\n",
      "        [    0.1306],\n",
      "        [    0.1377],\n",
      "        [    0.1453],\n",
      "        [    0.1566],\n",
      "        [    0.1462],\n",
      "        [    0.1615],\n",
      "        [    0.1615],\n",
      "        [    0.1626],\n",
      "        [    0.1630],\n",
      "        [    0.1592],\n",
      "        [    0.1617],\n",
      "        [    0.1540],\n",
      "        [    0.1551],\n",
      "        [    0.1701],\n",
      "        [    0.1830],\n",
      "        [    0.1716],\n",
      "        [    0.1889],\n",
      "        [    0.1763],\n",
      "        [    0.1959],\n",
      "        [    0.1972],\n",
      "        [    0.1980],\n",
      "        [    0.1989],\n",
      "        [    0.2036],\n",
      "        [    0.2036],\n",
      "        [    0.2113],\n",
      "        [    0.2127],\n",
      "        [    0.2280],\n",
      "        [    0.2345],\n",
      "        [    0.2460],\n",
      "        [    0.2572],\n",
      "        [    0.2456],\n",
      "        [    0.2516],\n",
      "        [    0.2591],\n",
      "        [    0.2737],\n",
      "        [    0.2758],\n",
      "        [    0.2774],\n",
      "        [    0.2798],\n",
      "        [    0.2992],\n",
      "        [    0.2983],\n",
      "        [    0.2984],\n",
      "        [    0.3010],\n",
      "        [    0.3095]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.31335684]\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0006],\n",
      "        [    0.0041],\n",
      "        [    0.0098],\n",
      "        [    0.0012],\n",
      "        [    0.0133],\n",
      "        [    0.0085],\n",
      "        [    0.0002],\n",
      "        [    0.0058],\n",
      "        [    0.0014],\n",
      "        [    0.0023],\n",
      "        [    0.0025],\n",
      "        [    0.0173],\n",
      "        [    0.0121],\n",
      "        [    0.0171],\n",
      "        [    0.0061],\n",
      "        [    0.0198],\n",
      "        [    0.0214],\n",
      "        [    0.0099],\n",
      "        [    0.0204],\n",
      "        [    0.0248],\n",
      "        [    0.0221],\n",
      "        [    0.0284],\n",
      "        [    0.0134],\n",
      "        [    0.0227],\n",
      "        [    0.0154],\n",
      "        [    0.0199],\n",
      "        [    0.0159],\n",
      "        [    0.0286],\n",
      "        [    0.0183],\n",
      "        [    0.0232],\n",
      "        [    0.0288],\n",
      "        [    0.0352],\n",
      "        [    0.0237],\n",
      "        [    0.0245],\n",
      "        [    0.0392],\n",
      "        [    0.0395],\n",
      "        [    0.0338],\n",
      "        [    0.0273],\n",
      "        [    0.0355],\n",
      "        [    0.0349],\n",
      "        [    0.0371],\n",
      "        [    0.0402],\n",
      "        [    0.0422],\n",
      "        [    0.0476],\n",
      "        [    0.0465],\n",
      "        [    0.0469],\n",
      "        [    0.0478],\n",
      "        [    0.0491],\n",
      "        [    0.0486],\n",
      "        [    0.0540],\n",
      "        [    0.0687],\n",
      "        [    0.0721],\n",
      "        [    0.0734],\n",
      "        [    0.0767],\n",
      "        [    0.0657],\n",
      "        [    0.0743],\n",
      "        [    0.0900],\n",
      "        [    0.0943],\n",
      "        [    0.0847],\n",
      "        [    0.0870],\n",
      "        [    0.1000],\n",
      "        [    0.1015],\n",
      "        [    0.0903],\n",
      "        [    0.0906],\n",
      "        [    0.0955],\n",
      "        [    0.1122],\n",
      "        [    0.1037],\n",
      "        [    0.1054],\n",
      "        [    0.1166],\n",
      "        [    0.1176],\n",
      "        [    0.1079],\n",
      "        [    0.1103],\n",
      "        [    0.1247],\n",
      "        [    0.1210],\n",
      "        [    0.1113],\n",
      "        [    0.1156],\n",
      "        [    0.1303],\n",
      "        [    0.1174],\n",
      "        [    0.1194],\n",
      "        [    0.1306],\n",
      "        [    0.1377],\n",
      "        [    0.1453],\n",
      "        [    0.1566],\n",
      "        [    0.1462],\n",
      "        [    0.1615],\n",
      "        [    0.1615],\n",
      "        [    0.1626],\n",
      "        [    0.1630],\n",
      "        [    0.1592],\n",
      "        [    0.1617],\n",
      "        [    0.1540],\n",
      "        [    0.1551],\n",
      "        [    0.1701],\n",
      "        [    0.1830],\n",
      "        [    0.1716],\n",
      "        [    0.1889],\n",
      "        [    0.1763],\n",
      "        [    0.1959],\n",
      "        [    0.1972],\n",
      "        [    0.1980],\n",
      "        [    0.1989],\n",
      "        [    0.2036],\n",
      "        [    0.2036],\n",
      "        [    0.2113],\n",
      "        [    0.2127],\n",
      "        [    0.2280],\n",
      "        [    0.2345],\n",
      "        [    0.2460],\n",
      "        [    0.2572],\n",
      "        [    0.2456],\n",
      "        [    0.2516],\n",
      "        [    0.2591],\n",
      "        [    0.2737],\n",
      "        [    0.2758],\n",
      "        [    0.2774],\n",
      "        [    0.2798],\n",
      "        [    0.2992],\n",
      "        [    0.2983],\n",
      "        [    0.2984],\n",
      "        [    0.3010],\n",
      "        [    0.3095]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.31\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.644432544708252\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 122\n",
      "剩餘X 資料 torch.Size([159, 18])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-92855c169a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"剩餘Y 資料\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0msorted_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselecting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c865263a620f>\u001b[0m in \u001b[0;36mselecting\u001b[0;34m(network, x_train_scaled, y_train_scaled)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtemp_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#         print(network.state_dict())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(temp_network.y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f1e5dc14d32d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, reg_strength)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0myo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# performance measure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation_table_train = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Maximum error\",\"Minimum error\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "evaluation_table_test = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Maximum error\",\"Minimum error\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "forecasted_price = pd.DataFrame(columns=[\"Date\", \"Actual\", \"Forecasted_price\"])\n",
    "\n",
    "date, x_data, y_data= get_data(4)\n",
    "\n",
    "x_data = sc.fit_transform(x_data)\n",
    "y_data = sc.fit_transform(y_data[:,3].reshape(-1,1))\n",
    "threshold_for_error = 8000/(sc.data_max_-sc.data_min_)\n",
    "\n",
    "data = range(x_data.shape[0])\n",
    "# window_size => the length of training block\n",
    "window_size = 159\n",
    "# step_window => step size of each window\n",
    "step_window = 4\n",
    "# the split data\n",
    "splits = []\n",
    "\n",
    "adjust = 0\n",
    "\n",
    "## Moving window mechnism\n",
    "for i in range(window_size, len(data), step_window):\n",
    "    train = np.array(data[i-window_size:i])\n",
    "    test = np.array(data[i:i+step_window])\n",
    "#     test = np.array(data[i-window_size:i+step_window])\n",
    "    splits.append(('TRAIN:', train, 'TEST:', test))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i_block in range(len(splits)):\n",
    "# for i_block in range(-2,0,1):\n",
    "# for i_block in range(2):\n",
    "    block_start = time.time()\n",
    "    ## Record the number of each step\n",
    "    nb_step4 = 0\n",
    "    nb_step6_1 = 0\n",
    "    nb_step6_2 = 0\n",
    "    \n",
    "    print(\"The <<%d>> Block\" %(i_block+1))\n",
    "#     print(\"The <<%d>> Block\" %(len(splits)+i_block+1))\n",
    "#     print(\"The training block\\n\", y_data[splits[i_block][1]])\n",
    "#     print(\"The testing block\\n\", y_data[splits[i_block][3]])\n",
    "    \n",
    "    x_train = x_data[splits[i_block][1]]\n",
    "    x_test = x_data[splits[i_block][3]]\n",
    "    y_train = y_data[splits[i_block][1]]\n",
    "    y_test = y_data[splits[i_block][3]]\n",
    "    \n",
    "    x_train_scaled = torch.FloatTensor(x_train)\n",
    "    x_test_scaled = torch.FloatTensor(x_test)\n",
    "    y_train_scaled = torch.FloatTensor(y_train)\n",
    "    y_test = sc.inverse_transform(y_test)\n",
    "\n",
    "    \n",
    "#     if i_block == -2:\n",
    "    if i_block == 0:\n",
    "        lower = torch.mean(y_train_scaled)-0.3*torch.std(y_train_scaled)\n",
    "        upper = torch.mean(y_train_scaled)+0.3*torch.std(y_train_scaled)\n",
    "        nonoutlier_index = torch.nonzero((y_train_scaled[:,0]>lower)&(y_train_scaled[:,0]<upper)).reshape([-1])\n",
    "        print(\"初始值\",nonoutlier_index.shape)\n",
    "        initial_x = x_train_scaled[nonoutlier_index[:19]]\n",
    "        initial_y = y_train_scaled[nonoutlier_index[:19]]\n",
    "        \n",
    "#         x_train_scaled = np.delete(x_train_scaled, nonoutlier_index[:19], 0)\n",
    "#         y_train_scaled = np.delete(y_train_scaled, nonoutlier_index[:19], 0)\n",
    "#         print(initial_x.shape[0])\n",
    "        \n",
    "        network = Network(1,initial_x,initial_y)\n",
    "        \n",
    "        network.nb_node_acceptable = torch.IntTensor([1 for _ in range(initial_x.shape[0])])\n",
    "        network.threshold_for_error = round(threshold_for_error[0],2)\n",
    "        \n",
    "        initializing(network, initial_x, initial_y)\n",
    "        \n",
    "        print(\"<<Initializing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(network.y-yo))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        remainder = int(window_size) - initial_x.shape[0]-adjust\n",
    "#         remainder = int(window_size*0.9624) - initial_x.shape[0]\n",
    "        nb_step4 += initial_x.shape[0]\n",
    "    \n",
    "    else:\n",
    "#         print(\"新的Code待驗證\")\n",
    "#         print(network.state_dict())\n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        restart_index = int(x_train_scaled.shape[0])-step_window-adjust\n",
    "        print(\"其他區塊剛開始選的資料索引：\",sorted_index[:restart_index])\n",
    "        init_x = x_train_scaled[sorted_index[:int(x_train_scaled.shape[0])-step_window-adjust]].reshape(-1,x_train_scaled.shape[1])\n",
    "        init_y = y_train_scaled[sorted_index[:int(x_train_scaled.shape[0])-step_window-adjust]].reshape(-1,1)\n",
    "#         print(\"取得的x\",init_x.shape)\n",
    "#         print(\"取得的y\",init_y.shape)\n",
    "#         print(\"前\")\n",
    "#         print(network.y.shape)\n",
    "        network.setData(init_x, init_y)\n",
    "#         print(\"後\")\n",
    "#         print(network.y.shape)\n",
    "        network.nb_node_acceptable = torch.IntTensor([network.linear1.bias.data.shape[0] for _ in range(init_x.shape[0])])\n",
    "        network.nb_node_pruned = 0\n",
    "        \n",
    "        print(\"<<其他區塊剛開始時看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(network.y-yo))\n",
    "        \n",
    "        remainder = int(window_size) - init_x.shape[0]-adjust\n",
    "#         remainder = int(window_size*0.9624) - init_x.shape[0]\n",
    "#         x_train_scaled = np.delete(x_train_scaled, sorted_index[:restart_index], 0)\n",
    "#         y_train_scaled = np.delete(y_train_scaled, sorted_index[:restart_index], 0)\n",
    "        nb_step4 += init_x.shape[0]\n",
    "#         print(\"X 資料\",x_train_scaled.shape)\n",
    "#         print(\"Y 資料\",y_train_scaled.shape)\n",
    "#     network.limit = network.linear1.bias.data.shape[0]\n",
    "#     print(\"Limit for node pruned:\",network.limit)\n",
    "\n",
    "#     for i in range(2):\n",
    "#     for i in range(remainder):\n",
    "    for i in range(network.x.shape[0]+1, int(window_size)+1):\n",
    "#         if i_block == -2:\n",
    "#         if i_block == 0:\n",
    "#             print(\"現在訓練到第幾筆資料: %d\"%(i+x_train_scaled.shape[1]+1))\n",
    "        print(\"現在訓練到第幾筆資料: %d\"%(i))\n",
    "#         else:\n",
    "#             print(\"現在訓練到第幾筆資料: %d\"%(restart_index+i))\n",
    "        \n",
    "        print(\"剩餘X 資料\",x_train_scaled.shape)\n",
    "        print(\"剩餘Y 資料\",y_train_scaled.shape)\n",
    "        \n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        \n",
    "\n",
    "        ## Add new data for training\n",
    "        \n",
    "        print(\"現在要進去模型的數據，索引:\",sorted_index[:i],\"數值\",y_train_scaled[sorted_index[:i]].shape)\n",
    "        network.setData(x_train_scaled[sorted_index[:i]], y_train_scaled[sorted_index[:i]])\n",
    "#         network.addData(x_train_scaled[sorted_index[0]], y_train_scaled[sorted_index[0]])\n",
    "        print(\"目前模型的Data狀態\",network.y.shape)\n",
    "#         x_train_scaled = np.delete(x_train_scaled, sorted_index[0], 0)\n",
    "#         y_train_scaled = np.delete(y_train_scaled, sorted_index[0], 0)\n",
    "        \n",
    "        yo,loss = network.forward()\n",
    "        print(\"<<預測值>>\")\n",
    "        print(yo)\n",
    "        print(\"<<差異>>\")\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        print(\"Loss值\")\n",
    "        print(loss)\n",
    "\n",
    "        pre_network = copy.deepcopy(network)\n",
    "        \n",
    "        if not torch.all(torch.abs(network.y-yo)<=network.threshold_for_error):\n",
    "            print(network.threshold_for_error)\n",
    "            network.acceptable = False\n",
    "            network = matching(network)\n",
    "            \n",
    "            print(\"<<Matching後看一下差異>>\")\n",
    "            yo,loss = network.forward()\n",
    "            print(torch.abs(yo-network.y))\n",
    "            print(\"threshold_for_error:\",threshold_for_error)\n",
    "            \n",
    "            if network.acceptable == False:\n",
    "                \n",
    "                network = copy.deepcopy(pre_network)\n",
    "                cramming(network)\n",
    "\n",
    "                if network.acceptable == False:\n",
    "                    sys.exit(0)  \n",
    "                \n",
    "                print(\"<<Cramming後看一下差異>>\")\n",
    "                yo,loss = network.forward()\n",
    "                print(torch.abs(yo-network.y))\n",
    "                print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "                nb_step6_2 += 1\n",
    "\n",
    "            else:\n",
    "                nb_step6_1 += 1\n",
    "\n",
    "        else:\n",
    "            nb_step4 += 1\n",
    "\n",
    "        network = reorganizing(network)\n",
    "        print(\"<<Reorganizing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        \n",
    "        network.nb_node_acceptable = torch.cat([network.nb_node_acceptable, torch.IntTensor([network.linear1.bias.data.shape[0]])],0)\n",
    "        print(\"看一下 hidden node\")\n",
    "        print(network.nb_node_acceptable)\n",
    "       \n",
    "        print(\"使用裝置\",(list(network.parameters())[0].device))\n",
    "        print(\"累計時間(s)\",time.time()-start)\n",
    "#         print(network.state_dict())\n",
    "        print(\"-\"*90)\n",
    "\n",
    "    \n",
    "    block_end = time.time()\n",
    "    print(\"到第 %d 個區塊累積花費時間(s)\"%(i_block+1),block_end-block_start)\n",
    "#     print(\"到第 %d 個區塊累積花費時間(s)\"%(len(splits)+i_block+1),block_end-block_start)\n",
    "    print(\"<<The performance of %d block>>\"%(i_block+1))\n",
    "#     print(\"<<The performance of %d block>>\"%(len(splits)+i_block+1))\n",
    "    \n",
    "    evaluation_table_train, evaluation_table_test, forecasted_price = validation(date.iloc[splits[i_block][3][0],:], network, nb_step4, nb_step6_1, nb_step6_2, x_train_scaled, y_train_scaled,x_test_scaled, y_test, block_start, block_end,i_block+1,evaluation_table_train,evaluation_table_test,forecasted_price)\n",
    "\n",
    "    evaluation_table_train.to_csv(\"evaluation_table_train.csv\",index=False)\n",
    "#     evaluation_table_outlier.to_csv(\"evaluation_table_outlier.csv\",index=False)\n",
    "    evaluation_table_test.to_csv(\"evaluation_table_inferencing.csv\",index=False)\n",
    "    forecasted_price.to_csv(\"forecast_price.csv\", index=False)\n",
    "#     validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,(len(splits)+i_block+1))\n",
    "end = time.time()\n",
    "print(\"總計時間(s)\", end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
