{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import tensorflow package for modeling\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Initializing module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "## Copy module\n",
    "import copy\n",
    "\n",
    "## Used to calculate the training time\n",
    "import time\n",
    "\n",
    "## Set the GUP environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the display\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control memory usage space for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前設備： 0\n",
      "目前設備名： GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "## 查詢有無可用 GPU\n",
    "torch.cuda.is_available()\n",
    "## 查詢可用 GPU 的數量\n",
    "torch.cuda.device_count()\n",
    "##目前設備\n",
    "print(\"目前設備：\",torch.cuda.current_device())\n",
    "## 目前設備名\n",
    "print(\"目前設備名：\",torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cacl(pred_value, actual_value):\n",
    "    \n",
    "#     yo, loss, tape = network.forward()\n",
    "    performance = []\n",
    "    performance.append(torch.mean(torch.abs(pred_value - actual_value)))\n",
    "    performance.append(torch.mean(torch.abs((pred_value - actual_value) / actual_value))) \n",
    "    performance.append(torch.sqrt(torch.mean((pred_value - actual_value)**2)))\n",
    "    \n",
    "    for i in range(2000,3001,1000):\n",
    "        correct_times = torch.nonzero(torch.abs(pred_value - actual_value) <= i, as_tuple =False)\n",
    "        accuracy = correct_times.shape[0]/pred_value.shape[0]\n",
    "        performance.append(accuracy)\n",
    "                       \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(name, pred_value, actual_value):\n",
    "    \n",
    "#     fig, ax = plt.subplots(2,2,figsize=(20,10), sharex=True, sharey=True)\n",
    "    fig, ax = plt.subplots(1,figsize=(20,10), sharex=True, sharey=True)\n",
    "#     ax.set_xlim(0,pred_value.shape[0])  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.plot(pred_value, label=\"LLAAT\")\n",
    "    ax.plot(actual_value, label=\"Actual\")\n",
    "    ax.set_title(\"Forecasted performance for l=%d\" %(1))\n",
    "    ax.legend()\n",
    "        \n",
    "    #fig.text(0.5, 0, \"Stage of training\", ha='center', fontsize=20)\n",
    "    #fig.text(0, 0.5, \"Copper price value\", va='center', rotation='vertical')\n",
    "\n",
    "    fig.suptitle(\"In the %s process\"%(name))\n",
    "    fig.tight_layout()\n",
    "#     fig.savefig(\"In the %s process in the M=%d window.png\"%(name, block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adopted_node(network):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "#     ax.set_xticklabels([i for i in range(network.nb_node_acceptable.shape[0]+5)])\n",
    "    \n",
    "    ax.set_title(\"Total amount of adopted hidden nodes in the training process\")\n",
    "    ax.plot(network.nb_node_acceptable,\"-o\")\n",
    "\n",
    "    ax.set_xlabel(\"Stage of training\")\n",
    "    ax.set_ylabel(\"Hidden nodes\")\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#     fig.savefig(\"hidden nodes in the training process in the M=%d window\"%(block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_table(evaluation_results, name, performance, nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node):\n",
    "\n",
    "    \n",
    "    new_result = pd.DataFrame({\n",
    "\n",
    "        \"Stage\":name,\n",
    "        \"MAE\" : round(performance[0].item(),2),\n",
    "        \"MAPE\" : \"%.2f\"%(performance[1]*100).item(),\n",
    "        \"RMSE\" : round(performance[2].item(),2),\n",
    "        \"Accuracy(2000)\" : [round(performance[3]*100,2)],\n",
    "        \"Accuracy(3000)\" : [round(performance[4]*100,2)],\n",
    "        \"Step4\":nb_step4,\n",
    "        \"Step6.1\":nb_step6_1,\n",
    "        \"Step6.2\":nb_step6_2,\n",
    "        \"Time\":time,\n",
    "        \"Adopted_hidden_node\":adopted_hidden_node\n",
    "    })\n",
    "\n",
    "    evaluation_results = evaluation_results.append(new_result, ignore_index=True)\n",
    "    \n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(network, nb_step4, nb_step6_1, nb_step6_2, x_train_scaled, y_train_scaled, x_test, y_test, start, end, evaluation_results_train, evaluation_results_test):\n",
    "\n",
    "    ## Training_Step\n",
    "    print(\"<<Training step>>\")\n",
    "    print(\"The training time(s):\",end - start)\n",
    "    time = end - start\n",
    "    yo, loss= network.forward()\n",
    "    \n",
    "    ## N - outlier\n",
    "    pre_train = yo.data.cpu()\n",
    "    true_train = network.y.data.cpu()\n",
    "    \n",
    "    pred_value_train = torch.FloatTensor(sc.inverse_transform(pre_train))\n",
    "    actual_value_train = torch.FloatTensor(sc.inverse_transform(true_train))\n",
    "    accuracy_train = accuracy_cacl(pred_value_train,actual_value_train)\n",
    "    \n",
    "    ## B\n",
    "    pred_value_test = torch.FloatTensor(sc.inverse_transform(network.forecast(x_test).data.cpu()))\n",
    "    accuracy_test = accuracy_cacl(pred_value_test, y_test)\n",
    "    \n",
    "    total_time = nb_step4 + nb_step6_1 + nb_step6_2\n",
    "    print(\"<<The percentage of each step>>\")\n",
    "    print(\"Step 4: %.2f%%\"%((nb_step4/total_time)*100))\n",
    "    print(\"Step 6.1: %.2f%%\"%((nb_step6_1/total_time)*100))\n",
    "    print(\"Step 6.2: %.2f%%\"%((nb_step6_2/total_time)*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"Total frequency of cramming occurrences:\",nb_step6_2)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of hidden node that be pruned:\",network.nb_node_pruned)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    adopted_hidden_node = network.nb_node_acceptable[-1].item()\n",
    "    print(\"The amount of adopted hidden nodes:\",network.nb_node_acceptable[-1].item())\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in training step>>\")\n",
    "    print(\"The MAE for l = 1: %.2f\" %(accuracy_train[0]))\n",
    "    print(\"The MAPE for l = 1: %.2f%%\" %(accuracy_train[1]))\n",
    "    print(\"The RMSE for l = 1: %.2f\" %(accuracy_train[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.2f%%\" %(accuracy_train[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.2f%%\" %(accuracy_train[4]*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in inferencing step>>\")\n",
    "    print(\"The MAE for l = 1: %.1f\" %(accuracy_test[0]))\n",
    "    print(\"The MAPE for l = 1: %.1f%%\" %(accuracy_test[1]))\n",
    "    print(\"The RMSE for l = 1: %.1f\" %(accuracy_test[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.1f%%\" %(accuracy_test[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.1f%%\" %(accuracy_test[4]*100))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    \n",
    "    evaluation_table_train = evaluation_table(evaluation_results_train, \"Training\", accuracy_train,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    evaluation_table_test = evaluation_table(evaluation_results_test, \"Inferencing\", accuracy_test,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    pre_LDSS = sc.inverse_transform(network.forecast(x_test).data.cpu())\n",
    "#     pd.DataFrame(pre_LDSS).to_csv(\"pre_LDSS_%d.csv\"%(block_index), index=False)\n",
    "     \n",
    "    predict_result = pd.DataFrame({\n",
    "        \"Actual\": y_test.reshape((-1,)),\n",
    "        \"Predict\": torch.reshape(pred_value_test,(-1,)).numpy(),\n",
    "        \"Absolute Error\":torch.reshape(torch.abs(pred_value_test - torch.FloatTensor(y_test)),(-1,)).numpy()\n",
    "    })\n",
    "    \n",
    "    predict_result.to_csv(\"pre_result.csv\", index=False)\n",
    "    \n",
    "#     if block_index%5==0:\n",
    "    plot_result(\"training\",pred_value_train, actual_value_train)\n",
    "    plot_result(\"inferencing\",pred_value_test, y_test)\n",
    "    plot_adopted_node(network)\n",
    "    \n",
    "    return(evaluation_table_train, evaluation_table_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=4, futureWeek=4, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek):\n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use min-max normalization to scale the data to the range from 1 to 0\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design get_data() to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(futureWeek):\n",
    "    \n",
    "    ## Read weekly copper price data\n",
    "    path = \"WeeklyFinalData.csv\"\n",
    "    data = read(path)\n",
    "    \n",
    "    date = data[\"Date\"]\n",
    "    data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "    ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "    x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "\n",
    "\n",
    "    return (x_data, y_data)\n",
    "\n",
    "#     return (x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_neuro, x_train_scaled, y_train_scaled):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(x_train_scaled.shape[1], nb_neuro).cuda()\n",
    "        self.linear2 = torch.nn.Linear(nb_neuro, 1).cuda()\n",
    "        \n",
    "        \n",
    "        # Stop criteria - threshold\n",
    "        self.threshold_for_error = 0.12\n",
    "        self.threshold_for_lr = 1e-4\n",
    "        \n",
    "        # Input data \n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = 1e-3\n",
    "        \n",
    "        # Whether the network is acceptable, default as False\n",
    "        self.acceptable = False\n",
    "        \n",
    "        # Some record for experiment\n",
    "        self.nb_node_pruned = 0\n",
    "        self.nb_node_acceptable=torch.IntTensor([nb_neuro])\n",
    "        \n",
    "        self.limit = nb_neuro\n",
    "        \n",
    "    ## Forecast the test data\n",
    "    def forecast(self, x_test):\n",
    "    \n",
    "        x_test = torch.FloatTensor(x_test).cuda()\n",
    "        activation_value = self.linear1(x_test).clamp(min=0)\n",
    "        forecast_value = self.linear2(activation_value)\n",
    "       \n",
    "        return forecast_value\n",
    "\n",
    "    ## Reset the x and y data\n",
    "    def setData(self, x_train_scaled, y_train_scaled):\n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "    \n",
    "    ## Add the new data to the x and y data\n",
    "    def addData(self, new_x_train, new_y_train):\n",
    "\n",
    "        self.x = torch.cat([self.x, new_x_train.reshape(1,-1).cuda()],0)\n",
    "        self.y = torch.cat([self.y, new_y_train.reshape(-1,1).cuda()],0)\n",
    "    \n",
    "    ## forward operation\n",
    "    def forward(self, reg_strength=0):\n",
    "       \n",
    "        y1 = self.linear1(self.x).clamp(min=0)\n",
    "        yo = self.linear2(y1)\n",
    "\n",
    "        # performance measure\n",
    "        param_val= torch.sum(torch.pow(self.linear2.bias.data,2))+torch.sum(torch.pow(self.linear2.weight.data,2))+torch.sum(torch.pow(self.linear1.bias.data,2))+torch.sum(torch.pow(self.linear1.weight.data,2))\n",
    "        reg_term= reg_strength/((self.linear2.bias.data.shape[0]*(self.linear2.weight.data.shape[1]+1)) +(self.linear1.bias.data.shape[0]*(self.linear1.weight.data.shape[1]+1)))*param_val\n",
    "        loss = torch.nn.functional.mse_loss(yo,self.y)+reg_term\n",
    "        loss = loss.cuda()\n",
    "        return(yo, loss)\n",
    "\n",
    "    # backward operation\n",
    "    def backward_Adadelta(self,loss):    \n",
    "\n",
    "        optimizer = optim.Adadelta(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing(network, initial_x, initial_y):\n",
    "    print(\"Initializing module\")\n",
    "    ## Find each minimum output value y\n",
    "    min_y = torch.min(initial_y, axis=0)\n",
    "    ## Subtract min_y from each y\n",
    "    res_y = initial_y-min_y.values\n",
    "    \n",
    "    ## Use linear regression to find the initial W1,b1,Wo,bo\n",
    "    reg = LinearRegression().fit(initial_x, res_y)\n",
    "    \n",
    "    ## Set up the initial parameter of the network\n",
    "    network.linear1.weight = torch.nn.Parameter(torch.FloatTensor(reg.coef_).cuda())\n",
    "    network.linear1.bias = torch.nn.Parameter(torch.FloatTensor(reg.intercept_).cuda())\n",
    "    network.linear2.weight=torch.nn.Parameter(torch.FloatTensor([[1]]).cuda())\n",
    "    network.linear2.bias = torch.nn.Parameter(torch.FloatTensor(min_y.values).cuda())\n",
    "    \n",
    "#     print(reg.coef_)\n",
    "#     print(reg.intercept_)\n",
    "\n",
    "    ## Set up the acceptable of the initial network as True\n",
    "    network.acceptable =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(network, x_train_scaled, y_train_scaled):\n",
    "    \n",
    "    print(\"<<Selecting module>>\")\n",
    "    loss = []\n",
    "    temp_network = copy.deepcopy(network)\n",
    "    \n",
    "    ## Put each data into network to calculate the loss value\n",
    "    for i in range(x_train_scaled.shape[0]):\n",
    "        temp_network.setData(x_train_scaled[i].reshape(1,-1), y_train_scaled[i].reshape(-1,1))\n",
    "        loss.append((temp_network.forward()[1].item(),i))\n",
    "#         print(network.state_dict())\n",
    "#         print(temp_network.y)\n",
    "#         print(\"-\"*20)\n",
    "#         print(temp_network.forward()[1])\n",
    "#         print(\"-\"*20)\n",
    "#     ## Sort the data according to the loss value from smallest to largest, and save the data index in sorted_index\n",
    "    sorted_index = [sorted_data[1] for sorted_data in sorted(loss, key = lambda x:x[0])]\n",
    "    \n",
    "    \n",
    "    ## Print out some info for debug\n",
    "    print(\"The loss value of k:\",loss[sorted_index[0]])\n",
    "#     print(\"The second_loss value of k:\",loss[sorted_index[1]])\n",
    "    print(\"Selecting module finish!\")\n",
    "#     print(\"Loss\",loss)\n",
    "#     print(network.state_dict())\n",
    "    \n",
    "    return sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matching(network):\n",
    "\n",
    "#     times_enlarge=0\n",
    "#     times_shrink=0\n",
    "    \n",
    "#     print(\"<<Matching module>>\")\n",
    "#     print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "#     ## Set up the learning rate of the network\n",
    "#     network.learning_rate = 1e-3\n",
    "#     network.acceptable = False\n",
    "#     initial_network = copy.deepcopy(network)\n",
    "\n",
    "#     yo, loss = network.forward()\n",
    "    \n",
    "#     if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "#         print(\"Matching finished (firstly) - the network is acceptable\")\n",
    "#         network.acceptable = True\n",
    "# #         print(\"Matching firstly finished - the network is acceptable\")\n",
    "#         print(\"Number of enlarge:\",times_enlarge)\n",
    "#         print(\"Number of shrink:\",times_shrink)\n",
    "#         return(network)\n",
    "    \n",
    "#     else:\n",
    "    \n",
    "#         while True:\n",
    "\n",
    "#             yo, loss = network.forward()\n",
    "#             network_pre = copy.deepcopy(network)\n",
    "#             loss_pre = loss\n",
    "            \n",
    "#             # Backward and check the loss performance of the network with new learning rate\n",
    "#             network.backward_Adadelta(loss)\n",
    "#             yo, loss = network.forward()\n",
    "\n",
    "#             # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "#             if loss <= loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "       \n",
    "#                 network.acceptable = True\n",
    "#                 print(\"Matching finished - the network is acceptable\")\n",
    "#                 print(\"Number of enlarge:\",times_enlarge)\n",
    "#                 print(\"Number of shrink:\",times_shrink)\n",
    "#                 return(network)\n",
    "\n",
    "#             elif loss <= loss_pre:\n",
    "                \n",
    "#                 times_enlarge+=1\n",
    "#                 network.learning_rate *= 1.2\n",
    "\n",
    "#             else:         \n",
    "\n",
    "#                 # Identify whether the current learning rate is less than the threshold\n",
    "#                 if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "#                     # If true, set the acceptable of the network as false and return it\n",
    "#                     network.acceptable = False\n",
    "#                     print(\"Matching finished - the network is Unacceptable\")\n",
    "#                     print(\"Number of enlarge:\",times_enlarge)\n",
    "#                     print(\"Number of shrink:\",times_shrink)\n",
    "#                     return(initial_network)\n",
    "\n",
    "#                 # On the contrary, restore w and adjust the learning rate\n",
    "#                 else:\n",
    "                    \n",
    "#                     # Restore the papameter of the network\n",
    "#                     network = copy.deepcopy(network_pre)\n",
    "#                     times_shrink+=1\n",
    "#                     network.learning_rate *= 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(10000):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "#             print(\"<前Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "#             print(\"<後Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "#                 print(\"*1.2\")\n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "#                     print(\"*0.7\")\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching for reorganizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_for_reorganizing(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module for reorganizing>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(500):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "#             print(\"<前Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "#             print(\"<後Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished(o) - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "#                 print(\"*1.2\")\n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished(o) - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "#                     print(\"*0.7\")\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramming module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramming(network):\n",
    "    \n",
    "    torch.random.manual_seed(0)\n",
    "    print(\"<<Cramming module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Find unsatisfied data:K\n",
    "    yo, loss = network.forward()\n",
    "    undesired_index = torch.nonzero(torch.abs(yo-network.y) > network.threshold_for_error+0.001, as_tuple =False)\n",
    "\n",
    "    ## Print out the undesired_index for debug\n",
    "    print(\"不滿足個數：\",undesired_index.shape[0])\n",
    "    print(\"The index of the undesired data:\",undesired_index)\n",
    "\n",
    "    \n",
    "    if undesired_index.shape[0] == 1:\n",
    "        \n",
    "        # Unsatisfied situation\n",
    "        ## Find the index of the unsatisfied data\n",
    "        k_data_num = undesired_index[0][0]\n",
    "\n",
    "        undesired_data = torch.reshape(network.x[k_data_num,:], [1,-1])\n",
    "\n",
    "        ## Remove the data that does not meet the error term\n",
    "        left_data = network.x[:k_data_num,:]\n",
    "        right_data = network.x[k_data_num+1:,:]\n",
    "        remain_tensor = torch.cat([left_data, right_data], 0)\n",
    "\n",
    "\n",
    "        ## Use the random method to find out the gamma and zeta\n",
    "        while True:\n",
    "\n",
    "            ## Find m-vector gamma: r\n",
    "            ## Use the random method to generate the gamma that can make the conditions met\n",
    "            gamma = torch.rand(size=[1,network.x.shape[1]]).cuda()\n",
    "            subtract_undesired_data = torch.sub(remain_tensor, undesired_data)\n",
    "            matmul_value = torch.mm(gamma,torch.t(subtract_undesired_data))\n",
    "\n",
    "            if torch.all(matmul_value != 0):\n",
    "                break\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## Find the tiny value: zeta\n",
    "            ## Use the random method to generate the zeta that can make the conditions met\n",
    "            zeta = torch.rand(size=[1]).cuda()\n",
    "\n",
    "            if torch.all(torch.mul(torch.add(zeta,matmul_value),torch.sub(zeta,matmul_value))<0):\n",
    "                break\n",
    "\n",
    "       \n",
    "\n",
    "        k_l = undesired_index[0][1]\n",
    "        \n",
    "        ## The weight of input layer to hidden layer I\n",
    "        w10 = gamma\n",
    "        w11 = gamma\n",
    "        w12 = gamma\n",
    "\n",
    "        W1_new = torch.cat([w10,w11,w12],0)\n",
    "        \n",
    "\n",
    "        ## The bias of input layer to hidden layer I\n",
    "        matual_value = torch.mm(gamma,torch.t(undesired_data))\n",
    "       \n",
    "        \n",
    "        b10 = torch.sub(zeta,matual_value)\n",
    "        b11 = -1*matual_value\n",
    "        b12 = torch.sub(-1*zeta,matual_value)\n",
    "\n",
    "        b1_new = torch.reshape(torch.cat([b10,b11,b12],0),[3])\n",
    "        \n",
    "#         print(\"b1_new\",b1_new)\n",
    "\n",
    "\n",
    "        ## The weight of hidden layer I to output layer\n",
    "        gap = network.y[k_data_num, k_l]-yo[k_data_num, k_l]\n",
    "#         print(\"gap:\",gap)\n",
    "\n",
    "        wo0_value = gap/zeta\n",
    "        wo1_value = (-2*gap)/zeta\n",
    "        wo2_value = gap/zeta\n",
    "\n",
    "        Wo_new = torch.reshape(torch.cat([wo0_value,wo1_value,wo2_value],0),[1,-1])\n",
    "\n",
    "        ## Add new neuroes to the network\n",
    "        network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight.data, W1_new]))\n",
    "        network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias.data, b1_new]))\n",
    "        network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight.data, Wo_new],1))\n",
    "\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        \n",
    "        ## Determine if cramming is successful and print out the corresponding information\n",
    "        if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            network.acceptable = True \n",
    "            print(\"Cramming success!\")\n",
    "\n",
    "        else:\n",
    "            print(\"Cramming failed!\")\n",
    "    \n",
    "    else:\n",
    "        print(\"條件不合，不能Cramming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizing(network):\n",
    "\n",
    "    print(\"<<Regularizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Record the number of executions\n",
    "    times_enlarge = 0\n",
    "    times_shrink = 0\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "\n",
    "    ## Set epoch to 100\n",
    "    for i in range(100):\n",
    "\n",
    "        ## Store the parameter of the network\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"調整前的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "        \n",
    "        ## Backward operation to obtain w'\n",
    "        network.backward_Adadelta(loss)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "#         print(\"調整後的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "         # Confirm whether the adjusted loss value is smaller than the current one\n",
    "        if loss <= loss_pre:\n",
    "            \n",
    "            ## Identify that all forecast value has met the error term\n",
    "            if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "                \n",
    "                ## If true, multiply the learning rate by 1.2\n",
    "#                 print(\"*1.2\")\n",
    "                network.learning_rate *= 1.2\n",
    "                times_enlarge += 1\n",
    "#                 print(\"Regularizing %d process - Enlarge\"%i)\n",
    "#                 print(\"第\\\"%d\\\"回合是成功執行regularizing\"%(i+1))\n",
    "#                 print(\"差異\")\n",
    "#                 print(torch.abs(yo-network.y))\n",
    "\n",
    "            else:\n",
    "\n",
    "                ## Else, restore w and end the process\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-因為沒有顧好預測誤差\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Unable to meet the error term\")\n",
    "                return(network)\n",
    "\n",
    "        # If the adjusted loss value is not smaller than the current one\n",
    "        else:\n",
    "\n",
    "            ## If the learning rate is greater than the threshold for learning rate\n",
    "            if network.learning_rate > network.threshold_for_lr:\n",
    "                \n",
    "                ## Restore the w and multiply the learning rate by 0.7\n",
    "                network = copy.deepcopy(network_pre)\n",
    "#                 print(\"*0.7\")\n",
    "                network.learning_rate *= 0.7\n",
    "                times_shrink += 1\n",
    "#                 print(\"把Learning rate變小\")\n",
    "#                 print(\"Regularizing %d process - Shrink\"%i)\n",
    "             ## If the learning rate is smaller than the threshold for learning rate\n",
    "            else:\n",
    "                \n",
    "                ## Restore the w\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-Learning不能這麼小\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Less than the epsilon for the learning rate\")\n",
    "                return(network)\n",
    "\n",
    "    print(\"第\\\"%d\\\"回合Regularizing module完畢\"%(i+1))\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganizing(network):\n",
    "    print(\"<<Reorganizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    limit = 4\n",
    "    if network.linear1.bias.shape[0] <= limit:\n",
    "        network = regularizing(network)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        ## Set up the k = 1, and p = the number of hidden node\n",
    "        k = 1\n",
    "    #     p = network.W1.shape[1]\n",
    "        p = network.linear1.weight.data.shape[0]\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## If k > p, end of Process\n",
    "            if k > p or p<=limit:\n",
    "\n",
    "                print(\"Reorganizing result: The final number of neuro is \",p)\n",
    "                return(network)\n",
    "\n",
    "            ## Else, Process is ongoing\n",
    "            else:\n",
    "\n",
    "                ## Using the regularizing module to adjust the network\n",
    "                network = regularizing(network)\n",
    "\n",
    "                ## Store the network and w\n",
    "                network_pre = copy.deepcopy(network)\n",
    "\n",
    "                ## Set up the acceptable of the network as false\n",
    "                network.acceptable = False\n",
    "                \n",
    "            \n",
    "                ## Ignore the K hidden node\n",
    "                network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight[:k-1],network.linear1.weight[k:]],0))\n",
    "                network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias[:k-1],network.linear1.bias[k:]]))\n",
    "                network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight[:,:k-1],network.linear2.weight[:,k:]],1))\n",
    "\n",
    "                \n",
    "                ## Using the matching module to adjust the network\n",
    "                network = matching_for_reorganizing(network)\n",
    "\n",
    "                print(\"是不是可以不要這個hidden node:\",network.acceptable)\n",
    "\n",
    "                ## If the resulting network is acceptable, this means that the k hidden node can be removed\n",
    "                if network.acceptable:\n",
    "\n",
    "                    print(\"Drop out the nero number: %d / %d\" %(k, p))\n",
    "                    network.nb_node_pruned += 1\n",
    "                    ## p--\n",
    "                    p-=1\n",
    "\n",
    "                ## Else, it means that the k hidden node cannot be removed\n",
    "                else:\n",
    "\n",
    "                    ## Restore the network and w\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    print(\"Cannot drop out the nero number: %d / %d\" %(k, p))\n",
    "\n",
    "                    ## k++\n",
    "                    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始值候選人 torch.Size([30])\n",
      "Initializing module\n",
      "<<Initializing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "現在訓練到第幾筆資料: 20\n",
      "剩餘X 資料 torch.Size([357, 18])\n",
      "剩餘Y 資料 torch.Size([357, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8040])\n",
      "目前模型的Data狀態 torch.Size([20, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5669],\n",
      "        [0.5265],\n",
      "        [0.5514],\n",
      "        [0.5638],\n",
      "        [0.5590],\n",
      "        [0.5611],\n",
      "        [0.5558],\n",
      "        [0.5479],\n",
      "        [0.5264],\n",
      "        [0.5406],\n",
      "        [0.5366],\n",
      "        [0.5340],\n",
      "        [0.5329],\n",
      "        [0.5230],\n",
      "        [0.5696],\n",
      "        [0.5413],\n",
      "        [0.5251],\n",
      "        [0.5716],\n",
      "        [0.5678],\n",
      "        [0.8234]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0195]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0022],\n",
      "        [0.0006],\n",
      "        [0.0007],\n",
      "        [0.0009],\n",
      "        [0.0006],\n",
      "        [0.0006],\n",
      "        [0.0004],\n",
      "        [0.0002],\n",
      "        [0.0002],\n",
      "        [0.0003],\n",
      "        [0.0006],\n",
      "        [0.0010],\n",
      "        [0.0011],\n",
      "        [0.0017],\n",
      "        [0.0006],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0003],\n",
      "        [0.0008],\n",
      "        [0.0054]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 21\n",
      "剩餘X 資料 torch.Size([356, 18])\n",
      "剩餘Y 資料 torch.Size([356, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8136])\n",
      "目前模型的Data狀態 torch.Size([21, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5647],\n",
      "        [0.5260],\n",
      "        [0.5508],\n",
      "        [0.5629],\n",
      "        [0.5584],\n",
      "        [0.5604],\n",
      "        [0.5554],\n",
      "        [0.5477],\n",
      "        [0.5266],\n",
      "        [0.5409],\n",
      "        [0.5372],\n",
      "        [0.5350],\n",
      "        [0.5340],\n",
      "        [0.5248],\n",
      "        [0.5701],\n",
      "        [0.5412],\n",
      "        [0.5249],\n",
      "        [0.5719],\n",
      "        [0.5670],\n",
      "        [0.8093],\n",
      "        [0.8340]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0022],\n",
      "        [0.0006],\n",
      "        [0.0007],\n",
      "        [0.0009],\n",
      "        [0.0006],\n",
      "        [0.0006],\n",
      "        [0.0004],\n",
      "        [0.0002],\n",
      "        [0.0002],\n",
      "        [0.0003],\n",
      "        [0.0006],\n",
      "        [0.0010],\n",
      "        [0.0011],\n",
      "        [0.0017],\n",
      "        [0.0006],\n",
      "        [0.0001],\n",
      "        [0.0002],\n",
      "        [0.0003],\n",
      "        [0.0008],\n",
      "        [0.0054],\n",
      "        [0.0205]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0005],\n",
      "        [    0.0007],\n",
      "        [    0.0011],\n",
      "        [    0.0006],\n",
      "        [    0.0008],\n",
      "        [    0.0003],\n",
      "        [    0.0000],\n",
      "        [    0.0006],\n",
      "        [    0.0008],\n",
      "        [    0.0014],\n",
      "        [    0.0021],\n",
      "        [    0.0023],\n",
      "        [    0.0022],\n",
      "        [    0.0008],\n",
      "        [    0.0004],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0054],\n",
      "        [    0.0096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 22\n",
      "剩餘X 資料 torch.Size([355, 18])\n",
      "剩餘Y 資料 torch.Size([355, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8421])\n",
      "目前模型的Data狀態 torch.Size([22, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5638],\n",
      "        [0.5260],\n",
      "        [0.5507],\n",
      "        [0.5626],\n",
      "        [0.5584],\n",
      "        [0.5603],\n",
      "        [0.5555],\n",
      "        [0.5480],\n",
      "        [0.5271],\n",
      "        [0.5414],\n",
      "        [0.5381],\n",
      "        [0.5361],\n",
      "        [0.5352],\n",
      "        [0.5252],\n",
      "        [0.5704],\n",
      "        [0.5409],\n",
      "        [0.5252],\n",
      "        [0.5717],\n",
      "        [0.5668],\n",
      "        [0.7986],\n",
      "        [0.8231],\n",
      "        [0.9111]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0005],\n",
      "        [    0.0007],\n",
      "        [    0.0011],\n",
      "        [    0.0006],\n",
      "        [    0.0008],\n",
      "        [    0.0003],\n",
      "        [    0.0000],\n",
      "        [    0.0006],\n",
      "        [    0.0008],\n",
      "        [    0.0014],\n",
      "        [    0.0021],\n",
      "        [    0.0023],\n",
      "        [    0.0022],\n",
      "        [    0.0008],\n",
      "        [    0.0004],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0054],\n",
      "        [    0.0096],\n",
      "        [    0.0689]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0000],\n",
      "        [    0.0008],\n",
      "        [    0.0020],\n",
      "        [    0.0014],\n",
      "        [    0.0018],\n",
      "        [    0.0007],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0014],\n",
      "        [    0.0024],\n",
      "        [    0.0036],\n",
      "        [    0.0038],\n",
      "        [    0.0037],\n",
      "        [    0.0009],\n",
      "        [    0.0012],\n",
      "        [    0.0009],\n",
      "        [    0.0004],\n",
      "        [    0.0026],\n",
      "        [    0.0269],\n",
      "        [    0.0125],\n",
      "        [    0.0461]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 23\n",
      "剩餘X 資料 torch.Size([354, 18])\n",
      "剩餘Y 資料 torch.Size([354, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8447])\n",
      "目前模型的Data狀態 torch.Size([23, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5613],\n",
      "        [0.5265],\n",
      "        [0.5506],\n",
      "        [0.5618],\n",
      "        [0.5576],\n",
      "        [0.5593],\n",
      "        [0.5551],\n",
      "        [0.5479],\n",
      "        [0.5276],\n",
      "        [0.5420],\n",
      "        [0.5390],\n",
      "        [0.5376],\n",
      "        [0.5368],\n",
      "        [0.5267],\n",
      "        [0.5705],\n",
      "        [0.5401],\n",
      "        [0.5259],\n",
      "        [0.5712],\n",
      "        [0.5652],\n",
      "        [0.7771],\n",
      "        [0.8011],\n",
      "        [0.8883],\n",
      "        [0.8296]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0000],\n",
      "        [    0.0008],\n",
      "        [    0.0020],\n",
      "        [    0.0014],\n",
      "        [    0.0018],\n",
      "        [    0.0007],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0014],\n",
      "        [    0.0024],\n",
      "        [    0.0036],\n",
      "        [    0.0038],\n",
      "        [    0.0037],\n",
      "        [    0.0009],\n",
      "        [    0.0012],\n",
      "        [    0.0009],\n",
      "        [    0.0004],\n",
      "        [    0.0026],\n",
      "        [    0.0269],\n",
      "        [    0.0125],\n",
      "        [    0.0461],\n",
      "        [    0.0151]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0043],\n",
      "        [0.0010],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0019],\n",
      "        [0.0023],\n",
      "        [0.0012],\n",
      "        [0.0005],\n",
      "        [0.0006],\n",
      "        [0.0006],\n",
      "        [0.0017],\n",
      "        [0.0028],\n",
      "        [0.0031],\n",
      "        [0.0029],\n",
      "        [0.0007],\n",
      "        [0.0011],\n",
      "        [0.0005],\n",
      "        [0.0009],\n",
      "        [0.0032],\n",
      "        [0.0243],\n",
      "        [0.0102],\n",
      "        [0.0477],\n",
      "        [0.0131]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 24\n",
      "剩餘X 資料 torch.Size([353, 18])\n",
      "剩餘Y 資料 torch.Size([353, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9290])\n",
      "目前模型的Data狀態 torch.Size([24, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5626],\n",
      "        [0.5275],\n",
      "        [0.5512],\n",
      "        [0.5621],\n",
      "        [0.5571],\n",
      "        [0.5588],\n",
      "        [0.5547],\n",
      "        [0.5474],\n",
      "        [0.5270],\n",
      "        [0.5412],\n",
      "        [0.5383],\n",
      "        [0.5368],\n",
      "        [0.5360],\n",
      "        [0.5260],\n",
      "        [0.5703],\n",
      "        [0.5402],\n",
      "        [0.5246],\n",
      "        [0.5707],\n",
      "        [0.5646],\n",
      "        [0.7796],\n",
      "        [0.8033],\n",
      "        [0.8898],\n",
      "        [0.8316],\n",
      "        [0.9182]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0043],\n",
      "        [0.0010],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0019],\n",
      "        [0.0023],\n",
      "        [0.0012],\n",
      "        [0.0005],\n",
      "        [0.0006],\n",
      "        [0.0006],\n",
      "        [0.0017],\n",
      "        [0.0028],\n",
      "        [0.0031],\n",
      "        [0.0029],\n",
      "        [0.0007],\n",
      "        [0.0011],\n",
      "        [0.0005],\n",
      "        [0.0009],\n",
      "        [0.0032],\n",
      "        [0.0243],\n",
      "        [0.0102],\n",
      "        [0.0477],\n",
      "        [0.0131],\n",
      "        [0.0108]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0028],\n",
      "        [0.0022],\n",
      "        [0.0006],\n",
      "        [0.0009],\n",
      "        [0.0016],\n",
      "        [0.0019],\n",
      "        [0.0007],\n",
      "        [0.0001],\n",
      "        [0.0009],\n",
      "        [0.0008],\n",
      "        [0.0018],\n",
      "        [0.0030],\n",
      "        [0.0032],\n",
      "        [0.0030],\n",
      "        [0.0013],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0005],\n",
      "        [0.0024],\n",
      "        [0.0213],\n",
      "        [0.0075],\n",
      "        [0.0499],\n",
      "        [0.0106],\n",
      "        [0.0083]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 25\n",
      "剩餘X 資料 torch.Size([352, 18])\n",
      "剩餘Y 資料 torch.Size([352, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9821])\n",
      "目前模型的Data狀態 torch.Size([25, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5641],\n",
      "        [0.5287],\n",
      "        [0.5520],\n",
      "        [0.5629],\n",
      "        [0.5574],\n",
      "        [0.5592],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5273],\n",
      "        [0.5414],\n",
      "        [0.5384],\n",
      "        [0.5370],\n",
      "        [0.5361],\n",
      "        [0.5261],\n",
      "        [0.5709],\n",
      "        [0.5410],\n",
      "        [0.5250],\n",
      "        [0.5711],\n",
      "        [0.5653],\n",
      "        [0.7826],\n",
      "        [0.8060],\n",
      "        [0.8920],\n",
      "        [0.8341],\n",
      "        [0.9206],\n",
      "        [0.9557]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0028],\n",
      "        [0.0022],\n",
      "        [0.0006],\n",
      "        [0.0009],\n",
      "        [0.0016],\n",
      "        [0.0019],\n",
      "        [0.0007],\n",
      "        [0.0001],\n",
      "        [0.0009],\n",
      "        [0.0008],\n",
      "        [0.0018],\n",
      "        [0.0030],\n",
      "        [0.0032],\n",
      "        [0.0030],\n",
      "        [0.0013],\n",
      "        [0.0002],\n",
      "        [0.0001],\n",
      "        [0.0005],\n",
      "        [0.0024],\n",
      "        [0.0213],\n",
      "        [0.0075],\n",
      "        [0.0499],\n",
      "        [0.0106],\n",
      "        [0.0083],\n",
      "        [0.0264]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0019],\n",
      "        [    0.0029],\n",
      "        [    0.0009],\n",
      "        [    0.0008],\n",
      "        [    0.0015],\n",
      "        [    0.0018],\n",
      "        [    0.0006],\n",
      "        [    0.0000],\n",
      "        [    0.0009],\n",
      "        [    0.0007],\n",
      "        [    0.0015],\n",
      "        [    0.0025],\n",
      "        [    0.0027],\n",
      "        [    0.0026],\n",
      "        [    0.0010],\n",
      "        [    0.0004],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0022],\n",
      "        [    0.0169],\n",
      "        [    0.0034],\n",
      "        [    0.0537],\n",
      "        [    0.0069],\n",
      "        [    0.0042],\n",
      "        [    0.0224]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 26\n",
      "剩餘X 資料 torch.Size([351, 18])\n",
      "剩餘Y 資料 torch.Size([351, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9747])\n",
      "目前模型的Data狀態 torch.Size([26, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5650],\n",
      "        [0.5294],\n",
      "        [0.5523],\n",
      "        [0.5630],\n",
      "        [0.5575],\n",
      "        [0.5592],\n",
      "        [0.5553],\n",
      "        [0.5480],\n",
      "        [0.5274],\n",
      "        [0.5413],\n",
      "        [0.5382],\n",
      "        [0.5365],\n",
      "        [0.5357],\n",
      "        [0.5256],\n",
      "        [0.5706],\n",
      "        [0.5409],\n",
      "        [0.5250],\n",
      "        [0.5707],\n",
      "        [0.5656],\n",
      "        [0.7870],\n",
      "        [0.8101],\n",
      "        [0.8958],\n",
      "        [0.8378],\n",
      "        [0.9248],\n",
      "        [0.9597],\n",
      "        [0.9517]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0019],\n",
      "        [    0.0029],\n",
      "        [    0.0009],\n",
      "        [    0.0008],\n",
      "        [    0.0015],\n",
      "        [    0.0018],\n",
      "        [    0.0006],\n",
      "        [    0.0000],\n",
      "        [    0.0009],\n",
      "        [    0.0007],\n",
      "        [    0.0015],\n",
      "        [    0.0025],\n",
      "        [    0.0027],\n",
      "        [    0.0026],\n",
      "        [    0.0010],\n",
      "        [    0.0004],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0022],\n",
      "        [    0.0169],\n",
      "        [    0.0034],\n",
      "        [    0.0537],\n",
      "        [    0.0069],\n",
      "        [    0.0042],\n",
      "        [    0.0224],\n",
      "        [    0.0231]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0012],\n",
      "        [0.0032],\n",
      "        [0.0010],\n",
      "        [0.0006],\n",
      "        [0.0014],\n",
      "        [0.0017],\n",
      "        [0.0004],\n",
      "        [0.0002],\n",
      "        [0.0011],\n",
      "        [0.0009],\n",
      "        [0.0015],\n",
      "        [0.0024],\n",
      "        [0.0026],\n",
      "        [0.0024],\n",
      "        [0.0015],\n",
      "        [0.0001],\n",
      "        [0.0004],\n",
      "        [0.0011],\n",
      "        [0.0021],\n",
      "        [0.0138],\n",
      "        [0.0006],\n",
      "        [0.0565],\n",
      "        [0.0041],\n",
      "        [0.0010],\n",
      "        [0.0191],\n",
      "        [0.0199]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 27\n",
      "剩餘X 資料 torch.Size([350, 18])\n",
      "剩餘Y 資料 torch.Size([350, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9994])\n",
      "目前模型的Data狀態 torch.Size([27, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5657],\n",
      "        [0.5297],\n",
      "        [0.5524],\n",
      "        [0.5631],\n",
      "        [0.5576],\n",
      "        [0.5593],\n",
      "        [0.5555],\n",
      "        [0.5482],\n",
      "        [0.5275],\n",
      "        [0.5415],\n",
      "        [0.5382],\n",
      "        [0.5364],\n",
      "        [0.5356],\n",
      "        [0.5254],\n",
      "        [0.5711],\n",
      "        [0.5414],\n",
      "        [0.5255],\n",
      "        [0.5705],\n",
      "        [0.5657],\n",
      "        [0.7902],\n",
      "        [0.8130],\n",
      "        [0.8987],\n",
      "        [0.8405],\n",
      "        [0.9279],\n",
      "        [0.9630],\n",
      "        [0.9548],\n",
      "        [1.0486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0012],\n",
      "        [0.0032],\n",
      "        [0.0010],\n",
      "        [0.0006],\n",
      "        [0.0014],\n",
      "        [0.0017],\n",
      "        [0.0004],\n",
      "        [0.0002],\n",
      "        [0.0011],\n",
      "        [0.0009],\n",
      "        [0.0015],\n",
      "        [0.0024],\n",
      "        [0.0026],\n",
      "        [0.0024],\n",
      "        [0.0015],\n",
      "        [0.0001],\n",
      "        [0.0004],\n",
      "        [0.0011],\n",
      "        [0.0021],\n",
      "        [0.0138],\n",
      "        [0.0006],\n",
      "        [0.0565],\n",
      "        [0.0041],\n",
      "        [0.0010],\n",
      "        [0.0191],\n",
      "        [0.0199],\n",
      "        [0.0491]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0020],\n",
      "        [0.0037],\n",
      "        [0.0009],\n",
      "        [0.0016],\n",
      "        [0.0018],\n",
      "        [0.0023],\n",
      "        [0.0007],\n",
      "        [0.0002],\n",
      "        [0.0012],\n",
      "        [0.0008],\n",
      "        [0.0014],\n",
      "        [0.0023],\n",
      "        [0.0026],\n",
      "        [0.0025],\n",
      "        [0.0013],\n",
      "        [0.0002],\n",
      "        [0.0005],\n",
      "        [0.0008],\n",
      "        [0.0020],\n",
      "        [0.0185],\n",
      "        [0.0055],\n",
      "        [0.0508],\n",
      "        [0.0094],\n",
      "        [0.0061],\n",
      "        [0.0243],\n",
      "        [0.0256],\n",
      "        [0.0427]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 28\n",
      "剩餘X 資料 torch.Size([349, 18])\n",
      "剩餘Y 資料 torch.Size([349, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9767])\n",
      "目前模型的Data狀態 torch.Size([28, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5649],\n",
      "        [0.5302],\n",
      "        [0.5523],\n",
      "        [0.5622],\n",
      "        [0.5572],\n",
      "        [0.5588],\n",
      "        [0.5552],\n",
      "        [0.5481],\n",
      "        [0.5277],\n",
      "        [0.5414],\n",
      "        [0.5380],\n",
      "        [0.5363],\n",
      "        [0.5355],\n",
      "        [0.5255],\n",
      "        [0.5708],\n",
      "        [0.5411],\n",
      "        [0.5256],\n",
      "        [0.5708],\n",
      "        [0.5658],\n",
      "        [0.7855],\n",
      "        [0.8081],\n",
      "        [0.8930],\n",
      "        [0.8353],\n",
      "        [0.9229],\n",
      "        [0.9578],\n",
      "        [0.9491],\n",
      "        [1.0421],\n",
      "        [1.0706]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0020],\n",
      "        [0.0037],\n",
      "        [0.0009],\n",
      "        [0.0016],\n",
      "        [0.0018],\n",
      "        [0.0023],\n",
      "        [0.0007],\n",
      "        [0.0002],\n",
      "        [0.0012],\n",
      "        [0.0008],\n",
      "        [0.0014],\n",
      "        [0.0023],\n",
      "        [0.0026],\n",
      "        [0.0025],\n",
      "        [0.0013],\n",
      "        [0.0002],\n",
      "        [0.0005],\n",
      "        [0.0008],\n",
      "        [0.0020],\n",
      "        [0.0185],\n",
      "        [0.0055],\n",
      "        [0.0508],\n",
      "        [0.0094],\n",
      "        [0.0061],\n",
      "        [0.0243],\n",
      "        [0.0256],\n",
      "        [0.0427],\n",
      "        [0.0939]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0037],\n",
      "        [0.0063],\n",
      "        [0.0023],\n",
      "        [0.0029],\n",
      "        [0.0019],\n",
      "        [0.0027],\n",
      "        [0.0007],\n",
      "        [0.0006],\n",
      "        [0.0023],\n",
      "        [0.0010],\n",
      "        [0.0014],\n",
      "        [0.0020],\n",
      "        [0.0023],\n",
      "        [0.0028],\n",
      "        [0.0004],\n",
      "        [0.0008],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0014],\n",
      "        [0.0240],\n",
      "        [0.0115],\n",
      "        [0.0423],\n",
      "        [0.0171],\n",
      "        [0.0139],\n",
      "        [0.0327],\n",
      "        [0.0364],\n",
      "        [0.0296],\n",
      "        [0.0791]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 29\n",
      "剩餘X 資料 torch.Size([348, 18])\n",
      "剩餘Y 資料 torch.Size([348, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9755])\n",
      "目前模型的Data狀態 torch.Size([29, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5632],\n",
      "        [0.5328],\n",
      "        [0.5537],\n",
      "        [0.5609],\n",
      "        [0.5571],\n",
      "        [0.5584],\n",
      "        [0.5551],\n",
      "        [0.5485],\n",
      "        [0.5288],\n",
      "        [0.5416],\n",
      "        [0.5380],\n",
      "        [0.5360],\n",
      "        [0.5352],\n",
      "        [0.5258],\n",
      "        [0.5700],\n",
      "        [0.5405],\n",
      "        [0.5263],\n",
      "        [0.5727],\n",
      "        [0.5663],\n",
      "        [0.7799],\n",
      "        [0.8020],\n",
      "        [0.8845],\n",
      "        [0.8276],\n",
      "        [0.9151],\n",
      "        [0.9494],\n",
      "        [0.9383],\n",
      "        [1.0290],\n",
      "        [1.0558],\n",
      "        [1.0901]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0037],\n",
      "        [0.0063],\n",
      "        [0.0023],\n",
      "        [0.0029],\n",
      "        [0.0019],\n",
      "        [0.0027],\n",
      "        [0.0007],\n",
      "        [0.0006],\n",
      "        [0.0023],\n",
      "        [0.0010],\n",
      "        [0.0014],\n",
      "        [0.0020],\n",
      "        [0.0023],\n",
      "        [0.0028],\n",
      "        [0.0004],\n",
      "        [0.0008],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0014],\n",
      "        [0.0240],\n",
      "        [0.0115],\n",
      "        [0.0423],\n",
      "        [0.0171],\n",
      "        [0.0139],\n",
      "        [0.0327],\n",
      "        [0.0364],\n",
      "        [0.0296],\n",
      "        [0.0791],\n",
      "        [0.1146]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0076],\n",
      "        [0.0084],\n",
      "        [0.0032],\n",
      "        [0.0059],\n",
      "        [0.0044],\n",
      "        [0.0056],\n",
      "        [0.0033],\n",
      "        [0.0016],\n",
      "        [0.0013],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0006],\n",
      "        [0.0003],\n",
      "        [0.0011],\n",
      "        [0.0019],\n",
      "        [0.0027],\n",
      "        [0.0009],\n",
      "        [0.0026],\n",
      "        [0.0036],\n",
      "        [0.0321],\n",
      "        [0.0198],\n",
      "        [0.0305],\n",
      "        [0.0277],\n",
      "        [0.0247],\n",
      "        [0.0448],\n",
      "        [0.0516],\n",
      "        [0.0111],\n",
      "        [0.0584],\n",
      "        [0.0914]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 30\n",
      "剩餘X 資料 torch.Size([347, 18])\n",
      "剩餘Y 資料 torch.Size([347, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9928])\n",
      "目前模型的Data狀態 torch.Size([30, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5593],\n",
      "        [0.5349],\n",
      "        [0.5546],\n",
      "        [0.5579],\n",
      "        [0.5546],\n",
      "        [0.5555],\n",
      "        [0.5526],\n",
      "        [0.5464],\n",
      "        [0.5277],\n",
      "        [0.5395],\n",
      "        [0.5357],\n",
      "        [0.5334],\n",
      "        [0.5327],\n",
      "        [0.5242],\n",
      "        [0.5676],\n",
      "        [0.5386],\n",
      "        [0.5260],\n",
      "        [0.5742],\n",
      "        [0.5641],\n",
      "        [0.7719],\n",
      "        [0.7938],\n",
      "        [0.8727],\n",
      "        [0.8170],\n",
      "        [0.9042],\n",
      "        [0.9373],\n",
      "        [0.9231],\n",
      "        [1.0106],\n",
      "        [1.0351],\n",
      "        [1.0670],\n",
      "        [1.0628]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0076],\n",
      "        [0.0084],\n",
      "        [0.0032],\n",
      "        [0.0059],\n",
      "        [0.0044],\n",
      "        [0.0056],\n",
      "        [0.0033],\n",
      "        [0.0016],\n",
      "        [0.0013],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0006],\n",
      "        [0.0003],\n",
      "        [0.0011],\n",
      "        [0.0019],\n",
      "        [0.0027],\n",
      "        [0.0009],\n",
      "        [0.0026],\n",
      "        [0.0036],\n",
      "        [0.0321],\n",
      "        [0.0198],\n",
      "        [0.0305],\n",
      "        [0.0277],\n",
      "        [0.0247],\n",
      "        [0.0448],\n",
      "        [0.0516],\n",
      "        [0.0111],\n",
      "        [0.0584],\n",
      "        [0.0914],\n",
      "        [0.0700]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0077],\n",
      "        [    0.0137],\n",
      "        [    0.0077],\n",
      "        [    0.0053],\n",
      "        [    0.0047],\n",
      "        [    0.0061],\n",
      "        [    0.0038],\n",
      "        [    0.0018],\n",
      "        [    0.0019],\n",
      "        [    0.0014],\n",
      "        [    0.0014],\n",
      "        [    0.0016],\n",
      "        [    0.0013],\n",
      "        [    0.0011],\n",
      "        [    0.0029],\n",
      "        [    0.0027],\n",
      "        [    0.0023],\n",
      "        [    0.0055],\n",
      "        [    0.0045],\n",
      "        [    0.0313],\n",
      "        [    0.0192],\n",
      "        [    0.0274],\n",
      "        [    0.0300],\n",
      "        [    0.0276],\n",
      "        [    0.0491],\n",
      "        [    0.0594],\n",
      "        [    0.0001],\n",
      "        [    0.0447],\n",
      "        [    0.0753],\n",
      "        [    0.0540]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 31\n",
      "剩餘X 資料 torch.Size([346, 18])\n",
      "剩餘Y 資料 torch.Size([346, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9790])\n",
      "目前模型的Data狀態 torch.Size([31, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5592],\n",
      "        [0.5403],\n",
      "        [0.5591],\n",
      "        [0.5585],\n",
      "        [0.5543],\n",
      "        [0.5549],\n",
      "        [0.5520],\n",
      "        [0.5462],\n",
      "        [0.5283],\n",
      "        [0.5392],\n",
      "        [0.5352],\n",
      "        [0.5324],\n",
      "        [0.5317],\n",
      "        [0.5241],\n",
      "        [0.5667],\n",
      "        [0.5386],\n",
      "        [0.5274],\n",
      "        [0.5771],\n",
      "        [0.5633],\n",
      "        [0.7726],\n",
      "        [0.7944],\n",
      "        [0.8696],\n",
      "        [0.8146],\n",
      "        [0.9014],\n",
      "        [0.9330],\n",
      "        [0.9154],\n",
      "        [0.9993],\n",
      "        [1.0214],\n",
      "        [1.0509],\n",
      "        [1.0468],\n",
      "        [1.0635]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0077],\n",
      "        [    0.0137],\n",
      "        [    0.0077],\n",
      "        [    0.0053],\n",
      "        [    0.0047],\n",
      "        [    0.0061],\n",
      "        [    0.0038],\n",
      "        [    0.0018],\n",
      "        [    0.0019],\n",
      "        [    0.0014],\n",
      "        [    0.0014],\n",
      "        [    0.0016],\n",
      "        [    0.0013],\n",
      "        [    0.0011],\n",
      "        [    0.0029],\n",
      "        [    0.0027],\n",
      "        [    0.0023],\n",
      "        [    0.0055],\n",
      "        [    0.0045],\n",
      "        [    0.0313],\n",
      "        [    0.0192],\n",
      "        [    0.0274],\n",
      "        [    0.0300],\n",
      "        [    0.0276],\n",
      "        [    0.0491],\n",
      "        [    0.0594],\n",
      "        [    0.0001],\n",
      "        [    0.0447],\n",
      "        [    0.0753],\n",
      "        [    0.0540],\n",
      "        [    0.0844]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0083],\n",
      "        [0.0182],\n",
      "        [0.0121],\n",
      "        [0.0046],\n",
      "        [0.0063],\n",
      "        [0.0079],\n",
      "        [0.0058],\n",
      "        [0.0037],\n",
      "        [0.0008],\n",
      "        [0.0030],\n",
      "        [0.0030],\n",
      "        [0.0034],\n",
      "        [0.0031],\n",
      "        [0.0001],\n",
      "        [0.0038],\n",
      "        [0.0026],\n",
      "        [0.0033],\n",
      "        [0.0077],\n",
      "        [0.0076],\n",
      "        [0.0322],\n",
      "        [0.0200],\n",
      "        [0.0231],\n",
      "        [0.0330],\n",
      "        [0.0320],\n",
      "        [0.0551],\n",
      "        [0.0679],\n",
      "        [0.0119],\n",
      "        [0.0305],\n",
      "        [0.0584],\n",
      "        [0.0365],\n",
      "        [0.0661]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 32\n",
      "剩餘X 資料 torch.Size([345, 18])\n",
      "剩餘Y 資料 torch.Size([345, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9973])\n",
      "目前模型的Data狀態 torch.Size([32, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5586],\n",
      "        [0.5447],\n",
      "        [0.5635],\n",
      "        [0.5592],\n",
      "        [0.5527],\n",
      "        [0.5532],\n",
      "        [0.5501],\n",
      "        [0.5443],\n",
      "        [0.5272],\n",
      "        [0.5376],\n",
      "        [0.5337],\n",
      "        [0.5306],\n",
      "        [0.5298],\n",
      "        [0.5231],\n",
      "        [0.5658],\n",
      "        [0.5387],\n",
      "        [0.5284],\n",
      "        [0.5793],\n",
      "        [0.5601],\n",
      "        [0.7718],\n",
      "        [0.7936],\n",
      "        [0.8653],\n",
      "        [0.8117],\n",
      "        [0.8970],\n",
      "        [0.9270],\n",
      "        [0.9068],\n",
      "        [0.9875],\n",
      "        [1.0072],\n",
      "        [1.0339],\n",
      "        [1.0292],\n",
      "        [1.0451],\n",
      "        [0.9319]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0083],\n",
      "        [0.0182],\n",
      "        [0.0121],\n",
      "        [0.0046],\n",
      "        [0.0063],\n",
      "        [0.0079],\n",
      "        [0.0058],\n",
      "        [0.0037],\n",
      "        [0.0008],\n",
      "        [0.0030],\n",
      "        [0.0030],\n",
      "        [0.0034],\n",
      "        [0.0031],\n",
      "        [0.0001],\n",
      "        [0.0038],\n",
      "        [0.0026],\n",
      "        [0.0033],\n",
      "        [0.0077],\n",
      "        [0.0076],\n",
      "        [0.0322],\n",
      "        [0.0200],\n",
      "        [0.0231],\n",
      "        [0.0330],\n",
      "        [0.0320],\n",
      "        [0.0551],\n",
      "        [0.0679],\n",
      "        [0.0119],\n",
      "        [0.0305],\n",
      "        [0.0584],\n",
      "        [0.0365],\n",
      "        [0.0661],\n",
      "        [0.0654]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0051],\n",
      "        [0.0230],\n",
      "        [0.0166],\n",
      "        [0.0009],\n",
      "        [0.0023],\n",
      "        [0.0040],\n",
      "        [0.0020],\n",
      "        [0.0002],\n",
      "        [0.0051],\n",
      "        [0.0003],\n",
      "        [0.0004],\n",
      "        [0.0019],\n",
      "        [0.0018],\n",
      "        [0.0022],\n",
      "        [0.0047],\n",
      "        [0.0021],\n",
      "        [0.0052],\n",
      "        [0.0090],\n",
      "        [0.0039],\n",
      "        [0.0170],\n",
      "        [0.0053],\n",
      "        [0.0351],\n",
      "        [0.0214],\n",
      "        [0.0207],\n",
      "        [0.0448],\n",
      "        [0.0610],\n",
      "        [0.0073],\n",
      "        [0.0332],\n",
      "        [0.0605],\n",
      "        [0.0396],\n",
      "        [0.0700],\n",
      "        [0.0568]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 33\n",
      "剩餘X 資料 torch.Size([344, 18])\n",
      "剩餘Y 資料 torch.Size([344, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9834])\n",
      "目前模型的Data狀態 torch.Size([33, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5618],\n",
      "        [0.5495],\n",
      "        [0.5680],\n",
      "        [0.5629],\n",
      "        [0.5567],\n",
      "        [0.5570],\n",
      "        [0.5538],\n",
      "        [0.5482],\n",
      "        [0.5315],\n",
      "        [0.5409],\n",
      "        [0.5362],\n",
      "        [0.5321],\n",
      "        [0.5311],\n",
      "        [0.5252],\n",
      "        [0.5648],\n",
      "        [0.5392],\n",
      "        [0.5303],\n",
      "        [0.5806],\n",
      "        [0.5638],\n",
      "        [0.7870],\n",
      "        [0.8082],\n",
      "        [0.8773],\n",
      "        [0.8233],\n",
      "        [0.9083],\n",
      "        [0.9373],\n",
      "        [0.9137],\n",
      "        [0.9921],\n",
      "        [1.0099],\n",
      "        [1.0360],\n",
      "        [1.0324],\n",
      "        [1.0491],\n",
      "        [0.9404],\n",
      "        [0.8902]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0051],\n",
      "        [0.0230],\n",
      "        [0.0166],\n",
      "        [0.0009],\n",
      "        [0.0023],\n",
      "        [0.0040],\n",
      "        [0.0020],\n",
      "        [0.0002],\n",
      "        [0.0051],\n",
      "        [0.0003],\n",
      "        [0.0004],\n",
      "        [0.0019],\n",
      "        [0.0018],\n",
      "        [0.0022],\n",
      "        [0.0047],\n",
      "        [0.0021],\n",
      "        [0.0052],\n",
      "        [0.0090],\n",
      "        [0.0039],\n",
      "        [0.0170],\n",
      "        [0.0053],\n",
      "        [0.0351],\n",
      "        [0.0214],\n",
      "        [0.0207],\n",
      "        [0.0448],\n",
      "        [0.0610],\n",
      "        [0.0073],\n",
      "        [0.0332],\n",
      "        [0.0605],\n",
      "        [0.0396],\n",
      "        [0.0700],\n",
      "        [0.0568],\n",
      "        [0.0932]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0065],\n",
      "        [    0.0225],\n",
      "        [    0.0150],\n",
      "        [    0.0014],\n",
      "        [    0.0003],\n",
      "        [    0.0023],\n",
      "        [    0.0000],\n",
      "        [    0.0026],\n",
      "        [    0.0082],\n",
      "        [    0.0022],\n",
      "        [    0.0003],\n",
      "        [    0.0024],\n",
      "        [    0.0027],\n",
      "        [    0.0020],\n",
      "        [    0.0086],\n",
      "        [    0.0049],\n",
      "        [    0.0042],\n",
      "        [    0.0069],\n",
      "        [    0.0005],\n",
      "        [    0.0052],\n",
      "        [    0.0058],\n",
      "        [    0.0440],\n",
      "        [    0.0137],\n",
      "        [    0.0125],\n",
      "        [    0.0371],\n",
      "        [    0.0567],\n",
      "        [    0.0049],\n",
      "        [    0.0339],\n",
      "        [    0.0616],\n",
      "        [    0.0428],\n",
      "        [    0.0750],\n",
      "        [    0.0472],\n",
      "        [    0.0816]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 34\n",
      "剩餘X 資料 torch.Size([343, 18])\n",
      "剩餘Y 資料 torch.Size([343, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9800])\n",
      "目前模型的Data狀態 torch.Size([34, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5604],\n",
      "        [0.5490],\n",
      "        [0.5664],\n",
      "        [0.5624],\n",
      "        [0.5587],\n",
      "        [0.5588],\n",
      "        [0.5558],\n",
      "        [0.5505],\n",
      "        [0.5346],\n",
      "        [0.5428],\n",
      "        [0.5369],\n",
      "        [0.5316],\n",
      "        [0.5302],\n",
      "        [0.5250],\n",
      "        [0.5609],\n",
      "        [0.5364],\n",
      "        [0.5293],\n",
      "        [0.5785],\n",
      "        [0.5673],\n",
      "        [0.7987],\n",
      "        [0.8194],\n",
      "        [0.8861],\n",
      "        [0.8310],\n",
      "        [0.9164],\n",
      "        [0.9450],\n",
      "        [0.9181],\n",
      "        [0.9945],\n",
      "        [1.0106],\n",
      "        [1.0371],\n",
      "        [1.0356],\n",
      "        [1.0541],\n",
      "        [0.9500],\n",
      "        [0.9018],\n",
      "        [0.8367]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0065],\n",
      "        [    0.0225],\n",
      "        [    0.0150],\n",
      "        [    0.0014],\n",
      "        [    0.0003],\n",
      "        [    0.0023],\n",
      "        [    0.0000],\n",
      "        [    0.0026],\n",
      "        [    0.0082],\n",
      "        [    0.0022],\n",
      "        [    0.0003],\n",
      "        [    0.0024],\n",
      "        [    0.0027],\n",
      "        [    0.0020],\n",
      "        [    0.0086],\n",
      "        [    0.0049],\n",
      "        [    0.0042],\n",
      "        [    0.0069],\n",
      "        [    0.0005],\n",
      "        [    0.0052],\n",
      "        [    0.0058],\n",
      "        [    0.0440],\n",
      "        [    0.0137],\n",
      "        [    0.0125],\n",
      "        [    0.0371],\n",
      "        [    0.0567],\n",
      "        [    0.0049],\n",
      "        [    0.0339],\n",
      "        [    0.0616],\n",
      "        [    0.0428],\n",
      "        [    0.0750],\n",
      "        [    0.0472],\n",
      "        [    0.0816],\n",
      "        [    0.1434]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0116],\n",
      "        [    0.0182],\n",
      "        [    0.0085],\n",
      "        [    0.0047],\n",
      "        [    0.0010],\n",
      "        [    0.0016],\n",
      "        [    0.0010],\n",
      "        [    0.0042],\n",
      "        [    0.0111],\n",
      "        [    0.0036],\n",
      "        [    0.0001],\n",
      "        [    0.0044],\n",
      "        [    0.0053],\n",
      "        [    0.0001],\n",
      "        [    0.0164],\n",
      "        [    0.0120],\n",
      "        [    0.0004],\n",
      "        [    0.0011],\n",
      "        [    0.0030],\n",
      "        [    0.0043],\n",
      "        [    0.0146],\n",
      "        [    0.0502],\n",
      "        [    0.0097],\n",
      "        [    0.0074],\n",
      "        [    0.0318],\n",
      "        [    0.0555],\n",
      "        [    0.0059],\n",
      "        [    0.0313],\n",
      "        [    0.0599],\n",
      "        [    0.0445],\n",
      "        [    0.0798],\n",
      "        [    0.0363],\n",
      "        [    0.0673],\n",
      "        [    0.1260]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 35\n",
      "剩餘X 資料 torch.Size([342, 18])\n",
      "剩餘Y 資料 torch.Size([342, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9673])\n",
      "目前模型的Data狀態 torch.Size([35, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5553],\n",
      "        [0.5447],\n",
      "        [0.5599],\n",
      "        [0.5591],\n",
      "        [0.5600],\n",
      "        [0.5595],\n",
      "        [0.5569],\n",
      "        [0.5522],\n",
      "        [0.5375],\n",
      "        [0.5441],\n",
      "        [0.5365],\n",
      "        [0.5296],\n",
      "        [0.5277],\n",
      "        [0.5231],\n",
      "        [0.5531],\n",
      "        [0.5293],\n",
      "        [0.5247],\n",
      "        [0.5727],\n",
      "        [0.5707],\n",
      "        [0.8082],\n",
      "        [0.8282],\n",
      "        [0.8923],\n",
      "        [0.8350],\n",
      "        [0.9216],\n",
      "        [0.9503],\n",
      "        [0.9192],\n",
      "        [0.9936],\n",
      "        [1.0080],\n",
      "        [1.0354],\n",
      "        [1.0372],\n",
      "        [1.0589],\n",
      "        [0.9609],\n",
      "        [0.9161],\n",
      "        [0.8540],\n",
      "        [0.8223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0116],\n",
      "        [    0.0182],\n",
      "        [    0.0085],\n",
      "        [    0.0047],\n",
      "        [    0.0010],\n",
      "        [    0.0016],\n",
      "        [    0.0010],\n",
      "        [    0.0042],\n",
      "        [    0.0111],\n",
      "        [    0.0036],\n",
      "        [    0.0001],\n",
      "        [    0.0044],\n",
      "        [    0.0053],\n",
      "        [    0.0001],\n",
      "        [    0.0164],\n",
      "        [    0.0120],\n",
      "        [    0.0004],\n",
      "        [    0.0011],\n",
      "        [    0.0030],\n",
      "        [    0.0043],\n",
      "        [    0.0146],\n",
      "        [    0.0502],\n",
      "        [    0.0097],\n",
      "        [    0.0074],\n",
      "        [    0.0318],\n",
      "        [    0.0555],\n",
      "        [    0.0059],\n",
      "        [    0.0313],\n",
      "        [    0.0599],\n",
      "        [    0.0445],\n",
      "        [    0.0798],\n",
      "        [    0.0363],\n",
      "        [    0.0673],\n",
      "        [    0.1260],\n",
      "        [    0.1451]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0132],\n",
      "        [0.0169],\n",
      "        [0.0045],\n",
      "        [0.0048],\n",
      "        [0.0047],\n",
      "        [0.0016],\n",
      "        [0.0043],\n",
      "        [0.0079],\n",
      "        [0.0160],\n",
      "        [0.0070],\n",
      "        [0.0020],\n",
      "        [0.0035],\n",
      "        [0.0049],\n",
      "        [0.0007],\n",
      "        [0.0202],\n",
      "        [0.0151],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0084],\n",
      "        [0.0157],\n",
      "        [0.0256],\n",
      "        [0.0586],\n",
      "        [0.0032],\n",
      "        [0.0003],\n",
      "        [0.0249],\n",
      "        [0.0522],\n",
      "        [0.0047],\n",
      "        [0.0312],\n",
      "        [0.0609],\n",
      "        [0.0487],\n",
      "        [0.0873],\n",
      "        [0.0231],\n",
      "        [0.0499],\n",
      "        [0.1051],\n",
      "        [0.1251]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 36\n",
      "剩餘X 資料 torch.Size([341, 18])\n",
      "剩餘Y 資料 torch.Size([341, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9438])\n",
      "目前模型的Data狀態 torch.Size([36, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5537],\n",
      "        [0.5434],\n",
      "        [0.5559],\n",
      "        [0.5590],\n",
      "        [0.5637],\n",
      "        [0.5626],\n",
      "        [0.5602],\n",
      "        [0.5559],\n",
      "        [0.5424],\n",
      "        [0.5476],\n",
      "        [0.5386],\n",
      "        [0.5305],\n",
      "        [0.5280],\n",
      "        [0.5237],\n",
      "        [0.5494],\n",
      "        [0.5262],\n",
      "        [0.5236],\n",
      "        [0.5702],\n",
      "        [0.5762],\n",
      "        [0.8197],\n",
      "        [0.8392],\n",
      "        [0.9007],\n",
      "        [0.8415],\n",
      "        [0.9286],\n",
      "        [0.9572],\n",
      "        [0.9226],\n",
      "        [0.9948],\n",
      "        [1.0079],\n",
      "        [1.0364],\n",
      "        [1.0415],\n",
      "        [1.0663],\n",
      "        [0.9742],\n",
      "        [0.9334],\n",
      "        [0.8749],\n",
      "        [0.8422],\n",
      "        [0.8089]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0132],\n",
      "        [0.0169],\n",
      "        [0.0045],\n",
      "        [0.0048],\n",
      "        [0.0047],\n",
      "        [0.0016],\n",
      "        [0.0043],\n",
      "        [0.0079],\n",
      "        [0.0160],\n",
      "        [0.0070],\n",
      "        [0.0020],\n",
      "        [0.0035],\n",
      "        [0.0049],\n",
      "        [0.0007],\n",
      "        [0.0202],\n",
      "        [0.0151],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0084],\n",
      "        [0.0157],\n",
      "        [0.0256],\n",
      "        [0.0586],\n",
      "        [0.0032],\n",
      "        [0.0003],\n",
      "        [0.0249],\n",
      "        [0.0522],\n",
      "        [0.0047],\n",
      "        [0.0312],\n",
      "        [0.0609],\n",
      "        [0.0487],\n",
      "        [0.0873],\n",
      "        [0.0231],\n",
      "        [0.0499],\n",
      "        [0.1051],\n",
      "        [0.1251],\n",
      "        [0.1349]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0166],\n",
      "        [0.0146],\n",
      "        [0.0010],\n",
      "        [0.0066],\n",
      "        [0.0066],\n",
      "        [0.0028],\n",
      "        [0.0056],\n",
      "        [0.0097],\n",
      "        [0.0189],\n",
      "        [0.0083],\n",
      "        [0.0022],\n",
      "        [0.0044],\n",
      "        [0.0064],\n",
      "        [0.0006],\n",
      "        [0.0246],\n",
      "        [0.0189],\n",
      "        [0.0033],\n",
      "        [0.0041],\n",
      "        [0.0120],\n",
      "        [0.0242],\n",
      "        [0.0340],\n",
      "        [0.0639],\n",
      "        [0.0002],\n",
      "        [0.0035],\n",
      "        [0.0214],\n",
      "        [0.0523],\n",
      "        [0.0074],\n",
      "        [0.0272],\n",
      "        [0.0579],\n",
      "        [0.0491],\n",
      "        [0.0910],\n",
      "        [0.0132],\n",
      "        [0.0352],\n",
      "        [0.0863],\n",
      "        [0.1067],\n",
      "        [0.1139]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 37\n",
      "剩餘X 資料 torch.Size([340, 18])\n",
      "剩餘Y 資料 torch.Size([340, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8890])\n",
      "目前模型的Data狀態 torch.Size([37, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5503],\n",
      "        [0.5411],\n",
      "        [0.5504],\n",
      "        [0.5572],\n",
      "        [0.5656],\n",
      "        [0.5639],\n",
      "        [0.5615],\n",
      "        [0.5576],\n",
      "        [0.5453],\n",
      "        [0.5489],\n",
      "        [0.5388],\n",
      "        [0.5296],\n",
      "        [0.5266],\n",
      "        [0.5224],\n",
      "        [0.5450],\n",
      "        [0.5224],\n",
      "        [0.5218],\n",
      "        [0.5675],\n",
      "        [0.5798],\n",
      "        [0.8282],\n",
      "        [0.8476],\n",
      "        [0.9061],\n",
      "        [0.8449],\n",
      "        [0.9325],\n",
      "        [0.9607],\n",
      "        [0.9224],\n",
      "        [0.9920],\n",
      "        [1.0039],\n",
      "        [1.0334],\n",
      "        [1.0418],\n",
      "        [1.0700],\n",
      "        [0.9841],\n",
      "        [0.9482],\n",
      "        [0.8937],\n",
      "        [0.8606],\n",
      "        [0.8299],\n",
      "        [0.7051]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0166],\n",
      "        [0.0146],\n",
      "        [0.0010],\n",
      "        [0.0066],\n",
      "        [0.0066],\n",
      "        [0.0028],\n",
      "        [0.0056],\n",
      "        [0.0097],\n",
      "        [0.0189],\n",
      "        [0.0083],\n",
      "        [0.0022],\n",
      "        [0.0044],\n",
      "        [0.0064],\n",
      "        [0.0006],\n",
      "        [0.0246],\n",
      "        [0.0189],\n",
      "        [0.0033],\n",
      "        [0.0041],\n",
      "        [0.0120],\n",
      "        [0.0242],\n",
      "        [0.0340],\n",
      "        [0.0639],\n",
      "        [0.0002],\n",
      "        [0.0035],\n",
      "        [0.0214],\n",
      "        [0.0523],\n",
      "        [0.0074],\n",
      "        [0.0272],\n",
      "        [0.0579],\n",
      "        [0.0491],\n",
      "        [0.0910],\n",
      "        [0.0132],\n",
      "        [0.0352],\n",
      "        [0.0863],\n",
      "        [0.1067],\n",
      "        [0.1139],\n",
      "        [0.1839]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0166],\n",
      "        [0.0155],\n",
      "        [0.0037],\n",
      "        [0.0054],\n",
      "        [0.0120],\n",
      "        [0.0075],\n",
      "        [0.0103],\n",
      "        [0.0148],\n",
      "        [0.0249],\n",
      "        [0.0123],\n",
      "        [0.0052],\n",
      "        [0.0024],\n",
      "        [0.0051],\n",
      "        [0.0006],\n",
      "        [0.0284],\n",
      "        [0.0220],\n",
      "        [0.0040],\n",
      "        [0.0052],\n",
      "        [0.0181],\n",
      "        [0.0352],\n",
      "        [0.0446],\n",
      "        [0.0705],\n",
      "        [0.0050],\n",
      "        [0.0080],\n",
      "        [0.0179],\n",
      "        [0.0527],\n",
      "        [0.0115],\n",
      "        [0.0220],\n",
      "        [0.0539],\n",
      "        [0.0489],\n",
      "        [0.0944],\n",
      "        [0.0019],\n",
      "        [0.0184],\n",
      "        [0.0644],\n",
      "        [0.0848],\n",
      "        [0.0882],\n",
      "        [0.1507]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 38\n",
      "剩餘X 資料 torch.Size([339, 18])\n",
      "剩餘Y 資料 torch.Size([339, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9141])\n",
      "目前模型的Data狀態 torch.Size([38, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5503],\n",
      "        [0.5420],\n",
      "        [0.5477],\n",
      "        [0.5584],\n",
      "        [0.5710],\n",
      "        [0.5685],\n",
      "        [0.5661],\n",
      "        [0.5628],\n",
      "        [0.5513],\n",
      "        [0.5529],\n",
      "        [0.5418],\n",
      "        [0.5316],\n",
      "        [0.5279],\n",
      "        [0.5236],\n",
      "        [0.5411],\n",
      "        [0.5193],\n",
      "        [0.5211],\n",
      "        [0.5664],\n",
      "        [0.5859],\n",
      "        [0.8391],\n",
      "        [0.8582],\n",
      "        [0.9126],\n",
      "        [0.8497],\n",
      "        [0.9369],\n",
      "        [0.9642],\n",
      "        [0.9220],\n",
      "        [0.9879],\n",
      "        [0.9987],\n",
      "        [1.0294],\n",
      "        [1.0416],\n",
      "        [1.0734],\n",
      "        [0.9953],\n",
      "        [0.9649],\n",
      "        [0.9156],\n",
      "        [0.8826],\n",
      "        [0.8556],\n",
      "        [0.7383],\n",
      "        [0.7838]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0166],\n",
      "        [0.0155],\n",
      "        [0.0037],\n",
      "        [0.0054],\n",
      "        [0.0120],\n",
      "        [0.0075],\n",
      "        [0.0103],\n",
      "        [0.0148],\n",
      "        [0.0249],\n",
      "        [0.0123],\n",
      "        [0.0052],\n",
      "        [0.0024],\n",
      "        [0.0051],\n",
      "        [0.0006],\n",
      "        [0.0284],\n",
      "        [0.0220],\n",
      "        [0.0040],\n",
      "        [0.0052],\n",
      "        [0.0181],\n",
      "        [0.0352],\n",
      "        [0.0446],\n",
      "        [0.0705],\n",
      "        [0.0050],\n",
      "        [0.0080],\n",
      "        [0.0179],\n",
      "        [0.0527],\n",
      "        [0.0115],\n",
      "        [0.0220],\n",
      "        [0.0539],\n",
      "        [0.0489],\n",
      "        [0.0944],\n",
      "        [0.0019],\n",
      "        [0.0184],\n",
      "        [0.0644],\n",
      "        [0.0848],\n",
      "        [0.0882],\n",
      "        [0.1507],\n",
      "        [0.1303]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0175],\n",
      "        [0.0154],\n",
      "        [0.0078],\n",
      "        [0.0065],\n",
      "        [0.0142],\n",
      "        [0.0090],\n",
      "        [0.0118],\n",
      "        [0.0169],\n",
      "        [0.0273],\n",
      "        [0.0130],\n",
      "        [0.0056],\n",
      "        [0.0024],\n",
      "        [0.0056],\n",
      "        [0.0005],\n",
      "        [0.0301],\n",
      "        [0.0228],\n",
      "        [0.0031],\n",
      "        [0.0053],\n",
      "        [0.0218],\n",
      "        [0.0422],\n",
      "        [0.0514],\n",
      "        [0.0735],\n",
      "        [0.0069],\n",
      "        [0.0092],\n",
      "        [0.0179],\n",
      "        [0.0558],\n",
      "        [0.0183],\n",
      "        [0.0145],\n",
      "        [0.0475],\n",
      "        [0.0459],\n",
      "        [0.0948],\n",
      "        [0.0054],\n",
      "        [0.0058],\n",
      "        [0.0469],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.1209],\n",
      "        [0.1055]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 39\n",
      "剩餘X 資料 torch.Size([338, 18])\n",
      "剩餘Y 資料 torch.Size([338, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9367])\n",
      "目前模型的Data狀態 torch.Size([39, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5494],\n",
      "        [0.5419],\n",
      "        [0.5436],\n",
      "        [0.5573],\n",
      "        [0.5732],\n",
      "        [0.5701],\n",
      "        [0.5677],\n",
      "        [0.5648],\n",
      "        [0.5538],\n",
      "        [0.5536],\n",
      "        [0.5422],\n",
      "        [0.5316],\n",
      "        [0.5273],\n",
      "        [0.5225],\n",
      "        [0.5395],\n",
      "        [0.5184],\n",
      "        [0.5220],\n",
      "        [0.5663],\n",
      "        [0.5895],\n",
      "        [0.8462],\n",
      "        [0.8650],\n",
      "        [0.9156],\n",
      "        [0.8516],\n",
      "        [0.9382],\n",
      "        [0.9642],\n",
      "        [0.9189],\n",
      "        [0.9811],\n",
      "        [0.9912],\n",
      "        [1.0231],\n",
      "        [1.0387],\n",
      "        [1.0739],\n",
      "        [1.0027],\n",
      "        [0.9775],\n",
      "        [0.9331],\n",
      "        [0.9011],\n",
      "        [0.8776],\n",
      "        [0.7680],\n",
      "        [0.8086],\n",
      "        [0.8293]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0175],\n",
      "        [0.0154],\n",
      "        [0.0078],\n",
      "        [0.0065],\n",
      "        [0.0142],\n",
      "        [0.0090],\n",
      "        [0.0118],\n",
      "        [0.0169],\n",
      "        [0.0273],\n",
      "        [0.0130],\n",
      "        [0.0056],\n",
      "        [0.0024],\n",
      "        [0.0056],\n",
      "        [0.0005],\n",
      "        [0.0301],\n",
      "        [0.0228],\n",
      "        [0.0031],\n",
      "        [0.0053],\n",
      "        [0.0218],\n",
      "        [0.0422],\n",
      "        [0.0514],\n",
      "        [0.0735],\n",
      "        [0.0069],\n",
      "        [0.0092],\n",
      "        [0.0179],\n",
      "        [0.0558],\n",
      "        [0.0183],\n",
      "        [0.0145],\n",
      "        [0.0475],\n",
      "        [0.0459],\n",
      "        [0.0948],\n",
      "        [0.0054],\n",
      "        [0.0058],\n",
      "        [0.0469],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.1209],\n",
      "        [0.1055],\n",
      "        [0.1074]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0178],\n",
      "        [0.0158],\n",
      "        [0.0105],\n",
      "        [0.0073],\n",
      "        [0.0156],\n",
      "        [0.0099],\n",
      "        [0.0126],\n",
      "        [0.0180],\n",
      "        [0.0286],\n",
      "        [0.0131],\n",
      "        [0.0057],\n",
      "        [0.0024],\n",
      "        [0.0059],\n",
      "        [0.0015],\n",
      "        [0.0305],\n",
      "        [0.0226],\n",
      "        [0.0018],\n",
      "        [0.0052],\n",
      "        [0.0233],\n",
      "        [0.0465],\n",
      "        [0.0556],\n",
      "        [0.0748],\n",
      "        [0.0077],\n",
      "        [0.0094],\n",
      "        [0.0188],\n",
      "        [0.0585],\n",
      "        [0.0237],\n",
      "        [0.0087],\n",
      "        [0.0427],\n",
      "        [0.0435],\n",
      "        [0.0950],\n",
      "        [0.0104],\n",
      "        [0.0030],\n",
      "        [0.0344],\n",
      "        [0.0525],\n",
      "        [0.0502],\n",
      "        [0.0988],\n",
      "        [0.0866],\n",
      "        [0.0888]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 40\n",
      "剩餘X 資料 torch.Size([337, 18])\n",
      "剩餘Y 資料 torch.Size([337, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9159])\n",
      "目前模型的Data狀態 torch.Size([40, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5491],\n",
      "        [0.5423],\n",
      "        [0.5409],\n",
      "        [0.5565],\n",
      "        [0.5746],\n",
      "        [0.5709],\n",
      "        [0.5685],\n",
      "        [0.5660],\n",
      "        [0.5551],\n",
      "        [0.5536],\n",
      "        [0.5423],\n",
      "        [0.5316],\n",
      "        [0.5270],\n",
      "        [0.5215],\n",
      "        [0.5391],\n",
      "        [0.5187],\n",
      "        [0.5232],\n",
      "        [0.5664],\n",
      "        [0.5911],\n",
      "        [0.8505],\n",
      "        [0.8691],\n",
      "        [0.9170],\n",
      "        [0.8524],\n",
      "        [0.9384],\n",
      "        [0.9633],\n",
      "        [0.9163],\n",
      "        [0.9757],\n",
      "        [0.9854],\n",
      "        [1.0183],\n",
      "        [1.0363],\n",
      "        [1.0740],\n",
      "        [1.0077],\n",
      "        [0.9864],\n",
      "        [0.9456],\n",
      "        [0.9148],\n",
      "        [0.8936],\n",
      "        [0.7902],\n",
      "        [0.8275],\n",
      "        [0.8478],\n",
      "        [0.8073]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0178],\n",
      "        [0.0158],\n",
      "        [0.0105],\n",
      "        [0.0073],\n",
      "        [0.0156],\n",
      "        [0.0099],\n",
      "        [0.0126],\n",
      "        [0.0180],\n",
      "        [0.0286],\n",
      "        [0.0131],\n",
      "        [0.0057],\n",
      "        [0.0024],\n",
      "        [0.0059],\n",
      "        [0.0015],\n",
      "        [0.0305],\n",
      "        [0.0226],\n",
      "        [0.0018],\n",
      "        [0.0052],\n",
      "        [0.0233],\n",
      "        [0.0465],\n",
      "        [0.0556],\n",
      "        [0.0748],\n",
      "        [0.0077],\n",
      "        [0.0094],\n",
      "        [0.0188],\n",
      "        [0.0585],\n",
      "        [0.0237],\n",
      "        [0.0087],\n",
      "        [0.0427],\n",
      "        [0.0435],\n",
      "        [0.0950],\n",
      "        [0.0104],\n",
      "        [0.0030],\n",
      "        [0.0344],\n",
      "        [0.0525],\n",
      "        [0.0502],\n",
      "        [0.0988],\n",
      "        [0.0866],\n",
      "        [0.0888],\n",
      "        [0.1086]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0169],\n",
      "        [0.0170],\n",
      "        [0.0120],\n",
      "        [0.0075],\n",
      "        [0.0169],\n",
      "        [0.0107],\n",
      "        [0.0133],\n",
      "        [0.0190],\n",
      "        [0.0294],\n",
      "        [0.0129],\n",
      "        [0.0058],\n",
      "        [0.0021],\n",
      "        [0.0058],\n",
      "        [0.0024],\n",
      "        [0.0306],\n",
      "        [0.0222],\n",
      "        [0.0006],\n",
      "        [0.0054],\n",
      "        [0.0235],\n",
      "        [0.0497],\n",
      "        [0.0584],\n",
      "        [0.0753],\n",
      "        [0.0080],\n",
      "        [0.0091],\n",
      "        [0.0201],\n",
      "        [0.0610],\n",
      "        [0.0286],\n",
      "        [0.0038],\n",
      "        [0.0386],\n",
      "        [0.0413],\n",
      "        [0.0950],\n",
      "        [0.0143],\n",
      "        [0.0101],\n",
      "        [0.0242],\n",
      "        [0.0408],\n",
      "        [0.0364],\n",
      "        [0.0795],\n",
      "        [0.0696],\n",
      "        [0.0721],\n",
      "        [0.0913]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 41\n",
      "剩餘X 資料 torch.Size([336, 18])\n",
      "剩餘Y 資料 torch.Size([336, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8533])\n",
      "目前模型的Data狀態 torch.Size([41, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5500],\n",
      "        [0.5435],\n",
      "        [0.5394],\n",
      "        [0.5563],\n",
      "        [0.5759],\n",
      "        [0.5717],\n",
      "        [0.5692],\n",
      "        [0.5670],\n",
      "        [0.5558],\n",
      "        [0.5535],\n",
      "        [0.5424],\n",
      "        [0.5319],\n",
      "        [0.5271],\n",
      "        [0.5207],\n",
      "        [0.5390],\n",
      "        [0.5191],\n",
      "        [0.5244],\n",
      "        [0.5662],\n",
      "        [0.5913],\n",
      "        [0.8536],\n",
      "        [0.8720],\n",
      "        [0.9175],\n",
      "        [0.8527],\n",
      "        [0.9381],\n",
      "        [0.9620],\n",
      "        [0.9137],\n",
      "        [0.9708],\n",
      "        [0.9805],\n",
      "        [1.0142],\n",
      "        [1.0340],\n",
      "        [1.0740],\n",
      "        [1.0116],\n",
      "        [0.9935],\n",
      "        [0.9558],\n",
      "        [0.9266],\n",
      "        [0.9074],\n",
      "        [0.8094],\n",
      "        [0.8445],\n",
      "        [0.8645],\n",
      "        [0.8246],\n",
      "        [0.8098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0169],\n",
      "        [0.0170],\n",
      "        [0.0120],\n",
      "        [0.0075],\n",
      "        [0.0169],\n",
      "        [0.0107],\n",
      "        [0.0133],\n",
      "        [0.0190],\n",
      "        [0.0294],\n",
      "        [0.0129],\n",
      "        [0.0058],\n",
      "        [0.0021],\n",
      "        [0.0058],\n",
      "        [0.0024],\n",
      "        [0.0306],\n",
      "        [0.0222],\n",
      "        [0.0006],\n",
      "        [0.0054],\n",
      "        [0.0235],\n",
      "        [0.0497],\n",
      "        [0.0584],\n",
      "        [0.0753],\n",
      "        [0.0080],\n",
      "        [0.0091],\n",
      "        [0.0201],\n",
      "        [0.0610],\n",
      "        [0.0286],\n",
      "        [0.0038],\n",
      "        [0.0386],\n",
      "        [0.0413],\n",
      "        [0.0950],\n",
      "        [0.0143],\n",
      "        [0.0101],\n",
      "        [0.0242],\n",
      "        [0.0408],\n",
      "        [0.0364],\n",
      "        [0.0795],\n",
      "        [0.0696],\n",
      "        [0.0721],\n",
      "        [0.0913],\n",
      "        [0.0435]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0137],\n",
      "        [    0.0207],\n",
      "        [    0.0106],\n",
      "        [    0.0057],\n",
      "        [    0.0194],\n",
      "        [    0.0127],\n",
      "        [    0.0152],\n",
      "        [    0.0212],\n",
      "        [    0.0312],\n",
      "        [    0.0140],\n",
      "        [    0.0075],\n",
      "        [    0.0000],\n",
      "        [    0.0039],\n",
      "        [    0.0014],\n",
      "        [    0.0272],\n",
      "        [    0.0182],\n",
      "        [    0.0037],\n",
      "        [    0.0027],\n",
      "        [    0.0254],\n",
      "        [    0.0540],\n",
      "        [    0.0625],\n",
      "        [    0.0775],\n",
      "        [    0.0103],\n",
      "        [    0.0109],\n",
      "        [    0.0193],\n",
      "        [    0.0611],\n",
      "        [    0.0307],\n",
      "        [    0.0019],\n",
      "        [    0.0373],\n",
      "        [    0.0413],\n",
      "        [    0.0968],\n",
      "        [    0.0191],\n",
      "        [    0.0175],\n",
      "        [    0.0143],\n",
      "        [    0.0293],\n",
      "        [    0.0234],\n",
      "        [    0.0620],\n",
      "        [    0.0535],\n",
      "        [    0.0562],\n",
      "        [    0.0748],\n",
      "        [    0.0263]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 42\n",
      "剩餘X 資料 torch.Size([335, 18])\n",
      "剩餘Y 資料 torch.Size([335, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8548])\n",
      "目前模型的Data狀態 torch.Size([42, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5532],\n",
      "        [0.5472],\n",
      "        [0.5408],\n",
      "        [0.5581],\n",
      "        [0.5784],\n",
      "        [0.5737],\n",
      "        [0.5711],\n",
      "        [0.5691],\n",
      "        [0.5576],\n",
      "        [0.5546],\n",
      "        [0.5441],\n",
      "        [0.5340],\n",
      "        [0.5291],\n",
      "        [0.5216],\n",
      "        [0.5424],\n",
      "        [0.5231],\n",
      "        [0.5288],\n",
      "        [0.5689],\n",
      "        [0.5932],\n",
      "        [0.8579],\n",
      "        [0.8761],\n",
      "        [0.9196],\n",
      "        [0.8550],\n",
      "        [0.9399],\n",
      "        [0.9628],\n",
      "        [0.9136],\n",
      "        [0.9687],\n",
      "        [0.9786],\n",
      "        [1.0129],\n",
      "        [1.0340],\n",
      "        [1.0759],\n",
      "        [1.0163],\n",
      "        [1.0009],\n",
      "        [0.9657],\n",
      "        [0.9381],\n",
      "        [0.9204],\n",
      "        [0.8270],\n",
      "        [0.8606],\n",
      "        [0.8805],\n",
      "        [0.8411],\n",
      "        [0.8270],\n",
      "        [0.8551]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0137],\n",
      "        [    0.0207],\n",
      "        [    0.0106],\n",
      "        [    0.0057],\n",
      "        [    0.0194],\n",
      "        [    0.0127],\n",
      "        [    0.0152],\n",
      "        [    0.0212],\n",
      "        [    0.0312],\n",
      "        [    0.0140],\n",
      "        [    0.0075],\n",
      "        [    0.0000],\n",
      "        [    0.0039],\n",
      "        [    0.0014],\n",
      "        [    0.0272],\n",
      "        [    0.0182],\n",
      "        [    0.0037],\n",
      "        [    0.0027],\n",
      "        [    0.0254],\n",
      "        [    0.0540],\n",
      "        [    0.0625],\n",
      "        [    0.0775],\n",
      "        [    0.0103],\n",
      "        [    0.0109],\n",
      "        [    0.0193],\n",
      "        [    0.0611],\n",
      "        [    0.0307],\n",
      "        [    0.0019],\n",
      "        [    0.0373],\n",
      "        [    0.0413],\n",
      "        [    0.0968],\n",
      "        [    0.0191],\n",
      "        [    0.0175],\n",
      "        [    0.0143],\n",
      "        [    0.0293],\n",
      "        [    0.0234],\n",
      "        [    0.0620],\n",
      "        [    0.0535],\n",
      "        [    0.0562],\n",
      "        [    0.0748],\n",
      "        [    0.0263],\n",
      "        [    0.0003]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0160],\n",
      "        [0.0192],\n",
      "        [0.0137],\n",
      "        [0.0092],\n",
      "        [0.0158],\n",
      "        [0.0088],\n",
      "        [0.0112],\n",
      "        [0.0173],\n",
      "        [0.0272],\n",
      "        [0.0098],\n",
      "        [0.0041],\n",
      "        [0.0029],\n",
      "        [0.0067],\n",
      "        [0.0051],\n",
      "        [0.0269],\n",
      "        [0.0179],\n",
      "        [0.0039],\n",
      "        [0.0036],\n",
      "        [0.0211],\n",
      "        [0.0488],\n",
      "        [0.0573],\n",
      "        [0.0711],\n",
      "        [0.0044],\n",
      "        [0.0045],\n",
      "        [0.0265],\n",
      "        [0.0681],\n",
      "        [0.0390],\n",
      "        [0.0064],\n",
      "        [0.0292],\n",
      "        [0.0336],\n",
      "        [0.0901],\n",
      "        [0.0138],\n",
      "        [0.0141],\n",
      "        [0.0159],\n",
      "        [0.0294],\n",
      "        [0.0227],\n",
      "        [0.0582],\n",
      "        [0.0503],\n",
      "        [0.0531],\n",
      "        [0.0712],\n",
      "        [0.0219],\n",
      "        [0.0044]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 43\n",
      "剩餘X 資料 torch.Size([334, 18])\n",
      "剩餘Y 資料 torch.Size([334, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8454])\n",
      "目前模型的Data狀態 torch.Size([43, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5509],\n",
      "        [0.5457],\n",
      "        [0.5377],\n",
      "        [0.5546],\n",
      "        [0.5748],\n",
      "        [0.5698],\n",
      "        [0.5670],\n",
      "        [0.5653],\n",
      "        [0.5536],\n",
      "        [0.5504],\n",
      "        [0.5407],\n",
      "        [0.5311],\n",
      "        [0.5263],\n",
      "        [0.5180],\n",
      "        [0.5426],\n",
      "        [0.5234],\n",
      "        [0.5290],\n",
      "        [0.5680],\n",
      "        [0.5889],\n",
      "        [0.8528],\n",
      "        [0.8709],\n",
      "        [0.9133],\n",
      "        [0.8491],\n",
      "        [0.9335],\n",
      "        [0.9557],\n",
      "        [0.9066],\n",
      "        [0.9604],\n",
      "        [0.9703],\n",
      "        [1.0047],\n",
      "        [1.0263],\n",
      "        [1.0691],\n",
      "        [1.0111],\n",
      "        [0.9975],\n",
      "        [0.9641],\n",
      "        [0.9380],\n",
      "        [0.9210],\n",
      "        [0.8307],\n",
      "        [0.8638],\n",
      "        [0.8836],\n",
      "        [0.8447],\n",
      "        [0.8314],\n",
      "        [0.8592],\n",
      "        [0.8688]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0160],\n",
      "        [0.0192],\n",
      "        [0.0137],\n",
      "        [0.0092],\n",
      "        [0.0158],\n",
      "        [0.0088],\n",
      "        [0.0112],\n",
      "        [0.0173],\n",
      "        [0.0272],\n",
      "        [0.0098],\n",
      "        [0.0041],\n",
      "        [0.0029],\n",
      "        [0.0067],\n",
      "        [0.0051],\n",
      "        [0.0269],\n",
      "        [0.0179],\n",
      "        [0.0039],\n",
      "        [0.0036],\n",
      "        [0.0211],\n",
      "        [0.0488],\n",
      "        [0.0573],\n",
      "        [0.0711],\n",
      "        [0.0044],\n",
      "        [0.0045],\n",
      "        [0.0265],\n",
      "        [0.0681],\n",
      "        [0.0390],\n",
      "        [0.0064],\n",
      "        [0.0292],\n",
      "        [0.0336],\n",
      "        [0.0901],\n",
      "        [0.0138],\n",
      "        [0.0141],\n",
      "        [0.0159],\n",
      "        [0.0294],\n",
      "        [0.0227],\n",
      "        [0.0582],\n",
      "        [0.0503],\n",
      "        [0.0531],\n",
      "        [0.0712],\n",
      "        [0.0219],\n",
      "        [0.0044],\n",
      "        [0.0234]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0140],\n",
      "        [0.0217],\n",
      "        [0.0125],\n",
      "        [0.0080],\n",
      "        [0.0166],\n",
      "        [0.0093],\n",
      "        [0.0117],\n",
      "        [0.0179],\n",
      "        [0.0276],\n",
      "        [0.0101],\n",
      "        [0.0050],\n",
      "        [0.0016],\n",
      "        [0.0053],\n",
      "        [0.0044],\n",
      "        [0.0228],\n",
      "        [0.0136],\n",
      "        [0.0080],\n",
      "        [0.0007],\n",
      "        [0.0217],\n",
      "        [0.0494],\n",
      "        [0.0578],\n",
      "        [0.0708],\n",
      "        [0.0045],\n",
      "        [0.0042],\n",
      "        [0.0274],\n",
      "        [0.0689],\n",
      "        [0.0408],\n",
      "        [0.0080],\n",
      "        [0.0276],\n",
      "        [0.0324],\n",
      "        [0.0895],\n",
      "        [0.0143],\n",
      "        [0.0160],\n",
      "        [0.0127],\n",
      "        [0.0250],\n",
      "        [0.0179],\n",
      "        [0.0512],\n",
      "        [0.0436],\n",
      "        [0.0465],\n",
      "        [0.0641],\n",
      "        [0.0144],\n",
      "        [0.0117],\n",
      "        [0.0298]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 44\n",
      "剩餘X 資料 torch.Size([333, 18])\n",
      "剩餘Y 資料 torch.Size([333, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7929])\n",
      "目前模型的Data狀態 torch.Size([44, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5529],\n",
      "        [0.5482],\n",
      "        [0.5390],\n",
      "        [0.5558],\n",
      "        [0.5756],\n",
      "        [0.5704],\n",
      "        [0.5675],\n",
      "        [0.5658],\n",
      "        [0.5541],\n",
      "        [0.5507],\n",
      "        [0.5416],\n",
      "        [0.5324],\n",
      "        [0.5276],\n",
      "        [0.5186],\n",
      "        [0.5467],\n",
      "        [0.5277],\n",
      "        [0.5331],\n",
      "        [0.5709],\n",
      "        [0.5895],\n",
      "        [0.8534],\n",
      "        [0.8714],\n",
      "        [0.9129],\n",
      "        [0.8492],\n",
      "        [0.9331],\n",
      "        [0.9547],\n",
      "        [0.9059],\n",
      "        [0.9586],\n",
      "        [0.9687],\n",
      "        [1.0031],\n",
      "        [1.0251],\n",
      "        [1.0686],\n",
      "        [1.0116],\n",
      "        [0.9994],\n",
      "        [0.9673],\n",
      "        [0.9423],\n",
      "        [0.9259],\n",
      "        [0.8377],\n",
      "        [0.8705],\n",
      "        [0.8902],\n",
      "        [0.8518],\n",
      "        [0.8390],\n",
      "        [0.8664],\n",
      "        [0.8752],\n",
      "        [0.8641]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0140],\n",
      "        [0.0217],\n",
      "        [0.0125],\n",
      "        [0.0080],\n",
      "        [0.0166],\n",
      "        [0.0093],\n",
      "        [0.0117],\n",
      "        [0.0179],\n",
      "        [0.0276],\n",
      "        [0.0101],\n",
      "        [0.0050],\n",
      "        [0.0016],\n",
      "        [0.0053],\n",
      "        [0.0044],\n",
      "        [0.0228],\n",
      "        [0.0136],\n",
      "        [0.0080],\n",
      "        [0.0007],\n",
      "        [0.0217],\n",
      "        [0.0494],\n",
      "        [0.0578],\n",
      "        [0.0708],\n",
      "        [0.0045],\n",
      "        [0.0042],\n",
      "        [0.0274],\n",
      "        [0.0689],\n",
      "        [0.0408],\n",
      "        [0.0080],\n",
      "        [0.0276],\n",
      "        [0.0324],\n",
      "        [0.0895],\n",
      "        [0.0143],\n",
      "        [0.0160],\n",
      "        [0.0127],\n",
      "        [0.0250],\n",
      "        [0.0179],\n",
      "        [0.0512],\n",
      "        [0.0436],\n",
      "        [0.0465],\n",
      "        [0.0641],\n",
      "        [0.0144],\n",
      "        [0.0117],\n",
      "        [0.0298],\n",
      "        [0.0713]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0156],\n",
      "        [0.0207],\n",
      "        [0.0141],\n",
      "        [0.0097],\n",
      "        [0.0142],\n",
      "        [0.0067],\n",
      "        [0.0091],\n",
      "        [0.0155],\n",
      "        [0.0254],\n",
      "        [0.0079],\n",
      "        [0.0033],\n",
      "        [0.0030],\n",
      "        [0.0066],\n",
      "        [0.0061],\n",
      "        [0.0208],\n",
      "        [0.0114],\n",
      "        [0.0099],\n",
      "        [0.0002],\n",
      "        [0.0199],\n",
      "        [0.0456],\n",
      "        [0.0540],\n",
      "        [0.0663],\n",
      "        [0.0006],\n",
      "        [0.0004],\n",
      "        [0.0323],\n",
      "        [0.0733],\n",
      "        [0.0460],\n",
      "        [0.0132],\n",
      "        [0.0220],\n",
      "        [0.0268],\n",
      "        [0.0842],\n",
      "        [0.0096],\n",
      "        [0.0123],\n",
      "        [0.0154],\n",
      "        [0.0269],\n",
      "        [0.0195],\n",
      "        [0.0513],\n",
      "        [0.0439],\n",
      "        [0.0469],\n",
      "        [0.0641],\n",
      "        [0.0140],\n",
      "        [0.0119],\n",
      "        [0.0294],\n",
      "        [0.0709]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 45\n",
      "剩餘X 資料 torch.Size([332, 18])\n",
      "剩餘Y 資料 torch.Size([332, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8065])\n",
      "目前模型的Data狀態 torch.Size([45, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5513],\n",
      "        [0.5472],\n",
      "        [0.5374],\n",
      "        [0.5541],\n",
      "        [0.5732],\n",
      "        [0.5678],\n",
      "        [0.5649],\n",
      "        [0.5635],\n",
      "        [0.5518],\n",
      "        [0.5485],\n",
      "        [0.5399],\n",
      "        [0.5310],\n",
      "        [0.5264],\n",
      "        [0.5169],\n",
      "        [0.5488],\n",
      "        [0.5299],\n",
      "        [0.5350],\n",
      "        [0.5714],\n",
      "        [0.5877],\n",
      "        [0.8496],\n",
      "        [0.8675],\n",
      "        [0.9084],\n",
      "        [0.8453],\n",
      "        [0.9286],\n",
      "        [0.9498],\n",
      "        [0.9014],\n",
      "        [0.9534],\n",
      "        [0.9635],\n",
      "        [0.9975],\n",
      "        [1.0195],\n",
      "        [1.0632],\n",
      "        [1.0069],\n",
      "        [0.9957],\n",
      "        [0.9646],\n",
      "        [0.9405],\n",
      "        [0.9242],\n",
      "        [0.8377],\n",
      "        [0.8702],\n",
      "        [0.8898],\n",
      "        [0.8518],\n",
      "        [0.8394],\n",
      "        [0.8666],\n",
      "        [0.8749],\n",
      "        [0.8638],\n",
      "        [0.9032]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0156],\n",
      "        [0.0207],\n",
      "        [0.0141],\n",
      "        [0.0097],\n",
      "        [0.0142],\n",
      "        [0.0067],\n",
      "        [0.0091],\n",
      "        [0.0155],\n",
      "        [0.0254],\n",
      "        [0.0079],\n",
      "        [0.0033],\n",
      "        [0.0030],\n",
      "        [0.0066],\n",
      "        [0.0061],\n",
      "        [0.0208],\n",
      "        [0.0114],\n",
      "        [0.0099],\n",
      "        [0.0002],\n",
      "        [0.0199],\n",
      "        [0.0456],\n",
      "        [0.0540],\n",
      "        [0.0663],\n",
      "        [0.0006],\n",
      "        [0.0004],\n",
      "        [0.0323],\n",
      "        [0.0733],\n",
      "        [0.0460],\n",
      "        [0.0132],\n",
      "        [0.0220],\n",
      "        [0.0268],\n",
      "        [0.0842],\n",
      "        [0.0096],\n",
      "        [0.0123],\n",
      "        [0.0154],\n",
      "        [0.0269],\n",
      "        [0.0195],\n",
      "        [0.0513],\n",
      "        [0.0439],\n",
      "        [0.0469],\n",
      "        [0.0641],\n",
      "        [0.0140],\n",
      "        [0.0119],\n",
      "        [0.0294],\n",
      "        [0.0709],\n",
      "        [0.0966]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0170],\n",
      "        [0.0192],\n",
      "        [0.0153],\n",
      "        [0.0104],\n",
      "        [0.0124],\n",
      "        [0.0049],\n",
      "        [0.0073],\n",
      "        [0.0139],\n",
      "        [0.0241],\n",
      "        [0.0068],\n",
      "        [0.0023],\n",
      "        [0.0038],\n",
      "        [0.0073],\n",
      "        [0.0070],\n",
      "        [0.0184],\n",
      "        [0.0088],\n",
      "        [0.0122],\n",
      "        [0.0003],\n",
      "        [0.0196],\n",
      "        [0.0430],\n",
      "        [0.0511],\n",
      "        [0.0628],\n",
      "        [0.0022],\n",
      "        [0.0043],\n",
      "        [0.0366],\n",
      "        [0.0768],\n",
      "        [0.0503],\n",
      "        [0.0177],\n",
      "        [0.0171],\n",
      "        [0.0216],\n",
      "        [0.0787],\n",
      "        [0.0048],\n",
      "        [0.0082],\n",
      "        [0.0188],\n",
      "        [0.0297],\n",
      "        [0.0223],\n",
      "        [0.0527],\n",
      "        [0.0460],\n",
      "        [0.0491],\n",
      "        [0.0660],\n",
      "        [0.0158],\n",
      "        [0.0097],\n",
      "        [0.0270],\n",
      "        [0.0684],\n",
      "        [0.0934]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 46\n",
      "剩餘X 資料 torch.Size([331, 18])\n",
      "剩餘Y 資料 torch.Size([331, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8315])\n",
      "目前模型的Data狀態 torch.Size([46, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5499],\n",
      "        [0.5457],\n",
      "        [0.5361],\n",
      "        [0.5534],\n",
      "        [0.5714],\n",
      "        [0.5660],\n",
      "        [0.5631],\n",
      "        [0.5618],\n",
      "        [0.5505],\n",
      "        [0.5474],\n",
      "        [0.5390],\n",
      "        [0.5302],\n",
      "        [0.5256],\n",
      "        [0.5160],\n",
      "        [0.5511],\n",
      "        [0.5325],\n",
      "        [0.5373],\n",
      "        [0.5719],\n",
      "        [0.5874],\n",
      "        [0.8469],\n",
      "        [0.8647],\n",
      "        [0.9050],\n",
      "        [0.8425],\n",
      "        [0.9246],\n",
      "        [0.9455],\n",
      "        [0.8980],\n",
      "        [0.9491],\n",
      "        [0.9590],\n",
      "        [0.9926],\n",
      "        [1.0144],\n",
      "        [1.0578],\n",
      "        [1.0021],\n",
      "        [0.9915],\n",
      "        [0.9612],\n",
      "        [0.9376],\n",
      "        [0.9215],\n",
      "        [0.8362],\n",
      "        [0.8681],\n",
      "        [0.8876],\n",
      "        [0.8499],\n",
      "        [0.8376],\n",
      "        [0.8644],\n",
      "        [0.8725],\n",
      "        [0.8613],\n",
      "        [0.9000],\n",
      "        [0.9358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0170],\n",
      "        [0.0192],\n",
      "        [0.0153],\n",
      "        [0.0104],\n",
      "        [0.0124],\n",
      "        [0.0049],\n",
      "        [0.0073],\n",
      "        [0.0139],\n",
      "        [0.0241],\n",
      "        [0.0068],\n",
      "        [0.0023],\n",
      "        [0.0038],\n",
      "        [0.0073],\n",
      "        [0.0070],\n",
      "        [0.0184],\n",
      "        [0.0088],\n",
      "        [0.0122],\n",
      "        [0.0003],\n",
      "        [0.0196],\n",
      "        [0.0430],\n",
      "        [0.0511],\n",
      "        [0.0628],\n",
      "        [0.0022],\n",
      "        [0.0043],\n",
      "        [0.0366],\n",
      "        [0.0768],\n",
      "        [0.0503],\n",
      "        [0.0177],\n",
      "        [0.0171],\n",
      "        [0.0216],\n",
      "        [0.0787],\n",
      "        [0.0048],\n",
      "        [0.0082],\n",
      "        [0.0188],\n",
      "        [0.0297],\n",
      "        [0.0223],\n",
      "        [0.0527],\n",
      "        [0.0460],\n",
      "        [0.0491],\n",
      "        [0.0660],\n",
      "        [0.0158],\n",
      "        [0.0097],\n",
      "        [0.0270],\n",
      "        [0.0684],\n",
      "        [0.0934],\n",
      "        [0.1043]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0181],\n",
      "        [    0.0168],\n",
      "        [    0.0164],\n",
      "        [    0.0099],\n",
      "        [    0.0110],\n",
      "        [    0.0036],\n",
      "        [    0.0060],\n",
      "        [    0.0127],\n",
      "        [    0.0233],\n",
      "        [    0.0062],\n",
      "        [    0.0019],\n",
      "        [    0.0042],\n",
      "        [    0.0078],\n",
      "        [    0.0074],\n",
      "        [    0.0159],\n",
      "        [    0.0053],\n",
      "        [    0.0152],\n",
      "        [    0.0002],\n",
      "        [    0.0207],\n",
      "        [    0.0426],\n",
      "        [    0.0503],\n",
      "        [    0.0611],\n",
      "        [    0.0028],\n",
      "        [    0.0075],\n",
      "        [    0.0404],\n",
      "        [    0.0791],\n",
      "        [    0.0538],\n",
      "        [    0.0215],\n",
      "        [    0.0126],\n",
      "        [    0.0166],\n",
      "        [    0.0727],\n",
      "        [    0.0000],\n",
      "        [    0.0037],\n",
      "        [    0.0225],\n",
      "        [    0.0330],\n",
      "        [    0.0253],\n",
      "        [    0.0542],\n",
      "        [    0.0486],\n",
      "        [    0.0522],\n",
      "        [    0.0686],\n",
      "        [    0.0184],\n",
      "        [    0.0058],\n",
      "        [    0.0232],\n",
      "        [    0.0646],\n",
      "        [    0.0884],\n",
      "        [    0.0971]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 47\n",
      "剩餘X 資料 torch.Size([330, 18])\n",
      "剩餘Y 資料 torch.Size([330, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8036])\n",
      "目前模型的Data狀態 torch.Size([47, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5488],\n",
      "        [0.5433],\n",
      "        [0.5350],\n",
      "        [0.5539],\n",
      "        [0.5700],\n",
      "        [0.5647],\n",
      "        [0.5618],\n",
      "        [0.5606],\n",
      "        [0.5498],\n",
      "        [0.5468],\n",
      "        [0.5385],\n",
      "        [0.5298],\n",
      "        [0.5251],\n",
      "        [0.5156],\n",
      "        [0.5536],\n",
      "        [0.5360],\n",
      "        [0.5402],\n",
      "        [0.5714],\n",
      "        [0.5885],\n",
      "        [0.8465],\n",
      "        [0.8638],\n",
      "        [0.9032],\n",
      "        [0.8419],\n",
      "        [0.9214],\n",
      "        [0.9417],\n",
      "        [0.8956],\n",
      "        [0.9456],\n",
      "        [0.9552],\n",
      "        [0.9881],\n",
      "        [1.0094],\n",
      "        [1.0518],\n",
      "        [0.9973],\n",
      "        [0.9871],\n",
      "        [0.9575],\n",
      "        [0.9343],\n",
      "        [0.9185],\n",
      "        [0.8348],\n",
      "        [0.8655],\n",
      "        [0.8845],\n",
      "        [0.8473],\n",
      "        [0.8349],\n",
      "        [0.8606],\n",
      "        [0.8687],\n",
      "        [0.8575],\n",
      "        [0.8949],\n",
      "        [0.9287],\n",
      "        [0.8966]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0181],\n",
      "        [    0.0168],\n",
      "        [    0.0164],\n",
      "        [    0.0099],\n",
      "        [    0.0110],\n",
      "        [    0.0036],\n",
      "        [    0.0060],\n",
      "        [    0.0127],\n",
      "        [    0.0233],\n",
      "        [    0.0062],\n",
      "        [    0.0019],\n",
      "        [    0.0042],\n",
      "        [    0.0078],\n",
      "        [    0.0074],\n",
      "        [    0.0159],\n",
      "        [    0.0053],\n",
      "        [    0.0152],\n",
      "        [    0.0002],\n",
      "        [    0.0207],\n",
      "        [    0.0426],\n",
      "        [    0.0503],\n",
      "        [    0.0611],\n",
      "        [    0.0028],\n",
      "        [    0.0075],\n",
      "        [    0.0404],\n",
      "        [    0.0791],\n",
      "        [    0.0538],\n",
      "        [    0.0215],\n",
      "        [    0.0126],\n",
      "        [    0.0166],\n",
      "        [    0.0727],\n",
      "        [    0.0000],\n",
      "        [    0.0037],\n",
      "        [    0.0225],\n",
      "        [    0.0330],\n",
      "        [    0.0253],\n",
      "        [    0.0542],\n",
      "        [    0.0486],\n",
      "        [    0.0522],\n",
      "        [    0.0686],\n",
      "        [    0.0184],\n",
      "        [    0.0058],\n",
      "        [    0.0232],\n",
      "        [    0.0646],\n",
      "        [    0.0884],\n",
      "        [    0.0971],\n",
      "        [    0.0930]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0189],\n",
      "        [0.0143],\n",
      "        [0.0173],\n",
      "        [0.0087],\n",
      "        [0.0100],\n",
      "        [0.0028],\n",
      "        [0.0052],\n",
      "        [0.0120],\n",
      "        [0.0230],\n",
      "        [0.0061],\n",
      "        [0.0016],\n",
      "        [0.0045],\n",
      "        [0.0084],\n",
      "        [0.0078],\n",
      "        [0.0147],\n",
      "        [0.0028],\n",
      "        [0.0172],\n",
      "        [0.0018],\n",
      "        [0.0225],\n",
      "        [0.0444],\n",
      "        [0.0516],\n",
      "        [0.0614],\n",
      "        [0.0015],\n",
      "        [0.0088],\n",
      "        [0.0425],\n",
      "        [0.0799],\n",
      "        [0.0556],\n",
      "        [0.0237],\n",
      "        [0.0097],\n",
      "        [0.0134],\n",
      "        [0.0684],\n",
      "        [0.0030],\n",
      "        [0.0008],\n",
      "        [0.0248],\n",
      "        [0.0351],\n",
      "        [0.0271],\n",
      "        [0.0545],\n",
      "        [0.0503],\n",
      "        [0.0545],\n",
      "        [0.0704],\n",
      "        [0.0205],\n",
      "        [0.0024],\n",
      "        [0.0199],\n",
      "        [0.0612],\n",
      "        [0.0837],\n",
      "        [0.0900],\n",
      "        [0.0862]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 48\n",
      "剩餘X 資料 torch.Size([329, 18])\n",
      "剩餘Y 資料 torch.Size([329, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8492])\n",
      "目前模型的Data狀態 torch.Size([48, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5480],\n",
      "        [0.5408],\n",
      "        [0.5342],\n",
      "        [0.5551],\n",
      "        [0.5690],\n",
      "        [0.5639],\n",
      "        [0.5610],\n",
      "        [0.5599],\n",
      "        [0.5495],\n",
      "        [0.5467],\n",
      "        [0.5382],\n",
      "        [0.5295],\n",
      "        [0.5246],\n",
      "        [0.5152],\n",
      "        [0.5549],\n",
      "        [0.5385],\n",
      "        [0.5422],\n",
      "        [0.5698],\n",
      "        [0.5902],\n",
      "        [0.8484],\n",
      "        [0.8652],\n",
      "        [0.9035],\n",
      "        [0.8432],\n",
      "        [0.9201],\n",
      "        [0.9396],\n",
      "        [0.8948],\n",
      "        [0.9438],\n",
      "        [0.9530],\n",
      "        [0.9852],\n",
      "        [1.0061],\n",
      "        [1.0474],\n",
      "        [0.9942],\n",
      "        [0.9842],\n",
      "        [0.9552],\n",
      "        [0.9323],\n",
      "        [0.9167],\n",
      "        [0.8344],\n",
      "        [0.8638],\n",
      "        [0.8822],\n",
      "        [0.8455],\n",
      "        [0.8328],\n",
      "        [0.8571],\n",
      "        [0.8653],\n",
      "        [0.8541],\n",
      "        [0.8902],\n",
      "        [0.9216],\n",
      "        [0.8899],\n",
      "        [0.8594]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0189],\n",
      "        [0.0143],\n",
      "        [0.0173],\n",
      "        [0.0087],\n",
      "        [0.0100],\n",
      "        [0.0028],\n",
      "        [0.0052],\n",
      "        [0.0120],\n",
      "        [0.0230],\n",
      "        [0.0061],\n",
      "        [0.0016],\n",
      "        [0.0045],\n",
      "        [0.0084],\n",
      "        [0.0078],\n",
      "        [0.0147],\n",
      "        [0.0028],\n",
      "        [0.0172],\n",
      "        [0.0018],\n",
      "        [0.0225],\n",
      "        [0.0444],\n",
      "        [0.0516],\n",
      "        [0.0614],\n",
      "        [0.0015],\n",
      "        [0.0088],\n",
      "        [0.0425],\n",
      "        [0.0799],\n",
      "        [0.0556],\n",
      "        [0.0237],\n",
      "        [0.0097],\n",
      "        [0.0134],\n",
      "        [0.0684],\n",
      "        [0.0030],\n",
      "        [0.0008],\n",
      "        [0.0248],\n",
      "        [0.0351],\n",
      "        [0.0271],\n",
      "        [0.0545],\n",
      "        [0.0503],\n",
      "        [0.0545],\n",
      "        [0.0704],\n",
      "        [0.0205],\n",
      "        [0.0024],\n",
      "        [0.0199],\n",
      "        [0.0612],\n",
      "        [0.0837],\n",
      "        [0.0900],\n",
      "        [0.0862],\n",
      "        [0.0102]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0193],\n",
      "        [0.0123],\n",
      "        [0.0178],\n",
      "        [0.0072],\n",
      "        [0.0095],\n",
      "        [0.0025],\n",
      "        [0.0048],\n",
      "        [0.0118],\n",
      "        [0.0230],\n",
      "        [0.0062],\n",
      "        [0.0015],\n",
      "        [0.0047],\n",
      "        [0.0089],\n",
      "        [0.0082],\n",
      "        [0.0150],\n",
      "        [0.0020],\n",
      "        [0.0176],\n",
      "        [0.0045],\n",
      "        [0.0236],\n",
      "        [0.0474],\n",
      "        [0.0542],\n",
      "        [0.0631],\n",
      "        [0.0009],\n",
      "        [0.0086],\n",
      "        [0.0428],\n",
      "        [0.0793],\n",
      "        [0.0559],\n",
      "        [0.0243],\n",
      "        [0.0087],\n",
      "        [0.0122],\n",
      "        [0.0664],\n",
      "        [0.0038],\n",
      "        [0.0003],\n",
      "        [0.0249],\n",
      "        [0.0350],\n",
      "        [0.0267],\n",
      "        [0.0530],\n",
      "        [0.0500],\n",
      "        [0.0546],\n",
      "        [0.0703],\n",
      "        [0.0206],\n",
      "        [0.0011],\n",
      "        [0.0186],\n",
      "        [0.0598],\n",
      "        [0.0813],\n",
      "        [0.0855],\n",
      "        [0.0818],\n",
      "        [0.0063]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 49\n",
      "剩餘X 資料 torch.Size([328, 18])\n",
      "剩餘Y 資料 torch.Size([328, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8295])\n",
      "目前模型的Data狀態 torch.Size([49, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5476],\n",
      "        [0.5388],\n",
      "        [0.5336],\n",
      "        [0.5565],\n",
      "        [0.5685],\n",
      "        [0.5635],\n",
      "        [0.5607],\n",
      "        [0.5597],\n",
      "        [0.5495],\n",
      "        [0.5468],\n",
      "        [0.5381],\n",
      "        [0.5293],\n",
      "        [0.5240],\n",
      "        [0.5148],\n",
      "        [0.5545],\n",
      "        [0.5393],\n",
      "        [0.5426],\n",
      "        [0.5671],\n",
      "        [0.5914],\n",
      "        [0.8514],\n",
      "        [0.8677],\n",
      "        [0.9052],\n",
      "        [0.8456],\n",
      "        [0.9203],\n",
      "        [0.9393],\n",
      "        [0.8954],\n",
      "        [0.9435],\n",
      "        [0.9524],\n",
      "        [0.9842],\n",
      "        [1.0049],\n",
      "        [1.0454],\n",
      "        [0.9935],\n",
      "        [0.9836],\n",
      "        [0.9551],\n",
      "        [0.9323],\n",
      "        [0.9171],\n",
      "        [0.8360],\n",
      "        [0.8641],\n",
      "        [0.8820],\n",
      "        [0.8456],\n",
      "        [0.8327],\n",
      "        [0.8558],\n",
      "        [0.8641],\n",
      "        [0.8527],\n",
      "        [0.8878],\n",
      "        [0.9171],\n",
      "        [0.8855],\n",
      "        [0.8555],\n",
      "        [0.8799]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0193],\n",
      "        [0.0123],\n",
      "        [0.0178],\n",
      "        [0.0072],\n",
      "        [0.0095],\n",
      "        [0.0025],\n",
      "        [0.0048],\n",
      "        [0.0118],\n",
      "        [0.0230],\n",
      "        [0.0062],\n",
      "        [0.0015],\n",
      "        [0.0047],\n",
      "        [0.0089],\n",
      "        [0.0082],\n",
      "        [0.0150],\n",
      "        [0.0020],\n",
      "        [0.0176],\n",
      "        [0.0045],\n",
      "        [0.0236],\n",
      "        [0.0474],\n",
      "        [0.0542],\n",
      "        [0.0631],\n",
      "        [0.0009],\n",
      "        [0.0086],\n",
      "        [0.0428],\n",
      "        [0.0793],\n",
      "        [0.0559],\n",
      "        [0.0243],\n",
      "        [0.0087],\n",
      "        [0.0122],\n",
      "        [0.0664],\n",
      "        [0.0038],\n",
      "        [0.0003],\n",
      "        [0.0249],\n",
      "        [0.0350],\n",
      "        [0.0267],\n",
      "        [0.0530],\n",
      "        [0.0500],\n",
      "        [0.0546],\n",
      "        [0.0703],\n",
      "        [0.0206],\n",
      "        [0.0011],\n",
      "        [0.0186],\n",
      "        [0.0598],\n",
      "        [0.0813],\n",
      "        [0.0855],\n",
      "        [0.0818],\n",
      "        [0.0063],\n",
      "        [0.0504]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0212],\n",
      "        [    0.0087],\n",
      "        [    0.0198],\n",
      "        [    0.0073],\n",
      "        [    0.0074],\n",
      "        [    0.0005],\n",
      "        [    0.0029],\n",
      "        [    0.0099],\n",
      "        [    0.0215],\n",
      "        [    0.0047],\n",
      "        [    0.0001],\n",
      "        [    0.0064],\n",
      "        [    0.0109],\n",
      "        [    0.0100],\n",
      "        [    0.0171],\n",
      "        [    0.0029],\n",
      "        [    0.0163],\n",
      "        [    0.0090],\n",
      "        [    0.0233],\n",
      "        [    0.0479],\n",
      "        [    0.0541],\n",
      "        [    0.0619],\n",
      "        [    0.0006],\n",
      "        [    0.0113],\n",
      "        [    0.0461],\n",
      "        [    0.0816],\n",
      "        [    0.0591],\n",
      "        [    0.0278],\n",
      "        [    0.0046],\n",
      "        [    0.0078],\n",
      "        [    0.0611],\n",
      "        [    0.0077],\n",
      "        [    0.0035],\n",
      "        [    0.0280],\n",
      "        [    0.0381],\n",
      "        [    0.0294],\n",
      "        [    0.0543],\n",
      "        [    0.0527],\n",
      "        [    0.0578],\n",
      "        [    0.0730],\n",
      "        [    0.0236],\n",
      "        [    0.0032],\n",
      "        [    0.0144],\n",
      "        [    0.0555],\n",
      "        [    0.0759],\n",
      "        [    0.0778],\n",
      "        [    0.0744],\n",
      "        [    0.0007],\n",
      "        [    0.0430]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 50\n",
      "剩餘X 資料 torch.Size([327, 18])\n",
      "剩餘Y 資料 torch.Size([327, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8496])\n",
      "目前模型的Data狀態 torch.Size([50, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5457],\n",
      "        [0.5352],\n",
      "        [0.5316],\n",
      "        [0.5564],\n",
      "        [0.5664],\n",
      "        [0.5616],\n",
      "        [0.5587],\n",
      "        [0.5579],\n",
      "        [0.5479],\n",
      "        [0.5453],\n",
      "        [0.5366],\n",
      "        [0.5276],\n",
      "        [0.5220],\n",
      "        [0.5130],\n",
      "        [0.5525],\n",
      "        [0.5384],\n",
      "        [0.5414],\n",
      "        [0.5626],\n",
      "        [0.5911],\n",
      "        [0.8518],\n",
      "        [0.8676],\n",
      "        [0.9041],\n",
      "        [0.8453],\n",
      "        [0.9177],\n",
      "        [0.9360],\n",
      "        [0.8932],\n",
      "        [0.9404],\n",
      "        [0.9489],\n",
      "        [0.9802],\n",
      "        [1.0006],\n",
      "        [1.0401],\n",
      "        [0.9895],\n",
      "        [0.9798],\n",
      "        [0.9520],\n",
      "        [0.9293],\n",
      "        [0.9144],\n",
      "        [0.8347],\n",
      "        [0.8614],\n",
      "        [0.8789],\n",
      "        [0.8429],\n",
      "        [0.8298],\n",
      "        [0.8516],\n",
      "        [0.8598],\n",
      "        [0.8483],\n",
      "        [0.8824],\n",
      "        [0.9094],\n",
      "        [0.8780],\n",
      "        [0.8485],\n",
      "        [0.8726],\n",
      "        [0.8777]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0212],\n",
      "        [    0.0087],\n",
      "        [    0.0198],\n",
      "        [    0.0073],\n",
      "        [    0.0074],\n",
      "        [    0.0005],\n",
      "        [    0.0029],\n",
      "        [    0.0099],\n",
      "        [    0.0215],\n",
      "        [    0.0047],\n",
      "        [    0.0001],\n",
      "        [    0.0064],\n",
      "        [    0.0109],\n",
      "        [    0.0100],\n",
      "        [    0.0171],\n",
      "        [    0.0029],\n",
      "        [    0.0163],\n",
      "        [    0.0090],\n",
      "        [    0.0233],\n",
      "        [    0.0479],\n",
      "        [    0.0541],\n",
      "        [    0.0619],\n",
      "        [    0.0006],\n",
      "        [    0.0113],\n",
      "        [    0.0461],\n",
      "        [    0.0816],\n",
      "        [    0.0591],\n",
      "        [    0.0278],\n",
      "        [    0.0046],\n",
      "        [    0.0078],\n",
      "        [    0.0611],\n",
      "        [    0.0077],\n",
      "        [    0.0035],\n",
      "        [    0.0280],\n",
      "        [    0.0381],\n",
      "        [    0.0294],\n",
      "        [    0.0543],\n",
      "        [    0.0527],\n",
      "        [    0.0578],\n",
      "        [    0.0730],\n",
      "        [    0.0236],\n",
      "        [    0.0032],\n",
      "        [    0.0144],\n",
      "        [    0.0555],\n",
      "        [    0.0759],\n",
      "        [    0.0778],\n",
      "        [    0.0744],\n",
      "        [    0.0007],\n",
      "        [    0.0430],\n",
      "        [    0.0281]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0201],\n",
      "        [0.0083],\n",
      "        [0.0189],\n",
      "        [0.0046],\n",
      "        [0.0085],\n",
      "        [0.0017],\n",
      "        [0.0041],\n",
      "        [0.0112],\n",
      "        [0.0229],\n",
      "        [0.0062],\n",
      "        [0.0012],\n",
      "        [0.0053],\n",
      "        [0.0102],\n",
      "        [0.0092],\n",
      "        [0.0169],\n",
      "        [0.0018],\n",
      "        [0.0173],\n",
      "        [0.0108],\n",
      "        [0.0258],\n",
      "        [0.0522],\n",
      "        [0.0579],\n",
      "        [0.0648],\n",
      "        [0.0040],\n",
      "        [0.0097],\n",
      "        [0.0450],\n",
      "        [0.0798],\n",
      "        [0.0580],\n",
      "        [0.0270],\n",
      "        [0.0051],\n",
      "        [0.0081],\n",
      "        [0.0607],\n",
      "        [0.0068],\n",
      "        [0.0025],\n",
      "        [0.0265],\n",
      "        [0.0366],\n",
      "        [0.0276],\n",
      "        [0.0513],\n",
      "        [0.0509],\n",
      "        [0.0564],\n",
      "        [0.0714],\n",
      "        [0.0222],\n",
      "        [0.0029],\n",
      "        [0.0146],\n",
      "        [0.0556],\n",
      "        [0.0752],\n",
      "        [0.0752],\n",
      "        [0.0717],\n",
      "        [0.0030],\n",
      "        [0.0403],\n",
      "        [0.0251]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 51\n",
      "剩餘X 資料 torch.Size([326, 18])\n",
      "剩餘Y 資料 torch.Size([326, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8043])\n",
      "目前模型的Data狀態 torch.Size([51, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5469],\n",
      "        [0.5348],\n",
      "        [0.5326],\n",
      "        [0.5591],\n",
      "        [0.5675],\n",
      "        [0.5628],\n",
      "        [0.5599],\n",
      "        [0.5591],\n",
      "        [0.5494],\n",
      "        [0.5467],\n",
      "        [0.5378],\n",
      "        [0.5287],\n",
      "        [0.5227],\n",
      "        [0.5139],\n",
      "        [0.5526],\n",
      "        [0.5395],\n",
      "        [0.5423],\n",
      "        [0.5608],\n",
      "        [0.5936],\n",
      "        [0.8561],\n",
      "        [0.8714],\n",
      "        [0.9070],\n",
      "        [0.8487],\n",
      "        [0.9193],\n",
      "        [0.9372],\n",
      "        [0.8949],\n",
      "        [0.9414],\n",
      "        [0.9497],\n",
      "        [0.9806],\n",
      "        [1.0009],\n",
      "        [1.0398],\n",
      "        [0.9905],\n",
      "        [0.9809],\n",
      "        [0.9536],\n",
      "        [0.9307],\n",
      "        [0.9162],\n",
      "        [0.8377],\n",
      "        [0.8632],\n",
      "        [0.8803],\n",
      "        [0.8446],\n",
      "        [0.8312],\n",
      "        [0.8519],\n",
      "        [0.8600],\n",
      "        [0.8485],\n",
      "        [0.8817],\n",
      "        [0.9067],\n",
      "        [0.8754],\n",
      "        [0.8462],\n",
      "        [0.8699],\n",
      "        [0.8747],\n",
      "        [0.8441]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0201],\n",
      "        [0.0083],\n",
      "        [0.0189],\n",
      "        [0.0046],\n",
      "        [0.0085],\n",
      "        [0.0017],\n",
      "        [0.0041],\n",
      "        [0.0112],\n",
      "        [0.0229],\n",
      "        [0.0062],\n",
      "        [0.0012],\n",
      "        [0.0053],\n",
      "        [0.0102],\n",
      "        [0.0092],\n",
      "        [0.0169],\n",
      "        [0.0018],\n",
      "        [0.0173],\n",
      "        [0.0108],\n",
      "        [0.0258],\n",
      "        [0.0522],\n",
      "        [0.0579],\n",
      "        [0.0648],\n",
      "        [0.0040],\n",
      "        [0.0097],\n",
      "        [0.0450],\n",
      "        [0.0798],\n",
      "        [0.0580],\n",
      "        [0.0270],\n",
      "        [0.0051],\n",
      "        [0.0081],\n",
      "        [0.0607],\n",
      "        [0.0068],\n",
      "        [0.0025],\n",
      "        [0.0265],\n",
      "        [0.0366],\n",
      "        [0.0276],\n",
      "        [0.0513],\n",
      "        [0.0509],\n",
      "        [0.0564],\n",
      "        [0.0714],\n",
      "        [0.0222],\n",
      "        [0.0029],\n",
      "        [0.0146],\n",
      "        [0.0556],\n",
      "        [0.0752],\n",
      "        [0.0752],\n",
      "        [0.0717],\n",
      "        [0.0030],\n",
      "        [0.0403],\n",
      "        [0.0251],\n",
      "        [0.0398]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0202],\n",
      "        [0.0067],\n",
      "        [0.0191],\n",
      "        [0.0033],\n",
      "        [0.0083],\n",
      "        [0.0015],\n",
      "        [0.0040],\n",
      "        [0.0112],\n",
      "        [0.0231],\n",
      "        [0.0063],\n",
      "        [0.0012],\n",
      "        [0.0055],\n",
      "        [0.0107],\n",
      "        [0.0095],\n",
      "        [0.0178],\n",
      "        [0.0017],\n",
      "        [0.0172],\n",
      "        [0.0138],\n",
      "        [0.0272],\n",
      "        [0.0545],\n",
      "        [0.0597],\n",
      "        [0.0659],\n",
      "        [0.0055],\n",
      "        [0.0098],\n",
      "        [0.0455],\n",
      "        [0.0798],\n",
      "        [0.0586],\n",
      "        [0.0278],\n",
      "        [0.0039],\n",
      "        [0.0068],\n",
      "        [0.0589],\n",
      "        [0.0075],\n",
      "        [0.0032],\n",
      "        [0.0268],\n",
      "        [0.0370],\n",
      "        [0.0277],\n",
      "        [0.0503],\n",
      "        [0.0509],\n",
      "        [0.0567],\n",
      "        [0.0714],\n",
      "        [0.0224],\n",
      "        [0.0042],\n",
      "        [0.0131],\n",
      "        [0.0540],\n",
      "        [0.0729],\n",
      "        [0.0711],\n",
      "        [0.0676],\n",
      "        [0.0069],\n",
      "        [0.0362],\n",
      "        [0.0208],\n",
      "        [0.0357]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 52\n",
      "剩餘X 資料 torch.Size([325, 18])\n",
      "剩餘Y 資料 torch.Size([325, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8094])\n",
      "目前模型的Data狀態 torch.Size([52, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5468],\n",
      "        [0.5332],\n",
      "        [0.5323],\n",
      "        [0.5604],\n",
      "        [0.5673],\n",
      "        [0.5626],\n",
      "        [0.5598],\n",
      "        [0.5592],\n",
      "        [0.5495],\n",
      "        [0.5469],\n",
      "        [0.5378],\n",
      "        [0.5285],\n",
      "        [0.5222],\n",
      "        [0.5135],\n",
      "        [0.5517],\n",
      "        [0.5396],\n",
      "        [0.5423],\n",
      "        [0.5578],\n",
      "        [0.5949],\n",
      "        [0.8585],\n",
      "        [0.8733],\n",
      "        [0.9080],\n",
      "        [0.8502],\n",
      "        [0.9192],\n",
      "        [0.9366],\n",
      "        [0.8950],\n",
      "        [0.9408],\n",
      "        [0.9489],\n",
      "        [0.9795],\n",
      "        [0.9996],\n",
      "        [1.0380],\n",
      "        [0.9898],\n",
      "        [0.9801],\n",
      "        [0.9532],\n",
      "        [0.9303],\n",
      "        [0.9161],\n",
      "        [0.8387],\n",
      "        [0.8632],\n",
      "        [0.8800],\n",
      "        [0.8445],\n",
      "        [0.8309],\n",
      "        [0.8506],\n",
      "        [0.8586],\n",
      "        [0.8469],\n",
      "        [0.8794],\n",
      "        [0.9026],\n",
      "        [0.8713],\n",
      "        [0.8423],\n",
      "        [0.8658],\n",
      "        [0.8703],\n",
      "        [0.8399],\n",
      "        [0.8864]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0202],\n",
      "        [0.0067],\n",
      "        [0.0191],\n",
      "        [0.0033],\n",
      "        [0.0083],\n",
      "        [0.0015],\n",
      "        [0.0040],\n",
      "        [0.0112],\n",
      "        [0.0231],\n",
      "        [0.0063],\n",
      "        [0.0012],\n",
      "        [0.0055],\n",
      "        [0.0107],\n",
      "        [0.0095],\n",
      "        [0.0178],\n",
      "        [0.0017],\n",
      "        [0.0172],\n",
      "        [0.0138],\n",
      "        [0.0272],\n",
      "        [0.0545],\n",
      "        [0.0597],\n",
      "        [0.0659],\n",
      "        [0.0055],\n",
      "        [0.0098],\n",
      "        [0.0455],\n",
      "        [0.0798],\n",
      "        [0.0586],\n",
      "        [0.0278],\n",
      "        [0.0039],\n",
      "        [0.0068],\n",
      "        [0.0589],\n",
      "        [0.0075],\n",
      "        [0.0032],\n",
      "        [0.0268],\n",
      "        [0.0370],\n",
      "        [0.0277],\n",
      "        [0.0503],\n",
      "        [0.0509],\n",
      "        [0.0567],\n",
      "        [0.0714],\n",
      "        [0.0224],\n",
      "        [0.0042],\n",
      "        [0.0131],\n",
      "        [0.0540],\n",
      "        [0.0729],\n",
      "        [0.0711],\n",
      "        [0.0676],\n",
      "        [0.0069],\n",
      "        [0.0362],\n",
      "        [0.0208],\n",
      "        [0.0357],\n",
      "        [0.0769]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0213],\n",
      "        [    0.0038],\n",
      "        [    0.0203],\n",
      "        [    0.0034],\n",
      "        [    0.0068],\n",
      "        [    0.0001],\n",
      "        [    0.0028],\n",
      "        [    0.0102],\n",
      "        [    0.0221],\n",
      "        [    0.0053],\n",
      "        [    0.0000],\n",
      "        [    0.0067],\n",
      "        [    0.0123],\n",
      "        [    0.0109],\n",
      "        [    0.0202],\n",
      "        [    0.0029],\n",
      "        [    0.0159],\n",
      "        [    0.0185],\n",
      "        [    0.0277],\n",
      "        [    0.0548],\n",
      "        [    0.0591],\n",
      "        [    0.0643],\n",
      "        [    0.0047],\n",
      "        [    0.0125],\n",
      "        [    0.0487],\n",
      "        [    0.0823],\n",
      "        [    0.0620],\n",
      "        [    0.0315],\n",
      "        [    0.0001],\n",
      "        [    0.0026],\n",
      "        [    0.0540],\n",
      "        [    0.0110],\n",
      "        [    0.0071],\n",
      "        [    0.0302],\n",
      "        [    0.0405],\n",
      "        [    0.0307],\n",
      "        [    0.0516],\n",
      "        [    0.0535],\n",
      "        [    0.0596],\n",
      "        [    0.0738],\n",
      "        [    0.0250],\n",
      "        [    0.0081],\n",
      "        [    0.0089],\n",
      "        [    0.0498],\n",
      "        [    0.0678],\n",
      "        [    0.0639],\n",
      "        [    0.0605],\n",
      "        [    0.0136],\n",
      "        [    0.0290],\n",
      "        [    0.0132],\n",
      "        [    0.0282],\n",
      "        [    0.0686]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 53\n",
      "剩餘X 資料 torch.Size([324, 18])\n",
      "剩餘Y 資料 torch.Size([324, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8200])\n",
      "目前模型的Data狀態 torch.Size([53, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5456],\n",
      "        [0.5303],\n",
      "        [0.5311],\n",
      "        [0.5603],\n",
      "        [0.5658],\n",
      "        [0.5612],\n",
      "        [0.5586],\n",
      "        [0.5581],\n",
      "        [0.5485],\n",
      "        [0.5458],\n",
      "        [0.5366],\n",
      "        [0.5273],\n",
      "        [0.5206],\n",
      "        [0.5121],\n",
      "        [0.5493],\n",
      "        [0.5384],\n",
      "        [0.5410],\n",
      "        [0.5531],\n",
      "        [0.5954],\n",
      "        [0.8587],\n",
      "        [0.8727],\n",
      "        [0.9065],\n",
      "        [0.8494],\n",
      "        [0.9164],\n",
      "        [0.9334],\n",
      "        [0.8924],\n",
      "        [0.9374],\n",
      "        [0.9452],\n",
      "        [0.9754],\n",
      "        [0.9953],\n",
      "        [1.0330],\n",
      "        [0.9863],\n",
      "        [0.9763],\n",
      "        [0.9499],\n",
      "        [0.9269],\n",
      "        [0.9131],\n",
      "        [0.8373],\n",
      "        [0.8606],\n",
      "        [0.8771],\n",
      "        [0.8421],\n",
      "        [0.8283],\n",
      "        [0.8466],\n",
      "        [0.8544],\n",
      "        [0.8426],\n",
      "        [0.8744],\n",
      "        [0.8954],\n",
      "        [0.8641],\n",
      "        [0.8356],\n",
      "        [0.8586],\n",
      "        [0.8627],\n",
      "        [0.8325],\n",
      "        [0.8781],\n",
      "        [0.9233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0213],\n",
      "        [    0.0038],\n",
      "        [    0.0203],\n",
      "        [    0.0034],\n",
      "        [    0.0068],\n",
      "        [    0.0001],\n",
      "        [    0.0028],\n",
      "        [    0.0102],\n",
      "        [    0.0221],\n",
      "        [    0.0053],\n",
      "        [    0.0000],\n",
      "        [    0.0067],\n",
      "        [    0.0123],\n",
      "        [    0.0109],\n",
      "        [    0.0202],\n",
      "        [    0.0029],\n",
      "        [    0.0159],\n",
      "        [    0.0185],\n",
      "        [    0.0277],\n",
      "        [    0.0548],\n",
      "        [    0.0591],\n",
      "        [    0.0643],\n",
      "        [    0.0047],\n",
      "        [    0.0125],\n",
      "        [    0.0487],\n",
      "        [    0.0823],\n",
      "        [    0.0620],\n",
      "        [    0.0315],\n",
      "        [    0.0001],\n",
      "        [    0.0026],\n",
      "        [    0.0540],\n",
      "        [    0.0110],\n",
      "        [    0.0071],\n",
      "        [    0.0302],\n",
      "        [    0.0405],\n",
      "        [    0.0307],\n",
      "        [    0.0516],\n",
      "        [    0.0535],\n",
      "        [    0.0596],\n",
      "        [    0.0738],\n",
      "        [    0.0250],\n",
      "        [    0.0081],\n",
      "        [    0.0089],\n",
      "        [    0.0498],\n",
      "        [    0.0678],\n",
      "        [    0.0639],\n",
      "        [    0.0605],\n",
      "        [    0.0136],\n",
      "        [    0.0290],\n",
      "        [    0.0132],\n",
      "        [    0.0282],\n",
      "        [    0.0686],\n",
      "        [    0.1034]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0207],\n",
      "        [0.0025],\n",
      "        [0.0198],\n",
      "        [0.0021],\n",
      "        [0.0072],\n",
      "        [0.0005],\n",
      "        [0.0034],\n",
      "        [0.0112],\n",
      "        [0.0229],\n",
      "        [0.0059],\n",
      "        [0.0005],\n",
      "        [0.0064],\n",
      "        [0.0124],\n",
      "        [0.0107],\n",
      "        [0.0219],\n",
      "        [0.0030],\n",
      "        [0.0159],\n",
      "        [0.0223],\n",
      "        [0.0305],\n",
      "        [0.0571],\n",
      "        [0.0604],\n",
      "        [0.0643],\n",
      "        [0.0054],\n",
      "        [0.0138],\n",
      "        [0.0507],\n",
      "        [0.0838],\n",
      "        [0.0648],\n",
      "        [0.0344],\n",
      "        [0.0034],\n",
      "        [0.0008],\n",
      "        [0.0499],\n",
      "        [0.0131],\n",
      "        [0.0097],\n",
      "        [0.0323],\n",
      "        [0.0428],\n",
      "        [0.0323],\n",
      "        [0.0508],\n",
      "        [0.0543],\n",
      "        [0.0607],\n",
      "        [0.0744],\n",
      "        [0.0257],\n",
      "        [0.0106],\n",
      "        [0.0060],\n",
      "        [0.0468],\n",
      "        [0.0640],\n",
      "        [0.0576],\n",
      "        [0.0541],\n",
      "        [0.0197],\n",
      "        [0.0223],\n",
      "        [0.0059],\n",
      "        [0.0209],\n",
      "        [0.0602],\n",
      "        [0.0932]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 54\n",
      "剩餘X 資料 torch.Size([323, 18])\n",
      "剩餘Y 資料 torch.Size([323, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8145])\n",
      "目前模型的Data狀態 torch.Size([54, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5462],\n",
      "        [0.5290],\n",
      "        [0.5316],\n",
      "        [0.5617],\n",
      "        [0.5662],\n",
      "        [0.5616],\n",
      "        [0.5593],\n",
      "        [0.5591],\n",
      "        [0.5494],\n",
      "        [0.5465],\n",
      "        [0.5371],\n",
      "        [0.5276],\n",
      "        [0.5205],\n",
      "        [0.5123],\n",
      "        [0.5477],\n",
      "        [0.5383],\n",
      "        [0.5410],\n",
      "        [0.5493],\n",
      "        [0.5983],\n",
      "        [0.8611],\n",
      "        [0.8740],\n",
      "        [0.9064],\n",
      "        [0.8501],\n",
      "        [0.9152],\n",
      "        [0.9314],\n",
      "        [0.8909],\n",
      "        [0.9347],\n",
      "        [0.9423],\n",
      "        [0.9721],\n",
      "        [0.9919],\n",
      "        [1.0290],\n",
      "        [0.9842],\n",
      "        [0.9737],\n",
      "        [0.9477],\n",
      "        [0.9246],\n",
      "        [0.9115],\n",
      "        [0.8382],\n",
      "        [0.8598],\n",
      "        [0.8760],\n",
      "        [0.8415],\n",
      "        [0.8277],\n",
      "        [0.8442],\n",
      "        [0.8515],\n",
      "        [0.8396],\n",
      "        [0.8705],\n",
      "        [0.8891],\n",
      "        [0.8577],\n",
      "        [0.8295],\n",
      "        [0.8519],\n",
      "        [0.8554],\n",
      "        [0.8251],\n",
      "        [0.8696],\n",
      "        [0.9132],\n",
      "        [0.9343]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0207],\n",
      "        [0.0025],\n",
      "        [0.0198],\n",
      "        [0.0021],\n",
      "        [0.0072],\n",
      "        [0.0005],\n",
      "        [0.0034],\n",
      "        [0.0112],\n",
      "        [0.0229],\n",
      "        [0.0059],\n",
      "        [0.0005],\n",
      "        [0.0064],\n",
      "        [0.0124],\n",
      "        [0.0107],\n",
      "        [0.0219],\n",
      "        [0.0030],\n",
      "        [0.0159],\n",
      "        [0.0223],\n",
      "        [0.0305],\n",
      "        [0.0571],\n",
      "        [0.0604],\n",
      "        [0.0643],\n",
      "        [0.0054],\n",
      "        [0.0138],\n",
      "        [0.0507],\n",
      "        [0.0838],\n",
      "        [0.0648],\n",
      "        [0.0344],\n",
      "        [0.0034],\n",
      "        [0.0008],\n",
      "        [0.0499],\n",
      "        [0.0131],\n",
      "        [0.0097],\n",
      "        [0.0323],\n",
      "        [0.0428],\n",
      "        [0.0323],\n",
      "        [0.0508],\n",
      "        [0.0543],\n",
      "        [0.0607],\n",
      "        [0.0744],\n",
      "        [0.0257],\n",
      "        [0.0106],\n",
      "        [0.0060],\n",
      "        [0.0468],\n",
      "        [0.0640],\n",
      "        [0.0576],\n",
      "        [0.0541],\n",
      "        [0.0197],\n",
      "        [0.0223],\n",
      "        [0.0059],\n",
      "        [0.0209],\n",
      "        [0.0602],\n",
      "        [0.0932],\n",
      "        [0.1199]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0212],\n",
      "        [    0.0001],\n",
      "        [    0.0201],\n",
      "        [    0.0019],\n",
      "        [    0.0069],\n",
      "        [    0.0001],\n",
      "        [    0.0035],\n",
      "        [    0.0116],\n",
      "        [    0.0231],\n",
      "        [    0.0058],\n",
      "        [    0.0000],\n",
      "        [    0.0072],\n",
      "        [    0.0137],\n",
      "        [    0.0116],\n",
      "        [    0.0255],\n",
      "        [    0.0046],\n",
      "        [    0.0146],\n",
      "        [    0.0279],\n",
      "        [    0.0331],\n",
      "        [    0.0590],\n",
      "        [    0.0611],\n",
      "        [    0.0631],\n",
      "        [    0.0050],\n",
      "        [    0.0165],\n",
      "        [    0.0542],\n",
      "        [    0.0872],\n",
      "        [    0.0698],\n",
      "        [    0.0399],\n",
      "        [    0.0092],\n",
      "        [    0.0065],\n",
      "        [    0.0435],\n",
      "        [    0.0166],\n",
      "        [    0.0139],\n",
      "        [    0.0361],\n",
      "        [    0.0468],\n",
      "        [    0.0351],\n",
      "        [    0.0502],\n",
      "        [    0.0560],\n",
      "        [    0.0628],\n",
      "        [    0.0758],\n",
      "        [    0.0272],\n",
      "        [    0.0143],\n",
      "        [    0.0015],\n",
      "        [    0.0422],\n",
      "        [    0.0583],\n",
      "        [    0.0490],\n",
      "        [    0.0454],\n",
      "        [    0.0281],\n",
      "        [    0.0131],\n",
      "        [    0.0042],\n",
      "        [    0.0108],\n",
      "        [    0.0485],\n",
      "        [    0.0793],\n",
      "        [    0.1048]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 55\n",
      "剩餘X 資料 torch.Size([322, 18])\n",
      "剩餘Y 資料 torch.Size([322, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8400])\n",
      "目前模型的Data狀態 torch.Size([55, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5457],\n",
      "        [0.5266],\n",
      "        [0.5313],\n",
      "        [0.5618],\n",
      "        [0.5658],\n",
      "        [0.5612],\n",
      "        [0.5593],\n",
      "        [0.5596],\n",
      "        [0.5496],\n",
      "        [0.5464],\n",
      "        [0.5366],\n",
      "        [0.5268],\n",
      "        [0.5193],\n",
      "        [0.5115],\n",
      "        [0.5441],\n",
      "        [0.5367],\n",
      "        [0.5397],\n",
      "        [0.5438],\n",
      "        [0.6009],\n",
      "        [0.8630],\n",
      "        [0.8746],\n",
      "        [0.9052],\n",
      "        [0.8497],\n",
      "        [0.9124],\n",
      "        [0.9279],\n",
      "        [0.8876],\n",
      "        [0.9296],\n",
      "        [0.9368],\n",
      "        [0.9663],\n",
      "        [0.9862],\n",
      "        [1.0225],\n",
      "        [0.9807],\n",
      "        [0.9694],\n",
      "        [0.9440],\n",
      "        [0.9205],\n",
      "        [0.9087],\n",
      "        [0.8387],\n",
      "        [0.8581],\n",
      "        [0.8738],\n",
      "        [0.8401],\n",
      "        [0.8262],\n",
      "        [0.8404],\n",
      "        [0.8470],\n",
      "        [0.8351],\n",
      "        [0.8648],\n",
      "        [0.8806],\n",
      "        [0.8490],\n",
      "        [0.8211],\n",
      "        [0.8427],\n",
      "        [0.8454],\n",
      "        [0.8150],\n",
      "        [0.8579],\n",
      "        [0.8993],\n",
      "        [0.9192],\n",
      "        [0.9301]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0212],\n",
      "        [    0.0001],\n",
      "        [    0.0201],\n",
      "        [    0.0019],\n",
      "        [    0.0069],\n",
      "        [    0.0001],\n",
      "        [    0.0035],\n",
      "        [    0.0116],\n",
      "        [    0.0231],\n",
      "        [    0.0058],\n",
      "        [    0.0000],\n",
      "        [    0.0072],\n",
      "        [    0.0137],\n",
      "        [    0.0116],\n",
      "        [    0.0255],\n",
      "        [    0.0046],\n",
      "        [    0.0146],\n",
      "        [    0.0279],\n",
      "        [    0.0331],\n",
      "        [    0.0590],\n",
      "        [    0.0611],\n",
      "        [    0.0631],\n",
      "        [    0.0050],\n",
      "        [    0.0165],\n",
      "        [    0.0542],\n",
      "        [    0.0872],\n",
      "        [    0.0698],\n",
      "        [    0.0399],\n",
      "        [    0.0092],\n",
      "        [    0.0065],\n",
      "        [    0.0435],\n",
      "        [    0.0166],\n",
      "        [    0.0139],\n",
      "        [    0.0361],\n",
      "        [    0.0468],\n",
      "        [    0.0351],\n",
      "        [    0.0502],\n",
      "        [    0.0560],\n",
      "        [    0.0628],\n",
      "        [    0.0758],\n",
      "        [    0.0272],\n",
      "        [    0.0143],\n",
      "        [    0.0015],\n",
      "        [    0.0422],\n",
      "        [    0.0583],\n",
      "        [    0.0490],\n",
      "        [    0.0454],\n",
      "        [    0.0281],\n",
      "        [    0.0131],\n",
      "        [    0.0042],\n",
      "        [    0.0108],\n",
      "        [    0.0485],\n",
      "        [    0.0793],\n",
      "        [    0.1048],\n",
      "        [    0.0901]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0203],\n",
      "        [0.0012],\n",
      "        [0.0192],\n",
      "        [0.0006],\n",
      "        [0.0077],\n",
      "        [0.0009],\n",
      "        [0.0046],\n",
      "        [0.0132],\n",
      "        [0.0243],\n",
      "        [0.0066],\n",
      "        [0.0004],\n",
      "        [0.0069],\n",
      "        [0.0139],\n",
      "        [0.0114],\n",
      "        [0.0273],\n",
      "        [0.0044],\n",
      "        [0.0152],\n",
      "        [0.0318],\n",
      "        [0.0370],\n",
      "        [0.0638],\n",
      "        [0.0646],\n",
      "        [0.0649],\n",
      "        [0.0076],\n",
      "        [0.0162],\n",
      "        [0.0548],\n",
      "        [0.0876],\n",
      "        [0.0718],\n",
      "        [0.0424],\n",
      "        [0.0117],\n",
      "        [0.0090],\n",
      "        [0.0404],\n",
      "        [0.0169],\n",
      "        [0.0152],\n",
      "        [0.0370],\n",
      "        [0.0480],\n",
      "        [0.0351],\n",
      "        [0.0470],\n",
      "        [0.0548],\n",
      "        [0.0622],\n",
      "        [0.0745],\n",
      "        [0.0260],\n",
      "        [0.0154],\n",
      "        [0.0002],\n",
      "        [0.0405],\n",
      "        [0.0554],\n",
      "        [0.0432],\n",
      "        [0.0394],\n",
      "        [0.0338],\n",
      "        [0.0066],\n",
      "        [0.0116],\n",
      "        [0.0032],\n",
      "        [0.0395],\n",
      "        [0.0681],\n",
      "        [0.0924],\n",
      "        [0.0766]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 56\n",
      "剩餘X 資料 torch.Size([321, 18])\n",
      "剩餘Y 資料 torch.Size([321, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8425])\n",
      "目前模型的Data狀態 torch.Size([56, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5466],\n",
      "        [0.5253],\n",
      "        [0.5322],\n",
      "        [0.5632],\n",
      "        [0.5667],\n",
      "        [0.5620],\n",
      "        [0.5604],\n",
      "        [0.5611],\n",
      "        [0.5507],\n",
      "        [0.5472],\n",
      "        [0.5371],\n",
      "        [0.5271],\n",
      "        [0.5190],\n",
      "        [0.5116],\n",
      "        [0.5422],\n",
      "        [0.5369],\n",
      "        [0.5402],\n",
      "        [0.5398],\n",
      "        [0.6048],\n",
      "        [0.8678],\n",
      "        [0.8782],\n",
      "        [0.9071],\n",
      "        [0.8523],\n",
      "        [0.9127],\n",
      "        [0.9273],\n",
      "        [0.8871],\n",
      "        [0.9276],\n",
      "        [0.9343],\n",
      "        [0.9638],\n",
      "        [0.9838],\n",
      "        [1.0195],\n",
      "        [0.9803],\n",
      "        [0.9681],\n",
      "        [0.9430],\n",
      "        [0.9194],\n",
      "        [0.9087],\n",
      "        [0.8419],\n",
      "        [0.8593],\n",
      "        [0.8745],\n",
      "        [0.8414],\n",
      "        [0.8274],\n",
      "        [0.8394],\n",
      "        [0.8452],\n",
      "        [0.8333],\n",
      "        [0.8619],\n",
      "        [0.8748],\n",
      "        [0.8430],\n",
      "        [0.8154],\n",
      "        [0.8361],\n",
      "        [0.8380],\n",
      "        [0.8074],\n",
      "        [0.8489],\n",
      "        [0.8881],\n",
      "        [0.9069],\n",
      "        [0.9166],\n",
      "        [0.9248]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0203],\n",
      "        [0.0012],\n",
      "        [0.0192],\n",
      "        [0.0006],\n",
      "        [0.0077],\n",
      "        [0.0009],\n",
      "        [0.0046],\n",
      "        [0.0132],\n",
      "        [0.0243],\n",
      "        [0.0066],\n",
      "        [0.0004],\n",
      "        [0.0069],\n",
      "        [0.0139],\n",
      "        [0.0114],\n",
      "        [0.0273],\n",
      "        [0.0044],\n",
      "        [0.0152],\n",
      "        [0.0318],\n",
      "        [0.0370],\n",
      "        [0.0638],\n",
      "        [0.0646],\n",
      "        [0.0649],\n",
      "        [0.0076],\n",
      "        [0.0162],\n",
      "        [0.0548],\n",
      "        [0.0876],\n",
      "        [0.0718],\n",
      "        [0.0424],\n",
      "        [0.0117],\n",
      "        [0.0090],\n",
      "        [0.0404],\n",
      "        [0.0169],\n",
      "        [0.0152],\n",
      "        [0.0370],\n",
      "        [0.0480],\n",
      "        [0.0351],\n",
      "        [0.0470],\n",
      "        [0.0548],\n",
      "        [0.0622],\n",
      "        [0.0745],\n",
      "        [0.0260],\n",
      "        [0.0154],\n",
      "        [0.0002],\n",
      "        [0.0405],\n",
      "        [0.0554],\n",
      "        [0.0432],\n",
      "        [0.0394],\n",
      "        [0.0338],\n",
      "        [0.0066],\n",
      "        [0.0116],\n",
      "        [0.0032],\n",
      "        [0.0395],\n",
      "        [0.0681],\n",
      "        [0.0924],\n",
      "        [0.0766],\n",
      "        [0.0823]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0172],\n",
      "        [0.0002],\n",
      "        [0.0161],\n",
      "        [0.0030],\n",
      "        [0.0109],\n",
      "        [0.0041],\n",
      "        [0.0081],\n",
      "        [0.0170],\n",
      "        [0.0276],\n",
      "        [0.0095],\n",
      "        [0.0030],\n",
      "        [0.0046],\n",
      "        [0.0121],\n",
      "        [0.0092],\n",
      "        [0.0272],\n",
      "        [0.0023],\n",
      "        [0.0177],\n",
      "        [0.0335],\n",
      "        [0.0429],\n",
      "        [0.0721],\n",
      "        [0.0717],\n",
      "        [0.0705],\n",
      "        [0.0135],\n",
      "        [0.0122],\n",
      "        [0.0516],\n",
      "        [0.0845],\n",
      "        [0.0701],\n",
      "        [0.0410],\n",
      "        [0.0102],\n",
      "        [0.0074],\n",
      "        [0.0416],\n",
      "        [0.0133],\n",
      "        [0.0126],\n",
      "        [0.0341],\n",
      "        [0.0454],\n",
      "        [0.0314],\n",
      "        [0.0405],\n",
      "        [0.0501],\n",
      "        [0.0580],\n",
      "        [0.0697],\n",
      "        [0.0214],\n",
      "        [0.0129],\n",
      "        [0.0017],\n",
      "        [0.0422],\n",
      "        [0.0562],\n",
      "        [0.0413],\n",
      "        [0.0371],\n",
      "        [0.0360],\n",
      "        [0.0037],\n",
      "        [0.0152],\n",
      "        [0.0008],\n",
      "        [0.0342],\n",
      "        [0.0609],\n",
      "        [0.0843],\n",
      "        [0.0672],\n",
      "        [0.0720]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 57\n",
      "剩餘X 資料 torch.Size([320, 18])\n",
      "剩餘Y 資料 torch.Size([320, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8635])\n",
      "目前模型的Data狀態 torch.Size([57, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5497],\n",
      "        [0.5263],\n",
      "        [0.5354],\n",
      "        [0.5668],\n",
      "        [0.5699],\n",
      "        [0.5652],\n",
      "        [0.5639],\n",
      "        [0.5649],\n",
      "        [0.5541],\n",
      "        [0.5501],\n",
      "        [0.5397],\n",
      "        [0.5294],\n",
      "        [0.5209],\n",
      "        [0.5139],\n",
      "        [0.5424],\n",
      "        [0.5390],\n",
      "        [0.5428],\n",
      "        [0.5381],\n",
      "        [0.6107],\n",
      "        [0.8760],\n",
      "        [0.8852],\n",
      "        [0.9126],\n",
      "        [0.8582],\n",
      "        [0.9167],\n",
      "        [0.9306],\n",
      "        [0.8902],\n",
      "        [0.9293],\n",
      "        [0.9357],\n",
      "        [0.9653],\n",
      "        [0.9854],\n",
      "        [1.0206],\n",
      "        [0.9840],\n",
      "        [0.9708],\n",
      "        [0.9459],\n",
      "        [0.9219],\n",
      "        [0.9123],\n",
      "        [0.8485],\n",
      "        [0.8640],\n",
      "        [0.8787],\n",
      "        [0.8462],\n",
      "        [0.8320],\n",
      "        [0.8419],\n",
      "        [0.8471],\n",
      "        [0.8351],\n",
      "        [0.8627],\n",
      "        [0.8728],\n",
      "        [0.8408],\n",
      "        [0.8132],\n",
      "        [0.8332],\n",
      "        [0.8344],\n",
      "        [0.8034],\n",
      "        [0.8437],\n",
      "        [0.8809],\n",
      "        [0.8987],\n",
      "        [0.9072],\n",
      "        [0.9145],\n",
      "        [0.9076]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0172],\n",
      "        [0.0002],\n",
      "        [0.0161],\n",
      "        [0.0030],\n",
      "        [0.0109],\n",
      "        [0.0041],\n",
      "        [0.0081],\n",
      "        [0.0170],\n",
      "        [0.0276],\n",
      "        [0.0095],\n",
      "        [0.0030],\n",
      "        [0.0046],\n",
      "        [0.0121],\n",
      "        [0.0092],\n",
      "        [0.0272],\n",
      "        [0.0023],\n",
      "        [0.0177],\n",
      "        [0.0335],\n",
      "        [0.0429],\n",
      "        [0.0721],\n",
      "        [0.0717],\n",
      "        [0.0705],\n",
      "        [0.0135],\n",
      "        [0.0122],\n",
      "        [0.0516],\n",
      "        [0.0845],\n",
      "        [0.0701],\n",
      "        [0.0410],\n",
      "        [0.0102],\n",
      "        [0.0074],\n",
      "        [0.0416],\n",
      "        [0.0133],\n",
      "        [0.0126],\n",
      "        [0.0341],\n",
      "        [0.0454],\n",
      "        [0.0314],\n",
      "        [0.0405],\n",
      "        [0.0501],\n",
      "        [0.0580],\n",
      "        [0.0697],\n",
      "        [0.0214],\n",
      "        [0.0129],\n",
      "        [0.0017],\n",
      "        [0.0422],\n",
      "        [0.0562],\n",
      "        [0.0413],\n",
      "        [0.0371],\n",
      "        [0.0360],\n",
      "        [0.0037],\n",
      "        [0.0152],\n",
      "        [0.0008],\n",
      "        [0.0342],\n",
      "        [0.0609],\n",
      "        [0.0843],\n",
      "        [0.0672],\n",
      "        [0.0720],\n",
      "        [0.0441]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0038],\n",
      "        [0.0179],\n",
      "        [0.0014],\n",
      "        [0.0090],\n",
      "        [0.0022],\n",
      "        [0.0064],\n",
      "        [0.0155],\n",
      "        [0.0258],\n",
      "        [0.0075],\n",
      "        [0.0009],\n",
      "        [0.0069],\n",
      "        [0.0147],\n",
      "        [0.0115],\n",
      "        [0.0303],\n",
      "        [0.0038],\n",
      "        [0.0164],\n",
      "        [0.0385],\n",
      "        [0.0433],\n",
      "        [0.0735],\n",
      "        [0.0722],\n",
      "        [0.0698],\n",
      "        [0.0134],\n",
      "        [0.0141],\n",
      "        [0.0541],\n",
      "        [0.0869],\n",
      "        [0.0736],\n",
      "        [0.0448],\n",
      "        [0.0140],\n",
      "        [0.0111],\n",
      "        [0.0374],\n",
      "        [0.0156],\n",
      "        [0.0157],\n",
      "        [0.0371],\n",
      "        [0.0485],\n",
      "        [0.0338],\n",
      "        [0.0404],\n",
      "        [0.0515],\n",
      "        [0.0597],\n",
      "        [0.0710],\n",
      "        [0.0227],\n",
      "        [0.0159],\n",
      "        [0.0018],\n",
      "        [0.0388],\n",
      "        [0.0518],\n",
      "        [0.0347],\n",
      "        [0.0304],\n",
      "        [0.0424],\n",
      "        [0.0033],\n",
      "        [0.0227],\n",
      "        [0.0087],\n",
      "        [0.0253],\n",
      "        [0.0504],\n",
      "        [0.0729],\n",
      "        [0.0548],\n",
      "        [0.0590],\n",
      "        [0.0315]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 58\n",
      "剩餘X 資料 torch.Size([319, 18])\n",
      "剩餘Y 資料 torch.Size([319, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9530])\n",
      "目前模型的Data狀態 torch.Size([58, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5228],\n",
      "        [0.5335],\n",
      "        [0.5651],\n",
      "        [0.5680],\n",
      "        [0.5633],\n",
      "        [0.5622],\n",
      "        [0.5635],\n",
      "        [0.5523],\n",
      "        [0.5481],\n",
      "        [0.5375],\n",
      "        [0.5271],\n",
      "        [0.5182],\n",
      "        [0.5115],\n",
      "        [0.5392],\n",
      "        [0.5375],\n",
      "        [0.5414],\n",
      "        [0.5331],\n",
      "        [0.6110],\n",
      "        [0.8775],\n",
      "        [0.8857],\n",
      "        [0.9119],\n",
      "        [0.8581],\n",
      "        [0.9148],\n",
      "        [0.9280],\n",
      "        [0.8879],\n",
      "        [0.9258],\n",
      "        [0.9319],\n",
      "        [0.9615],\n",
      "        [0.9816],\n",
      "        [1.0164],\n",
      "        [0.9817],\n",
      "        [0.9677],\n",
      "        [0.9429],\n",
      "        [0.9188],\n",
      "        [0.9100],\n",
      "        [0.8485],\n",
      "        [0.8626],\n",
      "        [0.8769],\n",
      "        [0.8449],\n",
      "        [0.8307],\n",
      "        [0.8388],\n",
      "        [0.8436],\n",
      "        [0.8316],\n",
      "        [0.8584],\n",
      "        [0.8663],\n",
      "        [0.8341],\n",
      "        [0.8068],\n",
      "        [0.8262],\n",
      "        [0.8268],\n",
      "        [0.7955],\n",
      "        [0.8347],\n",
      "        [0.8704],\n",
      "        [0.8874],\n",
      "        [0.8949],\n",
      "        [0.9015],\n",
      "        [0.8950],\n",
      "        [0.8945]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0038],\n",
      "        [0.0179],\n",
      "        [0.0014],\n",
      "        [0.0090],\n",
      "        [0.0022],\n",
      "        [0.0064],\n",
      "        [0.0155],\n",
      "        [0.0258],\n",
      "        [0.0075],\n",
      "        [0.0009],\n",
      "        [0.0069],\n",
      "        [0.0147],\n",
      "        [0.0115],\n",
      "        [0.0303],\n",
      "        [0.0038],\n",
      "        [0.0164],\n",
      "        [0.0385],\n",
      "        [0.0433],\n",
      "        [0.0735],\n",
      "        [0.0722],\n",
      "        [0.0698],\n",
      "        [0.0134],\n",
      "        [0.0141],\n",
      "        [0.0541],\n",
      "        [0.0869],\n",
      "        [0.0736],\n",
      "        [0.0448],\n",
      "        [0.0140],\n",
      "        [0.0111],\n",
      "        [0.0374],\n",
      "        [0.0156],\n",
      "        [0.0157],\n",
      "        [0.0371],\n",
      "        [0.0485],\n",
      "        [0.0338],\n",
      "        [0.0404],\n",
      "        [0.0515],\n",
      "        [0.0597],\n",
      "        [0.0710],\n",
      "        [0.0227],\n",
      "        [0.0159],\n",
      "        [0.0018],\n",
      "        [0.0388],\n",
      "        [0.0518],\n",
      "        [0.0347],\n",
      "        [0.0304],\n",
      "        [0.0424],\n",
      "        [0.0033],\n",
      "        [0.0227],\n",
      "        [0.0087],\n",
      "        [0.0253],\n",
      "        [0.0504],\n",
      "        [0.0729],\n",
      "        [0.0548],\n",
      "        [0.0590],\n",
      "        [0.0315],\n",
      "        [0.0585]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0171],\n",
      "        [0.0030],\n",
      "        [0.0161],\n",
      "        [0.0037],\n",
      "        [0.0111],\n",
      "        [0.0042],\n",
      "        [0.0085],\n",
      "        [0.0179],\n",
      "        [0.0278],\n",
      "        [0.0094],\n",
      "        [0.0026],\n",
      "        [0.0053],\n",
      "        [0.0134],\n",
      "        [0.0102],\n",
      "        [0.0282],\n",
      "        [0.0008],\n",
      "        [0.0194],\n",
      "        [0.0380],\n",
      "        [0.0472],\n",
      "        [0.0806],\n",
      "        [0.0788],\n",
      "        [0.0760],\n",
      "        [0.0194],\n",
      "        [0.0086],\n",
      "        [0.0488],\n",
      "        [0.0816],\n",
      "        [0.0687],\n",
      "        [0.0399],\n",
      "        [0.0087],\n",
      "        [0.0056],\n",
      "        [0.0430],\n",
      "        [0.0093],\n",
      "        [0.0100],\n",
      "        [0.0316],\n",
      "        [0.0431],\n",
      "        [0.0280],\n",
      "        [0.0338],\n",
      "        [0.0454],\n",
      "        [0.0537],\n",
      "        [0.0649],\n",
      "        [0.0169],\n",
      "        [0.0109],\n",
      "        [0.0030],\n",
      "        [0.0434],\n",
      "        [0.0560],\n",
      "        [0.0377],\n",
      "        [0.0331],\n",
      "        [0.0398],\n",
      "        [0.0008],\n",
      "        [0.0205],\n",
      "        [0.0071],\n",
      "        [0.0267],\n",
      "        [0.0511],\n",
      "        [0.0735],\n",
      "        [0.0549],\n",
      "        [0.0589],\n",
      "        [0.0316],\n",
      "        [0.0585]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 59\n",
      "剩餘X 資料 torch.Size([318, 18])\n",
      "剩餘Y 資料 torch.Size([318, 1])\n",
      "現在要進去模型的數據，y= tensor([1.])\n",
      "目前模型的Data狀態 torch.Size([59, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5498],\n",
      "        [0.5235],\n",
      "        [0.5353],\n",
      "        [0.5674],\n",
      "        [0.5701],\n",
      "        [0.5653],\n",
      "        [0.5643],\n",
      "        [0.5658],\n",
      "        [0.5543],\n",
      "        [0.5500],\n",
      "        [0.5392],\n",
      "        [0.5287],\n",
      "        [0.5195],\n",
      "        [0.5128],\n",
      "        [0.5414],\n",
      "        [0.5405],\n",
      "        [0.5445],\n",
      "        [0.5336],\n",
      "        [0.6149],\n",
      "        [0.8846],\n",
      "        [0.8924],\n",
      "        [0.9182],\n",
      "        [0.8641],\n",
      "        [0.9204],\n",
      "        [0.9333],\n",
      "        [0.8931],\n",
      "        [0.9307],\n",
      "        [0.9368],\n",
      "        [0.9668],\n",
      "        [0.9871],\n",
      "        [1.0221],\n",
      "        [0.9880],\n",
      "        [0.9733],\n",
      "        [0.9485],\n",
      "        [0.9242],\n",
      "        [0.9158],\n",
      "        [0.8552],\n",
      "        [0.8687],\n",
      "        [0.8830],\n",
      "        [0.8510],\n",
      "        [0.8365],\n",
      "        [0.8438],\n",
      "        [0.8484],\n",
      "        [0.8362],\n",
      "        [0.8626],\n",
      "        [0.8693],\n",
      "        [0.8368],\n",
      "        [0.8094],\n",
      "        [0.8288],\n",
      "        [0.8291],\n",
      "        [0.7972],\n",
      "        [0.8361],\n",
      "        [0.8711],\n",
      "        [0.8879],\n",
      "        [0.8949],\n",
      "        [0.9014],\n",
      "        [0.8951],\n",
      "        [0.8944],\n",
      "        [0.8776]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0171],\n",
      "        [0.0030],\n",
      "        [0.0161],\n",
      "        [0.0037],\n",
      "        [0.0111],\n",
      "        [0.0042],\n",
      "        [0.0085],\n",
      "        [0.0179],\n",
      "        [0.0278],\n",
      "        [0.0094],\n",
      "        [0.0026],\n",
      "        [0.0053],\n",
      "        [0.0134],\n",
      "        [0.0102],\n",
      "        [0.0282],\n",
      "        [0.0008],\n",
      "        [0.0194],\n",
      "        [0.0380],\n",
      "        [0.0472],\n",
      "        [0.0806],\n",
      "        [0.0788],\n",
      "        [0.0760],\n",
      "        [0.0194],\n",
      "        [0.0086],\n",
      "        [0.0488],\n",
      "        [0.0816],\n",
      "        [0.0687],\n",
      "        [0.0399],\n",
      "        [0.0087],\n",
      "        [0.0056],\n",
      "        [0.0430],\n",
      "        [0.0093],\n",
      "        [0.0100],\n",
      "        [0.0316],\n",
      "        [0.0431],\n",
      "        [0.0280],\n",
      "        [0.0338],\n",
      "        [0.0454],\n",
      "        [0.0537],\n",
      "        [0.0649],\n",
      "        [0.0169],\n",
      "        [0.0109],\n",
      "        [0.0030],\n",
      "        [0.0434],\n",
      "        [0.0560],\n",
      "        [0.0377],\n",
      "        [0.0331],\n",
      "        [0.0398],\n",
      "        [0.0008],\n",
      "        [0.0205],\n",
      "        [0.0071],\n",
      "        [0.0267],\n",
      "        [0.0511],\n",
      "        [0.0735],\n",
      "        [0.0549],\n",
      "        [0.0589],\n",
      "        [0.0316],\n",
      "        [0.0585],\n",
      "        [0.1224]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0176],\n",
      "        [0.0039],\n",
      "        [0.0165],\n",
      "        [0.0034],\n",
      "        [0.0103],\n",
      "        [0.0033],\n",
      "        [0.0076],\n",
      "        [0.0171],\n",
      "        [0.0268],\n",
      "        [0.0086],\n",
      "        [0.0019],\n",
      "        [0.0059],\n",
      "        [0.0140],\n",
      "        [0.0112],\n",
      "        [0.0265],\n",
      "        [0.0012],\n",
      "        [0.0210],\n",
      "        [0.0379],\n",
      "        [0.0472],\n",
      "        [0.0828],\n",
      "        [0.0810],\n",
      "        [0.0784],\n",
      "        [0.0215],\n",
      "        [0.0065],\n",
      "        [0.0466],\n",
      "        [0.0791],\n",
      "        [0.0659],\n",
      "        [0.0370],\n",
      "        [0.0054],\n",
      "        [0.0023],\n",
      "        [0.0464],\n",
      "        [0.0063],\n",
      "        [0.0073],\n",
      "        [0.0291],\n",
      "        [0.0404],\n",
      "        [0.0255],\n",
      "        [0.0312],\n",
      "        [0.0425],\n",
      "        [0.0507],\n",
      "        [0.0621],\n",
      "        [0.0141],\n",
      "        [0.0082],\n",
      "        [0.0057],\n",
      "        [0.0459],\n",
      "        [0.0585],\n",
      "        [0.0397],\n",
      "        [0.0352],\n",
      "        [0.0377],\n",
      "        [0.0015],\n",
      "        [0.0181],\n",
      "        [0.0053],\n",
      "        [0.0286],\n",
      "        [0.0530],\n",
      "        [0.0756],\n",
      "        [0.0568],\n",
      "        [0.0613],\n",
      "        [0.0340],\n",
      "        [0.0560],\n",
      "        [0.1199]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 60\n",
      "剩餘X 資料 torch.Size([317, 18])\n",
      "剩餘Y 資料 torch.Size([317, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9685])\n",
      "目前模型的Data狀態 torch.Size([60, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5493],\n",
      "        [0.5226],\n",
      "        [0.5349],\n",
      "        [0.5672],\n",
      "        [0.5693],\n",
      "        [0.5644],\n",
      "        [0.5635],\n",
      "        [0.5650],\n",
      "        [0.5533],\n",
      "        [0.5491],\n",
      "        [0.5385],\n",
      "        [0.5281],\n",
      "        [0.5189],\n",
      "        [0.5118],\n",
      "        [0.5431],\n",
      "        [0.5424],\n",
      "        [0.5460],\n",
      "        [0.5337],\n",
      "        [0.6150],\n",
      "        [0.8868],\n",
      "        [0.8946],\n",
      "        [0.9205],\n",
      "        [0.8662],\n",
      "        [0.9225],\n",
      "        [0.9355],\n",
      "        [0.8957],\n",
      "        [0.9335],\n",
      "        [0.9397],\n",
      "        [0.9701],\n",
      "        [0.9904],\n",
      "        [1.0255],\n",
      "        [0.9909],\n",
      "        [0.9761],\n",
      "        [0.9510],\n",
      "        [0.9269],\n",
      "        [0.9183],\n",
      "        [0.8577],\n",
      "        [0.8716],\n",
      "        [0.8860],\n",
      "        [0.8538],\n",
      "        [0.8392],\n",
      "        [0.8466],\n",
      "        [0.8511],\n",
      "        [0.8388],\n",
      "        [0.8650],\n",
      "        [0.8713],\n",
      "        [0.8388],\n",
      "        [0.8115],\n",
      "        [0.8311],\n",
      "        [0.8315],\n",
      "        [0.7990],\n",
      "        [0.8380],\n",
      "        [0.8730],\n",
      "        [0.8901],\n",
      "        [0.8968],\n",
      "        [0.9038],\n",
      "        [0.8975],\n",
      "        [0.8970],\n",
      "        [0.8801],\n",
      "        [0.8588]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0176],\n",
      "        [0.0039],\n",
      "        [0.0165],\n",
      "        [0.0034],\n",
      "        [0.0103],\n",
      "        [0.0033],\n",
      "        [0.0076],\n",
      "        [0.0171],\n",
      "        [0.0268],\n",
      "        [0.0086],\n",
      "        [0.0019],\n",
      "        [0.0059],\n",
      "        [0.0140],\n",
      "        [0.0112],\n",
      "        [0.0265],\n",
      "        [0.0012],\n",
      "        [0.0210],\n",
      "        [0.0379],\n",
      "        [0.0472],\n",
      "        [0.0828],\n",
      "        [0.0810],\n",
      "        [0.0784],\n",
      "        [0.0215],\n",
      "        [0.0065],\n",
      "        [0.0466],\n",
      "        [0.0791],\n",
      "        [0.0659],\n",
      "        [0.0370],\n",
      "        [0.0054],\n",
      "        [0.0023],\n",
      "        [0.0464],\n",
      "        [0.0063],\n",
      "        [0.0073],\n",
      "        [0.0291],\n",
      "        [0.0404],\n",
      "        [0.0255],\n",
      "        [0.0312],\n",
      "        [0.0425],\n",
      "        [0.0507],\n",
      "        [0.0621],\n",
      "        [0.0141],\n",
      "        [0.0082],\n",
      "        [0.0057],\n",
      "        [0.0459],\n",
      "        [0.0585],\n",
      "        [0.0397],\n",
      "        [0.0352],\n",
      "        [0.0377],\n",
      "        [0.0015],\n",
      "        [0.0181],\n",
      "        [0.0053],\n",
      "        [0.0286],\n",
      "        [0.0530],\n",
      "        [0.0756],\n",
      "        [0.0568],\n",
      "        [0.0613],\n",
      "        [0.0340],\n",
      "        [0.0560],\n",
      "        [0.1199],\n",
      "        [0.1097]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0182],\n",
      "        [0.0043],\n",
      "        [0.0169],\n",
      "        [0.0029],\n",
      "        [0.0091],\n",
      "        [0.0021],\n",
      "        [0.0063],\n",
      "        [0.0158],\n",
      "        [0.0254],\n",
      "        [0.0074],\n",
      "        [0.0010],\n",
      "        [0.0065],\n",
      "        [0.0146],\n",
      "        [0.0122],\n",
      "        [0.0249],\n",
      "        [0.0026],\n",
      "        [0.0218],\n",
      "        [0.0377],\n",
      "        [0.0457],\n",
      "        [0.0824],\n",
      "        [0.0809],\n",
      "        [0.0784],\n",
      "        [0.0216],\n",
      "        [0.0064],\n",
      "        [0.0464],\n",
      "        [0.0782],\n",
      "        [0.0648],\n",
      "        [0.0357],\n",
      "        [0.0039],\n",
      "        [0.0010],\n",
      "        [0.0479],\n",
      "        [0.0056],\n",
      "        [0.0065],\n",
      "        [0.0283],\n",
      "        [0.0392],\n",
      "        [0.0246],\n",
      "        [0.0305],\n",
      "        [0.0412],\n",
      "        [0.0492],\n",
      "        [0.0607],\n",
      "        [0.0126],\n",
      "        [0.0064],\n",
      "        [0.0076],\n",
      "        [0.0477],\n",
      "        [0.0601],\n",
      "        [0.0413],\n",
      "        [0.0369],\n",
      "        [0.0358],\n",
      "        [0.0037],\n",
      "        [0.0158],\n",
      "        [0.0033],\n",
      "        [0.0306],\n",
      "        [0.0553],\n",
      "        [0.0783],\n",
      "        [0.0594],\n",
      "        [0.0646],\n",
      "        [0.0374],\n",
      "        [0.0525],\n",
      "        [0.1164],\n",
      "        [0.1064]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 61\n",
      "剩餘X 資料 torch.Size([316, 18])\n",
      "剩餘Y 資料 torch.Size([316, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9682])\n",
      "目前模型的Data狀態 torch.Size([61, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5487],\n",
      "        [0.5222],\n",
      "        [0.5345],\n",
      "        [0.5667],\n",
      "        [0.5681],\n",
      "        [0.5631],\n",
      "        [0.5621],\n",
      "        [0.5637],\n",
      "        [0.5518],\n",
      "        [0.5479],\n",
      "        [0.5376],\n",
      "        [0.5275],\n",
      "        [0.5184],\n",
      "        [0.5108],\n",
      "        [0.5446],\n",
      "        [0.5438],\n",
      "        [0.5469],\n",
      "        [0.5339],\n",
      "        [0.6135],\n",
      "        [0.8864],\n",
      "        [0.8944],\n",
      "        [0.9206],\n",
      "        [0.8663],\n",
      "        [0.9226],\n",
      "        [0.9357],\n",
      "        [0.8965],\n",
      "        [0.9346],\n",
      "        [0.9410],\n",
      "        [0.9716],\n",
      "        [0.9918],\n",
      "        [1.0269],\n",
      "        [0.9916],\n",
      "        [0.9768],\n",
      "        [0.9517],\n",
      "        [0.9281],\n",
      "        [0.9192],\n",
      "        [0.8585],\n",
      "        [0.8729],\n",
      "        [0.8875],\n",
      "        [0.8552],\n",
      "        [0.8407],\n",
      "        [0.8483],\n",
      "        [0.8530],\n",
      "        [0.8406],\n",
      "        [0.8666],\n",
      "        [0.8728],\n",
      "        [0.8406],\n",
      "        [0.8134],\n",
      "        [0.8332],\n",
      "        [0.8338],\n",
      "        [0.8010],\n",
      "        [0.8401],\n",
      "        [0.8753],\n",
      "        [0.8927],\n",
      "        [0.8994],\n",
      "        [0.9071],\n",
      "        [0.9009],\n",
      "        [0.9005],\n",
      "        [0.8836],\n",
      "        [0.8621],\n",
      "        [0.8733]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0182],\n",
      "        [0.0043],\n",
      "        [0.0169],\n",
      "        [0.0029],\n",
      "        [0.0091],\n",
      "        [0.0021],\n",
      "        [0.0063],\n",
      "        [0.0158],\n",
      "        [0.0254],\n",
      "        [0.0074],\n",
      "        [0.0010],\n",
      "        [0.0065],\n",
      "        [0.0146],\n",
      "        [0.0122],\n",
      "        [0.0249],\n",
      "        [0.0026],\n",
      "        [0.0218],\n",
      "        [0.0377],\n",
      "        [0.0457],\n",
      "        [0.0824],\n",
      "        [0.0809],\n",
      "        [0.0784],\n",
      "        [0.0216],\n",
      "        [0.0064],\n",
      "        [0.0464],\n",
      "        [0.0782],\n",
      "        [0.0648],\n",
      "        [0.0357],\n",
      "        [0.0039],\n",
      "        [0.0010],\n",
      "        [0.0479],\n",
      "        [0.0056],\n",
      "        [0.0065],\n",
      "        [0.0283],\n",
      "        [0.0392],\n",
      "        [0.0246],\n",
      "        [0.0305],\n",
      "        [0.0412],\n",
      "        [0.0492],\n",
      "        [0.0607],\n",
      "        [0.0126],\n",
      "        [0.0064],\n",
      "        [0.0076],\n",
      "        [0.0477],\n",
      "        [0.0601],\n",
      "        [0.0413],\n",
      "        [0.0369],\n",
      "        [0.0358],\n",
      "        [0.0037],\n",
      "        [0.0158],\n",
      "        [0.0033],\n",
      "        [0.0306],\n",
      "        [0.0553],\n",
      "        [0.0783],\n",
      "        [0.0594],\n",
      "        [0.0646],\n",
      "        [0.0374],\n",
      "        [0.0525],\n",
      "        [0.1164],\n",
      "        [0.1064],\n",
      "        [0.0949]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0186],\n",
      "        [0.0044],\n",
      "        [0.0170],\n",
      "        [0.0028],\n",
      "        [0.0078],\n",
      "        [0.0008],\n",
      "        [0.0048],\n",
      "        [0.0143],\n",
      "        [0.0238],\n",
      "        [0.0061],\n",
      "        [0.0001],\n",
      "        [0.0069],\n",
      "        [0.0149],\n",
      "        [0.0131],\n",
      "        [0.0230],\n",
      "        [0.0041],\n",
      "        [0.0227],\n",
      "        [0.0372],\n",
      "        [0.0435],\n",
      "        [0.0811],\n",
      "        [0.0800],\n",
      "        [0.0779],\n",
      "        [0.0211],\n",
      "        [0.0067],\n",
      "        [0.0467],\n",
      "        [0.0775],\n",
      "        [0.0638],\n",
      "        [0.0343],\n",
      "        [0.0024],\n",
      "        [0.0003],\n",
      "        [0.0491],\n",
      "        [0.0055],\n",
      "        [0.0061],\n",
      "        [0.0279],\n",
      "        [0.0381],\n",
      "        [0.0239],\n",
      "        [0.0302],\n",
      "        [0.0400],\n",
      "        [0.0477],\n",
      "        [0.0593],\n",
      "        [0.0111],\n",
      "        [0.0044],\n",
      "        [0.0098],\n",
      "        [0.0499],\n",
      "        [0.0620],\n",
      "        [0.0433],\n",
      "        [0.0394],\n",
      "        [0.0331],\n",
      "        [0.0066],\n",
      "        [0.0125],\n",
      "        [0.0004],\n",
      "        [0.0337],\n",
      "        [0.0588],\n",
      "        [0.0822],\n",
      "        [0.0633],\n",
      "        [0.0695],\n",
      "        [0.0423],\n",
      "        [0.0472],\n",
      "        [0.1114],\n",
      "        [0.1015],\n",
      "        [0.0894]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 62\n",
      "剩餘X 資料 torch.Size([315, 18])\n",
      "剩餘Y 資料 torch.Size([315, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9669])\n",
      "目前模型的Data狀態 torch.Size([62, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5483],\n",
      "        [0.5222],\n",
      "        [0.5345],\n",
      "        [0.5665],\n",
      "        [0.5668],\n",
      "        [0.5618],\n",
      "        [0.5606],\n",
      "        [0.5622],\n",
      "        [0.5502],\n",
      "        [0.5467],\n",
      "        [0.5368],\n",
      "        [0.5271],\n",
      "        [0.5181],\n",
      "        [0.5099],\n",
      "        [0.5465],\n",
      "        [0.5454],\n",
      "        [0.5478],\n",
      "        [0.5344],\n",
      "        [0.6113],\n",
      "        [0.8850],\n",
      "        [0.8935],\n",
      "        [0.9201],\n",
      "        [0.8658],\n",
      "        [0.9222],\n",
      "        [0.9354],\n",
      "        [0.8972],\n",
      "        [0.9357],\n",
      "        [0.9424],\n",
      "        [0.9732],\n",
      "        [0.9931],\n",
      "        [1.0282],\n",
      "        [0.9917],\n",
      "        [0.9773],\n",
      "        [0.9521],\n",
      "        [0.9293],\n",
      "        [0.9199],\n",
      "        [0.8588],\n",
      "        [0.8741],\n",
      "        [0.8890],\n",
      "        [0.8566],\n",
      "        [0.8422],\n",
      "        [0.8504],\n",
      "        [0.8553],\n",
      "        [0.8427],\n",
      "        [0.8686],\n",
      "        [0.8749],\n",
      "        [0.8430],\n",
      "        [0.8161],\n",
      "        [0.8361],\n",
      "        [0.8371],\n",
      "        [0.8039],\n",
      "        [0.8432],\n",
      "        [0.8788],\n",
      "        [0.8967],\n",
      "        [0.9033],\n",
      "        [0.9120],\n",
      "        [0.9058],\n",
      "        [0.9058],\n",
      "        [0.8886],\n",
      "        [0.8670],\n",
      "        [0.8788],\n",
      "        [0.8826]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0186],\n",
      "        [0.0044],\n",
      "        [0.0170],\n",
      "        [0.0028],\n",
      "        [0.0078],\n",
      "        [0.0008],\n",
      "        [0.0048],\n",
      "        [0.0143],\n",
      "        [0.0238],\n",
      "        [0.0061],\n",
      "        [0.0001],\n",
      "        [0.0069],\n",
      "        [0.0149],\n",
      "        [0.0131],\n",
      "        [0.0230],\n",
      "        [0.0041],\n",
      "        [0.0227],\n",
      "        [0.0372],\n",
      "        [0.0435],\n",
      "        [0.0811],\n",
      "        [0.0800],\n",
      "        [0.0779],\n",
      "        [0.0211],\n",
      "        [0.0067],\n",
      "        [0.0467],\n",
      "        [0.0775],\n",
      "        [0.0638],\n",
      "        [0.0343],\n",
      "        [0.0024],\n",
      "        [0.0003],\n",
      "        [0.0491],\n",
      "        [0.0055],\n",
      "        [0.0061],\n",
      "        [0.0279],\n",
      "        [0.0381],\n",
      "        [0.0239],\n",
      "        [0.0302],\n",
      "        [0.0400],\n",
      "        [0.0477],\n",
      "        [0.0593],\n",
      "        [0.0111],\n",
      "        [0.0044],\n",
      "        [0.0098],\n",
      "        [0.0499],\n",
      "        [0.0620],\n",
      "        [0.0433],\n",
      "        [0.0394],\n",
      "        [0.0331],\n",
      "        [0.0066],\n",
      "        [0.0125],\n",
      "        [0.0004],\n",
      "        [0.0337],\n",
      "        [0.0588],\n",
      "        [0.0822],\n",
      "        [0.0633],\n",
      "        [0.0695],\n",
      "        [0.0423],\n",
      "        [0.0472],\n",
      "        [0.1114],\n",
      "        [0.1015],\n",
      "        [0.0894],\n",
      "        [0.0843]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0174],\n",
      "        [0.0029],\n",
      "        [0.0155],\n",
      "        [0.0043],\n",
      "        [0.0081],\n",
      "        [0.0011],\n",
      "        [0.0048],\n",
      "        [0.0142],\n",
      "        [0.0236],\n",
      "        [0.0063],\n",
      "        [0.0008],\n",
      "        [0.0058],\n",
      "        [0.0138],\n",
      "        [0.0127],\n",
      "        [0.0206],\n",
      "        [0.0062],\n",
      "        [0.0240],\n",
      "        [0.0360],\n",
      "        [0.0423],\n",
      "        [0.0812],\n",
      "        [0.0807],\n",
      "        [0.0790],\n",
      "        [0.0222],\n",
      "        [0.0057],\n",
      "        [0.0455],\n",
      "        [0.0755],\n",
      "        [0.0613],\n",
      "        [0.0314],\n",
      "        [0.0007],\n",
      "        [0.0031],\n",
      "        [0.0519],\n",
      "        [0.0039],\n",
      "        [0.0040],\n",
      "        [0.0257],\n",
      "        [0.0351],\n",
      "        [0.0213],\n",
      "        [0.0280],\n",
      "        [0.0369],\n",
      "        [0.0444],\n",
      "        [0.0560],\n",
      "        [0.0078],\n",
      "        [0.0005],\n",
      "        [0.0140],\n",
      "        [0.0539],\n",
      "        [0.0658],\n",
      "        [0.0472],\n",
      "        [0.0436],\n",
      "        [0.0288],\n",
      "        [0.0112],\n",
      "        [0.0076],\n",
      "        [0.0043],\n",
      "        [0.0386],\n",
      "        [0.0640],\n",
      "        [0.0880],\n",
      "        [0.0691],\n",
      "        [0.0763],\n",
      "        [0.0491],\n",
      "        [0.0401],\n",
      "        [0.1044],\n",
      "        [0.0947],\n",
      "        [0.0819],\n",
      "        [0.0771]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 63\n",
      "剩餘X 資料 torch.Size([314, 18])\n",
      "剩餘Y 資料 torch.Size([314, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9521])\n",
      "目前模型的Data狀態 torch.Size([63, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5495],\n",
      "        [0.5237],\n",
      "        [0.5359],\n",
      "        [0.5680],\n",
      "        [0.5671],\n",
      "        [0.5621],\n",
      "        [0.5607],\n",
      "        [0.5622],\n",
      "        [0.5501],\n",
      "        [0.5469],\n",
      "        [0.5374],\n",
      "        [0.5282],\n",
      "        [0.5192],\n",
      "        [0.5104],\n",
      "        [0.5489],\n",
      "        [0.5474],\n",
      "        [0.5491],\n",
      "        [0.5356],\n",
      "        [0.6100],\n",
      "        [0.8852],\n",
      "        [0.8942],\n",
      "        [0.9211],\n",
      "        [0.8669],\n",
      "        [0.9233],\n",
      "        [0.9366],\n",
      "        [0.8993],\n",
      "        [0.9381],\n",
      "        [0.9453],\n",
      "        [0.9762],\n",
      "        [0.9959],\n",
      "        [1.0309],\n",
      "        [0.9934],\n",
      "        [0.9794],\n",
      "        [0.9544],\n",
      "        [0.9322],\n",
      "        [0.9225],\n",
      "        [0.8610],\n",
      "        [0.8772],\n",
      "        [0.8922],\n",
      "        [0.8599],\n",
      "        [0.8456],\n",
      "        [0.8543],\n",
      "        [0.8594],\n",
      "        [0.8468],\n",
      "        [0.8723],\n",
      "        [0.8788],\n",
      "        [0.8473],\n",
      "        [0.8204],\n",
      "        [0.8407],\n",
      "        [0.8420],\n",
      "        [0.8086],\n",
      "        [0.8481],\n",
      "        [0.8840],\n",
      "        [0.9025],\n",
      "        [0.9091],\n",
      "        [0.9188],\n",
      "        [0.9126],\n",
      "        [0.9129],\n",
      "        [0.8956],\n",
      "        [0.8737],\n",
      "        [0.8862],\n",
      "        [0.8899],\n",
      "        [0.8702]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0174],\n",
      "        [0.0029],\n",
      "        [0.0155],\n",
      "        [0.0043],\n",
      "        [0.0081],\n",
      "        [0.0011],\n",
      "        [0.0048],\n",
      "        [0.0142],\n",
      "        [0.0236],\n",
      "        [0.0063],\n",
      "        [0.0008],\n",
      "        [0.0058],\n",
      "        [0.0138],\n",
      "        [0.0127],\n",
      "        [0.0206],\n",
      "        [0.0062],\n",
      "        [0.0240],\n",
      "        [0.0360],\n",
      "        [0.0423],\n",
      "        [0.0812],\n",
      "        [0.0807],\n",
      "        [0.0790],\n",
      "        [0.0222],\n",
      "        [0.0057],\n",
      "        [0.0455],\n",
      "        [0.0755],\n",
      "        [0.0613],\n",
      "        [0.0314],\n",
      "        [0.0007],\n",
      "        [0.0031],\n",
      "        [0.0519],\n",
      "        [0.0039],\n",
      "        [0.0040],\n",
      "        [0.0257],\n",
      "        [0.0351],\n",
      "        [0.0213],\n",
      "        [0.0280],\n",
      "        [0.0369],\n",
      "        [0.0444],\n",
      "        [0.0560],\n",
      "        [0.0078],\n",
      "        [0.0005],\n",
      "        [0.0140],\n",
      "        [0.0539],\n",
      "        [0.0658],\n",
      "        [0.0472],\n",
      "        [0.0436],\n",
      "        [0.0288],\n",
      "        [0.0112],\n",
      "        [0.0076],\n",
      "        [0.0043],\n",
      "        [0.0386],\n",
      "        [0.0640],\n",
      "        [0.0880],\n",
      "        [0.0691],\n",
      "        [0.0763],\n",
      "        [0.0491],\n",
      "        [0.0401],\n",
      "        [0.1044],\n",
      "        [0.0947],\n",
      "        [0.0819],\n",
      "        [0.0771],\n",
      "        [0.0819]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0172],\n",
      "        [0.0024],\n",
      "        [0.0152],\n",
      "        [0.0048],\n",
      "        [0.0074],\n",
      "        [0.0004],\n",
      "        [0.0038],\n",
      "        [0.0131],\n",
      "        [0.0224],\n",
      "        [0.0054],\n",
      "        [0.0004],\n",
      "        [0.0056],\n",
      "        [0.0136],\n",
      "        [0.0132],\n",
      "        [0.0196],\n",
      "        [0.0069],\n",
      "        [0.0239],\n",
      "        [0.0360],\n",
      "        [0.0396],\n",
      "        [0.0792],\n",
      "        [0.0793],\n",
      "        [0.0780],\n",
      "        [0.0213],\n",
      "        [0.0069],\n",
      "        [0.0467],\n",
      "        [0.0755],\n",
      "        [0.0611],\n",
      "        [0.0307],\n",
      "        [0.0015],\n",
      "        [0.0035],\n",
      "        [0.0521],\n",
      "        [0.0046],\n",
      "        [0.0040],\n",
      "        [0.0254],\n",
      "        [0.0339],\n",
      "        [0.0204],\n",
      "        [0.0274],\n",
      "        [0.0354],\n",
      "        [0.0429],\n",
      "        [0.0544],\n",
      "        [0.0060],\n",
      "        [0.0018],\n",
      "        [0.0166],\n",
      "        [0.0564],\n",
      "        [0.0678],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0261],\n",
      "        [0.0141],\n",
      "        [0.0042],\n",
      "        [0.0077],\n",
      "        [0.0420],\n",
      "        [0.0677],\n",
      "        [0.0921],\n",
      "        [0.0731],\n",
      "        [0.0812],\n",
      "        [0.0542],\n",
      "        [0.0346],\n",
      "        [0.0990],\n",
      "        [0.0894],\n",
      "        [0.0759],\n",
      "        [0.0712],\n",
      "        [0.0759]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 64\n",
      "剩餘X 資料 torch.Size([313, 18])\n",
      "剩餘Y 資料 torch.Size([313, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9018])\n",
      "目前模型的Data狀態 torch.Size([64, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5497],\n",
      "        [0.5241],\n",
      "        [0.5363],\n",
      "        [0.5686],\n",
      "        [0.5664],\n",
      "        [0.5615],\n",
      "        [0.5597],\n",
      "        [0.5611],\n",
      "        [0.5488],\n",
      "        [0.5460],\n",
      "        [0.5370],\n",
      "        [0.5284],\n",
      "        [0.5193],\n",
      "        [0.5099],\n",
      "        [0.5500],\n",
      "        [0.5481],\n",
      "        [0.5490],\n",
      "        [0.5356],\n",
      "        [0.6074],\n",
      "        [0.8832],\n",
      "        [0.8929],\n",
      "        [0.9201],\n",
      "        [0.8660],\n",
      "        [0.9221],\n",
      "        [0.9354],\n",
      "        [0.8992],\n",
      "        [0.9383],\n",
      "        [0.9460],\n",
      "        [0.9770],\n",
      "        [0.9963],\n",
      "        [1.0312],\n",
      "        [0.9927],\n",
      "        [0.9793],\n",
      "        [0.9546],\n",
      "        [0.9334],\n",
      "        [0.9233],\n",
      "        [0.8616],\n",
      "        [0.8787],\n",
      "        [0.8937],\n",
      "        [0.8615],\n",
      "        [0.8473],\n",
      "        [0.8566],\n",
      "        [0.8620],\n",
      "        [0.8493],\n",
      "        [0.8743],\n",
      "        [0.8809],\n",
      "        [0.8499],\n",
      "        [0.8231],\n",
      "        [0.8436],\n",
      "        [0.8453],\n",
      "        [0.8120],\n",
      "        [0.8515],\n",
      "        [0.8876],\n",
      "        [0.9066],\n",
      "        [0.9132],\n",
      "        [0.9238],\n",
      "        [0.9177],\n",
      "        [0.9184],\n",
      "        [0.9010],\n",
      "        [0.8791],\n",
      "        [0.8923],\n",
      "        [0.8958],\n",
      "        [0.8763],\n",
      "        [0.8418]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0172],\n",
      "        [0.0024],\n",
      "        [0.0152],\n",
      "        [0.0048],\n",
      "        [0.0074],\n",
      "        [0.0004],\n",
      "        [0.0038],\n",
      "        [0.0131],\n",
      "        [0.0224],\n",
      "        [0.0054],\n",
      "        [0.0004],\n",
      "        [0.0056],\n",
      "        [0.0136],\n",
      "        [0.0132],\n",
      "        [0.0196],\n",
      "        [0.0069],\n",
      "        [0.0239],\n",
      "        [0.0360],\n",
      "        [0.0396],\n",
      "        [0.0792],\n",
      "        [0.0793],\n",
      "        [0.0780],\n",
      "        [0.0213],\n",
      "        [0.0069],\n",
      "        [0.0467],\n",
      "        [0.0755],\n",
      "        [0.0611],\n",
      "        [0.0307],\n",
      "        [0.0015],\n",
      "        [0.0035],\n",
      "        [0.0521],\n",
      "        [0.0046],\n",
      "        [0.0040],\n",
      "        [0.0254],\n",
      "        [0.0339],\n",
      "        [0.0204],\n",
      "        [0.0274],\n",
      "        [0.0354],\n",
      "        [0.0429],\n",
      "        [0.0544],\n",
      "        [0.0060],\n",
      "        [0.0018],\n",
      "        [0.0166],\n",
      "        [0.0564],\n",
      "        [0.0678],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0261],\n",
      "        [0.0141],\n",
      "        [0.0042],\n",
      "        [0.0077],\n",
      "        [0.0420],\n",
      "        [0.0677],\n",
      "        [0.0921],\n",
      "        [0.0731],\n",
      "        [0.0812],\n",
      "        [0.0542],\n",
      "        [0.0346],\n",
      "        [0.0990],\n",
      "        [0.0894],\n",
      "        [0.0759],\n",
      "        [0.0712],\n",
      "        [0.0759],\n",
      "        [0.0601]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0168],\n",
      "        [0.0019],\n",
      "        [0.0148],\n",
      "        [0.0056],\n",
      "        [0.0070],\n",
      "        [0.0001],\n",
      "        [0.0032],\n",
      "        [0.0123],\n",
      "        [0.0214],\n",
      "        [0.0047],\n",
      "        [0.0002],\n",
      "        [0.0053],\n",
      "        [0.0133],\n",
      "        [0.0133],\n",
      "        [0.0189],\n",
      "        [0.0074],\n",
      "        [0.0237],\n",
      "        [0.0361],\n",
      "        [0.0374],\n",
      "        [0.0771],\n",
      "        [0.0779],\n",
      "        [0.0766],\n",
      "        [0.0203],\n",
      "        [0.0086],\n",
      "        [0.0486],\n",
      "        [0.0763],\n",
      "        [0.0619],\n",
      "        [0.0312],\n",
      "        [0.0011],\n",
      "        [0.0028],\n",
      "        [0.0511],\n",
      "        [0.0061],\n",
      "        [0.0048],\n",
      "        [0.0257],\n",
      "        [0.0332],\n",
      "        [0.0198],\n",
      "        [0.0265],\n",
      "        [0.0340],\n",
      "        [0.0417],\n",
      "        [0.0529],\n",
      "        [0.0044],\n",
      "        [0.0038],\n",
      "        [0.0188],\n",
      "        [0.0587],\n",
      "        [0.0692],\n",
      "        [0.0507],\n",
      "        [0.0481],\n",
      "        [0.0240],\n",
      "        [0.0162],\n",
      "        [0.0017],\n",
      "        [0.0106],\n",
      "        [0.0447],\n",
      "        [0.0702],\n",
      "        [0.0949],\n",
      "        [0.0759],\n",
      "        [0.0847],\n",
      "        [0.0579],\n",
      "        [0.0306],\n",
      "        [0.0948],\n",
      "        [0.0851],\n",
      "        [0.0709],\n",
      "        [0.0661],\n",
      "        [0.0704],\n",
      "        [0.0551]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 65\n",
      "剩餘X 資料 torch.Size([312, 18])\n",
      "剩餘Y 資料 torch.Size([312, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7079])\n",
      "目前模型的Data狀態 torch.Size([65, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5501],\n",
      "        [0.5246],\n",
      "        [0.5366],\n",
      "        [0.5694],\n",
      "        [0.5659],\n",
      "        [0.5612],\n",
      "        [0.5590],\n",
      "        [0.5602],\n",
      "        [0.5479],\n",
      "        [0.5453],\n",
      "        [0.5368],\n",
      "        [0.5287],\n",
      "        [0.5197],\n",
      "        [0.5097],\n",
      "        [0.5507],\n",
      "        [0.5486],\n",
      "        [0.5488],\n",
      "        [0.5355],\n",
      "        [0.6052],\n",
      "        [0.8811],\n",
      "        [0.8915],\n",
      "        [0.9188],\n",
      "        [0.8650],\n",
      "        [0.9203],\n",
      "        [0.9335],\n",
      "        [0.8984],\n",
      "        [0.9375],\n",
      "        [0.9455],\n",
      "        [0.9766],\n",
      "        [0.9956],\n",
      "        [1.0301],\n",
      "        [0.9911],\n",
      "        [0.9786],\n",
      "        [0.9543],\n",
      "        [0.9342],\n",
      "        [0.9240],\n",
      "        [0.8624],\n",
      "        [0.8801],\n",
      "        [0.8950],\n",
      "        [0.8630],\n",
      "        [0.8490],\n",
      "        [0.8585],\n",
      "        [0.8642],\n",
      "        [0.8515],\n",
      "        [0.8758],\n",
      "        [0.8822],\n",
      "        [0.8518],\n",
      "        [0.8252],\n",
      "        [0.8457],\n",
      "        [0.8479],\n",
      "        [0.8148],\n",
      "        [0.8541],\n",
      "        [0.8902],\n",
      "        [0.9094],\n",
      "        [0.9159],\n",
      "        [0.9273],\n",
      "        [0.9214],\n",
      "        [0.9224],\n",
      "        [0.9052],\n",
      "        [0.8834],\n",
      "        [0.8972],\n",
      "        [0.9008],\n",
      "        [0.8817],\n",
      "        [0.8468],\n",
      "        [0.8558]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0168],\n",
      "        [    0.0019],\n",
      "        [    0.0148],\n",
      "        [    0.0056],\n",
      "        [    0.0070],\n",
      "        [    0.0001],\n",
      "        [    0.0032],\n",
      "        [    0.0123],\n",
      "        [    0.0214],\n",
      "        [    0.0047],\n",
      "        [    0.0002],\n",
      "        [    0.0053],\n",
      "        [    0.0133],\n",
      "        [    0.0133],\n",
      "        [    0.0189],\n",
      "        [    0.0074],\n",
      "        [    0.0237],\n",
      "        [    0.0361],\n",
      "        [    0.0374],\n",
      "        [    0.0771],\n",
      "        [    0.0779],\n",
      "        [    0.0766],\n",
      "        [    0.0203],\n",
      "        [    0.0086],\n",
      "        [    0.0486],\n",
      "        [    0.0763],\n",
      "        [    0.0619],\n",
      "        [    0.0312],\n",
      "        [    0.0011],\n",
      "        [    0.0028],\n",
      "        [    0.0511],\n",
      "        [    0.0061],\n",
      "        [    0.0048],\n",
      "        [    0.0257],\n",
      "        [    0.0332],\n",
      "        [    0.0198],\n",
      "        [    0.0265],\n",
      "        [    0.0340],\n",
      "        [    0.0417],\n",
      "        [    0.0529],\n",
      "        [    0.0044],\n",
      "        [    0.0038],\n",
      "        [    0.0188],\n",
      "        [    0.0587],\n",
      "        [    0.0692],\n",
      "        [    0.0507],\n",
      "        [    0.0481],\n",
      "        [    0.0240],\n",
      "        [    0.0162],\n",
      "        [    0.0017],\n",
      "        [    0.0106],\n",
      "        [    0.0447],\n",
      "        [    0.0702],\n",
      "        [    0.0949],\n",
      "        [    0.0759],\n",
      "        [    0.0847],\n",
      "        [    0.0579],\n",
      "        [    0.0306],\n",
      "        [    0.0948],\n",
      "        [    0.0851],\n",
      "        [    0.0709],\n",
      "        [    0.0661],\n",
      "        [    0.0704],\n",
      "        [    0.0551],\n",
      "        [    0.1479]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0186],\n",
      "        [0.0037],\n",
      "        [0.0158],\n",
      "        [0.0045],\n",
      "        [0.0041],\n",
      "        [0.0026],\n",
      "        [0.0002],\n",
      "        [0.0093],\n",
      "        [0.0184],\n",
      "        [0.0022],\n",
      "        [0.0018],\n",
      "        [0.0067],\n",
      "        [0.0146],\n",
      "        [0.0150],\n",
      "        [0.0176],\n",
      "        [0.0086],\n",
      "        [0.0240],\n",
      "        [0.0370],\n",
      "        [0.0342],\n",
      "        [0.0712],\n",
      "        [0.0723],\n",
      "        [0.0712],\n",
      "        [0.0158],\n",
      "        [0.0143],\n",
      "        [0.0543],\n",
      "        [0.0803],\n",
      "        [0.0657],\n",
      "        [0.0347],\n",
      "        [0.0027],\n",
      "        [0.0019],\n",
      "        [0.0455],\n",
      "        [0.0126],\n",
      "        [0.0113],\n",
      "        [0.0322],\n",
      "        [0.0389],\n",
      "        [0.0260],\n",
      "        [0.0328],\n",
      "        [0.0395],\n",
      "        [0.0471],\n",
      "        [0.0580],\n",
      "        [0.0093],\n",
      "        [0.0010],\n",
      "        [0.0145],\n",
      "        [0.0544],\n",
      "        [0.0644],\n",
      "        [0.0453],\n",
      "        [0.0435],\n",
      "        [0.0279],\n",
      "        [0.0124],\n",
      "        [0.0051],\n",
      "        [0.0070],\n",
      "        [0.0409],\n",
      "        [0.0665],\n",
      "        [0.0916],\n",
      "        [0.0717],\n",
      "        [0.0813],\n",
      "        [0.0545],\n",
      "        [0.0336],\n",
      "        [0.0977],\n",
      "        [0.0879],\n",
      "        [0.0733],\n",
      "        [0.0690],\n",
      "        [0.0734],\n",
      "        [0.0590],\n",
      "        [0.1423]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 66\n",
      "剩餘X 資料 torch.Size([311, 18])\n",
      "剩餘Y 資料 torch.Size([311, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8433])\n",
      "目前模型的Data狀態 torch.Size([66, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5483],\n",
      "        [0.5228],\n",
      "        [0.5356],\n",
      "        [0.5682],\n",
      "        [0.5631],\n",
      "        [0.5584],\n",
      "        [0.5561],\n",
      "        [0.5572],\n",
      "        [0.5448],\n",
      "        [0.5428],\n",
      "        [0.5348],\n",
      "        [0.5273],\n",
      "        [0.5184],\n",
      "        [0.5080],\n",
      "        [0.5520],\n",
      "        [0.5499],\n",
      "        [0.5491],\n",
      "        [0.5346],\n",
      "        [0.6019],\n",
      "        [0.8752],\n",
      "        [0.8858],\n",
      "        [0.9134],\n",
      "        [0.8604],\n",
      "        [0.9147],\n",
      "        [0.9278],\n",
      "        [0.8945],\n",
      "        [0.9337],\n",
      "        [0.9420],\n",
      "        [0.9728],\n",
      "        [0.9909],\n",
      "        [1.0246],\n",
      "        [0.9846],\n",
      "        [0.9721],\n",
      "        [0.9478],\n",
      "        [0.9285],\n",
      "        [0.9178],\n",
      "        [0.8562],\n",
      "        [0.8746],\n",
      "        [0.8896],\n",
      "        [0.8579],\n",
      "        [0.8440],\n",
      "        [0.8538],\n",
      "        [0.8599],\n",
      "        [0.8472],\n",
      "        [0.8709],\n",
      "        [0.8768],\n",
      "        [0.8471],\n",
      "        [0.8213],\n",
      "        [0.8419],\n",
      "        [0.8444],\n",
      "        [0.8113],\n",
      "        [0.8503],\n",
      "        [0.8865],\n",
      "        [0.9061],\n",
      "        [0.9118],\n",
      "        [0.9238],\n",
      "        [0.9180],\n",
      "        [0.9194],\n",
      "        [0.9023],\n",
      "        [0.8806],\n",
      "        [0.8949],\n",
      "        [0.8979],\n",
      "        [0.8787],\n",
      "        [0.8428],\n",
      "        [0.8502],\n",
      "        [0.8723]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0186],\n",
      "        [0.0037],\n",
      "        [0.0158],\n",
      "        [0.0045],\n",
      "        [0.0041],\n",
      "        [0.0026],\n",
      "        [0.0002],\n",
      "        [0.0093],\n",
      "        [0.0184],\n",
      "        [0.0022],\n",
      "        [0.0018],\n",
      "        [0.0067],\n",
      "        [0.0146],\n",
      "        [0.0150],\n",
      "        [0.0176],\n",
      "        [0.0086],\n",
      "        [0.0240],\n",
      "        [0.0370],\n",
      "        [0.0342],\n",
      "        [0.0712],\n",
      "        [0.0723],\n",
      "        [0.0712],\n",
      "        [0.0158],\n",
      "        [0.0143],\n",
      "        [0.0543],\n",
      "        [0.0803],\n",
      "        [0.0657],\n",
      "        [0.0347],\n",
      "        [0.0027],\n",
      "        [0.0019],\n",
      "        [0.0455],\n",
      "        [0.0126],\n",
      "        [0.0113],\n",
      "        [0.0322],\n",
      "        [0.0389],\n",
      "        [0.0260],\n",
      "        [0.0328],\n",
      "        [0.0395],\n",
      "        [0.0471],\n",
      "        [0.0580],\n",
      "        [0.0093],\n",
      "        [0.0010],\n",
      "        [0.0145],\n",
      "        [0.0544],\n",
      "        [0.0644],\n",
      "        [0.0453],\n",
      "        [0.0435],\n",
      "        [0.0279],\n",
      "        [0.0124],\n",
      "        [0.0051],\n",
      "        [0.0070],\n",
      "        [0.0409],\n",
      "        [0.0665],\n",
      "        [0.0916],\n",
      "        [0.0717],\n",
      "        [0.0813],\n",
      "        [0.0545],\n",
      "        [0.0336],\n",
      "        [0.0977],\n",
      "        [0.0879],\n",
      "        [0.0733],\n",
      "        [0.0690],\n",
      "        [0.0734],\n",
      "        [0.0590],\n",
      "        [0.1423],\n",
      "        [0.0291]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0173],\n",
      "        [    0.0028],\n",
      "        [    0.0139],\n",
      "        [    0.0066],\n",
      "        [    0.0045],\n",
      "        [    0.0022],\n",
      "        [    0.0005],\n",
      "        [    0.0094],\n",
      "        [    0.0184],\n",
      "        [    0.0026],\n",
      "        [    0.0010],\n",
      "        [    0.0054],\n",
      "        [    0.0134],\n",
      "        [    0.0143],\n",
      "        [    0.0149],\n",
      "        [    0.0115],\n",
      "        [    0.0260],\n",
      "        [    0.0364],\n",
      "        [    0.0339],\n",
      "        [    0.0714],\n",
      "        [    0.0727],\n",
      "        [    0.0720],\n",
      "        [    0.0169],\n",
      "        [    0.0139],\n",
      "        [    0.0539],\n",
      "        [    0.0785],\n",
      "        [    0.0636],\n",
      "        [    0.0323],\n",
      "        [    0.0003],\n",
      "        [    0.0001],\n",
      "        [    0.0467],\n",
      "        [    0.0124],\n",
      "        [    0.0113],\n",
      "        [    0.0324],\n",
      "        [    0.0384],\n",
      "        [    0.0260],\n",
      "        [    0.0331],\n",
      "        [    0.0391],\n",
      "        [    0.0466],\n",
      "        [    0.0574],\n",
      "        [    0.0087],\n",
      "        [    0.0002],\n",
      "        [    0.0157],\n",
      "        [    0.0554],\n",
      "        [    0.0651],\n",
      "        [    0.0453],\n",
      "        [    0.0440],\n",
      "        [    0.0270],\n",
      "        [    0.0135],\n",
      "        [    0.0038],\n",
      "        [    0.0079],\n",
      "        [    0.0418],\n",
      "        [    0.0677],\n",
      "        [    0.0932],\n",
      "        [    0.0725],\n",
      "        [    0.0827],\n",
      "        [    0.0560],\n",
      "        [    0.0318],\n",
      "        [    0.0958],\n",
      "        [    0.0860],\n",
      "        [    0.0709],\n",
      "        [    0.0670],\n",
      "        [    0.0716],\n",
      "        [    0.0582],\n",
      "        [    0.1418],\n",
      "        [    0.0280]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 67\n",
      "剩餘X 資料 torch.Size([310, 18])\n",
      "剩餘Y 資料 torch.Size([310, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8297])\n",
      "目前模型的Data狀態 torch.Size([67, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5496],\n",
      "        [0.5237],\n",
      "        [0.5376],\n",
      "        [0.5704],\n",
      "        [0.5635],\n",
      "        [0.5589],\n",
      "        [0.5563],\n",
      "        [0.5574],\n",
      "        [0.5448],\n",
      "        [0.5432],\n",
      "        [0.5357],\n",
      "        [0.5286],\n",
      "        [0.5195],\n",
      "        [0.5088],\n",
      "        [0.5547],\n",
      "        [0.5527],\n",
      "        [0.5511],\n",
      "        [0.5352],\n",
      "        [0.6017],\n",
      "        [0.8754],\n",
      "        [0.8863],\n",
      "        [0.9141],\n",
      "        [0.8616],\n",
      "        [0.9151],\n",
      "        [0.9282],\n",
      "        [0.8962],\n",
      "        [0.9358],\n",
      "        [0.9444],\n",
      "        [0.9752],\n",
      "        [0.9927],\n",
      "        [1.0258],\n",
      "        [0.9848],\n",
      "        [0.9721],\n",
      "        [0.9477],\n",
      "        [0.9289],\n",
      "        [0.9177],\n",
      "        [0.8558],\n",
      "        [0.8750],\n",
      "        [0.8901],\n",
      "        [0.8585],\n",
      "        [0.8447],\n",
      "        [0.8545],\n",
      "        [0.8611],\n",
      "        [0.8483],\n",
      "        [0.8716],\n",
      "        [0.8769],\n",
      "        [0.8476],\n",
      "        [0.8222],\n",
      "        [0.8430],\n",
      "        [0.8458],\n",
      "        [0.8122],\n",
      "        [0.8513],\n",
      "        [0.8877],\n",
      "        [0.9076],\n",
      "        [0.9126],\n",
      "        [0.9253],\n",
      "        [0.9195],\n",
      "        [0.9212],\n",
      "        [0.9042],\n",
      "        [0.8825],\n",
      "        [0.8973],\n",
      "        [0.9000],\n",
      "        [0.8806],\n",
      "        [0.8437],\n",
      "        [0.8497],\n",
      "        [0.8713],\n",
      "        [0.8865]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0173],\n",
      "        [    0.0028],\n",
      "        [    0.0139],\n",
      "        [    0.0066],\n",
      "        [    0.0045],\n",
      "        [    0.0022],\n",
      "        [    0.0005],\n",
      "        [    0.0094],\n",
      "        [    0.0184],\n",
      "        [    0.0026],\n",
      "        [    0.0010],\n",
      "        [    0.0054],\n",
      "        [    0.0134],\n",
      "        [    0.0143],\n",
      "        [    0.0149],\n",
      "        [    0.0115],\n",
      "        [    0.0260],\n",
      "        [    0.0364],\n",
      "        [    0.0339],\n",
      "        [    0.0714],\n",
      "        [    0.0727],\n",
      "        [    0.0720],\n",
      "        [    0.0169],\n",
      "        [    0.0139],\n",
      "        [    0.0539],\n",
      "        [    0.0785],\n",
      "        [    0.0636],\n",
      "        [    0.0323],\n",
      "        [    0.0003],\n",
      "        [    0.0001],\n",
      "        [    0.0467],\n",
      "        [    0.0124],\n",
      "        [    0.0113],\n",
      "        [    0.0324],\n",
      "        [    0.0384],\n",
      "        [    0.0260],\n",
      "        [    0.0331],\n",
      "        [    0.0391],\n",
      "        [    0.0466],\n",
      "        [    0.0574],\n",
      "        [    0.0087],\n",
      "        [    0.0002],\n",
      "        [    0.0157],\n",
      "        [    0.0554],\n",
      "        [    0.0651],\n",
      "        [    0.0453],\n",
      "        [    0.0440],\n",
      "        [    0.0270],\n",
      "        [    0.0135],\n",
      "        [    0.0038],\n",
      "        [    0.0079],\n",
      "        [    0.0418],\n",
      "        [    0.0677],\n",
      "        [    0.0932],\n",
      "        [    0.0725],\n",
      "        [    0.0827],\n",
      "        [    0.0560],\n",
      "        [    0.0318],\n",
      "        [    0.0958],\n",
      "        [    0.0860],\n",
      "        [    0.0709],\n",
      "        [    0.0670],\n",
      "        [    0.0716],\n",
      "        [    0.0582],\n",
      "        [    0.1418],\n",
      "        [    0.0280],\n",
      "        [    0.0569]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0182],\n",
      "        [0.0039],\n",
      "        [0.0138],\n",
      "        [0.0066],\n",
      "        [0.0025],\n",
      "        [0.0040],\n",
      "        [0.0015],\n",
      "        [0.0074],\n",
      "        [0.0161],\n",
      "        [0.0008],\n",
      "        [0.0023],\n",
      "        [0.0062],\n",
      "        [0.0142],\n",
      "        [0.0155],\n",
      "        [0.0140],\n",
      "        [0.0125],\n",
      "        [0.0262],\n",
      "        [0.0379],\n",
      "        [0.0314],\n",
      "        [0.0684],\n",
      "        [0.0698],\n",
      "        [0.0694],\n",
      "        [0.0149],\n",
      "        [0.0168],\n",
      "        [0.0568],\n",
      "        [0.0798],\n",
      "        [0.0646],\n",
      "        [0.0330],\n",
      "        [0.0011],\n",
      "        [0.0017],\n",
      "        [0.0443],\n",
      "        [0.0159],\n",
      "        [0.0151],\n",
      "        [0.0364],\n",
      "        [0.0419],\n",
      "        [0.0300],\n",
      "        [0.0374],\n",
      "        [0.0424],\n",
      "        [0.0498],\n",
      "        [0.0604],\n",
      "        [0.0116],\n",
      "        [0.0031],\n",
      "        [0.0132],\n",
      "        [0.0529],\n",
      "        [0.0622],\n",
      "        [0.0416],\n",
      "        [0.0408],\n",
      "        [0.0296],\n",
      "        [0.0111],\n",
      "        [0.0060],\n",
      "        [0.0052],\n",
      "        [0.0391],\n",
      "        [0.0652],\n",
      "        [0.0911],\n",
      "        [0.0695],\n",
      "        [0.0803],\n",
      "        [0.0537],\n",
      "        [0.0338],\n",
      "        [0.0977],\n",
      "        [0.0879],\n",
      "        [0.0723],\n",
      "        [0.0689],\n",
      "        [0.0738],\n",
      "        [0.0615],\n",
      "        [0.1371],\n",
      "        [0.0227],\n",
      "        [0.0522]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 68\n",
      "剩餘X 資料 torch.Size([309, 18])\n",
      "剩餘Y 資料 torch.Size([309, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8463])\n",
      "目前模型的Data狀態 torch.Size([68, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5487],\n",
      "        [0.5226],\n",
      "        [0.5376],\n",
      "        [0.5704],\n",
      "        [0.5615],\n",
      "        [0.5571],\n",
      "        [0.5543],\n",
      "        [0.5553],\n",
      "        [0.5426],\n",
      "        [0.5414],\n",
      "        [0.5344],\n",
      "        [0.5278],\n",
      "        [0.5187],\n",
      "        [0.5075],\n",
      "        [0.5556],\n",
      "        [0.5538],\n",
      "        [0.5512],\n",
      "        [0.5337],\n",
      "        [0.5992],\n",
      "        [0.8723],\n",
      "        [0.8834],\n",
      "        [0.9116],\n",
      "        [0.8596],\n",
      "        [0.9122],\n",
      "        [0.9253],\n",
      "        [0.8950],\n",
      "        [0.9348],\n",
      "        [0.9437],\n",
      "        [0.9744],\n",
      "        [0.9911],\n",
      "        [1.0234],\n",
      "        [0.9814],\n",
      "        [0.9683],\n",
      "        [0.9436],\n",
      "        [0.9255],\n",
      "        [0.9138],\n",
      "        [0.8516],\n",
      "        [0.8717],\n",
      "        [0.8868],\n",
      "        [0.8555],\n",
      "        [0.8417],\n",
      "        [0.8516],\n",
      "        [0.8586],\n",
      "        [0.8458],\n",
      "        [0.8687],\n",
      "        [0.8732],\n",
      "        [0.8445],\n",
      "        [0.8196],\n",
      "        [0.8407],\n",
      "        [0.8436],\n",
      "        [0.8095],\n",
      "        [0.8486],\n",
      "        [0.8852],\n",
      "        [0.9055],\n",
      "        [0.9095],\n",
      "        [0.9228],\n",
      "        [0.9172],\n",
      "        [0.9192],\n",
      "        [0.9023],\n",
      "        [0.8806],\n",
      "        [0.8958],\n",
      "        [0.8981],\n",
      "        [0.8784],\n",
      "        [0.8404],\n",
      "        [0.8450],\n",
      "        [0.8660],\n",
      "        [0.8818],\n",
      "        [0.8902]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0182],\n",
      "        [0.0039],\n",
      "        [0.0138],\n",
      "        [0.0066],\n",
      "        [0.0025],\n",
      "        [0.0040],\n",
      "        [0.0015],\n",
      "        [0.0074],\n",
      "        [0.0161],\n",
      "        [0.0008],\n",
      "        [0.0023],\n",
      "        [0.0062],\n",
      "        [0.0142],\n",
      "        [0.0155],\n",
      "        [0.0140],\n",
      "        [0.0125],\n",
      "        [0.0262],\n",
      "        [0.0379],\n",
      "        [0.0314],\n",
      "        [0.0684],\n",
      "        [0.0698],\n",
      "        [0.0694],\n",
      "        [0.0149],\n",
      "        [0.0168],\n",
      "        [0.0568],\n",
      "        [0.0798],\n",
      "        [0.0646],\n",
      "        [0.0330],\n",
      "        [0.0011],\n",
      "        [0.0017],\n",
      "        [0.0443],\n",
      "        [0.0159],\n",
      "        [0.0151],\n",
      "        [0.0364],\n",
      "        [0.0419],\n",
      "        [0.0300],\n",
      "        [0.0374],\n",
      "        [0.0424],\n",
      "        [0.0498],\n",
      "        [0.0604],\n",
      "        [0.0116],\n",
      "        [0.0031],\n",
      "        [0.0132],\n",
      "        [0.0529],\n",
      "        [0.0622],\n",
      "        [0.0416],\n",
      "        [0.0408],\n",
      "        [0.0296],\n",
      "        [0.0111],\n",
      "        [0.0060],\n",
      "        [0.0052],\n",
      "        [0.0391],\n",
      "        [0.0652],\n",
      "        [0.0911],\n",
      "        [0.0695],\n",
      "        [0.0803],\n",
      "        [0.0537],\n",
      "        [0.0338],\n",
      "        [0.0977],\n",
      "        [0.0879],\n",
      "        [0.0723],\n",
      "        [0.0689],\n",
      "        [0.0738],\n",
      "        [0.0615],\n",
      "        [0.1371],\n",
      "        [0.0227],\n",
      "        [0.0522],\n",
      "        [0.0439]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0176],\n",
      "        [0.0040],\n",
      "        [0.0126],\n",
      "        [0.0080],\n",
      "        [0.0020],\n",
      "        [0.0045],\n",
      "        [0.0022],\n",
      "        [0.0067],\n",
      "        [0.0151],\n",
      "        [0.0003],\n",
      "        [0.0024],\n",
      "        [0.0059],\n",
      "        [0.0140],\n",
      "        [0.0157],\n",
      "        [0.0124],\n",
      "        [0.0142],\n",
      "        [0.0270],\n",
      "        [0.0387],\n",
      "        [0.0302],\n",
      "        [0.0674],\n",
      "        [0.0690],\n",
      "        [0.0689],\n",
      "        [0.0149],\n",
      "        [0.0176],\n",
      "        [0.0576],\n",
      "        [0.0791],\n",
      "        [0.0635],\n",
      "        [0.0316],\n",
      "        [0.0003],\n",
      "        [0.0010],\n",
      "        [0.0443],\n",
      "        [0.0170],\n",
      "        [0.0167],\n",
      "        [0.0384],\n",
      "        [0.0433],\n",
      "        [0.0319],\n",
      "        [0.0396],\n",
      "        [0.0438],\n",
      "        [0.0510],\n",
      "        [0.0614],\n",
      "        [0.0126],\n",
      "        [0.0041],\n",
      "        [0.0126],\n",
      "        [0.0522],\n",
      "        [0.0612],\n",
      "        [0.0398],\n",
      "        [0.0395],\n",
      "        [0.0304],\n",
      "        [0.0105],\n",
      "        [0.0065],\n",
      "        [0.0041],\n",
      "        [0.0380],\n",
      "        [0.0644],\n",
      "        [0.0907],\n",
      "        [0.0681],\n",
      "        [0.0795],\n",
      "        [0.0530],\n",
      "        [0.0343],\n",
      "        [0.0980],\n",
      "        [0.0882],\n",
      "        [0.0722],\n",
      "        [0.0691],\n",
      "        [0.0744],\n",
      "        [0.0632],\n",
      "        [0.1340],\n",
      "        [0.0190],\n",
      "        [0.0492],\n",
      "        [0.0406]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 69\n",
      "剩餘X 資料 torch.Size([308, 18])\n",
      "剩餘Y 資料 torch.Size([308, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8524])\n",
      "目前模型的Data狀態 torch.Size([69, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5493],\n",
      "        [0.5226],\n",
      "        [0.5389],\n",
      "        [0.5717],\n",
      "        [0.5610],\n",
      "        [0.5566],\n",
      "        [0.5536],\n",
      "        [0.5546],\n",
      "        [0.5416],\n",
      "        [0.5409],\n",
      "        [0.5343],\n",
      "        [0.5281],\n",
      "        [0.5190],\n",
      "        [0.5074],\n",
      "        [0.5571],\n",
      "        [0.5555],\n",
      "        [0.5521],\n",
      "        [0.5329],\n",
      "        [0.5979],\n",
      "        [0.8714],\n",
      "        [0.8826],\n",
      "        [0.9111],\n",
      "        [0.8596],\n",
      "        [0.9113],\n",
      "        [0.9245],\n",
      "        [0.8956],\n",
      "        [0.9359],\n",
      "        [0.9451],\n",
      "        [0.9758],\n",
      "        [0.9917],\n",
      "        [1.0233],\n",
      "        [0.9803],\n",
      "        [0.9666],\n",
      "        [0.9416],\n",
      "        [0.9241],\n",
      "        [0.9119],\n",
      "        [0.8494],\n",
      "        [0.8703],\n",
      "        [0.8856],\n",
      "        [0.8545],\n",
      "        [0.8407],\n",
      "        [0.8506],\n",
      "        [0.8581],\n",
      "        [0.8451],\n",
      "        [0.8677],\n",
      "        [0.8714],\n",
      "        [0.8431],\n",
      "        [0.8188],\n",
      "        [0.8400],\n",
      "        [0.8431],\n",
      "        [0.8084],\n",
      "        [0.8474],\n",
      "        [0.8843],\n",
      "        [0.9051],\n",
      "        [0.9081],\n",
      "        [0.9221],\n",
      "        [0.9165],\n",
      "        [0.9187],\n",
      "        [0.9020],\n",
      "        [0.8803],\n",
      "        [0.8960],\n",
      "        [0.8978],\n",
      "        [0.8778],\n",
      "        [0.8387],\n",
      "        [0.8419],\n",
      "        [0.8623],\n",
      "        [0.8788],\n",
      "        [0.8869],\n",
      "        [0.8447]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0176],\n",
      "        [0.0040],\n",
      "        [0.0126],\n",
      "        [0.0080],\n",
      "        [0.0020],\n",
      "        [0.0045],\n",
      "        [0.0022],\n",
      "        [0.0067],\n",
      "        [0.0151],\n",
      "        [0.0003],\n",
      "        [0.0024],\n",
      "        [0.0059],\n",
      "        [0.0140],\n",
      "        [0.0157],\n",
      "        [0.0124],\n",
      "        [0.0142],\n",
      "        [0.0270],\n",
      "        [0.0387],\n",
      "        [0.0302],\n",
      "        [0.0674],\n",
      "        [0.0690],\n",
      "        [0.0689],\n",
      "        [0.0149],\n",
      "        [0.0176],\n",
      "        [0.0576],\n",
      "        [0.0791],\n",
      "        [0.0635],\n",
      "        [0.0316],\n",
      "        [0.0003],\n",
      "        [0.0010],\n",
      "        [0.0443],\n",
      "        [0.0170],\n",
      "        [0.0167],\n",
      "        [0.0384],\n",
      "        [0.0433],\n",
      "        [0.0319],\n",
      "        [0.0396],\n",
      "        [0.0438],\n",
      "        [0.0510],\n",
      "        [0.0614],\n",
      "        [0.0126],\n",
      "        [0.0041],\n",
      "        [0.0126],\n",
      "        [0.0522],\n",
      "        [0.0612],\n",
      "        [0.0398],\n",
      "        [0.0395],\n",
      "        [0.0304],\n",
      "        [0.0105],\n",
      "        [0.0065],\n",
      "        [0.0041],\n",
      "        [0.0380],\n",
      "        [0.0644],\n",
      "        [0.0907],\n",
      "        [0.0681],\n",
      "        [0.0795],\n",
      "        [0.0530],\n",
      "        [0.0343],\n",
      "        [0.0980],\n",
      "        [0.0882],\n",
      "        [0.0722],\n",
      "        [0.0691],\n",
      "        [0.0744],\n",
      "        [0.0632],\n",
      "        [0.1340],\n",
      "        [0.0190],\n",
      "        [0.0492],\n",
      "        [0.0406],\n",
      "        [0.0077]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0170],\n",
      "        [    0.0039],\n",
      "        [    0.0113],\n",
      "        [    0.0094],\n",
      "        [    0.0017],\n",
      "        [    0.0047],\n",
      "        [    0.0026],\n",
      "        [    0.0063],\n",
      "        [    0.0144],\n",
      "        [    0.0001],\n",
      "        [    0.0023],\n",
      "        [    0.0055],\n",
      "        [    0.0137],\n",
      "        [    0.0158],\n",
      "        [    0.0118],\n",
      "        [    0.0151],\n",
      "        [    0.0271],\n",
      "        [    0.0401],\n",
      "        [    0.0289],\n",
      "        [    0.0674],\n",
      "        [    0.0691],\n",
      "        [    0.0693],\n",
      "        [    0.0155],\n",
      "        [    0.0176],\n",
      "        [    0.0575],\n",
      "        [    0.0777],\n",
      "        [    0.0618],\n",
      "        [    0.0295],\n",
      "        [    0.0025],\n",
      "        [    0.0006],\n",
      "        [    0.0453],\n",
      "        [    0.0169],\n",
      "        [    0.0171],\n",
      "        [    0.0390],\n",
      "        [    0.0434],\n",
      "        [    0.0324],\n",
      "        [    0.0405],\n",
      "        [    0.0438],\n",
      "        [    0.0510],\n",
      "        [    0.0612],\n",
      "        [    0.0125],\n",
      "        [    0.0039],\n",
      "        [    0.0132],\n",
      "        [    0.0526],\n",
      "        [    0.0613],\n",
      "        [    0.0392],\n",
      "        [    0.0392],\n",
      "        [    0.0304],\n",
      "        [    0.0107],\n",
      "        [    0.0061],\n",
      "        [    0.0039],\n",
      "        [    0.0378],\n",
      "        [    0.0644],\n",
      "        [    0.0911],\n",
      "        [    0.0678],\n",
      "        [    0.0798],\n",
      "        [    0.0533],\n",
      "        [    0.0337],\n",
      "        [    0.0973],\n",
      "        [    0.0874],\n",
      "        [    0.0710],\n",
      "        [    0.0683],\n",
      "        [    0.0738],\n",
      "        [    0.0637],\n",
      "        [    0.1324],\n",
      "        [    0.0169],\n",
      "        [    0.0477],\n",
      "        [    0.0388],\n",
      "        [    0.0094]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 70\n",
      "剩餘X 資料 torch.Size([307, 18])\n",
      "剩餘Y 資料 torch.Size([307, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8892])\n",
      "目前模型的Data狀態 torch.Size([70, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5499],\n",
      "        [0.5226],\n",
      "        [0.5401],\n",
      "        [0.5732],\n",
      "        [0.5607],\n",
      "        [0.5564],\n",
      "        [0.5533],\n",
      "        [0.5542],\n",
      "        [0.5408],\n",
      "        [0.5405],\n",
      "        [0.5343],\n",
      "        [0.5285],\n",
      "        [0.5192],\n",
      "        [0.5072],\n",
      "        [0.5578],\n",
      "        [0.5564],\n",
      "        [0.5521],\n",
      "        [0.5315],\n",
      "        [0.5966],\n",
      "        [0.8713],\n",
      "        [0.8826],\n",
      "        [0.9115],\n",
      "        [0.8602],\n",
      "        [0.9113],\n",
      "        [0.9246],\n",
      "        [0.8970],\n",
      "        [0.9376],\n",
      "        [0.9472],\n",
      "        [0.9780],\n",
      "        [0.9933],\n",
      "        [1.0243],\n",
      "        [0.9803],\n",
      "        [0.9663],\n",
      "        [0.9411],\n",
      "        [0.9240],\n",
      "        [0.9114],\n",
      "        [0.8485],\n",
      "        [0.8703],\n",
      "        [0.8857],\n",
      "        [0.8547],\n",
      "        [0.8409],\n",
      "        [0.8508],\n",
      "        [0.8586],\n",
      "        [0.8455],\n",
      "        [0.8678],\n",
      "        [0.8708],\n",
      "        [0.8429],\n",
      "        [0.8188],\n",
      "        [0.8403],\n",
      "        [0.8435],\n",
      "        [0.8081],\n",
      "        [0.8472],\n",
      "        [0.8844],\n",
      "        [0.9056],\n",
      "        [0.9078],\n",
      "        [0.9223],\n",
      "        [0.9169],\n",
      "        [0.9193],\n",
      "        [0.9027],\n",
      "        [0.8810],\n",
      "        [0.8971],\n",
      "        [0.8986],\n",
      "        [0.8783],\n",
      "        [0.8382],\n",
      "        [0.8403],\n",
      "        [0.8602],\n",
      "        [0.8773],\n",
      "        [0.8850],\n",
      "        [0.8430],\n",
      "        [0.8794]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0170],\n",
      "        [    0.0039],\n",
      "        [    0.0113],\n",
      "        [    0.0094],\n",
      "        [    0.0017],\n",
      "        [    0.0047],\n",
      "        [    0.0026],\n",
      "        [    0.0063],\n",
      "        [    0.0144],\n",
      "        [    0.0001],\n",
      "        [    0.0023],\n",
      "        [    0.0055],\n",
      "        [    0.0137],\n",
      "        [    0.0158],\n",
      "        [    0.0118],\n",
      "        [    0.0151],\n",
      "        [    0.0271],\n",
      "        [    0.0401],\n",
      "        [    0.0289],\n",
      "        [    0.0674],\n",
      "        [    0.0691],\n",
      "        [    0.0693],\n",
      "        [    0.0155],\n",
      "        [    0.0176],\n",
      "        [    0.0575],\n",
      "        [    0.0777],\n",
      "        [    0.0618],\n",
      "        [    0.0295],\n",
      "        [    0.0025],\n",
      "        [    0.0006],\n",
      "        [    0.0453],\n",
      "        [    0.0169],\n",
      "        [    0.0171],\n",
      "        [    0.0390],\n",
      "        [    0.0434],\n",
      "        [    0.0324],\n",
      "        [    0.0405],\n",
      "        [    0.0438],\n",
      "        [    0.0510],\n",
      "        [    0.0612],\n",
      "        [    0.0125],\n",
      "        [    0.0039],\n",
      "        [    0.0132],\n",
      "        [    0.0526],\n",
      "        [    0.0613],\n",
      "        [    0.0392],\n",
      "        [    0.0392],\n",
      "        [    0.0304],\n",
      "        [    0.0107],\n",
      "        [    0.0061],\n",
      "        [    0.0039],\n",
      "        [    0.0378],\n",
      "        [    0.0644],\n",
      "        [    0.0911],\n",
      "        [    0.0678],\n",
      "        [    0.0798],\n",
      "        [    0.0533],\n",
      "        [    0.0337],\n",
      "        [    0.0973],\n",
      "        [    0.0874],\n",
      "        [    0.0710],\n",
      "        [    0.0683],\n",
      "        [    0.0738],\n",
      "        [    0.0637],\n",
      "        [    0.1324],\n",
      "        [    0.0169],\n",
      "        [    0.0477],\n",
      "        [    0.0388],\n",
      "        [    0.0094],\n",
      "        [    0.0098]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0163],\n",
      "        [    0.0035],\n",
      "        [    0.0099],\n",
      "        [    0.0111],\n",
      "        [    0.0018],\n",
      "        [    0.0045],\n",
      "        [    0.0026],\n",
      "        [    0.0063],\n",
      "        [    0.0141],\n",
      "        [    0.0000],\n",
      "        [    0.0020],\n",
      "        [    0.0048],\n",
      "        [    0.0132],\n",
      "        [    0.0157],\n",
      "        [    0.0113],\n",
      "        [    0.0157],\n",
      "        [    0.0270],\n",
      "        [    0.0415],\n",
      "        [    0.0279],\n",
      "        [    0.0677],\n",
      "        [    0.0695],\n",
      "        [    0.0700],\n",
      "        [    0.0164],\n",
      "        [    0.0173],\n",
      "        [    0.0571],\n",
      "        [    0.0762],\n",
      "        [    0.0599],\n",
      "        [    0.0272],\n",
      "        [    0.0047],\n",
      "        [    0.0023],\n",
      "        [    0.0466],\n",
      "        [    0.0164],\n",
      "        [    0.0169],\n",
      "        [    0.0389],\n",
      "        [    0.0429],\n",
      "        [    0.0323],\n",
      "        [    0.0406],\n",
      "        [    0.0433],\n",
      "        [    0.0504],\n",
      "        [    0.0605],\n",
      "        [    0.0118],\n",
      "        [    0.0032],\n",
      "        [    0.0142],\n",
      "        [    0.0535],\n",
      "        [    0.0619],\n",
      "        [    0.0392],\n",
      "        [    0.0395],\n",
      "        [    0.0298],\n",
      "        [    0.0114],\n",
      "        [    0.0053],\n",
      "        [    0.0041],\n",
      "        [    0.0381],\n",
      "        [    0.0650],\n",
      "        [    0.0920],\n",
      "        [    0.0679],\n",
      "        [    0.0804],\n",
      "        [    0.0541],\n",
      "        [    0.0328],\n",
      "        [    0.0962],\n",
      "        [    0.0863],\n",
      "        [    0.0695],\n",
      "        [    0.0670],\n",
      "        [    0.0727],\n",
      "        [    0.0635],\n",
      "        [    0.1315],\n",
      "        [    0.0157],\n",
      "        [    0.0469],\n",
      "        [    0.0378],\n",
      "        [    0.0103],\n",
      "        [    0.0101]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 71\n",
      "剩餘X 資料 torch.Size([306, 18])\n",
      "剩餘Y 資料 torch.Size([306, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8978])\n",
      "目前模型的Data狀態 torch.Size([71, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5506],\n",
      "        [0.5230],\n",
      "        [0.5415],\n",
      "        [0.5749],\n",
      "        [0.5608],\n",
      "        [0.5566],\n",
      "        [0.5533],\n",
      "        [0.5542],\n",
      "        [0.5405],\n",
      "        [0.5406],\n",
      "        [0.5346],\n",
      "        [0.5292],\n",
      "        [0.5197],\n",
      "        [0.5073],\n",
      "        [0.5583],\n",
      "        [0.5570],\n",
      "        [0.5521],\n",
      "        [0.5301],\n",
      "        [0.5956],\n",
      "        [0.8716],\n",
      "        [0.8831],\n",
      "        [0.9122],\n",
      "        [0.8611],\n",
      "        [0.9117],\n",
      "        [0.9250],\n",
      "        [0.8985],\n",
      "        [0.9395],\n",
      "        [0.9495],\n",
      "        [0.9803],\n",
      "        [0.9951],\n",
      "        [1.0256],\n",
      "        [0.9808],\n",
      "        [0.9665],\n",
      "        [0.9411],\n",
      "        [0.9244],\n",
      "        [0.9114],\n",
      "        [0.8483],\n",
      "        [0.8708],\n",
      "        [0.8863],\n",
      "        [0.8554],\n",
      "        [0.8416],\n",
      "        [0.8516],\n",
      "        [0.8597],\n",
      "        [0.8464],\n",
      "        [0.8685],\n",
      "        [0.8707],\n",
      "        [0.8432],\n",
      "        [0.8194],\n",
      "        [0.8410],\n",
      "        [0.8443],\n",
      "        [0.8084],\n",
      "        [0.8475],\n",
      "        [0.8849],\n",
      "        [0.9064],\n",
      "        [0.9080],\n",
      "        [0.9230],\n",
      "        [0.9177],\n",
      "        [0.9202],\n",
      "        [0.9038],\n",
      "        [0.8822],\n",
      "        [0.8987],\n",
      "        [0.8999],\n",
      "        [0.8794],\n",
      "        [0.8384],\n",
      "        [0.8395],\n",
      "        [0.8589],\n",
      "        [0.8766],\n",
      "        [0.8841],\n",
      "        [0.8421],\n",
      "        [0.8791],\n",
      "        [0.8241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0163],\n",
      "        [    0.0035],\n",
      "        [    0.0099],\n",
      "        [    0.0111],\n",
      "        [    0.0018],\n",
      "        [    0.0045],\n",
      "        [    0.0026],\n",
      "        [    0.0063],\n",
      "        [    0.0141],\n",
      "        [    0.0000],\n",
      "        [    0.0020],\n",
      "        [    0.0048],\n",
      "        [    0.0132],\n",
      "        [    0.0157],\n",
      "        [    0.0113],\n",
      "        [    0.0157],\n",
      "        [    0.0270],\n",
      "        [    0.0415],\n",
      "        [    0.0279],\n",
      "        [    0.0677],\n",
      "        [    0.0695],\n",
      "        [    0.0700],\n",
      "        [    0.0164],\n",
      "        [    0.0173],\n",
      "        [    0.0571],\n",
      "        [    0.0762],\n",
      "        [    0.0599],\n",
      "        [    0.0272],\n",
      "        [    0.0047],\n",
      "        [    0.0023],\n",
      "        [    0.0466],\n",
      "        [    0.0164],\n",
      "        [    0.0169],\n",
      "        [    0.0389],\n",
      "        [    0.0429],\n",
      "        [    0.0323],\n",
      "        [    0.0406],\n",
      "        [    0.0433],\n",
      "        [    0.0504],\n",
      "        [    0.0605],\n",
      "        [    0.0118],\n",
      "        [    0.0032],\n",
      "        [    0.0142],\n",
      "        [    0.0535],\n",
      "        [    0.0619],\n",
      "        [    0.0392],\n",
      "        [    0.0395],\n",
      "        [    0.0298],\n",
      "        [    0.0114],\n",
      "        [    0.0053],\n",
      "        [    0.0041],\n",
      "        [    0.0381],\n",
      "        [    0.0650],\n",
      "        [    0.0920],\n",
      "        [    0.0679],\n",
      "        [    0.0804],\n",
      "        [    0.0541],\n",
      "        [    0.0328],\n",
      "        [    0.0962],\n",
      "        [    0.0863],\n",
      "        [    0.0695],\n",
      "        [    0.0670],\n",
      "        [    0.0727],\n",
      "        [    0.0635],\n",
      "        [    0.1315],\n",
      "        [    0.0157],\n",
      "        [    0.0469],\n",
      "        [    0.0378],\n",
      "        [    0.0103],\n",
      "        [    0.0101],\n",
      "        [    0.0737]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0142],\n",
      "        [0.0017],\n",
      "        [0.0071],\n",
      "        [0.0138],\n",
      "        [0.0031],\n",
      "        [0.0031],\n",
      "        [0.0015],\n",
      "        [0.0073],\n",
      "        [0.0149],\n",
      "        [0.0011],\n",
      "        [0.0006],\n",
      "        [0.0031],\n",
      "        [0.0117],\n",
      "        [0.0145],\n",
      "        [0.0108],\n",
      "        [0.0164],\n",
      "        [0.0271],\n",
      "        [0.0421],\n",
      "        [0.0273],\n",
      "        [0.0697],\n",
      "        [0.0718],\n",
      "        [0.0725],\n",
      "        [0.0188],\n",
      "        [0.0154],\n",
      "        [0.0551],\n",
      "        [0.0734],\n",
      "        [0.0568],\n",
      "        [0.0239],\n",
      "        [0.0082],\n",
      "        [0.0052],\n",
      "        [0.0491],\n",
      "        [0.0145],\n",
      "        [0.0150],\n",
      "        [0.0370],\n",
      "        [0.0405],\n",
      "        [0.0302],\n",
      "        [0.0387],\n",
      "        [0.0409],\n",
      "        [0.0479],\n",
      "        [0.0579],\n",
      "        [0.0091],\n",
      "        [0.0005],\n",
      "        [0.0172],\n",
      "        [0.0563],\n",
      "        [0.0644],\n",
      "        [0.0412],\n",
      "        [0.0417],\n",
      "        [0.0276],\n",
      "        [0.0138],\n",
      "        [0.0028],\n",
      "        [0.0063],\n",
      "        [0.0403],\n",
      "        [0.0674],\n",
      "        [0.0946],\n",
      "        [0.0701],\n",
      "        [0.0830],\n",
      "        [0.0569],\n",
      "        [0.0299],\n",
      "        [0.0931],\n",
      "        [0.0831],\n",
      "        [0.0659],\n",
      "        [0.0636],\n",
      "        [0.0694],\n",
      "        [0.0608],\n",
      "        [0.1333],\n",
      "        [0.0171],\n",
      "        [0.0488],\n",
      "        [0.0395],\n",
      "        [0.0085],\n",
      "        [0.0077],\n",
      "        [0.0709]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 72\n",
      "剩餘X 資料 torch.Size([305, 18])\n",
      "剩餘Y 資料 torch.Size([305, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8835])\n",
      "目前模型的Data狀態 torch.Size([72, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5527],\n",
      "        [0.5248],\n",
      "        [0.5443],\n",
      "        [0.5776],\n",
      "        [0.5621],\n",
      "        [0.5579],\n",
      "        [0.5544],\n",
      "        [0.5553],\n",
      "        [0.5413],\n",
      "        [0.5417],\n",
      "        [0.5361],\n",
      "        [0.5309],\n",
      "        [0.5213],\n",
      "        [0.5085],\n",
      "        [0.5588],\n",
      "        [0.5577],\n",
      "        [0.5522],\n",
      "        [0.5295],\n",
      "        [0.5951],\n",
      "        [0.8737],\n",
      "        [0.8853],\n",
      "        [0.9146],\n",
      "        [0.8635],\n",
      "        [0.9136],\n",
      "        [0.9270],\n",
      "        [0.9014],\n",
      "        [0.9427],\n",
      "        [0.9528],\n",
      "        [0.9837],\n",
      "        [0.9979],\n",
      "        [1.0281],\n",
      "        [0.9828],\n",
      "        [0.9684],\n",
      "        [0.9431],\n",
      "        [0.9268],\n",
      "        [0.9136],\n",
      "        [0.8503],\n",
      "        [0.8732],\n",
      "        [0.8888],\n",
      "        [0.8580],\n",
      "        [0.8443],\n",
      "        [0.8542],\n",
      "        [0.8626],\n",
      "        [0.8492],\n",
      "        [0.8710],\n",
      "        [0.8727],\n",
      "        [0.8454],\n",
      "        [0.8216],\n",
      "        [0.8433],\n",
      "        [0.8468],\n",
      "        [0.8106],\n",
      "        [0.8497],\n",
      "        [0.8874],\n",
      "        [0.9091],\n",
      "        [0.9101],\n",
      "        [0.9255],\n",
      "        [0.9204],\n",
      "        [0.9231],\n",
      "        [0.9069],\n",
      "        [0.8854],\n",
      "        [0.9023],\n",
      "        [0.9034],\n",
      "        [0.8828],\n",
      "        [0.8410],\n",
      "        [0.8412],\n",
      "        [0.8604],\n",
      "        [0.8785],\n",
      "        [0.8858],\n",
      "        [0.8439],\n",
      "        [0.8815],\n",
      "        [0.8269],\n",
      "        [0.8305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0142],\n",
      "        [0.0017],\n",
      "        [0.0071],\n",
      "        [0.0138],\n",
      "        [0.0031],\n",
      "        [0.0031],\n",
      "        [0.0015],\n",
      "        [0.0073],\n",
      "        [0.0149],\n",
      "        [0.0011],\n",
      "        [0.0006],\n",
      "        [0.0031],\n",
      "        [0.0117],\n",
      "        [0.0145],\n",
      "        [0.0108],\n",
      "        [0.0164],\n",
      "        [0.0271],\n",
      "        [0.0421],\n",
      "        [0.0273],\n",
      "        [0.0697],\n",
      "        [0.0718],\n",
      "        [0.0725],\n",
      "        [0.0188],\n",
      "        [0.0154],\n",
      "        [0.0551],\n",
      "        [0.0734],\n",
      "        [0.0568],\n",
      "        [0.0239],\n",
      "        [0.0082],\n",
      "        [0.0052],\n",
      "        [0.0491],\n",
      "        [0.0145],\n",
      "        [0.0150],\n",
      "        [0.0370],\n",
      "        [0.0405],\n",
      "        [0.0302],\n",
      "        [0.0387],\n",
      "        [0.0409],\n",
      "        [0.0479],\n",
      "        [0.0579],\n",
      "        [0.0091],\n",
      "        [0.0005],\n",
      "        [0.0172],\n",
      "        [0.0563],\n",
      "        [0.0644],\n",
      "        [0.0412],\n",
      "        [0.0417],\n",
      "        [0.0276],\n",
      "        [0.0138],\n",
      "        [0.0028],\n",
      "        [0.0063],\n",
      "        [0.0403],\n",
      "        [0.0674],\n",
      "        [0.0946],\n",
      "        [0.0701],\n",
      "        [0.0830],\n",
      "        [0.0569],\n",
      "        [0.0299],\n",
      "        [0.0931],\n",
      "        [0.0831],\n",
      "        [0.0659],\n",
      "        [0.0636],\n",
      "        [0.0694],\n",
      "        [0.0608],\n",
      "        [0.1333],\n",
      "        [0.0171],\n",
      "        [0.0488],\n",
      "        [0.0395],\n",
      "        [0.0085],\n",
      "        [0.0077],\n",
      "        [0.0709],\n",
      "        [0.0529]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 7\n",
      "Number of shrink: 11\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0142],\n",
      "        [0.0017],\n",
      "        [0.0071],\n",
      "        [0.0138],\n",
      "        [0.0031],\n",
      "        [0.0031],\n",
      "        [0.0015],\n",
      "        [0.0073],\n",
      "        [0.0149],\n",
      "        [0.0011],\n",
      "        [0.0006],\n",
      "        [0.0031],\n",
      "        [0.0117],\n",
      "        [0.0145],\n",
      "        [0.0108],\n",
      "        [0.0164],\n",
      "        [0.0271],\n",
      "        [0.0421],\n",
      "        [0.0273],\n",
      "        [0.0697],\n",
      "        [0.0718],\n",
      "        [0.0725],\n",
      "        [0.0188],\n",
      "        [0.0154],\n",
      "        [0.0551],\n",
      "        [0.0734],\n",
      "        [0.0568],\n",
      "        [0.0239],\n",
      "        [0.0082],\n",
      "        [0.0052],\n",
      "        [0.0491],\n",
      "        [0.0145],\n",
      "        [0.0150],\n",
      "        [0.0370],\n",
      "        [0.0405],\n",
      "        [0.0302],\n",
      "        [0.0387],\n",
      "        [0.0409],\n",
      "        [0.0479],\n",
      "        [0.0579],\n",
      "        [0.0091],\n",
      "        [0.0005],\n",
      "        [0.0172],\n",
      "        [0.0563],\n",
      "        [0.0644],\n",
      "        [0.0412],\n",
      "        [0.0417],\n",
      "        [0.0276],\n",
      "        [0.0138],\n",
      "        [0.0028],\n",
      "        [0.0063],\n",
      "        [0.0403],\n",
      "        [0.0674],\n",
      "        [0.0946],\n",
      "        [0.0701],\n",
      "        [0.0830],\n",
      "        [0.0569],\n",
      "        [0.0299],\n",
      "        [0.0931],\n",
      "        [0.0831],\n",
      "        [0.0659],\n",
      "        [0.0636],\n",
      "        [0.0694],\n",
      "        [0.0608],\n",
      "        [0.1333],\n",
      "        [0.0171],\n",
      "        [0.0488],\n",
      "        [0.0395],\n",
      "        [0.0085],\n",
      "        [0.0077],\n",
      "        [0.0709],\n",
      "        [0.0529]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 73\n",
      "剩餘X 資料 torch.Size([304, 18])\n",
      "剩餘Y 資料 torch.Size([304, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8674])\n",
      "目前模型的Data狀態 torch.Size([73, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5527],\n",
      "        [0.5248],\n",
      "        [0.5443],\n",
      "        [0.5776],\n",
      "        [0.5621],\n",
      "        [0.5579],\n",
      "        [0.5544],\n",
      "        [0.5553],\n",
      "        [0.5413],\n",
      "        [0.5417],\n",
      "        [0.5361],\n",
      "        [0.5309],\n",
      "        [0.5213],\n",
      "        [0.5085],\n",
      "        [0.5588],\n",
      "        [0.5577],\n",
      "        [0.5522],\n",
      "        [0.5295],\n",
      "        [0.5951],\n",
      "        [0.8737],\n",
      "        [0.8853],\n",
      "        [0.9146],\n",
      "        [0.8635],\n",
      "        [0.9136],\n",
      "        [0.9270],\n",
      "        [0.9014],\n",
      "        [0.9427],\n",
      "        [0.9528],\n",
      "        [0.9837],\n",
      "        [0.9979],\n",
      "        [1.0281],\n",
      "        [0.9828],\n",
      "        [0.9684],\n",
      "        [0.9431],\n",
      "        [0.9268],\n",
      "        [0.9136],\n",
      "        [0.8503],\n",
      "        [0.8732],\n",
      "        [0.8888],\n",
      "        [0.8580],\n",
      "        [0.8443],\n",
      "        [0.8542],\n",
      "        [0.8626],\n",
      "        [0.8492],\n",
      "        [0.8710],\n",
      "        [0.8727],\n",
      "        [0.8454],\n",
      "        [0.8216],\n",
      "        [0.8433],\n",
      "        [0.8468],\n",
      "        [0.8106],\n",
      "        [0.8497],\n",
      "        [0.8874],\n",
      "        [0.9091],\n",
      "        [0.9101],\n",
      "        [0.9255],\n",
      "        [0.9204],\n",
      "        [0.9231],\n",
      "        [0.9069],\n",
      "        [0.8854],\n",
      "        [0.9023],\n",
      "        [0.9034],\n",
      "        [0.8828],\n",
      "        [0.8410],\n",
      "        [0.8412],\n",
      "        [0.8604],\n",
      "        [0.8785],\n",
      "        [0.8858],\n",
      "        [0.8439],\n",
      "        [0.8815],\n",
      "        [0.8269],\n",
      "        [0.8305],\n",
      "        [0.8277]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0142],\n",
      "        [0.0017],\n",
      "        [0.0071],\n",
      "        [0.0138],\n",
      "        [0.0031],\n",
      "        [0.0031],\n",
      "        [0.0015],\n",
      "        [0.0073],\n",
      "        [0.0149],\n",
      "        [0.0011],\n",
      "        [0.0006],\n",
      "        [0.0031],\n",
      "        [0.0117],\n",
      "        [0.0145],\n",
      "        [0.0108],\n",
      "        [0.0164],\n",
      "        [0.0271],\n",
      "        [0.0421],\n",
      "        [0.0273],\n",
      "        [0.0697],\n",
      "        [0.0718],\n",
      "        [0.0725],\n",
      "        [0.0188],\n",
      "        [0.0154],\n",
      "        [0.0551],\n",
      "        [0.0734],\n",
      "        [0.0568],\n",
      "        [0.0239],\n",
      "        [0.0082],\n",
      "        [0.0052],\n",
      "        [0.0491],\n",
      "        [0.0145],\n",
      "        [0.0150],\n",
      "        [0.0370],\n",
      "        [0.0405],\n",
      "        [0.0302],\n",
      "        [0.0387],\n",
      "        [0.0409],\n",
      "        [0.0479],\n",
      "        [0.0579],\n",
      "        [0.0091],\n",
      "        [0.0005],\n",
      "        [0.0172],\n",
      "        [0.0563],\n",
      "        [0.0644],\n",
      "        [0.0412],\n",
      "        [0.0417],\n",
      "        [0.0276],\n",
      "        [0.0138],\n",
      "        [0.0028],\n",
      "        [0.0063],\n",
      "        [0.0403],\n",
      "        [0.0674],\n",
      "        [0.0946],\n",
      "        [0.0701],\n",
      "        [0.0830],\n",
      "        [0.0569],\n",
      "        [0.0299],\n",
      "        [0.0931],\n",
      "        [0.0831],\n",
      "        [0.0659],\n",
      "        [0.0636],\n",
      "        [0.0694],\n",
      "        [0.0608],\n",
      "        [0.1333],\n",
      "        [0.0171],\n",
      "        [0.0488],\n",
      "        [0.0395],\n",
      "        [0.0085],\n",
      "        [0.0077],\n",
      "        [0.0709],\n",
      "        [0.0529],\n",
      "        [0.0397]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0138],\n",
      "        [0.0012],\n",
      "        [0.0059],\n",
      "        [0.0147],\n",
      "        [0.0025],\n",
      "        [0.0036],\n",
      "        [0.0022],\n",
      "        [0.0064],\n",
      "        [0.0139],\n",
      "        [0.0004],\n",
      "        [0.0008],\n",
      "        [0.0031],\n",
      "        [0.0117],\n",
      "        [0.0149],\n",
      "        [0.0118],\n",
      "        [0.0154],\n",
      "        [0.0255],\n",
      "        [0.0437],\n",
      "        [0.0246],\n",
      "        [0.0691],\n",
      "        [0.0716],\n",
      "        [0.0724],\n",
      "        [0.0189],\n",
      "        [0.0159],\n",
      "        [0.0556],\n",
      "        [0.0731],\n",
      "        [0.0564],\n",
      "        [0.0234],\n",
      "        [0.0086],\n",
      "        [0.0050],\n",
      "        [0.0484],\n",
      "        [0.0156],\n",
      "        [0.0158],\n",
      "        [0.0376],\n",
      "        [0.0406],\n",
      "        [0.0304],\n",
      "        [0.0391],\n",
      "        [0.0410],\n",
      "        [0.0481],\n",
      "        [0.0578],\n",
      "        [0.0088],\n",
      "        [0.0002],\n",
      "        [0.0178],\n",
      "        [0.0569],\n",
      "        [0.0646],\n",
      "        [0.0410],\n",
      "        [0.0418],\n",
      "        [0.0274],\n",
      "        [0.0141],\n",
      "        [0.0022],\n",
      "        [0.0070],\n",
      "        [0.0408],\n",
      "        [0.0680],\n",
      "        [0.0954],\n",
      "        [0.0704],\n",
      "        [0.0837],\n",
      "        [0.0578],\n",
      "        [0.0287],\n",
      "        [0.0918],\n",
      "        [0.0816],\n",
      "        [0.0641],\n",
      "        [0.0618],\n",
      "        [0.0676],\n",
      "        [0.0596],\n",
      "        [0.1335],\n",
      "        [0.0169],\n",
      "        [0.0491],\n",
      "        [0.0396],\n",
      "        [0.0081],\n",
      "        [0.0069],\n",
      "        [0.0694],\n",
      "        [0.0514],\n",
      "        [0.0386]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 74\n",
      "剩餘X 資料 torch.Size([303, 18])\n",
      "剩餘Y 資料 torch.Size([303, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8926])\n",
      "目前模型的Data狀態 torch.Size([74, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5531],\n",
      "        [0.5254],\n",
      "        [0.5456],\n",
      "        [0.5784],\n",
      "        [0.5615],\n",
      "        [0.5575],\n",
      "        [0.5536],\n",
      "        [0.5544],\n",
      "        [0.5403],\n",
      "        [0.5410],\n",
      "        [0.5358],\n",
      "        [0.5309],\n",
      "        [0.5212],\n",
      "        [0.5082],\n",
      "        [0.5577],\n",
      "        [0.5567],\n",
      "        [0.5506],\n",
      "        [0.5279],\n",
      "        [0.5923],\n",
      "        [0.8731],\n",
      "        [0.8852],\n",
      "        [0.9146],\n",
      "        [0.8636],\n",
      "        [0.9131],\n",
      "        [0.9265],\n",
      "        [0.9016],\n",
      "        [0.9430],\n",
      "        [0.9533],\n",
      "        [0.9841],\n",
      "        [0.9978],\n",
      "        [1.0275],\n",
      "        [0.9817],\n",
      "        [0.9676],\n",
      "        [0.9424],\n",
      "        [0.9268],\n",
      "        [0.9134],\n",
      "        [0.8499],\n",
      "        [0.8731],\n",
      "        [0.8886],\n",
      "        [0.8581],\n",
      "        [0.8445],\n",
      "        [0.8545],\n",
      "        [0.8632],\n",
      "        [0.8498],\n",
      "        [0.8711],\n",
      "        [0.8725],\n",
      "        [0.8455],\n",
      "        [0.8218],\n",
      "        [0.8436],\n",
      "        [0.8474],\n",
      "        [0.8112],\n",
      "        [0.8502],\n",
      "        [0.8880],\n",
      "        [0.9098],\n",
      "        [0.9105],\n",
      "        [0.9263],\n",
      "        [0.9213],\n",
      "        [0.9243],\n",
      "        [0.9082],\n",
      "        [0.8868],\n",
      "        [0.9041],\n",
      "        [0.9051],\n",
      "        [0.8845],\n",
      "        [0.8422],\n",
      "        [0.8415],\n",
      "        [0.8602],\n",
      "        [0.8787],\n",
      "        [0.8859],\n",
      "        [0.8443],\n",
      "        [0.8823],\n",
      "        [0.8285],\n",
      "        [0.8321],\n",
      "        [0.8288],\n",
      "        [0.8373]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0138],\n",
      "        [0.0012],\n",
      "        [0.0059],\n",
      "        [0.0147],\n",
      "        [0.0025],\n",
      "        [0.0036],\n",
      "        [0.0022],\n",
      "        [0.0064],\n",
      "        [0.0139],\n",
      "        [0.0004],\n",
      "        [0.0008],\n",
      "        [0.0031],\n",
      "        [0.0117],\n",
      "        [0.0149],\n",
      "        [0.0118],\n",
      "        [0.0154],\n",
      "        [0.0255],\n",
      "        [0.0437],\n",
      "        [0.0246],\n",
      "        [0.0691],\n",
      "        [0.0716],\n",
      "        [0.0724],\n",
      "        [0.0189],\n",
      "        [0.0159],\n",
      "        [0.0556],\n",
      "        [0.0731],\n",
      "        [0.0564],\n",
      "        [0.0234],\n",
      "        [0.0086],\n",
      "        [0.0050],\n",
      "        [0.0484],\n",
      "        [0.0156],\n",
      "        [0.0158],\n",
      "        [0.0376],\n",
      "        [0.0406],\n",
      "        [0.0304],\n",
      "        [0.0391],\n",
      "        [0.0410],\n",
      "        [0.0481],\n",
      "        [0.0578],\n",
      "        [0.0088],\n",
      "        [0.0002],\n",
      "        [0.0178],\n",
      "        [0.0569],\n",
      "        [0.0646],\n",
      "        [0.0410],\n",
      "        [0.0418],\n",
      "        [0.0274],\n",
      "        [0.0141],\n",
      "        [0.0022],\n",
      "        [0.0070],\n",
      "        [0.0408],\n",
      "        [0.0680],\n",
      "        [0.0954],\n",
      "        [0.0704],\n",
      "        [0.0837],\n",
      "        [0.0578],\n",
      "        [0.0287],\n",
      "        [0.0918],\n",
      "        [0.0816],\n",
      "        [0.0641],\n",
      "        [0.0618],\n",
      "        [0.0676],\n",
      "        [0.0596],\n",
      "        [0.1335],\n",
      "        [0.0169],\n",
      "        [0.0491],\n",
      "        [0.0396],\n",
      "        [0.0081],\n",
      "        [0.0069],\n",
      "        [0.0694],\n",
      "        [0.0514],\n",
      "        [0.0386],\n",
      "        [0.0553]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0120],\n",
      "        [    0.0007],\n",
      "        [    0.0034],\n",
      "        [    0.0167],\n",
      "        [    0.0033],\n",
      "        [    0.0027],\n",
      "        [    0.0017],\n",
      "        [    0.0069],\n",
      "        [    0.0142],\n",
      "        [    0.0011],\n",
      "        [    0.0002],\n",
      "        [    0.0018],\n",
      "        [    0.0104],\n",
      "        [    0.0139],\n",
      "        [    0.0114],\n",
      "        [    0.0159],\n",
      "        [    0.0254],\n",
      "        [    0.0437],\n",
      "        [    0.0235],\n",
      "        [    0.0704],\n",
      "        [    0.0733],\n",
      "        [    0.0742],\n",
      "        [    0.0207],\n",
      "        [    0.0146],\n",
      "        [    0.0544],\n",
      "        [    0.0712],\n",
      "        [    0.0544],\n",
      "        [    0.0213],\n",
      "        [    0.0105],\n",
      "        [    0.0065],\n",
      "        [    0.0494],\n",
      "        [    0.0150],\n",
      "        [    0.0148],\n",
      "        [    0.0365],\n",
      "        [    0.0388],\n",
      "        [    0.0288],\n",
      "        [    0.0376],\n",
      "        [    0.0392],\n",
      "        [    0.0465],\n",
      "        [    0.0561],\n",
      "        [    0.0068],\n",
      "        [    0.0018],\n",
      "        [    0.0201],\n",
      "        [    0.0592],\n",
      "        [    0.0665],\n",
      "        [    0.0425],\n",
      "        [    0.0436],\n",
      "        [    0.0256],\n",
      "        [    0.0160],\n",
      "        [    0.0000],\n",
      "        [    0.0093],\n",
      "        [    0.0430],\n",
      "        [    0.0703],\n",
      "        [    0.0978],\n",
      "        [    0.0724],\n",
      "        [    0.0861],\n",
      "        [    0.0603],\n",
      "        [    0.0259],\n",
      "        [    0.0887],\n",
      "        [    0.0785],\n",
      "        [    0.0606],\n",
      "        [    0.0583],\n",
      "        [    0.0640],\n",
      "        [    0.0564],\n",
      "        [    0.1358],\n",
      "        [    0.0188],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0059],\n",
      "        [    0.0042],\n",
      "        [    0.0660],\n",
      "        [    0.0480],\n",
      "        [    0.0355],\n",
      "        [    0.0522]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 75\n",
      "剩餘X 資料 torch.Size([302, 18])\n",
      "剩餘Y 資料 torch.Size([302, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9096])\n",
      "目前模型的Data狀態 torch.Size([75, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5549],\n",
      "        [0.5273],\n",
      "        [0.5481],\n",
      "        [0.5804],\n",
      "        [0.5623],\n",
      "        [0.5584],\n",
      "        [0.5542],\n",
      "        [0.5548],\n",
      "        [0.5407],\n",
      "        [0.5416],\n",
      "        [0.5368],\n",
      "        [0.5322],\n",
      "        [0.5225],\n",
      "        [0.5092],\n",
      "        [0.5581],\n",
      "        [0.5572],\n",
      "        [0.5505],\n",
      "        [0.5279],\n",
      "        [0.5913],\n",
      "        [0.8743],\n",
      "        [0.8868],\n",
      "        [0.9163],\n",
      "        [0.8654],\n",
      "        [0.9143],\n",
      "        [0.9277],\n",
      "        [0.9035],\n",
      "        [0.9450],\n",
      "        [0.9554],\n",
      "        [0.9861],\n",
      "        [0.9992],\n",
      "        [1.0285],\n",
      "        [0.9823],\n",
      "        [0.9685],\n",
      "        [0.9435],\n",
      "        [0.9286],\n",
      "        [0.9150],\n",
      "        [0.8514],\n",
      "        [0.8749],\n",
      "        [0.8902],\n",
      "        [0.8599],\n",
      "        [0.8466],\n",
      "        [0.8566],\n",
      "        [0.8656],\n",
      "        [0.8521],\n",
      "        [0.8730],\n",
      "        [0.8740],\n",
      "        [0.8473],\n",
      "        [0.8236],\n",
      "        [0.8456],\n",
      "        [0.8496],\n",
      "        [0.8136],\n",
      "        [0.8524],\n",
      "        [0.8902],\n",
      "        [0.9122],\n",
      "        [0.9125],\n",
      "        [0.9287],\n",
      "        [0.9239],\n",
      "        [0.9271],\n",
      "        [0.9113],\n",
      "        [0.8900],\n",
      "        [0.9075],\n",
      "        [0.9086],\n",
      "        [0.8881],\n",
      "        [0.8454],\n",
      "        [0.8437],\n",
      "        [0.8621],\n",
      "        [0.8809],\n",
      "        [0.8880],\n",
      "        [0.8465],\n",
      "        [0.8851],\n",
      "        [0.8318],\n",
      "        [0.8355],\n",
      "        [0.8319],\n",
      "        [0.8403],\n",
      "        [0.8220]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0120],\n",
      "        [    0.0007],\n",
      "        [    0.0034],\n",
      "        [    0.0167],\n",
      "        [    0.0033],\n",
      "        [    0.0027],\n",
      "        [    0.0017],\n",
      "        [    0.0069],\n",
      "        [    0.0142],\n",
      "        [    0.0011],\n",
      "        [    0.0002],\n",
      "        [    0.0018],\n",
      "        [    0.0104],\n",
      "        [    0.0139],\n",
      "        [    0.0114],\n",
      "        [    0.0159],\n",
      "        [    0.0254],\n",
      "        [    0.0437],\n",
      "        [    0.0235],\n",
      "        [    0.0704],\n",
      "        [    0.0733],\n",
      "        [    0.0742],\n",
      "        [    0.0207],\n",
      "        [    0.0146],\n",
      "        [    0.0544],\n",
      "        [    0.0712],\n",
      "        [    0.0544],\n",
      "        [    0.0213],\n",
      "        [    0.0105],\n",
      "        [    0.0065],\n",
      "        [    0.0494],\n",
      "        [    0.0150],\n",
      "        [    0.0148],\n",
      "        [    0.0365],\n",
      "        [    0.0388],\n",
      "        [    0.0288],\n",
      "        [    0.0376],\n",
      "        [    0.0392],\n",
      "        [    0.0465],\n",
      "        [    0.0561],\n",
      "        [    0.0068],\n",
      "        [    0.0018],\n",
      "        [    0.0201],\n",
      "        [    0.0592],\n",
      "        [    0.0665],\n",
      "        [    0.0425],\n",
      "        [    0.0436],\n",
      "        [    0.0256],\n",
      "        [    0.0160],\n",
      "        [    0.0000],\n",
      "        [    0.0093],\n",
      "        [    0.0430],\n",
      "        [    0.0703],\n",
      "        [    0.0978],\n",
      "        [    0.0724],\n",
      "        [    0.0861],\n",
      "        [    0.0603],\n",
      "        [    0.0259],\n",
      "        [    0.0887],\n",
      "        [    0.0785],\n",
      "        [    0.0606],\n",
      "        [    0.0583],\n",
      "        [    0.0640],\n",
      "        [    0.0564],\n",
      "        [    0.1358],\n",
      "        [    0.0188],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0059],\n",
      "        [    0.0042],\n",
      "        [    0.0660],\n",
      "        [    0.0480],\n",
      "        [    0.0355],\n",
      "        [    0.0522],\n",
      "        [    0.0876]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0117],\n",
      "        [    0.0014],\n",
      "        [    0.0024],\n",
      "        [    0.0168],\n",
      "        [    0.0025],\n",
      "        [    0.0033],\n",
      "        [    0.0027],\n",
      "        [    0.0057],\n",
      "        [    0.0131],\n",
      "        [    0.0002],\n",
      "        [    0.0004],\n",
      "        [    0.0021],\n",
      "        [    0.0107],\n",
      "        [    0.0143],\n",
      "        [    0.0130],\n",
      "        [    0.0144],\n",
      "        [    0.0234],\n",
      "        [    0.0451],\n",
      "        [    0.0205],\n",
      "        [    0.0693],\n",
      "        [    0.0727],\n",
      "        [    0.0736],\n",
      "        [    0.0202],\n",
      "        [    0.0158],\n",
      "        [    0.0558],\n",
      "        [    0.0719],\n",
      "        [    0.0553],\n",
      "        [    0.0222],\n",
      "        [    0.0095],\n",
      "        [    0.0050],\n",
      "        [    0.0474],\n",
      "        [    0.0171],\n",
      "        [    0.0164],\n",
      "        [    0.0377],\n",
      "        [    0.0393],\n",
      "        [    0.0294],\n",
      "        [    0.0380],\n",
      "        [    0.0396],\n",
      "        [    0.0472],\n",
      "        [    0.0565],\n",
      "        [    0.0069],\n",
      "        [    0.0016],\n",
      "        [    0.0203],\n",
      "        [    0.0595],\n",
      "        [    0.0661],\n",
      "        [    0.0419],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0158],\n",
      "        [    0.0001],\n",
      "        [    0.0099],\n",
      "        [    0.0432],\n",
      "        [    0.0704],\n",
      "        [    0.0979],\n",
      "        [    0.0722],\n",
      "        [    0.0862],\n",
      "        [    0.0606],\n",
      "        [    0.0254],\n",
      "        [    0.0879],\n",
      "        [    0.0775],\n",
      "        [    0.0594],\n",
      "        [    0.0569],\n",
      "        [    0.0624],\n",
      "        [    0.0548],\n",
      "        [    0.1365],\n",
      "        [    0.0191],\n",
      "        [    0.0518],\n",
      "        [    0.0421],\n",
      "        [    0.0053],\n",
      "        [    0.0033],\n",
      "        [    0.0642],\n",
      "        [    0.0461],\n",
      "        [    0.0341],\n",
      "        [    0.0507],\n",
      "        [    0.0859]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 76\n",
      "剩餘X 資料 torch.Size([301, 18])\n",
      "剩餘Y 資料 torch.Size([301, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9059])\n",
      "目前模型的Data狀態 torch.Size([76, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5552],\n",
      "        [0.5279],\n",
      "        [0.5490],\n",
      "        [0.5806],\n",
      "        [0.5615],\n",
      "        [0.5577],\n",
      "        [0.5532],\n",
      "        [0.5536],\n",
      "        [0.5395],\n",
      "        [0.5407],\n",
      "        [0.5362],\n",
      "        [0.5319],\n",
      "        [0.5222],\n",
      "        [0.5087],\n",
      "        [0.5566],\n",
      "        [0.5557],\n",
      "        [0.5485],\n",
      "        [0.5265],\n",
      "        [0.5883],\n",
      "        [0.8732],\n",
      "        [0.8863],\n",
      "        [0.9157],\n",
      "        [0.8649],\n",
      "        [0.9131],\n",
      "        [0.9263],\n",
      "        [0.9028],\n",
      "        [0.9441],\n",
      "        [0.9545],\n",
      "        [0.9851],\n",
      "        [0.9977],\n",
      "        [1.0265],\n",
      "        [0.9802],\n",
      "        [0.9670],\n",
      "        [0.9423],\n",
      "        [0.9280],\n",
      "        [0.9144],\n",
      "        [0.8510],\n",
      "        [0.8745],\n",
      "        [0.8895],\n",
      "        [0.8594],\n",
      "        [0.8464],\n",
      "        [0.8564],\n",
      "        [0.8657],\n",
      "        [0.8523],\n",
      "        [0.8726],\n",
      "        [0.8734],\n",
      "        [0.8469],\n",
      "        [0.8233],\n",
      "        [0.8453],\n",
      "        [0.8496],\n",
      "        [0.8142],\n",
      "        [0.8527],\n",
      "        [0.8904],\n",
      "        [0.9123],\n",
      "        [0.9123],\n",
      "        [0.9287],\n",
      "        [0.9241],\n",
      "        [0.9276],\n",
      "        [0.9121],\n",
      "        [0.8910],\n",
      "        [0.9088],\n",
      "        [0.9101],\n",
      "        [0.8898],\n",
      "        [0.8470],\n",
      "        [0.8444],\n",
      "        [0.8624],\n",
      "        [0.8814],\n",
      "        [0.8883],\n",
      "        [0.8471],\n",
      "        [0.8859],\n",
      "        [0.8336],\n",
      "        [0.8373],\n",
      "        [0.8334],\n",
      "        [0.8419],\n",
      "        [0.8237],\n",
      "        [0.8071]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0117],\n",
      "        [    0.0014],\n",
      "        [    0.0024],\n",
      "        [    0.0168],\n",
      "        [    0.0025],\n",
      "        [    0.0033],\n",
      "        [    0.0027],\n",
      "        [    0.0057],\n",
      "        [    0.0131],\n",
      "        [    0.0002],\n",
      "        [    0.0004],\n",
      "        [    0.0021],\n",
      "        [    0.0107],\n",
      "        [    0.0143],\n",
      "        [    0.0130],\n",
      "        [    0.0144],\n",
      "        [    0.0234],\n",
      "        [    0.0451],\n",
      "        [    0.0205],\n",
      "        [    0.0693],\n",
      "        [    0.0727],\n",
      "        [    0.0736],\n",
      "        [    0.0202],\n",
      "        [    0.0158],\n",
      "        [    0.0558],\n",
      "        [    0.0719],\n",
      "        [    0.0553],\n",
      "        [    0.0222],\n",
      "        [    0.0095],\n",
      "        [    0.0050],\n",
      "        [    0.0474],\n",
      "        [    0.0171],\n",
      "        [    0.0164],\n",
      "        [    0.0377],\n",
      "        [    0.0393],\n",
      "        [    0.0294],\n",
      "        [    0.0380],\n",
      "        [    0.0396],\n",
      "        [    0.0472],\n",
      "        [    0.0565],\n",
      "        [    0.0069],\n",
      "        [    0.0016],\n",
      "        [    0.0203],\n",
      "        [    0.0595],\n",
      "        [    0.0661],\n",
      "        [    0.0419],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0158],\n",
      "        [    0.0001],\n",
      "        [    0.0099],\n",
      "        [    0.0432],\n",
      "        [    0.0704],\n",
      "        [    0.0979],\n",
      "        [    0.0722],\n",
      "        [    0.0862],\n",
      "        [    0.0606],\n",
      "        [    0.0254],\n",
      "        [    0.0879],\n",
      "        [    0.0775],\n",
      "        [    0.0594],\n",
      "        [    0.0569],\n",
      "        [    0.0624],\n",
      "        [    0.0548],\n",
      "        [    0.1365],\n",
      "        [    0.0191],\n",
      "        [    0.0518],\n",
      "        [    0.0421],\n",
      "        [    0.0053],\n",
      "        [    0.0033],\n",
      "        [    0.0642],\n",
      "        [    0.0461],\n",
      "        [    0.0341],\n",
      "        [    0.0507],\n",
      "        [    0.0859],\n",
      "        [    0.0988]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0089],\n",
      "        [0.0043],\n",
      "        [0.0007],\n",
      "        [0.0192],\n",
      "        [0.0042],\n",
      "        [0.0014],\n",
      "        [0.0011],\n",
      "        [0.0070],\n",
      "        [0.0144],\n",
      "        [0.0017],\n",
      "        [0.0014],\n",
      "        [0.0002],\n",
      "        [0.0088],\n",
      "        [0.0125],\n",
      "        [0.0133],\n",
      "        [0.0142],\n",
      "        [0.0229],\n",
      "        [0.0446],\n",
      "        [0.0200],\n",
      "        [0.0715],\n",
      "        [0.0754],\n",
      "        [0.0760],\n",
      "        [0.0228],\n",
      "        [0.0141],\n",
      "        [0.0542],\n",
      "        [0.0701],\n",
      "        [0.0538],\n",
      "        [0.0208],\n",
      "        [0.0109],\n",
      "        [0.0060],\n",
      "        [0.0481],\n",
      "        [0.0161],\n",
      "        [0.0147],\n",
      "        [0.0356],\n",
      "        [0.0366],\n",
      "        [0.0265],\n",
      "        [0.0346],\n",
      "        [0.0366],\n",
      "        [0.0446],\n",
      "        [0.0537],\n",
      "        [0.0038],\n",
      "        [0.0046],\n",
      "        [0.0235],\n",
      "        [0.0628],\n",
      "        [0.0687],\n",
      "        [0.0443],\n",
      "        [0.0459],\n",
      "        [0.0235],\n",
      "        [0.0182],\n",
      "        [0.0027],\n",
      "        [0.0133],\n",
      "        [0.0462],\n",
      "        [0.0730],\n",
      "        [0.1003],\n",
      "        [0.0746],\n",
      "        [0.0886],\n",
      "        [0.0632],\n",
      "        [0.0226],\n",
      "        [0.0848],\n",
      "        [0.0740],\n",
      "        [0.0558],\n",
      "        [0.0528],\n",
      "        [0.0578],\n",
      "        [0.0499],\n",
      "        [0.1409],\n",
      "        [0.0232],\n",
      "        [0.0559],\n",
      "        [0.0461],\n",
      "        [0.0012],\n",
      "        [0.0007],\n",
      "        [0.0593],\n",
      "        [0.0412],\n",
      "        [0.0294],\n",
      "        [0.0459],\n",
      "        [0.0809],\n",
      "        [0.0940]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 77\n",
      "剩餘X 資料 torch.Size([300, 18])\n",
      "剩餘Y 資料 torch.Size([300, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9200])\n",
      "目前模型的Data狀態 torch.Size([77, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5580],\n",
      "        [0.5309],\n",
      "        [0.5521],\n",
      "        [0.5830],\n",
      "        [0.5632],\n",
      "        [0.5596],\n",
      "        [0.5547],\n",
      "        [0.5550],\n",
      "        [0.5409],\n",
      "        [0.5423],\n",
      "        [0.5380],\n",
      "        [0.5338],\n",
      "        [0.5241],\n",
      "        [0.5105],\n",
      "        [0.5563],\n",
      "        [0.5555],\n",
      "        [0.5480],\n",
      "        [0.5270],\n",
      "        [0.5878],\n",
      "        [0.8755],\n",
      "        [0.8890],\n",
      "        [0.9182],\n",
      "        [0.8674],\n",
      "        [0.9149],\n",
      "        [0.9279],\n",
      "        [0.9046],\n",
      "        [0.9456],\n",
      "        [0.9559],\n",
      "        [0.9864],\n",
      "        [0.9988],\n",
      "        [1.0271],\n",
      "        [0.9812],\n",
      "        [0.9687],\n",
      "        [0.9444],\n",
      "        [0.9307],\n",
      "        [0.9173],\n",
      "        [0.8543],\n",
      "        [0.8775],\n",
      "        [0.8920],\n",
      "        [0.8622],\n",
      "        [0.8495],\n",
      "        [0.8594],\n",
      "        [0.8689],\n",
      "        [0.8557],\n",
      "        [0.8753],\n",
      "        [0.8758],\n",
      "        [0.8495],\n",
      "        [0.8257],\n",
      "        [0.8477],\n",
      "        [0.8523],\n",
      "        [0.8176],\n",
      "        [0.8556],\n",
      "        [0.8930],\n",
      "        [0.9148],\n",
      "        [0.9146],\n",
      "        [0.9312],\n",
      "        [0.9267],\n",
      "        [0.9304],\n",
      "        [0.9152],\n",
      "        [0.8945],\n",
      "        [0.9124],\n",
      "        [0.9141],\n",
      "        [0.8944],\n",
      "        [0.8520],\n",
      "        [0.8488],\n",
      "        [0.8665],\n",
      "        [0.8855],\n",
      "        [0.8923],\n",
      "        [0.8512],\n",
      "        [0.8899],\n",
      "        [0.8385],\n",
      "        [0.8423],\n",
      "        [0.8380],\n",
      "        [0.8467],\n",
      "        [0.8287],\n",
      "        [0.8119],\n",
      "        [0.8318]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0089],\n",
      "        [0.0043],\n",
      "        [0.0007],\n",
      "        [0.0192],\n",
      "        [0.0042],\n",
      "        [0.0014],\n",
      "        [0.0011],\n",
      "        [0.0070],\n",
      "        [0.0144],\n",
      "        [0.0017],\n",
      "        [0.0014],\n",
      "        [0.0002],\n",
      "        [0.0088],\n",
      "        [0.0125],\n",
      "        [0.0133],\n",
      "        [0.0142],\n",
      "        [0.0229],\n",
      "        [0.0446],\n",
      "        [0.0200],\n",
      "        [0.0715],\n",
      "        [0.0754],\n",
      "        [0.0760],\n",
      "        [0.0228],\n",
      "        [0.0141],\n",
      "        [0.0542],\n",
      "        [0.0701],\n",
      "        [0.0538],\n",
      "        [0.0208],\n",
      "        [0.0109],\n",
      "        [0.0060],\n",
      "        [0.0481],\n",
      "        [0.0161],\n",
      "        [0.0147],\n",
      "        [0.0356],\n",
      "        [0.0366],\n",
      "        [0.0265],\n",
      "        [0.0346],\n",
      "        [0.0366],\n",
      "        [0.0446],\n",
      "        [0.0537],\n",
      "        [0.0038],\n",
      "        [0.0046],\n",
      "        [0.0235],\n",
      "        [0.0628],\n",
      "        [0.0687],\n",
      "        [0.0443],\n",
      "        [0.0459],\n",
      "        [0.0235],\n",
      "        [0.0182],\n",
      "        [0.0027],\n",
      "        [0.0133],\n",
      "        [0.0462],\n",
      "        [0.0730],\n",
      "        [0.1003],\n",
      "        [0.0746],\n",
      "        [0.0886],\n",
      "        [0.0632],\n",
      "        [0.0226],\n",
      "        [0.0848],\n",
      "        [0.0740],\n",
      "        [0.0558],\n",
      "        [0.0528],\n",
      "        [0.0578],\n",
      "        [0.0499],\n",
      "        [0.1409],\n",
      "        [0.0232],\n",
      "        [0.0559],\n",
      "        [0.0461],\n",
      "        [0.0012],\n",
      "        [0.0007],\n",
      "        [0.0593],\n",
      "        [0.0412],\n",
      "        [0.0294],\n",
      "        [0.0459],\n",
      "        [0.0809],\n",
      "        [0.0940],\n",
      "        [0.0882]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0074],\n",
      "        [0.0060],\n",
      "        [0.0023],\n",
      "        [0.0198],\n",
      "        [0.0047],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0072],\n",
      "        [0.0147],\n",
      "        [0.0020],\n",
      "        [0.0019],\n",
      "        [0.0004],\n",
      "        [0.0082],\n",
      "        [0.0118],\n",
      "        [0.0148],\n",
      "        [0.0127],\n",
      "        [0.0213],\n",
      "        [0.0449],\n",
      "        [0.0184],\n",
      "        [0.0721],\n",
      "        [0.0765],\n",
      "        [0.0768],\n",
      "        [0.0236],\n",
      "        [0.0140],\n",
      "        [0.0544],\n",
      "        [0.0700],\n",
      "        [0.0542],\n",
      "        [0.0214],\n",
      "        [0.0103],\n",
      "        [0.0052],\n",
      "        [0.0468],\n",
      "        [0.0167],\n",
      "        [0.0147],\n",
      "        [0.0352],\n",
      "        [0.0356],\n",
      "        [0.0252],\n",
      "        [0.0327],\n",
      "        [0.0352],\n",
      "        [0.0438],\n",
      "        [0.0526],\n",
      "        [0.0024],\n",
      "        [0.0059],\n",
      "        [0.0250],\n",
      "        [0.0645],\n",
      "        [0.0696],\n",
      "        [0.0451],\n",
      "        [0.0469],\n",
      "        [0.0225],\n",
      "        [0.0190],\n",
      "        [0.0038],\n",
      "        [0.0152],\n",
      "        [0.0476],\n",
      "        [0.0739],\n",
      "        [0.1009],\n",
      "        [0.0752],\n",
      "        [0.0892],\n",
      "        [0.0640],\n",
      "        [0.0216],\n",
      "        [0.0834],\n",
      "        [0.0723],\n",
      "        [0.0541],\n",
      "        [0.0506],\n",
      "        [0.0550],\n",
      "        [0.0465],\n",
      "        [0.1439],\n",
      "        [0.0259],\n",
      "        [0.0585],\n",
      "        [0.0485],\n",
      "        [0.0013],\n",
      "        [0.0030],\n",
      "        [0.0560],\n",
      "        [0.0378],\n",
      "        [0.0262],\n",
      "        [0.0425],\n",
      "        [0.0772],\n",
      "        [0.0904],\n",
      "        [0.0856]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 78\n",
      "剩餘X 資料 torch.Size([299, 18])\n",
      "剩餘Y 資料 torch.Size([299, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9354])\n",
      "目前模型的Data狀態 torch.Size([78, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5595],\n",
      "        [0.5326],\n",
      "        [0.5537],\n",
      "        [0.5836],\n",
      "        [0.5637],\n",
      "        [0.5603],\n",
      "        [0.5550],\n",
      "        [0.5551],\n",
      "        [0.5411],\n",
      "        [0.5426],\n",
      "        [0.5385],\n",
      "        [0.5344],\n",
      "        [0.5247],\n",
      "        [0.5112],\n",
      "        [0.5548],\n",
      "        [0.5540],\n",
      "        [0.5463],\n",
      "        [0.5267],\n",
      "        [0.5862],\n",
      "        [0.8761],\n",
      "        [0.8901],\n",
      "        [0.9190],\n",
      "        [0.8683],\n",
      "        [0.9150],\n",
      "        [0.9277],\n",
      "        [0.9047],\n",
      "        [0.9452],\n",
      "        [0.9553],\n",
      "        [0.9858],\n",
      "        [0.9980],\n",
      "        [1.0259],\n",
      "        [0.9805],\n",
      "        [0.9687],\n",
      "        [0.9449],\n",
      "        [0.9317],\n",
      "        [0.9186],\n",
      "        [0.8563],\n",
      "        [0.8789],\n",
      "        [0.8929],\n",
      "        [0.8633],\n",
      "        [0.8509],\n",
      "        [0.8607],\n",
      "        [0.8704],\n",
      "        [0.8574],\n",
      "        [0.8762],\n",
      "        [0.8767],\n",
      "        [0.8505],\n",
      "        [0.8267],\n",
      "        [0.8485],\n",
      "        [0.8534],\n",
      "        [0.8195],\n",
      "        [0.8570],\n",
      "        [0.8939],\n",
      "        [0.9154],\n",
      "        [0.9153],\n",
      "        [0.9318],\n",
      "        [0.9275],\n",
      "        [0.9314],\n",
      "        [0.9166],\n",
      "        [0.8962],\n",
      "        [0.9141],\n",
      "        [0.9163],\n",
      "        [0.8972],\n",
      "        [0.8553],\n",
      "        [0.8518],\n",
      "        [0.8692],\n",
      "        [0.8881],\n",
      "        [0.8948],\n",
      "        [0.8537],\n",
      "        [0.8922],\n",
      "        [0.8419],\n",
      "        [0.8457],\n",
      "        [0.8413],\n",
      "        [0.8501],\n",
      "        [0.8324],\n",
      "        [0.8155],\n",
      "        [0.8344],\n",
      "        [0.8603]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0074],\n",
      "        [0.0060],\n",
      "        [0.0023],\n",
      "        [0.0198],\n",
      "        [0.0047],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0072],\n",
      "        [0.0147],\n",
      "        [0.0020],\n",
      "        [0.0019],\n",
      "        [0.0004],\n",
      "        [0.0082],\n",
      "        [0.0118],\n",
      "        [0.0148],\n",
      "        [0.0127],\n",
      "        [0.0213],\n",
      "        [0.0449],\n",
      "        [0.0184],\n",
      "        [0.0721],\n",
      "        [0.0765],\n",
      "        [0.0768],\n",
      "        [0.0236],\n",
      "        [0.0140],\n",
      "        [0.0544],\n",
      "        [0.0700],\n",
      "        [0.0542],\n",
      "        [0.0214],\n",
      "        [0.0103],\n",
      "        [0.0052],\n",
      "        [0.0468],\n",
      "        [0.0167],\n",
      "        [0.0147],\n",
      "        [0.0352],\n",
      "        [0.0356],\n",
      "        [0.0252],\n",
      "        [0.0327],\n",
      "        [0.0352],\n",
      "        [0.0438],\n",
      "        [0.0526],\n",
      "        [0.0024],\n",
      "        [0.0059],\n",
      "        [0.0250],\n",
      "        [0.0645],\n",
      "        [0.0696],\n",
      "        [0.0451],\n",
      "        [0.0469],\n",
      "        [0.0225],\n",
      "        [0.0190],\n",
      "        [0.0038],\n",
      "        [0.0152],\n",
      "        [0.0476],\n",
      "        [0.0739],\n",
      "        [0.1009],\n",
      "        [0.0752],\n",
      "        [0.0892],\n",
      "        [0.0640],\n",
      "        [0.0216],\n",
      "        [0.0834],\n",
      "        [0.0723],\n",
      "        [0.0541],\n",
      "        [0.0506],\n",
      "        [0.0550],\n",
      "        [0.0465],\n",
      "        [0.1439],\n",
      "        [0.0259],\n",
      "        [0.0585],\n",
      "        [0.0485],\n",
      "        [0.0013],\n",
      "        [0.0030],\n",
      "        [0.0560],\n",
      "        [0.0378],\n",
      "        [0.0262],\n",
      "        [0.0425],\n",
      "        [0.0772],\n",
      "        [0.0904],\n",
      "        [0.0856],\n",
      "        [0.0751]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0074],\n",
      "        [0.0064],\n",
      "        [0.0025],\n",
      "        [0.0190],\n",
      "        [0.0041],\n",
      "        [0.0012],\n",
      "        [0.0015],\n",
      "        [0.0063],\n",
      "        [0.0140],\n",
      "        [0.0014],\n",
      "        [0.0013],\n",
      "        [0.0002],\n",
      "        [0.0087],\n",
      "        [0.0123],\n",
      "        [0.0170],\n",
      "        [0.0105],\n",
      "        [0.0190],\n",
      "        [0.0458],\n",
      "        [0.0164],\n",
      "        [0.0717],\n",
      "        [0.0765],\n",
      "        [0.0765],\n",
      "        [0.0232],\n",
      "        [0.0149],\n",
      "        [0.0554],\n",
      "        [0.0710],\n",
      "        [0.0557],\n",
      "        [0.0230],\n",
      "        [0.0087],\n",
      "        [0.0035],\n",
      "        [0.0448],\n",
      "        [0.0182],\n",
      "        [0.0156],\n",
      "        [0.0358],\n",
      "        [0.0358],\n",
      "        [0.0251],\n",
      "        [0.0320],\n",
      "        [0.0351],\n",
      "        [0.0441],\n",
      "        [0.0528],\n",
      "        [0.0024],\n",
      "        [0.0058],\n",
      "        [0.0251],\n",
      "        [0.0648],\n",
      "        [0.0693],\n",
      "        [0.0448],\n",
      "        [0.0467],\n",
      "        [0.0228],\n",
      "        [0.0186],\n",
      "        [0.0037],\n",
      "        [0.0159],\n",
      "        [0.0477],\n",
      "        [0.0736],\n",
      "        [0.1003],\n",
      "        [0.0747],\n",
      "        [0.0887],\n",
      "        [0.0636],\n",
      "        [0.0218],\n",
      "        [0.0834],\n",
      "        [0.0720],\n",
      "        [0.0538],\n",
      "        [0.0499],\n",
      "        [0.0537],\n",
      "        [0.0447],\n",
      "        [0.1454],\n",
      "        [0.0273],\n",
      "        [0.0597],\n",
      "        [0.0497],\n",
      "        [0.0024],\n",
      "        [0.0039],\n",
      "        [0.0541],\n",
      "        [0.0359],\n",
      "        [0.0244],\n",
      "        [0.0405],\n",
      "        [0.0750],\n",
      "        [0.0881],\n",
      "        [0.0841],\n",
      "        [0.0740]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 79\n",
      "剩餘X 資料 torch.Size([298, 18])\n",
      "剩餘Y 資料 torch.Size([298, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9594])\n",
      "目前模型的Data狀態 torch.Size([79, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5595],\n",
      "        [0.5329],\n",
      "        [0.5539],\n",
      "        [0.5828],\n",
      "        [0.5631],\n",
      "        [0.5598],\n",
      "        [0.5543],\n",
      "        [0.5542],\n",
      "        [0.5404],\n",
      "        [0.5419],\n",
      "        [0.5379],\n",
      "        [0.5338],\n",
      "        [0.5242],\n",
      "        [0.5108],\n",
      "        [0.5526],\n",
      "        [0.5518],\n",
      "        [0.5440],\n",
      "        [0.5258],\n",
      "        [0.5841],\n",
      "        [0.8757],\n",
      "        [0.8900],\n",
      "        [0.9187],\n",
      "        [0.8679],\n",
      "        [0.9141],\n",
      "        [0.9267],\n",
      "        [0.9037],\n",
      "        [0.9437],\n",
      "        [0.9537],\n",
      "        [0.9842],\n",
      "        [0.9962],\n",
      "        [1.0239],\n",
      "        [0.9790],\n",
      "        [0.9677],\n",
      "        [0.9442],\n",
      "        [0.9315],\n",
      "        [0.9187],\n",
      "        [0.8570],\n",
      "        [0.8790],\n",
      "        [0.8925],\n",
      "        [0.8631],\n",
      "        [0.8509],\n",
      "        [0.8606],\n",
      "        [0.8705],\n",
      "        [0.8577],\n",
      "        [0.8758],\n",
      "        [0.8763],\n",
      "        [0.8504],\n",
      "        [0.8264],\n",
      "        [0.8482],\n",
      "        [0.8533],\n",
      "        [0.8202],\n",
      "        [0.8572],\n",
      "        [0.8936],\n",
      "        [0.9148],\n",
      "        [0.9148],\n",
      "        [0.9313],\n",
      "        [0.9271],\n",
      "        [0.9312],\n",
      "        [0.9166],\n",
      "        [0.8964],\n",
      "        [0.9143],\n",
      "        [0.9170],\n",
      "        [0.8984],\n",
      "        [0.8571],\n",
      "        [0.8533],\n",
      "        [0.8706],\n",
      "        [0.8893],\n",
      "        [0.8960],\n",
      "        [0.8548],\n",
      "        [0.8932],\n",
      "        [0.8437],\n",
      "        [0.8476],\n",
      "        [0.8430],\n",
      "        [0.8521],\n",
      "        [0.8346],\n",
      "        [0.8178],\n",
      "        [0.8359],\n",
      "        [0.8614],\n",
      "        [0.8839]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0074],\n",
      "        [0.0064],\n",
      "        [0.0025],\n",
      "        [0.0190],\n",
      "        [0.0041],\n",
      "        [0.0012],\n",
      "        [0.0015],\n",
      "        [0.0063],\n",
      "        [0.0140],\n",
      "        [0.0014],\n",
      "        [0.0013],\n",
      "        [0.0002],\n",
      "        [0.0087],\n",
      "        [0.0123],\n",
      "        [0.0170],\n",
      "        [0.0105],\n",
      "        [0.0190],\n",
      "        [0.0458],\n",
      "        [0.0164],\n",
      "        [0.0717],\n",
      "        [0.0765],\n",
      "        [0.0765],\n",
      "        [0.0232],\n",
      "        [0.0149],\n",
      "        [0.0554],\n",
      "        [0.0710],\n",
      "        [0.0557],\n",
      "        [0.0230],\n",
      "        [0.0087],\n",
      "        [0.0035],\n",
      "        [0.0448],\n",
      "        [0.0182],\n",
      "        [0.0156],\n",
      "        [0.0358],\n",
      "        [0.0358],\n",
      "        [0.0251],\n",
      "        [0.0320],\n",
      "        [0.0351],\n",
      "        [0.0441],\n",
      "        [0.0528],\n",
      "        [0.0024],\n",
      "        [0.0058],\n",
      "        [0.0251],\n",
      "        [0.0648],\n",
      "        [0.0693],\n",
      "        [0.0448],\n",
      "        [0.0467],\n",
      "        [0.0228],\n",
      "        [0.0186],\n",
      "        [0.0037],\n",
      "        [0.0159],\n",
      "        [0.0477],\n",
      "        [0.0736],\n",
      "        [0.1003],\n",
      "        [0.0747],\n",
      "        [0.0887],\n",
      "        [0.0636],\n",
      "        [0.0218],\n",
      "        [0.0834],\n",
      "        [0.0720],\n",
      "        [0.0538],\n",
      "        [0.0499],\n",
      "        [0.0537],\n",
      "        [0.0447],\n",
      "        [0.1454],\n",
      "        [0.0273],\n",
      "        [0.0597],\n",
      "        [0.0497],\n",
      "        [0.0024],\n",
      "        [0.0039],\n",
      "        [0.0541],\n",
      "        [0.0359],\n",
      "        [0.0244],\n",
      "        [0.0405],\n",
      "        [0.0750],\n",
      "        [0.0881],\n",
      "        [0.0841],\n",
      "        [0.0740],\n",
      "        [0.0755]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0057],\n",
      "        [0.0081],\n",
      "        [0.0041],\n",
      "        [0.0198],\n",
      "        [0.0050],\n",
      "        [0.0002],\n",
      "        [0.0007],\n",
      "        [0.0070],\n",
      "        [0.0148],\n",
      "        [0.0022],\n",
      "        [0.0021],\n",
      "        [0.0007],\n",
      "        [0.0079],\n",
      "        [0.0113],\n",
      "        [0.0176],\n",
      "        [0.0098],\n",
      "        [0.0182],\n",
      "        [0.0451],\n",
      "        [0.0163],\n",
      "        [0.0737],\n",
      "        [0.0789],\n",
      "        [0.0788],\n",
      "        [0.0253],\n",
      "        [0.0132],\n",
      "        [0.0538],\n",
      "        [0.0694],\n",
      "        [0.0545],\n",
      "        [0.0219],\n",
      "        [0.0100],\n",
      "        [0.0047],\n",
      "        [0.0458],\n",
      "        [0.0169],\n",
      "        [0.0138],\n",
      "        [0.0338],\n",
      "        [0.0336],\n",
      "        [0.0226],\n",
      "        [0.0291],\n",
      "        [0.0327],\n",
      "        [0.0422],\n",
      "        [0.0508],\n",
      "        [0.0003],\n",
      "        [0.0079],\n",
      "        [0.0274],\n",
      "        [0.0673],\n",
      "        [0.0712],\n",
      "        [0.0468],\n",
      "        [0.0488],\n",
      "        [0.0210],\n",
      "        [0.0205],\n",
      "        [0.0058],\n",
      "        [0.0186],\n",
      "        [0.0501],\n",
      "        [0.0757],\n",
      "        [0.1022],\n",
      "        [0.0767],\n",
      "        [0.0907],\n",
      "        [0.0656],\n",
      "        [0.0197],\n",
      "        [0.0810],\n",
      "        [0.0695],\n",
      "        [0.0514],\n",
      "        [0.0470],\n",
      "        [0.0503],\n",
      "        [0.0410],\n",
      "        [0.1490],\n",
      "        [0.0308],\n",
      "        [0.0631],\n",
      "        [0.0530],\n",
      "        [0.0054],\n",
      "        [0.0070],\n",
      "        [0.0504],\n",
      "        [0.0320],\n",
      "        [0.0206],\n",
      "        [0.0365],\n",
      "        [0.0708],\n",
      "        [0.0839],\n",
      "        [0.0805],\n",
      "        [0.0706],\n",
      "        [0.0724]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 80\n",
      "剩餘X 資料 torch.Size([297, 18])\n",
      "剩餘Y 資料 torch.Size([297, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9552])\n",
      "目前模型的Data狀態 torch.Size([80, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5612],\n",
      "        [0.5346],\n",
      "        [0.5556],\n",
      "        [0.5835],\n",
      "        [0.5640],\n",
      "        [0.5609],\n",
      "        [0.5551],\n",
      "        [0.5549],\n",
      "        [0.5412],\n",
      "        [0.5428],\n",
      "        [0.5387],\n",
      "        [0.5347],\n",
      "        [0.5251],\n",
      "        [0.5117],\n",
      "        [0.5520],\n",
      "        [0.5510],\n",
      "        [0.5433],\n",
      "        [0.5265],\n",
      "        [0.5840],\n",
      "        [0.8777],\n",
      "        [0.8924],\n",
      "        [0.9210],\n",
      "        [0.8700],\n",
      "        [0.9157],\n",
      "        [0.9283],\n",
      "        [0.9053],\n",
      "        [0.9450],\n",
      "        [0.9548],\n",
      "        [0.9855],\n",
      "        [0.9975],\n",
      "        [1.0249],\n",
      "        [0.9804],\n",
      "        [0.9695],\n",
      "        [0.9462],\n",
      "        [0.9338],\n",
      "        [0.9212],\n",
      "        [0.8599],\n",
      "        [0.8814],\n",
      "        [0.8945],\n",
      "        [0.8651],\n",
      "        [0.8530],\n",
      "        [0.8627],\n",
      "        [0.8729],\n",
      "        [0.8601],\n",
      "        [0.8777],\n",
      "        [0.8784],\n",
      "        [0.8524],\n",
      "        [0.8282],\n",
      "        [0.8500],\n",
      "        [0.8554],\n",
      "        [0.8229],\n",
      "        [0.8595],\n",
      "        [0.8957],\n",
      "        [0.9166],\n",
      "        [0.9167],\n",
      "        [0.9332],\n",
      "        [0.9292],\n",
      "        [0.9333],\n",
      "        [0.9190],\n",
      "        [0.8990],\n",
      "        [0.9168],\n",
      "        [0.9200],\n",
      "        [0.9018],\n",
      "        [0.8608],\n",
      "        [0.8569],\n",
      "        [0.8741],\n",
      "        [0.8927],\n",
      "        [0.8993],\n",
      "        [0.8578],\n",
      "        [0.8962],\n",
      "        [0.8475],\n",
      "        [0.8515],\n",
      "        [0.8469],\n",
      "        [0.8561],\n",
      "        [0.8388],\n",
      "        [0.8220],\n",
      "        [0.8395],\n",
      "        [0.8649],\n",
      "        [0.8870],\n",
      "        [0.9166]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0057],\n",
      "        [0.0081],\n",
      "        [0.0041],\n",
      "        [0.0198],\n",
      "        [0.0050],\n",
      "        [0.0002],\n",
      "        [0.0007],\n",
      "        [0.0070],\n",
      "        [0.0148],\n",
      "        [0.0022],\n",
      "        [0.0021],\n",
      "        [0.0007],\n",
      "        [0.0079],\n",
      "        [0.0113],\n",
      "        [0.0176],\n",
      "        [0.0098],\n",
      "        [0.0182],\n",
      "        [0.0451],\n",
      "        [0.0163],\n",
      "        [0.0737],\n",
      "        [0.0789],\n",
      "        [0.0788],\n",
      "        [0.0253],\n",
      "        [0.0132],\n",
      "        [0.0538],\n",
      "        [0.0694],\n",
      "        [0.0545],\n",
      "        [0.0219],\n",
      "        [0.0100],\n",
      "        [0.0047],\n",
      "        [0.0458],\n",
      "        [0.0169],\n",
      "        [0.0138],\n",
      "        [0.0338],\n",
      "        [0.0336],\n",
      "        [0.0226],\n",
      "        [0.0291],\n",
      "        [0.0327],\n",
      "        [0.0422],\n",
      "        [0.0508],\n",
      "        [0.0003],\n",
      "        [0.0079],\n",
      "        [0.0274],\n",
      "        [0.0673],\n",
      "        [0.0712],\n",
      "        [0.0468],\n",
      "        [0.0488],\n",
      "        [0.0210],\n",
      "        [0.0205],\n",
      "        [0.0058],\n",
      "        [0.0186],\n",
      "        [0.0501],\n",
      "        [0.0757],\n",
      "        [0.1022],\n",
      "        [0.0767],\n",
      "        [0.0907],\n",
      "        [0.0656],\n",
      "        [0.0197],\n",
      "        [0.0810],\n",
      "        [0.0695],\n",
      "        [0.0514],\n",
      "        [0.0470],\n",
      "        [0.0503],\n",
      "        [0.0410],\n",
      "        [0.1490],\n",
      "        [0.0308],\n",
      "        [0.0631],\n",
      "        [0.0530],\n",
      "        [0.0054],\n",
      "        [0.0070],\n",
      "        [0.0504],\n",
      "        [0.0320],\n",
      "        [0.0206],\n",
      "        [0.0365],\n",
      "        [0.0708],\n",
      "        [0.0839],\n",
      "        [0.0805],\n",
      "        [0.0706],\n",
      "        [0.0724],\n",
      "        [0.0386]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 8\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0057],\n",
      "        [0.0081],\n",
      "        [0.0041],\n",
      "        [0.0198],\n",
      "        [0.0050],\n",
      "        [0.0002],\n",
      "        [0.0007],\n",
      "        [0.0070],\n",
      "        [0.0148],\n",
      "        [0.0022],\n",
      "        [0.0021],\n",
      "        [0.0007],\n",
      "        [0.0079],\n",
      "        [0.0113],\n",
      "        [0.0176],\n",
      "        [0.0098],\n",
      "        [0.0182],\n",
      "        [0.0451],\n",
      "        [0.0163],\n",
      "        [0.0737],\n",
      "        [0.0789],\n",
      "        [0.0788],\n",
      "        [0.0253],\n",
      "        [0.0132],\n",
      "        [0.0538],\n",
      "        [0.0694],\n",
      "        [0.0545],\n",
      "        [0.0219],\n",
      "        [0.0100],\n",
      "        [0.0047],\n",
      "        [0.0458],\n",
      "        [0.0169],\n",
      "        [0.0138],\n",
      "        [0.0338],\n",
      "        [0.0336],\n",
      "        [0.0226],\n",
      "        [0.0291],\n",
      "        [0.0327],\n",
      "        [0.0422],\n",
      "        [0.0508],\n",
      "        [0.0003],\n",
      "        [0.0079],\n",
      "        [0.0274],\n",
      "        [0.0673],\n",
      "        [0.0712],\n",
      "        [0.0468],\n",
      "        [0.0488],\n",
      "        [0.0210],\n",
      "        [0.0205],\n",
      "        [0.0058],\n",
      "        [0.0186],\n",
      "        [0.0501],\n",
      "        [0.0757],\n",
      "        [0.1022],\n",
      "        [0.0767],\n",
      "        [0.0907],\n",
      "        [0.0656],\n",
      "        [0.0197],\n",
      "        [0.0811],\n",
      "        [0.0695],\n",
      "        [0.0514],\n",
      "        [0.0470],\n",
      "        [0.0503],\n",
      "        [0.0410],\n",
      "        [0.1490],\n",
      "        [0.0308],\n",
      "        [0.0631],\n",
      "        [0.0530],\n",
      "        [0.0054],\n",
      "        [0.0070],\n",
      "        [0.0504],\n",
      "        [0.0320],\n",
      "        [0.0206],\n",
      "        [0.0365],\n",
      "        [0.0708],\n",
      "        [0.0839],\n",
      "        [0.0805],\n",
      "        [0.0706],\n",
      "        [0.0724],\n",
      "        [0.0386]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 81\n",
      "剩餘X 資料 torch.Size([296, 18])\n",
      "剩餘Y 資料 torch.Size([296, 1])\n",
      "現在要進去模型的數據，y= tensor([0.9203])\n",
      "目前模型的Data狀態 torch.Size([81, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5612],\n",
      "        [0.5346],\n",
      "        [0.5556],\n",
      "        [0.5835],\n",
      "        [0.5640],\n",
      "        [0.5609],\n",
      "        [0.5551],\n",
      "        [0.5549],\n",
      "        [0.5412],\n",
      "        [0.5428],\n",
      "        [0.5387],\n",
      "        [0.5347],\n",
      "        [0.5251],\n",
      "        [0.5117],\n",
      "        [0.5520],\n",
      "        [0.5510],\n",
      "        [0.5433],\n",
      "        [0.5265],\n",
      "        [0.5840],\n",
      "        [0.8777],\n",
      "        [0.8924],\n",
      "        [0.9210],\n",
      "        [0.8700],\n",
      "        [0.9157],\n",
      "        [0.9283],\n",
      "        [0.9053],\n",
      "        [0.9450],\n",
      "        [0.9548],\n",
      "        [0.9855],\n",
      "        [0.9975],\n",
      "        [1.0249],\n",
      "        [0.9804],\n",
      "        [0.9695],\n",
      "        [0.9462],\n",
      "        [0.9338],\n",
      "        [0.9212],\n",
      "        [0.8599],\n",
      "        [0.8814],\n",
      "        [0.8945],\n",
      "        [0.8651],\n",
      "        [0.8530],\n",
      "        [0.8627],\n",
      "        [0.8729],\n",
      "        [0.8601],\n",
      "        [0.8777],\n",
      "        [0.8784],\n",
      "        [0.8524],\n",
      "        [0.8282],\n",
      "        [0.8500],\n",
      "        [0.8554],\n",
      "        [0.8229],\n",
      "        [0.8595],\n",
      "        [0.8957],\n",
      "        [0.9166],\n",
      "        [0.9167],\n",
      "        [0.9332],\n",
      "        [0.9292],\n",
      "        [0.9333],\n",
      "        [0.9189],\n",
      "        [0.8990],\n",
      "        [0.9168],\n",
      "        [0.9200],\n",
      "        [0.9018],\n",
      "        [0.8608],\n",
      "        [0.8569],\n",
      "        [0.8741],\n",
      "        [0.8927],\n",
      "        [0.8993],\n",
      "        [0.8578],\n",
      "        [0.8962],\n",
      "        [0.8475],\n",
      "        [0.8515],\n",
      "        [0.8469],\n",
      "        [0.8561],\n",
      "        [0.8388],\n",
      "        [0.8220],\n",
      "        [0.8395],\n",
      "        [0.8649],\n",
      "        [0.8870],\n",
      "        [0.9166],\n",
      "        [0.9420]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0057],\n",
      "        [0.0081],\n",
      "        [0.0041],\n",
      "        [0.0198],\n",
      "        [0.0050],\n",
      "        [0.0002],\n",
      "        [0.0007],\n",
      "        [0.0070],\n",
      "        [0.0148],\n",
      "        [0.0022],\n",
      "        [0.0021],\n",
      "        [0.0007],\n",
      "        [0.0079],\n",
      "        [0.0113],\n",
      "        [0.0176],\n",
      "        [0.0098],\n",
      "        [0.0182],\n",
      "        [0.0451],\n",
      "        [0.0163],\n",
      "        [0.0737],\n",
      "        [0.0789],\n",
      "        [0.0788],\n",
      "        [0.0253],\n",
      "        [0.0132],\n",
      "        [0.0538],\n",
      "        [0.0694],\n",
      "        [0.0545],\n",
      "        [0.0219],\n",
      "        [0.0100],\n",
      "        [0.0047],\n",
      "        [0.0458],\n",
      "        [0.0169],\n",
      "        [0.0138],\n",
      "        [0.0338],\n",
      "        [0.0336],\n",
      "        [0.0226],\n",
      "        [0.0291],\n",
      "        [0.0327],\n",
      "        [0.0422],\n",
      "        [0.0508],\n",
      "        [0.0003],\n",
      "        [0.0079],\n",
      "        [0.0274],\n",
      "        [0.0673],\n",
      "        [0.0712],\n",
      "        [0.0468],\n",
      "        [0.0488],\n",
      "        [0.0210],\n",
      "        [0.0205],\n",
      "        [0.0058],\n",
      "        [0.0186],\n",
      "        [0.0501],\n",
      "        [0.0757],\n",
      "        [0.1022],\n",
      "        [0.0767],\n",
      "        [0.0907],\n",
      "        [0.0656],\n",
      "        [0.0197],\n",
      "        [0.0811],\n",
      "        [0.0695],\n",
      "        [0.0514],\n",
      "        [0.0470],\n",
      "        [0.0503],\n",
      "        [0.0410],\n",
      "        [0.1490],\n",
      "        [0.0308],\n",
      "        [0.0631],\n",
      "        [0.0530],\n",
      "        [0.0054],\n",
      "        [0.0070],\n",
      "        [0.0504],\n",
      "        [0.0320],\n",
      "        [0.0206],\n",
      "        [0.0365],\n",
      "        [0.0708],\n",
      "        [0.0839],\n",
      "        [0.0805],\n",
      "        [0.0706],\n",
      "        [0.0724],\n",
      "        [0.0386],\n",
      "        [0.0217]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0052],\n",
      "        [0.0087],\n",
      "        [0.0047],\n",
      "        [0.0194],\n",
      "        [0.0049],\n",
      "        [0.0003],\n",
      "        [0.0009],\n",
      "        [0.0066],\n",
      "        [0.0145],\n",
      "        [0.0021],\n",
      "        [0.0020],\n",
      "        [0.0006],\n",
      "        [0.0079],\n",
      "        [0.0112],\n",
      "        [0.0182],\n",
      "        [0.0090],\n",
      "        [0.0174],\n",
      "        [0.0448],\n",
      "        [0.0156],\n",
      "        [0.0737],\n",
      "        [0.0792],\n",
      "        [0.0791],\n",
      "        [0.0254],\n",
      "        [0.0135],\n",
      "        [0.0542],\n",
      "        [0.0696],\n",
      "        [0.0550],\n",
      "        [0.0225],\n",
      "        [0.0094],\n",
      "        [0.0041],\n",
      "        [0.0448],\n",
      "        [0.0176],\n",
      "        [0.0143],\n",
      "        [0.0341],\n",
      "        [0.0337],\n",
      "        [0.0225],\n",
      "        [0.0286],\n",
      "        [0.0326],\n",
      "        [0.0425],\n",
      "        [0.0510],\n",
      "        [0.0005],\n",
      "        [0.0078],\n",
      "        [0.0276],\n",
      "        [0.0675],\n",
      "        [0.0709],\n",
      "        [0.0466],\n",
      "        [0.0487],\n",
      "        [0.0210],\n",
      "        [0.0204],\n",
      "        [0.0060],\n",
      "        [0.0193],\n",
      "        [0.0505],\n",
      "        [0.0758],\n",
      "        [0.1020],\n",
      "        [0.0766],\n",
      "        [0.0906],\n",
      "        [0.0656],\n",
      "        [0.0196],\n",
      "        [0.0808],\n",
      "        [0.0691],\n",
      "        [0.0510],\n",
      "        [0.0463],\n",
      "        [0.0493],\n",
      "        [0.0397],\n",
      "        [0.1500],\n",
      "        [0.0318],\n",
      "        [0.0639],\n",
      "        [0.0537],\n",
      "        [0.0059],\n",
      "        [0.0076],\n",
      "        [0.0490],\n",
      "        [0.0305],\n",
      "        [0.0191],\n",
      "        [0.0348],\n",
      "        [0.0690],\n",
      "        [0.0822],\n",
      "        [0.0792],\n",
      "        [0.0695],\n",
      "        [0.0716],\n",
      "        [0.0381],\n",
      "        [0.0222]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 82\n",
      "剩餘X 資料 torch.Size([295, 18])\n",
      "剩餘Y 資料 torch.Size([295, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8833])\n",
      "目前模型的Data狀態 torch.Size([82, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5617],\n",
      "        [0.5352],\n",
      "        [0.5561],\n",
      "        [0.5832],\n",
      "        [0.5639],\n",
      "        [0.5608],\n",
      "        [0.5549],\n",
      "        [0.5546],\n",
      "        [0.5410],\n",
      "        [0.5426],\n",
      "        [0.5386],\n",
      "        [0.5346],\n",
      "        [0.5250],\n",
      "        [0.5118],\n",
      "        [0.5514],\n",
      "        [0.5503],\n",
      "        [0.5425],\n",
      "        [0.5268],\n",
      "        [0.5833],\n",
      "        [0.8777],\n",
      "        [0.8927],\n",
      "        [0.9212],\n",
      "        [0.8701],\n",
      "        [0.9155],\n",
      "        [0.9279],\n",
      "        [0.9051],\n",
      "        [0.9445],\n",
      "        [0.9542],\n",
      "        [0.9850],\n",
      "        [0.9968],\n",
      "        [1.0239],\n",
      "        [0.9796],\n",
      "        [0.9691],\n",
      "        [0.9459],\n",
      "        [0.9337],\n",
      "        [0.9213],\n",
      "        [0.8604],\n",
      "        [0.8815],\n",
      "        [0.8942],\n",
      "        [0.8649],\n",
      "        [0.8529],\n",
      "        [0.8626],\n",
      "        [0.8730],\n",
      "        [0.8604],\n",
      "        [0.8775],\n",
      "        [0.8782],\n",
      "        [0.8524],\n",
      "        [0.8282],\n",
      "        [0.8499],\n",
      "        [0.8556],\n",
      "        [0.8235],\n",
      "        [0.8599],\n",
      "        [0.8958],\n",
      "        [0.9165],\n",
      "        [0.9166],\n",
      "        [0.9331],\n",
      "        [0.9291],\n",
      "        [0.9334],\n",
      "        [0.9192],\n",
      "        [0.8994],\n",
      "        [0.9171],\n",
      "        [0.9206],\n",
      "        [0.9029],\n",
      "        [0.8621],\n",
      "        [0.8579],\n",
      "        [0.8751],\n",
      "        [0.8935],\n",
      "        [0.9000],\n",
      "        [0.8584],\n",
      "        [0.8968],\n",
      "        [0.8488],\n",
      "        [0.8530],\n",
      "        [0.8483],\n",
      "        [0.8578],\n",
      "        [0.8406],\n",
      "        [0.8237],\n",
      "        [0.8407],\n",
      "        [0.8659],\n",
      "        [0.8878],\n",
      "        [0.9171],\n",
      "        [0.9425],\n",
      "        [0.9245]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0052],\n",
      "        [0.0087],\n",
      "        [0.0047],\n",
      "        [0.0194],\n",
      "        [0.0049],\n",
      "        [0.0003],\n",
      "        [0.0009],\n",
      "        [0.0066],\n",
      "        [0.0145],\n",
      "        [0.0021],\n",
      "        [0.0020],\n",
      "        [0.0006],\n",
      "        [0.0079],\n",
      "        [0.0112],\n",
      "        [0.0182],\n",
      "        [0.0090],\n",
      "        [0.0174],\n",
      "        [0.0448],\n",
      "        [0.0156],\n",
      "        [0.0737],\n",
      "        [0.0792],\n",
      "        [0.0791],\n",
      "        [0.0254],\n",
      "        [0.0135],\n",
      "        [0.0542],\n",
      "        [0.0696],\n",
      "        [0.0550],\n",
      "        [0.0225],\n",
      "        [0.0094],\n",
      "        [0.0041],\n",
      "        [0.0448],\n",
      "        [0.0176],\n",
      "        [0.0143],\n",
      "        [0.0341],\n",
      "        [0.0337],\n",
      "        [0.0225],\n",
      "        [0.0286],\n",
      "        [0.0326],\n",
      "        [0.0425],\n",
      "        [0.0510],\n",
      "        [0.0005],\n",
      "        [0.0078],\n",
      "        [0.0276],\n",
      "        [0.0675],\n",
      "        [0.0709],\n",
      "        [0.0466],\n",
      "        [0.0487],\n",
      "        [0.0210],\n",
      "        [0.0204],\n",
      "        [0.0060],\n",
      "        [0.0193],\n",
      "        [0.0505],\n",
      "        [0.0758],\n",
      "        [0.1020],\n",
      "        [0.0766],\n",
      "        [0.0906],\n",
      "        [0.0656],\n",
      "        [0.0196],\n",
      "        [0.0808],\n",
      "        [0.0691],\n",
      "        [0.0510],\n",
      "        [0.0463],\n",
      "        [0.0493],\n",
      "        [0.0397],\n",
      "        [0.1500],\n",
      "        [0.0318],\n",
      "        [0.0639],\n",
      "        [0.0537],\n",
      "        [0.0059],\n",
      "        [0.0076],\n",
      "        [0.0490],\n",
      "        [0.0305],\n",
      "        [0.0191],\n",
      "        [0.0348],\n",
      "        [0.0690],\n",
      "        [0.0822],\n",
      "        [0.0792],\n",
      "        [0.0695],\n",
      "        [0.0716],\n",
      "        [0.0381],\n",
      "        [0.0222],\n",
      "        [0.0411]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0083],\n",
      "        [    0.0044],\n",
      "        [    0.0182],\n",
      "        [    0.0039],\n",
      "        [    0.0012],\n",
      "        [    0.0020],\n",
      "        [    0.0055],\n",
      "        [    0.0136],\n",
      "        [    0.0012],\n",
      "        [    0.0012],\n",
      "        [    0.0001],\n",
      "        [    0.0085],\n",
      "        [    0.0117],\n",
      "        [    0.0186],\n",
      "        [    0.0086],\n",
      "        [    0.0169],\n",
      "        [    0.0446],\n",
      "        [    0.0145],\n",
      "        [    0.0721],\n",
      "        [    0.0778],\n",
      "        [    0.0776],\n",
      "        [    0.0241],\n",
      "        [    0.0154],\n",
      "        [    0.0563],\n",
      "        [    0.0714],\n",
      "        [    0.0571],\n",
      "        [    0.0248],\n",
      "        [    0.0071],\n",
      "        [    0.0015],\n",
      "        [    0.0418],\n",
      "        [    0.0203],\n",
      "        [    0.0168],\n",
      "        [    0.0365],\n",
      "        [    0.0357],\n",
      "        [    0.0244],\n",
      "        [    0.0300],\n",
      "        [    0.0345],\n",
      "        [    0.0446],\n",
      "        [    0.0530],\n",
      "        [    0.0024],\n",
      "        [    0.0058],\n",
      "        [    0.0258],\n",
      "        [    0.0660],\n",
      "        [    0.0688],\n",
      "        [    0.0444],\n",
      "        [    0.0468],\n",
      "        [    0.0228],\n",
      "        [    0.0186],\n",
      "        [    0.0044],\n",
      "        [    0.0182],\n",
      "        [    0.0489],\n",
      "        [    0.0739],\n",
      "        [    0.0999],\n",
      "        [    0.0744],\n",
      "        [    0.0883],\n",
      "        [    0.0634],\n",
      "        [    0.0216],\n",
      "        [    0.0826],\n",
      "        [    0.0707],\n",
      "        [    0.0528],\n",
      "        [    0.0478],\n",
      "        [    0.0504],\n",
      "        [    0.0405],\n",
      "        [    0.1489],\n",
      "        [    0.0305],\n",
      "        [    0.0625],\n",
      "        [    0.0522],\n",
      "        [    0.0044],\n",
      "        [    0.0060],\n",
      "        [    0.0496],\n",
      "        [    0.0309],\n",
      "        [    0.0197],\n",
      "        [    0.0352],\n",
      "        [    0.0693],\n",
      "        [    0.0825],\n",
      "        [    0.0800],\n",
      "        [    0.0706],\n",
      "        [    0.0730],\n",
      "        [    0.0399],\n",
      "        [    0.0203],\n",
      "        [    0.0393]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 83\n",
      "剩餘X 資料 torch.Size([294, 18])\n",
      "剩餘Y 資料 torch.Size([294, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8617])\n",
      "目前模型的Data狀態 torch.Size([83, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5612],\n",
      "        [0.5348],\n",
      "        [0.5558],\n",
      "        [0.5820],\n",
      "        [0.5629],\n",
      "        [0.5599],\n",
      "        [0.5539],\n",
      "        [0.5535],\n",
      "        [0.5401],\n",
      "        [0.5418],\n",
      "        [0.5378],\n",
      "        [0.5339],\n",
      "        [0.5245],\n",
      "        [0.5114],\n",
      "        [0.5510],\n",
      "        [0.5499],\n",
      "        [0.5420],\n",
      "        [0.5270],\n",
      "        [0.5823],\n",
      "        [0.8760],\n",
      "        [0.8914],\n",
      "        [0.9197],\n",
      "        [0.8688],\n",
      "        [0.9135],\n",
      "        [0.9258],\n",
      "        [0.9034],\n",
      "        [0.9423],\n",
      "        [0.9518],\n",
      "        [0.9826],\n",
      "        [0.9943],\n",
      "        [1.0209],\n",
      "        [0.9769],\n",
      "        [0.9665],\n",
      "        [0.9435],\n",
      "        [0.9316],\n",
      "        [0.9194],\n",
      "        [0.8590],\n",
      "        [0.8796],\n",
      "        [0.8920],\n",
      "        [0.8629],\n",
      "        [0.8510],\n",
      "        [0.8606],\n",
      "        [0.8713],\n",
      "        [0.8588],\n",
      "        [0.8753],\n",
      "        [0.8760],\n",
      "        [0.8504],\n",
      "        [0.8264],\n",
      "        [0.8481],\n",
      "        [0.8540],\n",
      "        [0.8225],\n",
      "        [0.8584],\n",
      "        [0.8939],\n",
      "        [0.9143],\n",
      "        [0.9144],\n",
      "        [0.9308],\n",
      "        [0.9270],\n",
      "        [0.9314],\n",
      "        [0.9174],\n",
      "        [0.8977],\n",
      "        [0.9154],\n",
      "        [0.9191],\n",
      "        [0.9018],\n",
      "        [0.8613],\n",
      "        [0.8568],\n",
      "        [0.8738],\n",
      "        [0.8921],\n",
      "        [0.8985],\n",
      "        [0.8568],\n",
      "        [0.8952],\n",
      "        [0.8482],\n",
      "        [0.8526],\n",
      "        [0.8477],\n",
      "        [0.8574],\n",
      "        [0.8403],\n",
      "        [0.8234],\n",
      "        [0.8399],\n",
      "        [0.8649],\n",
      "        [0.8864],\n",
      "        [0.9154],\n",
      "        [0.9406],\n",
      "        [0.9226],\n",
      "        [0.9241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0083],\n",
      "        [    0.0044],\n",
      "        [    0.0182],\n",
      "        [    0.0039],\n",
      "        [    0.0012],\n",
      "        [    0.0020],\n",
      "        [    0.0055],\n",
      "        [    0.0136],\n",
      "        [    0.0012],\n",
      "        [    0.0012],\n",
      "        [    0.0001],\n",
      "        [    0.0085],\n",
      "        [    0.0117],\n",
      "        [    0.0186],\n",
      "        [    0.0086],\n",
      "        [    0.0169],\n",
      "        [    0.0446],\n",
      "        [    0.0145],\n",
      "        [    0.0721],\n",
      "        [    0.0778],\n",
      "        [    0.0776],\n",
      "        [    0.0241],\n",
      "        [    0.0154],\n",
      "        [    0.0563],\n",
      "        [    0.0714],\n",
      "        [    0.0571],\n",
      "        [    0.0248],\n",
      "        [    0.0071],\n",
      "        [    0.0015],\n",
      "        [    0.0418],\n",
      "        [    0.0203],\n",
      "        [    0.0168],\n",
      "        [    0.0365],\n",
      "        [    0.0357],\n",
      "        [    0.0244],\n",
      "        [    0.0300],\n",
      "        [    0.0345],\n",
      "        [    0.0446],\n",
      "        [    0.0530],\n",
      "        [    0.0024],\n",
      "        [    0.0058],\n",
      "        [    0.0258],\n",
      "        [    0.0660],\n",
      "        [    0.0688],\n",
      "        [    0.0444],\n",
      "        [    0.0468],\n",
      "        [    0.0228],\n",
      "        [    0.0186],\n",
      "        [    0.0044],\n",
      "        [    0.0182],\n",
      "        [    0.0489],\n",
      "        [    0.0739],\n",
      "        [    0.0999],\n",
      "        [    0.0744],\n",
      "        [    0.0883],\n",
      "        [    0.0634],\n",
      "        [    0.0216],\n",
      "        [    0.0826],\n",
      "        [    0.0707],\n",
      "        [    0.0528],\n",
      "        [    0.0478],\n",
      "        [    0.0504],\n",
      "        [    0.0405],\n",
      "        [    0.1489],\n",
      "        [    0.0305],\n",
      "        [    0.0625],\n",
      "        [    0.0522],\n",
      "        [    0.0044],\n",
      "        [    0.0060],\n",
      "        [    0.0496],\n",
      "        [    0.0309],\n",
      "        [    0.0197],\n",
      "        [    0.0352],\n",
      "        [    0.0693],\n",
      "        [    0.0825],\n",
      "        [    0.0800],\n",
      "        [    0.0706],\n",
      "        [    0.0730],\n",
      "        [    0.0399],\n",
      "        [    0.0203],\n",
      "        [    0.0393],\n",
      "        [    0.0624]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0058],\n",
      "        [    0.0083],\n",
      "        [    0.0047],\n",
      "        [    0.0178],\n",
      "        [    0.0037],\n",
      "        [    0.0013],\n",
      "        [    0.0022],\n",
      "        [    0.0052],\n",
      "        [    0.0135],\n",
      "        [    0.0012],\n",
      "        [    0.0012],\n",
      "        [    0.0000],\n",
      "        [    0.0082],\n",
      "        [    0.0113],\n",
      "        [    0.0177],\n",
      "        [    0.0097],\n",
      "        [    0.0178],\n",
      "        [    0.0436],\n",
      "        [    0.0146],\n",
      "        [    0.0715],\n",
      "        [    0.0774],\n",
      "        [    0.0771],\n",
      "        [    0.0238],\n",
      "        [    0.0164],\n",
      "        [    0.0574],\n",
      "        [    0.0721],\n",
      "        [    0.0583],\n",
      "        [    0.0261],\n",
      "        [    0.0058],\n",
      "        [    0.0001],\n",
      "        [    0.0399],\n",
      "        [    0.0220],\n",
      "        [    0.0183],\n",
      "        [    0.0380],\n",
      "        [    0.0369],\n",
      "        [    0.0255],\n",
      "        [    0.0305],\n",
      "        [    0.0353],\n",
      "        [    0.0458],\n",
      "        [    0.0541],\n",
      "        [    0.0033],\n",
      "        [    0.0047],\n",
      "        [    0.0249],\n",
      "        [    0.0652],\n",
      "        [    0.0675],\n",
      "        [    0.0429],\n",
      "        [    0.0455],\n",
      "        [    0.0239],\n",
      "        [    0.0175],\n",
      "        [    0.0036],\n",
      "        [    0.0177],\n",
      "        [    0.0480],\n",
      "        [    0.0725],\n",
      "        [    0.0983],\n",
      "        [    0.0726],\n",
      "        [    0.0865],\n",
      "        [    0.0617],\n",
      "        [    0.0232],\n",
      "        [    0.0840],\n",
      "        [    0.0719],\n",
      "        [    0.0540],\n",
      "        [    0.0489],\n",
      "        [    0.0511],\n",
      "        [    0.0409],\n",
      "        [    0.1482],\n",
      "        [    0.0296],\n",
      "        [    0.0615],\n",
      "        [    0.0512],\n",
      "        [    0.0034],\n",
      "        [    0.0049],\n",
      "        [    0.0498],\n",
      "        [    0.0310],\n",
      "        [    0.0199],\n",
      "        [    0.0353],\n",
      "        [    0.0693],\n",
      "        [    0.0825],\n",
      "        [    0.0804],\n",
      "        [    0.0713],\n",
      "        [    0.0740],\n",
      "        [    0.0413],\n",
      "        [    0.0186],\n",
      "        [    0.0378],\n",
      "        [    0.0610]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 84\n",
      "剩餘X 資料 torch.Size([293, 18])\n",
      "剩餘Y 資料 torch.Size([293, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8743])\n",
      "目前模型的Data狀態 torch.Size([84, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5611],\n",
      "        [0.5348],\n",
      "        [0.5561],\n",
      "        [0.5815],\n",
      "        [0.5626],\n",
      "        [0.5598],\n",
      "        [0.5536],\n",
      "        [0.5532],\n",
      "        [0.5399],\n",
      "        [0.5418],\n",
      "        [0.5378],\n",
      "        [0.5340],\n",
      "        [0.5247],\n",
      "        [0.5117],\n",
      "        [0.5519],\n",
      "        [0.5509],\n",
      "        [0.5429],\n",
      "        [0.5280],\n",
      "        [0.5824],\n",
      "        [0.8755],\n",
      "        [0.8910],\n",
      "        [0.9193],\n",
      "        [0.8685],\n",
      "        [0.9126],\n",
      "        [0.9247],\n",
      "        [0.9027],\n",
      "        [0.9412],\n",
      "        [0.9506],\n",
      "        [0.9813],\n",
      "        [0.9928],\n",
      "        [1.0190],\n",
      "        [0.9753],\n",
      "        [0.9650],\n",
      "        [0.9421],\n",
      "        [0.9304],\n",
      "        [0.9183],\n",
      "        [0.8585],\n",
      "        [0.8788],\n",
      "        [0.8908],\n",
      "        [0.8618],\n",
      "        [0.8500],\n",
      "        [0.8594],\n",
      "        [0.8703],\n",
      "        [0.8581],\n",
      "        [0.8740],\n",
      "        [0.8744],\n",
      "        [0.8491],\n",
      "        [0.8253],\n",
      "        [0.8470],\n",
      "        [0.8532],\n",
      "        [0.8220],\n",
      "        [0.8574],\n",
      "        [0.8925],\n",
      "        [0.9127],\n",
      "        [0.9126],\n",
      "        [0.9291],\n",
      "        [0.9252],\n",
      "        [0.9298],\n",
      "        [0.9160],\n",
      "        [0.8966],\n",
      "        [0.9142],\n",
      "        [0.9181],\n",
      "        [0.9011],\n",
      "        [0.8609],\n",
      "        [0.8561],\n",
      "        [0.8729],\n",
      "        [0.8912],\n",
      "        [0.8975],\n",
      "        [0.8559],\n",
      "        [0.8942],\n",
      "        [0.8481],\n",
      "        [0.8525],\n",
      "        [0.8475],\n",
      "        [0.8573],\n",
      "        [0.8402],\n",
      "        [0.8234],\n",
      "        [0.8395],\n",
      "        [0.8642],\n",
      "        [0.8854],\n",
      "        [0.9140],\n",
      "        [0.9389],\n",
      "        [0.9211],\n",
      "        [0.9226],\n",
      "        [0.8942]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0058],\n",
      "        [    0.0083],\n",
      "        [    0.0047],\n",
      "        [    0.0178],\n",
      "        [    0.0037],\n",
      "        [    0.0013],\n",
      "        [    0.0022],\n",
      "        [    0.0052],\n",
      "        [    0.0135],\n",
      "        [    0.0012],\n",
      "        [    0.0012],\n",
      "        [    0.0000],\n",
      "        [    0.0082],\n",
      "        [    0.0113],\n",
      "        [    0.0177],\n",
      "        [    0.0097],\n",
      "        [    0.0178],\n",
      "        [    0.0436],\n",
      "        [    0.0146],\n",
      "        [    0.0715],\n",
      "        [    0.0774],\n",
      "        [    0.0771],\n",
      "        [    0.0238],\n",
      "        [    0.0164],\n",
      "        [    0.0574],\n",
      "        [    0.0721],\n",
      "        [    0.0583],\n",
      "        [    0.0261],\n",
      "        [    0.0058],\n",
      "        [    0.0001],\n",
      "        [    0.0399],\n",
      "        [    0.0220],\n",
      "        [    0.0183],\n",
      "        [    0.0380],\n",
      "        [    0.0369],\n",
      "        [    0.0255],\n",
      "        [    0.0305],\n",
      "        [    0.0353],\n",
      "        [    0.0458],\n",
      "        [    0.0541],\n",
      "        [    0.0033],\n",
      "        [    0.0047],\n",
      "        [    0.0249],\n",
      "        [    0.0652],\n",
      "        [    0.0675],\n",
      "        [    0.0429],\n",
      "        [    0.0455],\n",
      "        [    0.0239],\n",
      "        [    0.0175],\n",
      "        [    0.0036],\n",
      "        [    0.0177],\n",
      "        [    0.0480],\n",
      "        [    0.0725],\n",
      "        [    0.0983],\n",
      "        [    0.0726],\n",
      "        [    0.0865],\n",
      "        [    0.0617],\n",
      "        [    0.0232],\n",
      "        [    0.0840],\n",
      "        [    0.0719],\n",
      "        [    0.0540],\n",
      "        [    0.0489],\n",
      "        [    0.0511],\n",
      "        [    0.0409],\n",
      "        [    0.1482],\n",
      "        [    0.0296],\n",
      "        [    0.0615],\n",
      "        [    0.0512],\n",
      "        [    0.0034],\n",
      "        [    0.0049],\n",
      "        [    0.0498],\n",
      "        [    0.0310],\n",
      "        [    0.0199],\n",
      "        [    0.0353],\n",
      "        [    0.0693],\n",
      "        [    0.0825],\n",
      "        [    0.0804],\n",
      "        [    0.0713],\n",
      "        [    0.0740],\n",
      "        [    0.0413],\n",
      "        [    0.0186],\n",
      "        [    0.0378],\n",
      "        [    0.0610],\n",
      "        [    0.0198]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0056],\n",
      "        [0.0086],\n",
      "        [0.0054],\n",
      "        [0.0178],\n",
      "        [0.0039],\n",
      "        [0.0010],\n",
      "        [0.0020],\n",
      "        [0.0054],\n",
      "        [0.0137],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0004],\n",
      "        [0.0077],\n",
      "        [0.0107],\n",
      "        [0.0166],\n",
      "        [0.0110],\n",
      "        [0.0190],\n",
      "        [0.0424],\n",
      "        [0.0152],\n",
      "        [0.0725],\n",
      "        [0.0786],\n",
      "        [0.0783],\n",
      "        [0.0249],\n",
      "        [0.0157],\n",
      "        [0.0568],\n",
      "        [0.0712],\n",
      "        [0.0576],\n",
      "        [0.0256],\n",
      "        [0.0064],\n",
      "        [0.0006],\n",
      "        [0.0401],\n",
      "        [0.0217],\n",
      "        [0.0180],\n",
      "        [0.0377],\n",
      "        [0.0364],\n",
      "        [0.0248],\n",
      "        [0.0295],\n",
      "        [0.0347],\n",
      "        [0.0454],\n",
      "        [0.0536],\n",
      "        [0.0028],\n",
      "        [0.0050],\n",
      "        [0.0255],\n",
      "        [0.0659],\n",
      "        [0.0677],\n",
      "        [0.0428],\n",
      "        [0.0456],\n",
      "        [0.0236],\n",
      "        [0.0178],\n",
      "        [0.0041],\n",
      "        [0.0185],\n",
      "        [0.0484],\n",
      "        [0.0726],\n",
      "        [0.0982],\n",
      "        [0.0723],\n",
      "        [0.0863],\n",
      "        [0.0616],\n",
      "        [0.0231],\n",
      "        [0.0837],\n",
      "        [0.0715],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0502],\n",
      "        [0.0398],\n",
      "        [0.1490],\n",
      "        [0.0303],\n",
      "        [0.0621],\n",
      "        [0.0518],\n",
      "        [0.0039],\n",
      "        [0.0054],\n",
      "        [0.0486],\n",
      "        [0.0297],\n",
      "        [0.0188],\n",
      "        [0.0339],\n",
      "        [0.0680],\n",
      "        [0.0812],\n",
      "        [0.0795],\n",
      "        [0.0705],\n",
      "        [0.0736],\n",
      "        [0.0411],\n",
      "        [0.0185],\n",
      "        [0.0377],\n",
      "        [0.0610],\n",
      "        [0.0199]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 85\n",
      "剩餘X 資料 torch.Size([292, 18])\n",
      "剩餘Y 資料 torch.Size([292, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8356])\n",
      "目前模型的Data狀態 torch.Size([85, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5613],\n",
      "        [0.5351],\n",
      "        [0.5568],\n",
      "        [0.5815],\n",
      "        [0.5629],\n",
      "        [0.5601],\n",
      "        [0.5538],\n",
      "        [0.5533],\n",
      "        [0.5402],\n",
      "        [0.5421],\n",
      "        [0.5382],\n",
      "        [0.5344],\n",
      "        [0.5253],\n",
      "        [0.5123],\n",
      "        [0.5530],\n",
      "        [0.5523],\n",
      "        [0.5441],\n",
      "        [0.5292],\n",
      "        [0.5829],\n",
      "        [0.8764],\n",
      "        [0.8922],\n",
      "        [0.9205],\n",
      "        [0.8696],\n",
      "        [0.9133],\n",
      "        [0.9253],\n",
      "        [0.9036],\n",
      "        [0.9418],\n",
      "        [0.9511],\n",
      "        [0.9819],\n",
      "        [0.9933],\n",
      "        [1.0191],\n",
      "        [0.9756],\n",
      "        [0.9654],\n",
      "        [0.9424],\n",
      "        [0.9310],\n",
      "        [0.9190],\n",
      "        [0.8595],\n",
      "        [0.8794],\n",
      "        [0.8913],\n",
      "        [0.8623],\n",
      "        [0.8505],\n",
      "        [0.8598],\n",
      "        [0.8710],\n",
      "        [0.8588],\n",
      "        [0.8742],\n",
      "        [0.8744],\n",
      "        [0.8492],\n",
      "        [0.8256],\n",
      "        [0.8473],\n",
      "        [0.8537],\n",
      "        [0.8228],\n",
      "        [0.8578],\n",
      "        [0.8926],\n",
      "        [0.9127],\n",
      "        [0.9123],\n",
      "        [0.9289],\n",
      "        [0.9251],\n",
      "        [0.9299],\n",
      "        [0.9163],\n",
      "        [0.8970],\n",
      "        [0.9145],\n",
      "        [0.9186],\n",
      "        [0.9019],\n",
      "        [0.8620],\n",
      "        [0.8569],\n",
      "        [0.8735],\n",
      "        [0.8917],\n",
      "        [0.8980],\n",
      "        [0.8563],\n",
      "        [0.8946],\n",
      "        [0.8493],\n",
      "        [0.8538],\n",
      "        [0.8486],\n",
      "        [0.8587],\n",
      "        [0.8416],\n",
      "        [0.8247],\n",
      "        [0.8405],\n",
      "        [0.8649],\n",
      "        [0.8858],\n",
      "        [0.9141],\n",
      "        [0.9388],\n",
      "        [0.9210],\n",
      "        [0.9227],\n",
      "        [0.8943],\n",
      "        [0.8835]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0056],\n",
      "        [0.0086],\n",
      "        [0.0054],\n",
      "        [0.0178],\n",
      "        [0.0039],\n",
      "        [0.0010],\n",
      "        [0.0020],\n",
      "        [0.0054],\n",
      "        [0.0137],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0004],\n",
      "        [0.0077],\n",
      "        [0.0107],\n",
      "        [0.0166],\n",
      "        [0.0110],\n",
      "        [0.0190],\n",
      "        [0.0424],\n",
      "        [0.0152],\n",
      "        [0.0725],\n",
      "        [0.0786],\n",
      "        [0.0783],\n",
      "        [0.0249],\n",
      "        [0.0157],\n",
      "        [0.0568],\n",
      "        [0.0712],\n",
      "        [0.0576],\n",
      "        [0.0256],\n",
      "        [0.0064],\n",
      "        [0.0006],\n",
      "        [0.0401],\n",
      "        [0.0217],\n",
      "        [0.0180],\n",
      "        [0.0377],\n",
      "        [0.0364],\n",
      "        [0.0248],\n",
      "        [0.0295],\n",
      "        [0.0347],\n",
      "        [0.0454],\n",
      "        [0.0536],\n",
      "        [0.0028],\n",
      "        [0.0050],\n",
      "        [0.0255],\n",
      "        [0.0659],\n",
      "        [0.0677],\n",
      "        [0.0428],\n",
      "        [0.0456],\n",
      "        [0.0236],\n",
      "        [0.0178],\n",
      "        [0.0041],\n",
      "        [0.0185],\n",
      "        [0.0484],\n",
      "        [0.0726],\n",
      "        [0.0982],\n",
      "        [0.0723],\n",
      "        [0.0863],\n",
      "        [0.0616],\n",
      "        [0.0231],\n",
      "        [0.0837],\n",
      "        [0.0715],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0502],\n",
      "        [0.0398],\n",
      "        [0.1490],\n",
      "        [0.0303],\n",
      "        [0.0621],\n",
      "        [0.0518],\n",
      "        [0.0039],\n",
      "        [0.0054],\n",
      "        [0.0486],\n",
      "        [0.0297],\n",
      "        [0.0188],\n",
      "        [0.0339],\n",
      "        [0.0680],\n",
      "        [0.0812],\n",
      "        [0.0795],\n",
      "        [0.0705],\n",
      "        [0.0736],\n",
      "        [0.0411],\n",
      "        [0.0185],\n",
      "        [0.0377],\n",
      "        [0.0610],\n",
      "        [0.0199],\n",
      "        [0.0479]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0070],\n",
      "        [0.0073],\n",
      "        [0.0045],\n",
      "        [0.0163],\n",
      "        [0.0027],\n",
      "        [0.0021],\n",
      "        [0.0032],\n",
      "        [0.0042],\n",
      "        [0.0126],\n",
      "        [0.0006],\n",
      "        [0.0007],\n",
      "        [0.0003],\n",
      "        [0.0083],\n",
      "        [0.0113],\n",
      "        [0.0162],\n",
      "        [0.0116],\n",
      "        [0.0195],\n",
      "        [0.0422],\n",
      "        [0.0145],\n",
      "        [0.0713],\n",
      "        [0.0777],\n",
      "        [0.0774],\n",
      "        [0.0241],\n",
      "        [0.0170],\n",
      "        [0.0582],\n",
      "        [0.0721],\n",
      "        [0.0588],\n",
      "        [0.0269],\n",
      "        [0.0052],\n",
      "        [0.0008],\n",
      "        [0.0383],\n",
      "        [0.0234],\n",
      "        [0.0197],\n",
      "        [0.0395],\n",
      "        [0.0379],\n",
      "        [0.0263],\n",
      "        [0.0307],\n",
      "        [0.0361],\n",
      "        [0.0470],\n",
      "        [0.0551],\n",
      "        [0.0043],\n",
      "        [0.0034],\n",
      "        [0.0241],\n",
      "        [0.0646],\n",
      "        [0.0659],\n",
      "        [0.0409],\n",
      "        [0.0438],\n",
      "        [0.0250],\n",
      "        [0.0164],\n",
      "        [0.0030],\n",
      "        [0.0175],\n",
      "        [0.0471],\n",
      "        [0.0710],\n",
      "        [0.0965],\n",
      "        [0.0703],\n",
      "        [0.0844],\n",
      "        [0.0597],\n",
      "        [0.0248],\n",
      "        [0.0852],\n",
      "        [0.0729],\n",
      "        [0.0550],\n",
      "        [0.0496],\n",
      "        [0.0513],\n",
      "        [0.0408],\n",
      "        [0.1476],\n",
      "        [0.0287],\n",
      "        [0.0605],\n",
      "        [0.0502],\n",
      "        [0.0023],\n",
      "        [0.0039],\n",
      "        [0.0493],\n",
      "        [0.0303],\n",
      "        [0.0196],\n",
      "        [0.0346],\n",
      "        [0.0688],\n",
      "        [0.0821],\n",
      "        [0.0806],\n",
      "        [0.0719],\n",
      "        [0.0753],\n",
      "        [0.0431],\n",
      "        [0.0164],\n",
      "        [0.0355],\n",
      "        [0.0589],\n",
      "        [0.0178],\n",
      "        [0.0454]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 86\n",
      "剩餘X 資料 torch.Size([291, 18])\n",
      "剩餘Y 資料 torch.Size([291, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8355])\n",
      "目前模型的Data狀態 torch.Size([86, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5599],\n",
      "        [0.5338],\n",
      "        [0.5560],\n",
      "        [0.5801],\n",
      "        [0.5617],\n",
      "        [0.5590],\n",
      "        [0.5526],\n",
      "        [0.5521],\n",
      "        [0.5391],\n",
      "        [0.5412],\n",
      "        [0.5373],\n",
      "        [0.5337],\n",
      "        [0.5246],\n",
      "        [0.5117],\n",
      "        [0.5534],\n",
      "        [0.5529],\n",
      "        [0.5446],\n",
      "        [0.5294],\n",
      "        [0.5822],\n",
      "        [0.8753],\n",
      "        [0.8913],\n",
      "        [0.9196],\n",
      "        [0.8688],\n",
      "        [0.9120],\n",
      "        [0.9239],\n",
      "        [0.9026],\n",
      "        [0.9407],\n",
      "        [0.9498],\n",
      "        [0.9807],\n",
      "        [0.9919],\n",
      "        [1.0174],\n",
      "        [0.9738],\n",
      "        [0.9636],\n",
      "        [0.9405],\n",
      "        [0.9294],\n",
      "        [0.9175],\n",
      "        [0.8583],\n",
      "        [0.8780],\n",
      "        [0.8897],\n",
      "        [0.8608],\n",
      "        [0.8490],\n",
      "        [0.8581],\n",
      "        [0.8696],\n",
      "        [0.8575],\n",
      "        [0.8725],\n",
      "        [0.8724],\n",
      "        [0.8475],\n",
      "        [0.8241],\n",
      "        [0.8459],\n",
      "        [0.8526],\n",
      "        [0.8218],\n",
      "        [0.8565],\n",
      "        [0.8910],\n",
      "        [0.9109],\n",
      "        [0.9103],\n",
      "        [0.9270],\n",
      "        [0.9232],\n",
      "        [0.9282],\n",
      "        [0.9148],\n",
      "        [0.8956],\n",
      "        [0.9131],\n",
      "        [0.9173],\n",
      "        [0.9008],\n",
      "        [0.8611],\n",
      "        [0.8555],\n",
      "        [0.8720],\n",
      "        [0.8902],\n",
      "        [0.8964],\n",
      "        [0.8547],\n",
      "        [0.8932],\n",
      "        [0.8485],\n",
      "        [0.8532],\n",
      "        [0.8478],\n",
      "        [0.8580],\n",
      "        [0.8408],\n",
      "        [0.8239],\n",
      "        [0.8394],\n",
      "        [0.8636],\n",
      "        [0.8841],\n",
      "        [0.9122],\n",
      "        [0.9367],\n",
      "        [0.9189],\n",
      "        [0.9206],\n",
      "        [0.8921],\n",
      "        [0.8810],\n",
      "        [0.9223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0070],\n",
      "        [0.0073],\n",
      "        [0.0045],\n",
      "        [0.0163],\n",
      "        [0.0027],\n",
      "        [0.0021],\n",
      "        [0.0032],\n",
      "        [0.0042],\n",
      "        [0.0126],\n",
      "        [0.0006],\n",
      "        [0.0007],\n",
      "        [0.0003],\n",
      "        [0.0083],\n",
      "        [0.0113],\n",
      "        [0.0162],\n",
      "        [0.0116],\n",
      "        [0.0195],\n",
      "        [0.0422],\n",
      "        [0.0145],\n",
      "        [0.0713],\n",
      "        [0.0777],\n",
      "        [0.0774],\n",
      "        [0.0241],\n",
      "        [0.0170],\n",
      "        [0.0582],\n",
      "        [0.0721],\n",
      "        [0.0588],\n",
      "        [0.0269],\n",
      "        [0.0052],\n",
      "        [0.0008],\n",
      "        [0.0383],\n",
      "        [0.0234],\n",
      "        [0.0197],\n",
      "        [0.0395],\n",
      "        [0.0379],\n",
      "        [0.0263],\n",
      "        [0.0307],\n",
      "        [0.0361],\n",
      "        [0.0470],\n",
      "        [0.0551],\n",
      "        [0.0043],\n",
      "        [0.0034],\n",
      "        [0.0241],\n",
      "        [0.0646],\n",
      "        [0.0659],\n",
      "        [0.0409],\n",
      "        [0.0438],\n",
      "        [0.0250],\n",
      "        [0.0164],\n",
      "        [0.0030],\n",
      "        [0.0175],\n",
      "        [0.0471],\n",
      "        [0.0710],\n",
      "        [0.0965],\n",
      "        [0.0703],\n",
      "        [0.0844],\n",
      "        [0.0597],\n",
      "        [0.0248],\n",
      "        [0.0852],\n",
      "        [0.0729],\n",
      "        [0.0550],\n",
      "        [0.0496],\n",
      "        [0.0513],\n",
      "        [0.0408],\n",
      "        [0.1476],\n",
      "        [0.0287],\n",
      "        [0.0605],\n",
      "        [0.0502],\n",
      "        [0.0023],\n",
      "        [0.0039],\n",
      "        [0.0493],\n",
      "        [0.0303],\n",
      "        [0.0196],\n",
      "        [0.0346],\n",
      "        [0.0688],\n",
      "        [0.0821],\n",
      "        [0.0806],\n",
      "        [0.0719],\n",
      "        [0.0753],\n",
      "        [0.0431],\n",
      "        [0.0164],\n",
      "        [0.0355],\n",
      "        [0.0589],\n",
      "        [0.0178],\n",
      "        [0.0454],\n",
      "        [0.0868]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0075],\n",
      "        [0.0071],\n",
      "        [0.0047],\n",
      "        [0.0161],\n",
      "        [0.0028],\n",
      "        [0.0018],\n",
      "        [0.0031],\n",
      "        [0.0043],\n",
      "        [0.0130],\n",
      "        [0.0011],\n",
      "        [0.0013],\n",
      "        [0.0004],\n",
      "        [0.0075],\n",
      "        [0.0104],\n",
      "        [0.0141],\n",
      "        [0.0139],\n",
      "        [0.0216],\n",
      "        [0.0404],\n",
      "        [0.0151],\n",
      "        [0.0709],\n",
      "        [0.0776],\n",
      "        [0.0774],\n",
      "        [0.0242],\n",
      "        [0.0175],\n",
      "        [0.0589],\n",
      "        [0.0721],\n",
      "        [0.0590],\n",
      "        [0.0273],\n",
      "        [0.0048],\n",
      "        [0.0013],\n",
      "        [0.0374],\n",
      "        [0.0244],\n",
      "        [0.0206],\n",
      "        [0.0404],\n",
      "        [0.0385],\n",
      "        [0.0268],\n",
      "        [0.0309],\n",
      "        [0.0364],\n",
      "        [0.0476],\n",
      "        [0.0556],\n",
      "        [0.0048],\n",
      "        [0.0027],\n",
      "        [0.0238],\n",
      "        [0.0644],\n",
      "        [0.0652],\n",
      "        [0.0398],\n",
      "        [0.0431],\n",
      "        [0.0254],\n",
      "        [0.0161],\n",
      "        [0.0031],\n",
      "        [0.0178],\n",
      "        [0.0469],\n",
      "        [0.0705],\n",
      "        [0.0959],\n",
      "        [0.0693],\n",
      "        [0.0836],\n",
      "        [0.0589],\n",
      "        [0.0254],\n",
      "        [0.0856],\n",
      "        [0.0731],\n",
      "        [0.0552],\n",
      "        [0.0497],\n",
      "        [0.0512],\n",
      "        [0.0404],\n",
      "        [0.1474],\n",
      "        [0.0283],\n",
      "        [0.0601],\n",
      "        [0.0498],\n",
      "        [0.0019],\n",
      "        [0.0036],\n",
      "        [0.0488],\n",
      "        [0.0298],\n",
      "        [0.0193],\n",
      "        [0.0342],\n",
      "        [0.0684],\n",
      "        [0.0818],\n",
      "        [0.0807],\n",
      "        [0.0723],\n",
      "        [0.0761],\n",
      "        [0.0442],\n",
      "        [0.0150],\n",
      "        [0.0342],\n",
      "        [0.0576],\n",
      "        [0.0164],\n",
      "        [0.0436],\n",
      "        [0.0850]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 87\n",
      "剩餘X 資料 torch.Size([290, 18])\n",
      "剩餘Y 資料 torch.Size([290, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7936])\n",
      "目前模型的Data狀態 torch.Size([87, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5594],\n",
      "        [0.5336],\n",
      "        [0.5562],\n",
      "        [0.5799],\n",
      "        [0.5618],\n",
      "        [0.5592],\n",
      "        [0.5528],\n",
      "        [0.5523],\n",
      "        [0.5394],\n",
      "        [0.5417],\n",
      "        [0.5379],\n",
      "        [0.5344],\n",
      "        [0.5255],\n",
      "        [0.5126],\n",
      "        [0.5555],\n",
      "        [0.5552],\n",
      "        [0.5467],\n",
      "        [0.5312],\n",
      "        [0.5829],\n",
      "        [0.8749],\n",
      "        [0.8911],\n",
      "        [0.9196],\n",
      "        [0.8689],\n",
      "        [0.9115],\n",
      "        [0.9232],\n",
      "        [0.9026],\n",
      "        [0.9404],\n",
      "        [0.9494],\n",
      "        [0.9803],\n",
      "        [0.9914],\n",
      "        [1.0164],\n",
      "        [0.9729],\n",
      "        [0.9628],\n",
      "        [0.9397],\n",
      "        [0.9289],\n",
      "        [0.9170],\n",
      "        [0.8581],\n",
      "        [0.8777],\n",
      "        [0.8891],\n",
      "        [0.8603],\n",
      "        [0.8486],\n",
      "        [0.8575],\n",
      "        [0.8692],\n",
      "        [0.8573],\n",
      "        [0.8717],\n",
      "        [0.8714],\n",
      "        [0.8468],\n",
      "        [0.8238],\n",
      "        [0.8457],\n",
      "        [0.8527],\n",
      "        [0.8220],\n",
      "        [0.8564],\n",
      "        [0.8905],\n",
      "        [0.9103],\n",
      "        [0.9093],\n",
      "        [0.9262],\n",
      "        [0.9225],\n",
      "        [0.9276],\n",
      "        [0.9144],\n",
      "        [0.8954],\n",
      "        [0.9130],\n",
      "        [0.9172],\n",
      "        [0.9009],\n",
      "        [0.8614],\n",
      "        [0.8553],\n",
      "        [0.8716],\n",
      "        [0.8898],\n",
      "        [0.8960],\n",
      "        [0.8543],\n",
      "        [0.8928],\n",
      "        [0.8490],\n",
      "        [0.8537],\n",
      "        [0.8481],\n",
      "        [0.8584],\n",
      "        [0.8412],\n",
      "        [0.8241],\n",
      "        [0.8393],\n",
      "        [0.8632],\n",
      "        [0.8833],\n",
      "        [0.9110],\n",
      "        [0.9353],\n",
      "        [0.9175],\n",
      "        [0.9192],\n",
      "        [0.8907],\n",
      "        [0.8793],\n",
      "        [0.9205],\n",
      "        [0.9248]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0075],\n",
      "        [0.0071],\n",
      "        [0.0047],\n",
      "        [0.0161],\n",
      "        [0.0028],\n",
      "        [0.0018],\n",
      "        [0.0031],\n",
      "        [0.0043],\n",
      "        [0.0130],\n",
      "        [0.0011],\n",
      "        [0.0013],\n",
      "        [0.0004],\n",
      "        [0.0075],\n",
      "        [0.0104],\n",
      "        [0.0141],\n",
      "        [0.0139],\n",
      "        [0.0216],\n",
      "        [0.0404],\n",
      "        [0.0151],\n",
      "        [0.0709],\n",
      "        [0.0776],\n",
      "        [0.0774],\n",
      "        [0.0242],\n",
      "        [0.0175],\n",
      "        [0.0589],\n",
      "        [0.0721],\n",
      "        [0.0590],\n",
      "        [0.0273],\n",
      "        [0.0048],\n",
      "        [0.0013],\n",
      "        [0.0374],\n",
      "        [0.0244],\n",
      "        [0.0206],\n",
      "        [0.0404],\n",
      "        [0.0385],\n",
      "        [0.0268],\n",
      "        [0.0309],\n",
      "        [0.0364],\n",
      "        [0.0476],\n",
      "        [0.0556],\n",
      "        [0.0048],\n",
      "        [0.0027],\n",
      "        [0.0238],\n",
      "        [0.0644],\n",
      "        [0.0652],\n",
      "        [0.0398],\n",
      "        [0.0431],\n",
      "        [0.0254],\n",
      "        [0.0161],\n",
      "        [0.0031],\n",
      "        [0.0178],\n",
      "        [0.0469],\n",
      "        [0.0705],\n",
      "        [0.0959],\n",
      "        [0.0693],\n",
      "        [0.0836],\n",
      "        [0.0589],\n",
      "        [0.0254],\n",
      "        [0.0856],\n",
      "        [0.0731],\n",
      "        [0.0552],\n",
      "        [0.0497],\n",
      "        [0.0512],\n",
      "        [0.0404],\n",
      "        [0.1474],\n",
      "        [0.0283],\n",
      "        [0.0601],\n",
      "        [0.0498],\n",
      "        [0.0019],\n",
      "        [0.0036],\n",
      "        [0.0488],\n",
      "        [0.0298],\n",
      "        [0.0193],\n",
      "        [0.0342],\n",
      "        [0.0684],\n",
      "        [0.0818],\n",
      "        [0.0807],\n",
      "        [0.0723],\n",
      "        [0.0761],\n",
      "        [0.0442],\n",
      "        [0.0150],\n",
      "        [0.0342],\n",
      "        [0.0576],\n",
      "        [0.0164],\n",
      "        [0.0436],\n",
      "        [0.0850],\n",
      "        [0.1312]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0099],\n",
      "        [0.0050],\n",
      "        [0.0031],\n",
      "        [0.0143],\n",
      "        [0.0015],\n",
      "        [0.0030],\n",
      "        [0.0044],\n",
      "        [0.0030],\n",
      "        [0.0119],\n",
      "        [0.0002],\n",
      "        [0.0005],\n",
      "        [0.0002],\n",
      "        [0.0078],\n",
      "        [0.0107],\n",
      "        [0.0131],\n",
      "        [0.0154],\n",
      "        [0.0228],\n",
      "        [0.0396],\n",
      "        [0.0141],\n",
      "        [0.0675],\n",
      "        [0.0745],\n",
      "        [0.0744],\n",
      "        [0.0216],\n",
      "        [0.0210],\n",
      "        [0.0627],\n",
      "        [0.0751],\n",
      "        [0.0623],\n",
      "        [0.0307],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0330],\n",
      "        [0.0286],\n",
      "        [0.0246],\n",
      "        [0.0442],\n",
      "        [0.0419],\n",
      "        [0.0302],\n",
      "        [0.0337],\n",
      "        [0.0395],\n",
      "        [0.0509],\n",
      "        [0.0587],\n",
      "        [0.0078],\n",
      "        [0.0006],\n",
      "        [0.0208],\n",
      "        [0.0616],\n",
      "        [0.0617],\n",
      "        [0.0361],\n",
      "        [0.0399],\n",
      "        [0.0280],\n",
      "        [0.0135],\n",
      "        [0.0008],\n",
      "        [0.0159],\n",
      "        [0.0445],\n",
      "        [0.0676],\n",
      "        [0.0928],\n",
      "        [0.0658],\n",
      "        [0.0802],\n",
      "        [0.0555],\n",
      "        [0.0285],\n",
      "        [0.0885],\n",
      "        [0.0758],\n",
      "        [0.0578],\n",
      "        [0.0523],\n",
      "        [0.0534],\n",
      "        [0.0422],\n",
      "        [0.1450],\n",
      "        [0.0256],\n",
      "        [0.0573],\n",
      "        [0.0470],\n",
      "        [0.0007],\n",
      "        [0.0009],\n",
      "        [0.0505],\n",
      "        [0.0314],\n",
      "        [0.0212],\n",
      "        [0.0360],\n",
      "        [0.0702],\n",
      "        [0.0838],\n",
      "        [0.0833],\n",
      "        [0.0753],\n",
      "        [0.0798],\n",
      "        [0.0484],\n",
      "        [0.0105],\n",
      "        [0.0298],\n",
      "        [0.0532],\n",
      "        [0.0120],\n",
      "        [0.0387],\n",
      "        [0.0798],\n",
      "        [0.1258]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 88\n",
      "剩餘X 資料 torch.Size([289, 18])\n",
      "剩餘Y 資料 torch.Size([289, 1])\n",
      "現在要進去模型的數據，y= tensor([0.8166])\n",
      "目前模型的Data狀態 torch.Size([88, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5570],\n",
      "        [0.5315],\n",
      "        [0.5545],\n",
      "        [0.5780],\n",
      "        [0.5605],\n",
      "        [0.5581],\n",
      "        [0.5514],\n",
      "        [0.5509],\n",
      "        [0.5383],\n",
      "        [0.5408],\n",
      "        [0.5371],\n",
      "        [0.5338],\n",
      "        [0.5251],\n",
      "        [0.5124],\n",
      "        [0.5565],\n",
      "        [0.5566],\n",
      "        [0.5479],\n",
      "        [0.5320],\n",
      "        [0.5818],\n",
      "        [0.8715],\n",
      "        [0.8881],\n",
      "        [0.9166],\n",
      "        [0.8663],\n",
      "        [0.9079],\n",
      "        [0.9194],\n",
      "        [0.8997],\n",
      "        [0.9372],\n",
      "        [0.9460],\n",
      "        [0.9768],\n",
      "        [0.9877],\n",
      "        [1.0121],\n",
      "        [0.9687],\n",
      "        [0.9588],\n",
      "        [0.9358],\n",
      "        [0.9255],\n",
      "        [0.9136],\n",
      "        [0.8552],\n",
      "        [0.8746],\n",
      "        [0.8857],\n",
      "        [0.8572],\n",
      "        [0.8455],\n",
      "        [0.8542],\n",
      "        [0.8662],\n",
      "        [0.8545],\n",
      "        [0.8683],\n",
      "        [0.8676],\n",
      "        [0.8436],\n",
      "        [0.8212],\n",
      "        [0.8430],\n",
      "        [0.8504],\n",
      "        [0.8202],\n",
      "        [0.8539],\n",
      "        [0.8876],\n",
      "        [0.9072],\n",
      "        [0.9058],\n",
      "        [0.9228],\n",
      "        [0.9190],\n",
      "        [0.9245],\n",
      "        [0.9115],\n",
      "        [0.8927],\n",
      "        [0.9104],\n",
      "        [0.9147],\n",
      "        [0.8988],\n",
      "        [0.8597],\n",
      "        [0.8529],\n",
      "        [0.8689],\n",
      "        [0.8870],\n",
      "        [0.8932],\n",
      "        [0.8517],\n",
      "        [0.8901],\n",
      "        [0.8474],\n",
      "        [0.8521],\n",
      "        [0.8462],\n",
      "        [0.8566],\n",
      "        [0.8394],\n",
      "        [0.8222],\n",
      "        [0.8367],\n",
      "        [0.8601],\n",
      "        [0.8796],\n",
      "        [0.9069],\n",
      "        [0.9308],\n",
      "        [0.9131],\n",
      "        [0.9149],\n",
      "        [0.8864],\n",
      "        [0.8744],\n",
      "        [0.9152],\n",
      "        [0.9195],\n",
      "        [0.9017]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0099],\n",
      "        [0.0050],\n",
      "        [0.0031],\n",
      "        [0.0143],\n",
      "        [0.0015],\n",
      "        [0.0030],\n",
      "        [0.0044],\n",
      "        [0.0030],\n",
      "        [0.0119],\n",
      "        [0.0002],\n",
      "        [0.0005],\n",
      "        [0.0002],\n",
      "        [0.0078],\n",
      "        [0.0107],\n",
      "        [0.0131],\n",
      "        [0.0154],\n",
      "        [0.0228],\n",
      "        [0.0396],\n",
      "        [0.0141],\n",
      "        [0.0675],\n",
      "        [0.0745],\n",
      "        [0.0744],\n",
      "        [0.0216],\n",
      "        [0.0210],\n",
      "        [0.0627],\n",
      "        [0.0751],\n",
      "        [0.0623],\n",
      "        [0.0307],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0330],\n",
      "        [0.0286],\n",
      "        [0.0246],\n",
      "        [0.0442],\n",
      "        [0.0419],\n",
      "        [0.0302],\n",
      "        [0.0337],\n",
      "        [0.0395],\n",
      "        [0.0509],\n",
      "        [0.0587],\n",
      "        [0.0078],\n",
      "        [0.0006],\n",
      "        [0.0208],\n",
      "        [0.0616],\n",
      "        [0.0617],\n",
      "        [0.0361],\n",
      "        [0.0399],\n",
      "        [0.0280],\n",
      "        [0.0135],\n",
      "        [0.0008],\n",
      "        [0.0159],\n",
      "        [0.0445],\n",
      "        [0.0676],\n",
      "        [0.0928],\n",
      "        [0.0658],\n",
      "        [0.0802],\n",
      "        [0.0555],\n",
      "        [0.0285],\n",
      "        [0.0885],\n",
      "        [0.0758],\n",
      "        [0.0578],\n",
      "        [0.0523],\n",
      "        [0.0534],\n",
      "        [0.0422],\n",
      "        [0.1450],\n",
      "        [0.0256],\n",
      "        [0.0573],\n",
      "        [0.0470],\n",
      "        [0.0007],\n",
      "        [0.0009],\n",
      "        [0.0505],\n",
      "        [0.0314],\n",
      "        [0.0212],\n",
      "        [0.0360],\n",
      "        [0.0702],\n",
      "        [0.0838],\n",
      "        [0.0833],\n",
      "        [0.0753],\n",
      "        [0.0798],\n",
      "        [0.0484],\n",
      "        [0.0105],\n",
      "        [0.0298],\n",
      "        [0.0532],\n",
      "        [0.0120],\n",
      "        [0.0387],\n",
      "        [0.0798],\n",
      "        [0.1258],\n",
      "        [0.0851]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0119],\n",
      "        [    0.0034],\n",
      "        [    0.0019],\n",
      "        [    0.0132],\n",
      "        [    0.0011],\n",
      "        [    0.0032],\n",
      "        [    0.0048],\n",
      "        [    0.0026],\n",
      "        [    0.0117],\n",
      "        [    0.0002],\n",
      "        [    0.0006],\n",
      "        [    0.0001],\n",
      "        [    0.0075],\n",
      "        [    0.0103],\n",
      "        [    0.0120],\n",
      "        [    0.0169],\n",
      "        [    0.0242],\n",
      "        [    0.0386],\n",
      "        [    0.0136],\n",
      "        [    0.0662],\n",
      "        [    0.0736],\n",
      "        [    0.0736],\n",
      "        [    0.0209],\n",
      "        [    0.0225],\n",
      "        [    0.0644],\n",
      "        [    0.0761],\n",
      "        [    0.0635],\n",
      "        [    0.0321],\n",
      "        [    0.0001],\n",
      "        [    0.0065],\n",
      "        [    0.0312],\n",
      "        [    0.0303],\n",
      "        [    0.0260],\n",
      "        [    0.0456],\n",
      "        [    0.0428],\n",
      "        [    0.0310],\n",
      "        [    0.0343],\n",
      "        [    0.0403],\n",
      "        [    0.0520],\n",
      "        [    0.0596],\n",
      "        [    0.0087],\n",
      "        [    0.0018],\n",
      "        [    0.0199],\n",
      "        [    0.0609],\n",
      "        [    0.0604],\n",
      "        [    0.0344],\n",
      "        [    0.0387],\n",
      "        [    0.0288],\n",
      "        [    0.0127],\n",
      "        [    0.0005],\n",
      "        [    0.0159],\n",
      "        [    0.0440],\n",
      "        [    0.0666],\n",
      "        [    0.0917],\n",
      "        [    0.0643],\n",
      "        [    0.0788],\n",
      "        [    0.0541],\n",
      "        [    0.0296],\n",
      "        [    0.0893],\n",
      "        [    0.0765],\n",
      "        [    0.0584],\n",
      "        [    0.0527],\n",
      "        [    0.0534],\n",
      "        [    0.0417],\n",
      "        [    0.1448],\n",
      "        [    0.0252],\n",
      "        [    0.0569],\n",
      "        [    0.0467],\n",
      "        [    0.0011],\n",
      "        [    0.0004],\n",
      "        [    0.0500],\n",
      "        [    0.0309],\n",
      "        [    0.0210],\n",
      "        [    0.0357],\n",
      "        [    0.0700],\n",
      "        [    0.0836],\n",
      "        [    0.0837],\n",
      "        [    0.0762],\n",
      "        [    0.0814],\n",
      "        [    0.0505],\n",
      "        [    0.0082],\n",
      "        [    0.0275],\n",
      "        [    0.0510],\n",
      "        [    0.0098],\n",
      "        [    0.0358],\n",
      "        [    0.0766],\n",
      "        [    0.1224],\n",
      "        [    0.0818]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 89\n",
      "剩餘X 資料 torch.Size([288, 18])\n",
      "剩餘Y 資料 torch.Size([288, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7038])\n",
      "目前模型的Data狀態 torch.Size([89, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5550],\n",
      "        [0.5299],\n",
      "        [0.5533],\n",
      "        [0.5770],\n",
      "        [0.5601],\n",
      "        [0.5579],\n",
      "        [0.5511],\n",
      "        [0.5505],\n",
      "        [0.5381],\n",
      "        [0.5408],\n",
      "        [0.5372],\n",
      "        [0.5339],\n",
      "        [0.5255],\n",
      "        [0.5128],\n",
      "        [0.5576],\n",
      "        [0.5582],\n",
      "        [0.5493],\n",
      "        [0.5330],\n",
      "        [0.5814],\n",
      "        [0.8702],\n",
      "        [0.8871],\n",
      "        [0.9157],\n",
      "        [0.8656],\n",
      "        [0.9065],\n",
      "        [0.9177],\n",
      "        [0.8987],\n",
      "        [0.9360],\n",
      "        [0.9446],\n",
      "        [0.9754],\n",
      "        [0.9862],\n",
      "        [1.0102],\n",
      "        [0.9669],\n",
      "        [0.9573],\n",
      "        [0.9345],\n",
      "        [0.9246],\n",
      "        [0.9128],\n",
      "        [0.8547],\n",
      "        [0.8738],\n",
      "        [0.8847],\n",
      "        [0.8563],\n",
      "        [0.8446],\n",
      "        [0.8530],\n",
      "        [0.8653],\n",
      "        [0.8537],\n",
      "        [0.8669],\n",
      "        [0.8660],\n",
      "        [0.8423],\n",
      "        [0.8204],\n",
      "        [0.8423],\n",
      "        [0.8500],\n",
      "        [0.8202],\n",
      "        [0.8534],\n",
      "        [0.8866],\n",
      "        [0.9061],\n",
      "        [0.9043],\n",
      "        [0.9214],\n",
      "        [0.9176],\n",
      "        [0.9234],\n",
      "        [0.9107],\n",
      "        [0.8920],\n",
      "        [0.9097],\n",
      "        [0.9143],\n",
      "        [0.8987],\n",
      "        [0.8601],\n",
      "        [0.8527],\n",
      "        [0.8685],\n",
      "        [0.8866],\n",
      "        [0.8929],\n",
      "        [0.8513],\n",
      "        [0.8897],\n",
      "        [0.8479],\n",
      "        [0.8526],\n",
      "        [0.8464],\n",
      "        [0.8568],\n",
      "        [0.8396],\n",
      "        [0.8223],\n",
      "        [0.8363],\n",
      "        [0.8592],\n",
      "        [0.8780],\n",
      "        [0.9048],\n",
      "        [0.9285],\n",
      "        [0.9108],\n",
      "        [0.9127],\n",
      "        [0.8841],\n",
      "        [0.8714],\n",
      "        [0.9120],\n",
      "        [0.9160],\n",
      "        [0.8984],\n",
      "        [0.9115]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0119],\n",
      "        [    0.0034],\n",
      "        [    0.0019],\n",
      "        [    0.0132],\n",
      "        [    0.0011],\n",
      "        [    0.0032],\n",
      "        [    0.0048],\n",
      "        [    0.0026],\n",
      "        [    0.0117],\n",
      "        [    0.0002],\n",
      "        [    0.0006],\n",
      "        [    0.0001],\n",
      "        [    0.0075],\n",
      "        [    0.0103],\n",
      "        [    0.0120],\n",
      "        [    0.0169],\n",
      "        [    0.0242],\n",
      "        [    0.0386],\n",
      "        [    0.0136],\n",
      "        [    0.0662],\n",
      "        [    0.0736],\n",
      "        [    0.0736],\n",
      "        [    0.0209],\n",
      "        [    0.0225],\n",
      "        [    0.0644],\n",
      "        [    0.0761],\n",
      "        [    0.0635],\n",
      "        [    0.0321],\n",
      "        [    0.0001],\n",
      "        [    0.0065],\n",
      "        [    0.0312],\n",
      "        [    0.0303],\n",
      "        [    0.0260],\n",
      "        [    0.0456],\n",
      "        [    0.0428],\n",
      "        [    0.0310],\n",
      "        [    0.0343],\n",
      "        [    0.0403],\n",
      "        [    0.0520],\n",
      "        [    0.0596],\n",
      "        [    0.0087],\n",
      "        [    0.0018],\n",
      "        [    0.0199],\n",
      "        [    0.0609],\n",
      "        [    0.0604],\n",
      "        [    0.0344],\n",
      "        [    0.0387],\n",
      "        [    0.0288],\n",
      "        [    0.0127],\n",
      "        [    0.0005],\n",
      "        [    0.0159],\n",
      "        [    0.0440],\n",
      "        [    0.0666],\n",
      "        [    0.0917],\n",
      "        [    0.0643],\n",
      "        [    0.0788],\n",
      "        [    0.0541],\n",
      "        [    0.0296],\n",
      "        [    0.0893],\n",
      "        [    0.0765],\n",
      "        [    0.0584],\n",
      "        [    0.0527],\n",
      "        [    0.0534],\n",
      "        [    0.0417],\n",
      "        [    0.1448],\n",
      "        [    0.0252],\n",
      "        [    0.0569],\n",
      "        [    0.0467],\n",
      "        [    0.0011],\n",
      "        [    0.0004],\n",
      "        [    0.0500],\n",
      "        [    0.0309],\n",
      "        [    0.0210],\n",
      "        [    0.0357],\n",
      "        [    0.0700],\n",
      "        [    0.0836],\n",
      "        [    0.0837],\n",
      "        [    0.0762],\n",
      "        [    0.0814],\n",
      "        [    0.0505],\n",
      "        [    0.0082],\n",
      "        [    0.0275],\n",
      "        [    0.0510],\n",
      "        [    0.0098],\n",
      "        [    0.0358],\n",
      "        [    0.0766],\n",
      "        [    0.1224],\n",
      "        [    0.0818],\n",
      "        [    0.2076]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0140],\n",
      "        [    0.0020],\n",
      "        [    0.0009],\n",
      "        [    0.0130],\n",
      "        [    0.0024],\n",
      "        [    0.0017],\n",
      "        [    0.0034],\n",
      "        [    0.0039],\n",
      "        [    0.0133],\n",
      "        [    0.0019],\n",
      "        [    0.0022],\n",
      "        [    0.0015],\n",
      "        [    0.0058],\n",
      "        [    0.0083],\n",
      "        [    0.0107],\n",
      "        [    0.0189],\n",
      "        [    0.0264],\n",
      "        [    0.0371],\n",
      "        [    0.0143],\n",
      "        [    0.0649],\n",
      "        [    0.0726],\n",
      "        [    0.0725],\n",
      "        [    0.0201],\n",
      "        [    0.0243],\n",
      "        [    0.0665],\n",
      "        [    0.0776],\n",
      "        [    0.0654],\n",
      "        [    0.0343],\n",
      "        [    0.0023],\n",
      "        [    0.0087],\n",
      "        [    0.0287],\n",
      "        [    0.0321],\n",
      "        [    0.0273],\n",
      "        [    0.0465],\n",
      "        [    0.0434],\n",
      "        [    0.0313],\n",
      "        [    0.0339],\n",
      "        [    0.0406],\n",
      "        [    0.0525],\n",
      "        [    0.0599],\n",
      "        [    0.0091],\n",
      "        [    0.0027],\n",
      "        [    0.0191],\n",
      "        [    0.0603],\n",
      "        [    0.0592],\n",
      "        [    0.0329],\n",
      "        [    0.0376],\n",
      "        [    0.0293],\n",
      "        [    0.0121],\n",
      "        [    0.0001],\n",
      "        [    0.0161],\n",
      "        [    0.0435],\n",
      "        [    0.0653],\n",
      "        [    0.0900],\n",
      "        [    0.0622],\n",
      "        [    0.0766],\n",
      "        [    0.0518],\n",
      "        [    0.0315],\n",
      "        [    0.0910],\n",
      "        [    0.0778],\n",
      "        [    0.0597],\n",
      "        [    0.0536],\n",
      "        [    0.0536],\n",
      "        [    0.0408],\n",
      "        [    0.1455],\n",
      "        [    0.0257],\n",
      "        [    0.0571],\n",
      "        [    0.0470],\n",
      "        [    0.0008],\n",
      "        [    0.0003],\n",
      "        [    0.0492],\n",
      "        [    0.0303],\n",
      "        [    0.0208],\n",
      "        [    0.0354],\n",
      "        [    0.0694],\n",
      "        [    0.0830],\n",
      "        [    0.0838],\n",
      "        [    0.0769],\n",
      "        [    0.0834],\n",
      "        [    0.0533],\n",
      "        [    0.0051],\n",
      "        [    0.0245],\n",
      "        [    0.0480],\n",
      "        [    0.0069],\n",
      "        [    0.0323],\n",
      "        [    0.0725],\n",
      "        [    0.1178],\n",
      "        [    0.0771],\n",
      "        [    0.2025]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 90\n",
      "剩餘X 資料 torch.Size([287, 18])\n",
      "剩餘Y 資料 torch.Size([287, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6492])\n",
      "目前模型的Data狀態 torch.Size([90, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5529],\n",
      "        [0.5285],\n",
      "        [0.5523],\n",
      "        [0.5768],\n",
      "        [0.5614],\n",
      "        [0.5594],\n",
      "        [0.5524],\n",
      "        [0.5518],\n",
      "        [0.5398],\n",
      "        [0.5425],\n",
      "        [0.5388],\n",
      "        [0.5355],\n",
      "        [0.5272],\n",
      "        [0.5147],\n",
      "        [0.5589],\n",
      "        [0.5602],\n",
      "        [0.5514],\n",
      "        [0.5345],\n",
      "        [0.5820],\n",
      "        [0.8689],\n",
      "        [0.8862],\n",
      "        [0.9146],\n",
      "        [0.8648],\n",
      "        [0.9047],\n",
      "        [0.9156],\n",
      "        [0.8971],\n",
      "        [0.9340],\n",
      "        [0.9424],\n",
      "        [0.9732],\n",
      "        [0.9840],\n",
      "        [1.0077],\n",
      "        [0.9651],\n",
      "        [0.9560],\n",
      "        [0.9335],\n",
      "        [0.9239],\n",
      "        [0.9125],\n",
      "        [0.8551],\n",
      "        [0.8735],\n",
      "        [0.8841],\n",
      "        [0.8560],\n",
      "        [0.8443],\n",
      "        [0.8521],\n",
      "        [0.8646],\n",
      "        [0.8532],\n",
      "        [0.8658],\n",
      "        [0.8645],\n",
      "        [0.8413],\n",
      "        [0.8199],\n",
      "        [0.8416],\n",
      "        [0.8497],\n",
      "        [0.8204],\n",
      "        [0.8530],\n",
      "        [0.8853],\n",
      "        [0.9045],\n",
      "        [0.9022],\n",
      "        [0.9192],\n",
      "        [0.9153],\n",
      "        [0.9214],\n",
      "        [0.9090],\n",
      "        [0.8907],\n",
      "        [0.9084],\n",
      "        [0.9134],\n",
      "        [0.8985],\n",
      "        [0.8610],\n",
      "        [0.8534],\n",
      "        [0.8690],\n",
      "        [0.8867],\n",
      "        [0.8933],\n",
      "        [0.8516],\n",
      "        [0.8895],\n",
      "        [0.8487],\n",
      "        [0.8532],\n",
      "        [0.8466],\n",
      "        [0.8571],\n",
      "        [0.8402],\n",
      "        [0.8229],\n",
      "        [0.8362],\n",
      "        [0.8586],\n",
      "        [0.8760],\n",
      "        [0.9019],\n",
      "        [0.9254],\n",
      "        [0.9078],\n",
      "        [0.9097],\n",
      "        [0.8812],\n",
      "        [0.8679],\n",
      "        [0.9079],\n",
      "        [0.9114],\n",
      "        [0.8937],\n",
      "        [0.9064],\n",
      "        [0.9034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0140],\n",
      "        [    0.0020],\n",
      "        [    0.0009],\n",
      "        [    0.0130],\n",
      "        [    0.0024],\n",
      "        [    0.0017],\n",
      "        [    0.0034],\n",
      "        [    0.0039],\n",
      "        [    0.0133],\n",
      "        [    0.0019],\n",
      "        [    0.0022],\n",
      "        [    0.0015],\n",
      "        [    0.0058],\n",
      "        [    0.0083],\n",
      "        [    0.0107],\n",
      "        [    0.0189],\n",
      "        [    0.0264],\n",
      "        [    0.0371],\n",
      "        [    0.0143],\n",
      "        [    0.0649],\n",
      "        [    0.0726],\n",
      "        [    0.0725],\n",
      "        [    0.0201],\n",
      "        [    0.0243],\n",
      "        [    0.0665],\n",
      "        [    0.0776],\n",
      "        [    0.0654],\n",
      "        [    0.0343],\n",
      "        [    0.0023],\n",
      "        [    0.0087],\n",
      "        [    0.0287],\n",
      "        [    0.0321],\n",
      "        [    0.0273],\n",
      "        [    0.0465],\n",
      "        [    0.0434],\n",
      "        [    0.0313],\n",
      "        [    0.0339],\n",
      "        [    0.0406],\n",
      "        [    0.0525],\n",
      "        [    0.0599],\n",
      "        [    0.0091],\n",
      "        [    0.0027],\n",
      "        [    0.0191],\n",
      "        [    0.0603],\n",
      "        [    0.0592],\n",
      "        [    0.0329],\n",
      "        [    0.0376],\n",
      "        [    0.0293],\n",
      "        [    0.0121],\n",
      "        [    0.0001],\n",
      "        [    0.0161],\n",
      "        [    0.0435],\n",
      "        [    0.0653],\n",
      "        [    0.0900],\n",
      "        [    0.0622],\n",
      "        [    0.0766],\n",
      "        [    0.0518],\n",
      "        [    0.0315],\n",
      "        [    0.0910],\n",
      "        [    0.0778],\n",
      "        [    0.0597],\n",
      "        [    0.0536],\n",
      "        [    0.0536],\n",
      "        [    0.0408],\n",
      "        [    0.1455],\n",
      "        [    0.0257],\n",
      "        [    0.0571],\n",
      "        [    0.0470],\n",
      "        [    0.0008],\n",
      "        [    0.0003],\n",
      "        [    0.0492],\n",
      "        [    0.0303],\n",
      "        [    0.0208],\n",
      "        [    0.0354],\n",
      "        [    0.0694],\n",
      "        [    0.0830],\n",
      "        [    0.0838],\n",
      "        [    0.0769],\n",
      "        [    0.0834],\n",
      "        [    0.0533],\n",
      "        [    0.0051],\n",
      "        [    0.0245],\n",
      "        [    0.0480],\n",
      "        [    0.0069],\n",
      "        [    0.0323],\n",
      "        [    0.0725],\n",
      "        [    0.1178],\n",
      "        [    0.0771],\n",
      "        [    0.2025],\n",
      "        [    0.2542]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0209],\n",
      "        [    0.0042],\n",
      "        [    0.0046],\n",
      "        [    0.0089],\n",
      "        [    0.0011],\n",
      "        [    0.0027],\n",
      "        [    0.0045],\n",
      "        [    0.0027],\n",
      "        [    0.0125],\n",
      "        [    0.0011],\n",
      "        [    0.0011],\n",
      "        [    0.0002],\n",
      "        [    0.0068],\n",
      "        [    0.0088],\n",
      "        [    0.0124],\n",
      "        [    0.0187],\n",
      "        [    0.0265],\n",
      "        [    0.0384],\n",
      "        [    0.0124],\n",
      "        [    0.0600],\n",
      "        [    0.0679],\n",
      "        [    0.0676],\n",
      "        [    0.0156],\n",
      "        [    0.0302],\n",
      "        [    0.0729],\n",
      "        [    0.0834],\n",
      "        [    0.0718],\n",
      "        [    0.0413],\n",
      "        [    0.0093],\n",
      "        [    0.0154],\n",
      "        [    0.0216],\n",
      "        [    0.0379],\n",
      "        [    0.0327],\n",
      "        [    0.0514],\n",
      "        [    0.0481],\n",
      "        [    0.0355],\n",
      "        [    0.0368],\n",
      "        [    0.0445],\n",
      "        [    0.0569],\n",
      "        [    0.0638],\n",
      "        [    0.0131],\n",
      "        [    0.0078],\n",
      "        [    0.0141],\n",
      "        [    0.0557],\n",
      "        [    0.0538],\n",
      "        [    0.0269],\n",
      "        [    0.0321],\n",
      "        [    0.0341],\n",
      "        [    0.0070],\n",
      "        [    0.0048],\n",
      "        [    0.0119],\n",
      "        [    0.0384],\n",
      "        [    0.0589],\n",
      "        [    0.0829],\n",
      "        [    0.0544],\n",
      "        [    0.0684],\n",
      "        [    0.0435],\n",
      "        [    0.0396],\n",
      "        [    0.0984],\n",
      "        [    0.0846],\n",
      "        [    0.0668],\n",
      "        [    0.0600],\n",
      "        [    0.0591],\n",
      "        [    0.0443],\n",
      "        [    0.1420],\n",
      "        [    0.0221],\n",
      "        [    0.0529],\n",
      "        [    0.0432],\n",
      "        [    0.0047],\n",
      "        [    0.0043],\n",
      "        [    0.0525],\n",
      "        [    0.0342],\n",
      "        [    0.0251],\n",
      "        [    0.0398],\n",
      "        [    0.0735],\n",
      "        [    0.0867],\n",
      "        [    0.0880],\n",
      "        [    0.0820],\n",
      "        [    0.0906],\n",
      "        [    0.0619],\n",
      "        [    0.0041],\n",
      "        [    0.0154],\n",
      "        [    0.0389],\n",
      "        [    0.0021],\n",
      "        [    0.0225],\n",
      "        [    0.0623],\n",
      "        [    0.1070],\n",
      "        [    0.0658],\n",
      "        [    0.1903],\n",
      "        [    0.2401]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 91\n",
      "剩餘X 資料 torch.Size([286, 18])\n",
      "剩餘Y 資料 torch.Size([286, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6585])\n",
      "目前模型的Data狀態 torch.Size([91, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5460],\n",
      "        [0.5223],\n",
      "        [0.5468],\n",
      "        [0.5726],\n",
      "        [0.5601],\n",
      "        [0.5584],\n",
      "        [0.5513],\n",
      "        [0.5506],\n",
      "        [0.5390],\n",
      "        [0.5416],\n",
      "        [0.5378],\n",
      "        [0.5342],\n",
      "        [0.5261],\n",
      "        [0.5142],\n",
      "        [0.5572],\n",
      "        [0.5599],\n",
      "        [0.5516],\n",
      "        [0.5332],\n",
      "        [0.5802],\n",
      "        [0.8640],\n",
      "        [0.8814],\n",
      "        [0.9097],\n",
      "        [0.8603],\n",
      "        [0.8988],\n",
      "        [0.9092],\n",
      "        [0.8913],\n",
      "        [0.9276],\n",
      "        [0.9354],\n",
      "        [0.9662],\n",
      "        [0.9773],\n",
      "        [1.0006],\n",
      "        [0.9594],\n",
      "        [0.9507],\n",
      "        [0.9286],\n",
      "        [0.9192],\n",
      "        [0.9083],\n",
      "        [0.8521],\n",
      "        [0.8696],\n",
      "        [0.8798],\n",
      "        [0.8521],\n",
      "        [0.8402],\n",
      "        [0.8470],\n",
      "        [0.8596],\n",
      "        [0.8485],\n",
      "        [0.8603],\n",
      "        [0.8584],\n",
      "        [0.8358],\n",
      "        [0.8151],\n",
      "        [0.8365],\n",
      "        [0.8448],\n",
      "        [0.8162],\n",
      "        [0.8478],\n",
      "        [0.8789],\n",
      "        [0.8974],\n",
      "        [0.8945],\n",
      "        [0.9109],\n",
      "        [0.9070],\n",
      "        [0.9134],\n",
      "        [0.9016],\n",
      "        [0.8838],\n",
      "        [0.9014],\n",
      "        [0.9070],\n",
      "        [0.8930],\n",
      "        [0.8575],\n",
      "        [0.8499],\n",
      "        [0.8654],\n",
      "        [0.8826],\n",
      "        [0.8894],\n",
      "        [0.8477],\n",
      "        [0.8849],\n",
      "        [0.8454],\n",
      "        [0.8493],\n",
      "        [0.8423],\n",
      "        [0.8527],\n",
      "        [0.8361],\n",
      "        [0.8193],\n",
      "        [0.8320],\n",
      "        [0.8535],\n",
      "        [0.8687],\n",
      "        [0.8933],\n",
      "        [0.9162],\n",
      "        [0.8987],\n",
      "        [0.9005],\n",
      "        [0.8722],\n",
      "        [0.8582],\n",
      "        [0.8978],\n",
      "        [0.9006],\n",
      "        [0.8825],\n",
      "        [0.8941],\n",
      "        [0.8894],\n",
      "        [0.9195]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0209],\n",
      "        [    0.0042],\n",
      "        [    0.0046],\n",
      "        [    0.0089],\n",
      "        [    0.0011],\n",
      "        [    0.0027],\n",
      "        [    0.0045],\n",
      "        [    0.0027],\n",
      "        [    0.0125],\n",
      "        [    0.0011],\n",
      "        [    0.0011],\n",
      "        [    0.0002],\n",
      "        [    0.0068],\n",
      "        [    0.0088],\n",
      "        [    0.0124],\n",
      "        [    0.0187],\n",
      "        [    0.0265],\n",
      "        [    0.0384],\n",
      "        [    0.0124],\n",
      "        [    0.0600],\n",
      "        [    0.0679],\n",
      "        [    0.0676],\n",
      "        [    0.0156],\n",
      "        [    0.0302],\n",
      "        [    0.0729],\n",
      "        [    0.0834],\n",
      "        [    0.0718],\n",
      "        [    0.0413],\n",
      "        [    0.0093],\n",
      "        [    0.0154],\n",
      "        [    0.0216],\n",
      "        [    0.0379],\n",
      "        [    0.0327],\n",
      "        [    0.0514],\n",
      "        [    0.0481],\n",
      "        [    0.0355],\n",
      "        [    0.0368],\n",
      "        [    0.0445],\n",
      "        [    0.0569],\n",
      "        [    0.0638],\n",
      "        [    0.0131],\n",
      "        [    0.0078],\n",
      "        [    0.0141],\n",
      "        [    0.0557],\n",
      "        [    0.0538],\n",
      "        [    0.0269],\n",
      "        [    0.0321],\n",
      "        [    0.0341],\n",
      "        [    0.0070],\n",
      "        [    0.0048],\n",
      "        [    0.0119],\n",
      "        [    0.0384],\n",
      "        [    0.0589],\n",
      "        [    0.0829],\n",
      "        [    0.0544],\n",
      "        [    0.0684],\n",
      "        [    0.0435],\n",
      "        [    0.0396],\n",
      "        [    0.0984],\n",
      "        [    0.0846],\n",
      "        [    0.0668],\n",
      "        [    0.0600],\n",
      "        [    0.0591],\n",
      "        [    0.0443],\n",
      "        [    0.1420],\n",
      "        [    0.0221],\n",
      "        [    0.0529],\n",
      "        [    0.0432],\n",
      "        [    0.0047],\n",
      "        [    0.0043],\n",
      "        [    0.0525],\n",
      "        [    0.0342],\n",
      "        [    0.0251],\n",
      "        [    0.0398],\n",
      "        [    0.0735],\n",
      "        [    0.0867],\n",
      "        [    0.0880],\n",
      "        [    0.0820],\n",
      "        [    0.0906],\n",
      "        [    0.0619],\n",
      "        [    0.0041],\n",
      "        [    0.0154],\n",
      "        [    0.0389],\n",
      "        [    0.0021],\n",
      "        [    0.0225],\n",
      "        [    0.0623],\n",
      "        [    0.1070],\n",
      "        [    0.0658],\n",
      "        [    0.1903],\n",
      "        [    0.2401],\n",
      "        [    0.2610]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0274],\n",
      "        [    0.0103],\n",
      "        [    0.0099],\n",
      "        [    0.0057],\n",
      "        [    0.0018],\n",
      "        [    0.0017],\n",
      "        [    0.0037],\n",
      "        [    0.0035],\n",
      "        [    0.0135],\n",
      "        [    0.0018],\n",
      "        [    0.0015],\n",
      "        [    0.0002],\n",
      "        [    0.0066],\n",
      "        [    0.0078],\n",
      "        [    0.0135],\n",
      "        [    0.0196],\n",
      "        [    0.0283],\n",
      "        [    0.0388],\n",
      "        [    0.0127],\n",
      "        [    0.0577],\n",
      "        [    0.0657],\n",
      "        [    0.0651],\n",
      "        [    0.0134],\n",
      "        [    0.0338],\n",
      "        [    0.0774],\n",
      "        [    0.0877],\n",
      "        [    0.0768],\n",
      "        [    0.0468],\n",
      "        [    0.0147],\n",
      "        [    0.0202],\n",
      "        [    0.0167],\n",
      "        [    0.0409],\n",
      "        [    0.0355],\n",
      "        [    0.0539],\n",
      "        [    0.0505],\n",
      "        [    0.0369],\n",
      "        [    0.0367],\n",
      "        [    0.0456],\n",
      "        [    0.0584],\n",
      "        [    0.0649],\n",
      "        [    0.0144],\n",
      "        [    0.0106],\n",
      "        [    0.0112],\n",
      "        [    0.0532],\n",
      "        [    0.0505],\n",
      "        [    0.0228],\n",
      "        [    0.0284],\n",
      "        [    0.0372],\n",
      "        [    0.0035],\n",
      "        [    0.0082],\n",
      "        [    0.0091],\n",
      "        [    0.0344],\n",
      "        [    0.0534],\n",
      "        [    0.0765],\n",
      "        [    0.0472],\n",
      "        [    0.0604],\n",
      "        [    0.0353],\n",
      "        [    0.0474],\n",
      "        [    0.1054],\n",
      "        [    0.0909],\n",
      "        [    0.0733],\n",
      "        [    0.0656],\n",
      "        [    0.0635],\n",
      "        [    0.0459],\n",
      "        [    0.1408],\n",
      "        [    0.0210],\n",
      "        [    0.0508],\n",
      "        [    0.0415],\n",
      "        [    0.0068],\n",
      "        [    0.0074],\n",
      "        [    0.0543],\n",
      "        [    0.0368],\n",
      "        [    0.0282],\n",
      "        [    0.0429],\n",
      "        [    0.0760],\n",
      "        [    0.0886],\n",
      "        [    0.0904],\n",
      "        [    0.0853],\n",
      "        [    0.0967],\n",
      "        [    0.0696],\n",
      "        [    0.0126],\n",
      "        [    0.0070],\n",
      "        [    0.0304],\n",
      "        [    0.0102],\n",
      "        [    0.0137],\n",
      "        [    0.0532],\n",
      "        [    0.0968],\n",
      "        [    0.0550],\n",
      "        [    0.1779],\n",
      "        [    0.2250],\n",
      "        [    0.2438]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 92\n",
      "剩餘X 資料 torch.Size([285, 18])\n",
      "剩餘Y 資料 torch.Size([285, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7461])\n",
      "目前模型的Data狀態 torch.Size([92, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5395],\n",
      "        [0.5162],\n",
      "        [0.5416],\n",
      "        [0.5695],\n",
      "        [0.5608],\n",
      "        [0.5594],\n",
      "        [0.5521],\n",
      "        [0.5514],\n",
      "        [0.5399],\n",
      "        [0.5424],\n",
      "        [0.5381],\n",
      "        [0.5342],\n",
      "        [0.5264],\n",
      "        [0.5152],\n",
      "        [0.5561],\n",
      "        [0.5609],\n",
      "        [0.5533],\n",
      "        [0.5328],\n",
      "        [0.5804],\n",
      "        [0.8616],\n",
      "        [0.8792],\n",
      "        [0.9072],\n",
      "        [0.8581],\n",
      "        [0.8952],\n",
      "        [0.9047],\n",
      "        [0.8871],\n",
      "        [0.9227],\n",
      "        [0.9299],\n",
      "        [0.9608],\n",
      "        [0.9725],\n",
      "        [0.9957],\n",
      "        [0.9563],\n",
      "        [0.9478],\n",
      "        [0.9262],\n",
      "        [0.9169],\n",
      "        [0.9068],\n",
      "        [0.8522],\n",
      "        [0.8685],\n",
      "        [0.8783],\n",
      "        [0.8510],\n",
      "        [0.8389],\n",
      "        [0.8442],\n",
      "        [0.8566],\n",
      "        [0.8461],\n",
      "        [0.8570],\n",
      "        [0.8543],\n",
      "        [0.8321],\n",
      "        [0.8120],\n",
      "        [0.8330],\n",
      "        [0.8414],\n",
      "        [0.8133],\n",
      "        [0.8439],\n",
      "        [0.8733],\n",
      "        [0.8910],\n",
      "        [0.8872],\n",
      "        [0.9029],\n",
      "        [0.8989],\n",
      "        [0.9056],\n",
      "        [0.8946],\n",
      "        [0.8776],\n",
      "        [0.8949],\n",
      "        [0.9014],\n",
      "        [0.8886],\n",
      "        [0.8559],\n",
      "        [0.8487],\n",
      "        [0.8643],\n",
      "        [0.8805],\n",
      "        [0.8877],\n",
      "        [0.8456],\n",
      "        [0.8818],\n",
      "        [0.8436],\n",
      "        [0.8467],\n",
      "        [0.8392],\n",
      "        [0.8496],\n",
      "        [0.8336],\n",
      "        [0.8173],\n",
      "        [0.8296],\n",
      "        [0.8501],\n",
      "        [0.8627],\n",
      "        [0.8856],\n",
      "        [0.9077],\n",
      "        [0.8903],\n",
      "        [0.8920],\n",
      "        [0.8641],\n",
      "        [0.8493],\n",
      "        [0.8886],\n",
      "        [0.8904],\n",
      "        [0.8717],\n",
      "        [0.8817],\n",
      "        [0.8742],\n",
      "        [0.9023],\n",
      "        [0.9364]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0274],\n",
      "        [    0.0103],\n",
      "        [    0.0099],\n",
      "        [    0.0057],\n",
      "        [    0.0018],\n",
      "        [    0.0017],\n",
      "        [    0.0037],\n",
      "        [    0.0035],\n",
      "        [    0.0135],\n",
      "        [    0.0018],\n",
      "        [    0.0015],\n",
      "        [    0.0002],\n",
      "        [    0.0066],\n",
      "        [    0.0078],\n",
      "        [    0.0135],\n",
      "        [    0.0196],\n",
      "        [    0.0283],\n",
      "        [    0.0388],\n",
      "        [    0.0127],\n",
      "        [    0.0577],\n",
      "        [    0.0657],\n",
      "        [    0.0651],\n",
      "        [    0.0134],\n",
      "        [    0.0338],\n",
      "        [    0.0774],\n",
      "        [    0.0877],\n",
      "        [    0.0768],\n",
      "        [    0.0468],\n",
      "        [    0.0147],\n",
      "        [    0.0202],\n",
      "        [    0.0167],\n",
      "        [    0.0409],\n",
      "        [    0.0355],\n",
      "        [    0.0539],\n",
      "        [    0.0505],\n",
      "        [    0.0369],\n",
      "        [    0.0367],\n",
      "        [    0.0456],\n",
      "        [    0.0584],\n",
      "        [    0.0649],\n",
      "        [    0.0144],\n",
      "        [    0.0106],\n",
      "        [    0.0112],\n",
      "        [    0.0532],\n",
      "        [    0.0505],\n",
      "        [    0.0228],\n",
      "        [    0.0284],\n",
      "        [    0.0372],\n",
      "        [    0.0035],\n",
      "        [    0.0082],\n",
      "        [    0.0091],\n",
      "        [    0.0344],\n",
      "        [    0.0534],\n",
      "        [    0.0765],\n",
      "        [    0.0472],\n",
      "        [    0.0604],\n",
      "        [    0.0353],\n",
      "        [    0.0474],\n",
      "        [    0.1054],\n",
      "        [    0.0909],\n",
      "        [    0.0733],\n",
      "        [    0.0656],\n",
      "        [    0.0635],\n",
      "        [    0.0459],\n",
      "        [    0.1408],\n",
      "        [    0.0210],\n",
      "        [    0.0508],\n",
      "        [    0.0415],\n",
      "        [    0.0068],\n",
      "        [    0.0074],\n",
      "        [    0.0543],\n",
      "        [    0.0368],\n",
      "        [    0.0282],\n",
      "        [    0.0429],\n",
      "        [    0.0760],\n",
      "        [    0.0886],\n",
      "        [    0.0904],\n",
      "        [    0.0853],\n",
      "        [    0.0967],\n",
      "        [    0.0696],\n",
      "        [    0.0126],\n",
      "        [    0.0070],\n",
      "        [    0.0304],\n",
      "        [    0.0102],\n",
      "        [    0.0137],\n",
      "        [    0.0532],\n",
      "        [    0.0968],\n",
      "        [    0.0550],\n",
      "        [    0.1779],\n",
      "        [    0.2250],\n",
      "        [    0.2438],\n",
      "        [    0.1902]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0331],\n",
      "        [0.0158],\n",
      "        [0.0145],\n",
      "        [0.0034],\n",
      "        [0.0037],\n",
      "        [0.0004],\n",
      "        [0.0017],\n",
      "        [0.0053],\n",
      "        [0.0154],\n",
      "        [0.0034],\n",
      "        [0.0028],\n",
      "        [0.0011],\n",
      "        [0.0055],\n",
      "        [0.0060],\n",
      "        [0.0142],\n",
      "        [0.0211],\n",
      "        [0.0307],\n",
      "        [0.0388],\n",
      "        [0.0138],\n",
      "        [0.0576],\n",
      "        [0.0657],\n",
      "        [0.0649],\n",
      "        [0.0134],\n",
      "        [0.0350],\n",
      "        [0.0795],\n",
      "        [0.0896],\n",
      "        [0.0793],\n",
      "        [0.0498],\n",
      "        [0.0174],\n",
      "        [0.0223],\n",
      "        [0.0147],\n",
      "        [0.0411],\n",
      "        [0.0357],\n",
      "        [0.0537],\n",
      "        [0.0502],\n",
      "        [0.0358],\n",
      "        [0.0342],\n",
      "        [0.0442],\n",
      "        [0.0573],\n",
      "        [0.0634],\n",
      "        [0.0132],\n",
      "        [0.0110],\n",
      "        [0.0107],\n",
      "        [0.0531],\n",
      "        [0.0497],\n",
      "        [0.0212],\n",
      "        [0.0271],\n",
      "        [0.0380],\n",
      "        [0.0022],\n",
      "        [0.0094],\n",
      "        [0.0083],\n",
      "        [0.0326],\n",
      "        [0.0502],\n",
      "        [0.0725],\n",
      "        [0.0423],\n",
      "        [0.0548],\n",
      "        [0.0296],\n",
      "        [0.0529],\n",
      "        [0.1101],\n",
      "        [0.0948],\n",
      "        [0.0775],\n",
      "        [0.0687],\n",
      "        [0.0655],\n",
      "        [0.0452],\n",
      "        [0.1421],\n",
      "        [0.0223],\n",
      "        [0.0513],\n",
      "        [0.0423],\n",
      "        [0.0065],\n",
      "        [0.0081],\n",
      "        [0.0539],\n",
      "        [0.0373],\n",
      "        [0.0291],\n",
      "        [0.0439],\n",
      "        [0.0765],\n",
      "        [0.0884],\n",
      "        [0.0905],\n",
      "        [0.0863],\n",
      "        [0.1004],\n",
      "        [0.0749],\n",
      "        [0.0186],\n",
      "        [0.0010],\n",
      "        [0.0243],\n",
      "        [0.0161],\n",
      "        [0.0070],\n",
      "        [0.0465],\n",
      "        [0.0890],\n",
      "        [0.0465],\n",
      "        [0.1676],\n",
      "        [0.2117],\n",
      "        [0.2285],\n",
      "        [0.1735]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 93\n",
      "剩餘X 資料 torch.Size([284, 18])\n",
      "剩餘Y 資料 torch.Size([284, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7455])\n",
      "目前模型的Data狀態 torch.Size([93, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5338],\n",
      "        [0.5107],\n",
      "        [0.5370],\n",
      "        [0.5672],\n",
      "        [0.5627],\n",
      "        [0.5615],\n",
      "        [0.5541],\n",
      "        [0.5533],\n",
      "        [0.5418],\n",
      "        [0.5440],\n",
      "        [0.5394],\n",
      "        [0.5351],\n",
      "        [0.5275],\n",
      "        [0.5170],\n",
      "        [0.5554],\n",
      "        [0.5624],\n",
      "        [0.5557],\n",
      "        [0.5328],\n",
      "        [0.5816],\n",
      "        [0.8615],\n",
      "        [0.8792],\n",
      "        [0.9071],\n",
      "        [0.8581],\n",
      "        [0.8939],\n",
      "        [0.9027],\n",
      "        [0.8851],\n",
      "        [0.9201],\n",
      "        [0.9269],\n",
      "        [0.9581],\n",
      "        [0.9705],\n",
      "        [0.9937],\n",
      "        [0.9561],\n",
      "        [0.9477],\n",
      "        [0.9264],\n",
      "        [0.9171],\n",
      "        [0.9080],\n",
      "        [0.8547],\n",
      "        [0.8699],\n",
      "        [0.8793],\n",
      "        [0.8525],\n",
      "        [0.8401],\n",
      "        [0.8438],\n",
      "        [0.8561],\n",
      "        [0.8460],\n",
      "        [0.8563],\n",
      "        [0.8527],\n",
      "        [0.8308],\n",
      "        [0.8112],\n",
      "        [0.8317],\n",
      "        [0.8401],\n",
      "        [0.8125],\n",
      "        [0.8421],\n",
      "        [0.8701],\n",
      "        [0.8870],\n",
      "        [0.8823],\n",
      "        [0.8973],\n",
      "        [0.8932],\n",
      "        [0.9001],\n",
      "        [0.8899],\n",
      "        [0.8737],\n",
      "        [0.8907],\n",
      "        [0.8982],\n",
      "        [0.8866],\n",
      "        [0.8567],\n",
      "        [0.8500],\n",
      "        [0.8656],\n",
      "        [0.8809],\n",
      "        [0.8886],\n",
      "        [0.8459],\n",
      "        [0.8811],\n",
      "        [0.8440],\n",
      "        [0.8462],\n",
      "        [0.8383],\n",
      "        [0.8487],\n",
      "        [0.8331],\n",
      "        [0.8175],\n",
      "        [0.8295],\n",
      "        [0.8492],\n",
      "        [0.8590],\n",
      "        [0.8804],\n",
      "        [0.9017],\n",
      "        [0.8843],\n",
      "        [0.8859],\n",
      "        [0.8583],\n",
      "        [0.8427],\n",
      "        [0.8819],\n",
      "        [0.8827],\n",
      "        [0.8631],\n",
      "        [0.8715],\n",
      "        [0.8609],\n",
      "        [0.8870],\n",
      "        [0.9196],\n",
      "        [0.9082]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0331],\n",
      "        [0.0158],\n",
      "        [0.0145],\n",
      "        [0.0034],\n",
      "        [0.0037],\n",
      "        [0.0004],\n",
      "        [0.0017],\n",
      "        [0.0053],\n",
      "        [0.0154],\n",
      "        [0.0034],\n",
      "        [0.0028],\n",
      "        [0.0011],\n",
      "        [0.0055],\n",
      "        [0.0060],\n",
      "        [0.0142],\n",
      "        [0.0211],\n",
      "        [0.0307],\n",
      "        [0.0388],\n",
      "        [0.0138],\n",
      "        [0.0576],\n",
      "        [0.0657],\n",
      "        [0.0649],\n",
      "        [0.0134],\n",
      "        [0.0350],\n",
      "        [0.0795],\n",
      "        [0.0896],\n",
      "        [0.0793],\n",
      "        [0.0498],\n",
      "        [0.0174],\n",
      "        [0.0223],\n",
      "        [0.0147],\n",
      "        [0.0411],\n",
      "        [0.0357],\n",
      "        [0.0537],\n",
      "        [0.0502],\n",
      "        [0.0358],\n",
      "        [0.0342],\n",
      "        [0.0442],\n",
      "        [0.0573],\n",
      "        [0.0634],\n",
      "        [0.0132],\n",
      "        [0.0110],\n",
      "        [0.0107],\n",
      "        [0.0531],\n",
      "        [0.0497],\n",
      "        [0.0212],\n",
      "        [0.0271],\n",
      "        [0.0380],\n",
      "        [0.0022],\n",
      "        [0.0094],\n",
      "        [0.0083],\n",
      "        [0.0326],\n",
      "        [0.0502],\n",
      "        [0.0725],\n",
      "        [0.0423],\n",
      "        [0.0548],\n",
      "        [0.0296],\n",
      "        [0.0529],\n",
      "        [0.1101],\n",
      "        [0.0948],\n",
      "        [0.0775],\n",
      "        [0.0687],\n",
      "        [0.0655],\n",
      "        [0.0452],\n",
      "        [0.1421],\n",
      "        [0.0223],\n",
      "        [0.0513],\n",
      "        [0.0423],\n",
      "        [0.0065],\n",
      "        [0.0081],\n",
      "        [0.0539],\n",
      "        [0.0373],\n",
      "        [0.0291],\n",
      "        [0.0439],\n",
      "        [0.0765],\n",
      "        [0.0884],\n",
      "        [0.0905],\n",
      "        [0.0863],\n",
      "        [0.1004],\n",
      "        [0.0749],\n",
      "        [0.0186],\n",
      "        [0.0010],\n",
      "        [0.0243],\n",
      "        [0.0161],\n",
      "        [0.0070],\n",
      "        [0.0465],\n",
      "        [0.0890],\n",
      "        [0.0465],\n",
      "        [0.1676],\n",
      "        [0.2117],\n",
      "        [0.2285],\n",
      "        [0.1735],\n",
      "        [0.1627]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0397],\n",
      "        [0.0224],\n",
      "        [0.0201],\n",
      "        [0.0002],\n",
      "        [0.0048],\n",
      "        [0.0017],\n",
      "        [0.0007],\n",
      "        [0.0062],\n",
      "        [0.0163],\n",
      "        [0.0041],\n",
      "        [0.0031],\n",
      "        [0.0010],\n",
      "        [0.0053],\n",
      "        [0.0052],\n",
      "        [0.0154],\n",
      "        [0.0220],\n",
      "        [0.0324],\n",
      "        [0.0394],\n",
      "        [0.0142],\n",
      "        [0.0576],\n",
      "        [0.0659],\n",
      "        [0.0654],\n",
      "        [0.0137],\n",
      "        [0.0356],\n",
      "        [0.0808],\n",
      "        [0.0909],\n",
      "        [0.0808],\n",
      "        [0.0516],\n",
      "        [0.0188],\n",
      "        [0.0230],\n",
      "        [0.0142],\n",
      "        [0.0404],\n",
      "        [0.0349],\n",
      "        [0.0528],\n",
      "        [0.0493],\n",
      "        [0.0342],\n",
      "        [0.0317],\n",
      "        [0.0425],\n",
      "        [0.0559],\n",
      "        [0.0617],\n",
      "        [0.0119],\n",
      "        [0.0110],\n",
      "        [0.0106],\n",
      "        [0.0534],\n",
      "        [0.0495],\n",
      "        [0.0203],\n",
      "        [0.0265],\n",
      "        [0.0383],\n",
      "        [0.0017],\n",
      "        [0.0099],\n",
      "        [0.0080],\n",
      "        [0.0317],\n",
      "        [0.0481],\n",
      "        [0.0699],\n",
      "        [0.0386],\n",
      "        [0.0506],\n",
      "        [0.0253],\n",
      "        [0.0570],\n",
      "        [0.1135],\n",
      "        [0.0976],\n",
      "        [0.0804],\n",
      "        [0.0707],\n",
      "        [0.0665],\n",
      "        [0.0438],\n",
      "        [0.1438],\n",
      "        [0.0242],\n",
      "        [0.0523],\n",
      "        [0.0437],\n",
      "        [0.0060],\n",
      "        [0.0079],\n",
      "        [0.0529],\n",
      "        [0.0371],\n",
      "        [0.0294],\n",
      "        [0.0442],\n",
      "        [0.0765],\n",
      "        [0.0879],\n",
      "        [0.0902],\n",
      "        [0.0867],\n",
      "        [0.1034],\n",
      "        [0.0791],\n",
      "        [0.0234],\n",
      "        [0.0040],\n",
      "        [0.0192],\n",
      "        [0.0212],\n",
      "        [0.0009],\n",
      "        [0.0405],\n",
      "        [0.0821],\n",
      "        [0.0387],\n",
      "        [0.1582],\n",
      "        [0.1992],\n",
      "        [0.2142],\n",
      "        [0.1579],\n",
      "        [0.1461]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 94\n",
      "剩餘X 資料 torch.Size([283, 18])\n",
      "剩餘Y 資料 torch.Size([283, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7606])\n",
      "目前模型的Data狀態 torch.Size([94, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5272],\n",
      "        [0.5041],\n",
      "        [0.5314],\n",
      "        [0.5640],\n",
      "        [0.5638],\n",
      "        [0.5627],\n",
      "        [0.5552],\n",
      "        [0.5542],\n",
      "        [0.5427],\n",
      "        [0.5447],\n",
      "        [0.5397],\n",
      "        [0.5350],\n",
      "        [0.5276],\n",
      "        [0.5178],\n",
      "        [0.5542],\n",
      "        [0.5633],\n",
      "        [0.5575],\n",
      "        [0.5322],\n",
      "        [0.5820],\n",
      "        [0.8615],\n",
      "        [0.8795],\n",
      "        [0.9076],\n",
      "        [0.8584],\n",
      "        [0.8933],\n",
      "        [0.9013],\n",
      "        [0.8838],\n",
      "        [0.9186],\n",
      "        [0.9251],\n",
      "        [0.9567],\n",
      "        [0.9697],\n",
      "        [0.9932],\n",
      "        [0.9569],\n",
      "        [0.9484],\n",
      "        [0.9272],\n",
      "        [0.9180],\n",
      "        [0.9096],\n",
      "        [0.8572],\n",
      "        [0.8716],\n",
      "        [0.8808],\n",
      "        [0.8542],\n",
      "        [0.8415],\n",
      "        [0.8438],\n",
      "        [0.8560],\n",
      "        [0.8463],\n",
      "        [0.8560],\n",
      "        [0.8518],\n",
      "        [0.8301],\n",
      "        [0.8109],\n",
      "        [0.8312],\n",
      "        [0.8397],\n",
      "        [0.8122],\n",
      "        [0.8411],\n",
      "        [0.8681],\n",
      "        [0.8843],\n",
      "        [0.8787],\n",
      "        [0.8931],\n",
      "        [0.8888],\n",
      "        [0.8960],\n",
      "        [0.8865],\n",
      "        [0.8708],\n",
      "        [0.8878],\n",
      "        [0.8963],\n",
      "        [0.8857],\n",
      "        [0.8580],\n",
      "        [0.8517],\n",
      "        [0.8675],\n",
      "        [0.8820],\n",
      "        [0.8900],\n",
      "        [0.8464],\n",
      "        [0.8813],\n",
      "        [0.8450],\n",
      "        [0.8464],\n",
      "        [0.8380],\n",
      "        [0.8483],\n",
      "        [0.8331],\n",
      "        [0.8180],\n",
      "        [0.8298],\n",
      "        [0.8488],\n",
      "        [0.8560],\n",
      "        [0.8761],\n",
      "        [0.8969],\n",
      "        [0.8794],\n",
      "        [0.8809],\n",
      "        [0.8532],\n",
      "        [0.8366],\n",
      "        [0.8760],\n",
      "        [0.8757],\n",
      "        [0.8553],\n",
      "        [0.8620],\n",
      "        [0.8485],\n",
      "        [0.8726],\n",
      "        [0.9040],\n",
      "        [0.8916],\n",
      "        [0.8739]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0397],\n",
      "        [0.0224],\n",
      "        [0.0201],\n",
      "        [0.0002],\n",
      "        [0.0048],\n",
      "        [0.0017],\n",
      "        [0.0007],\n",
      "        [0.0062],\n",
      "        [0.0163],\n",
      "        [0.0041],\n",
      "        [0.0031],\n",
      "        [0.0010],\n",
      "        [0.0053],\n",
      "        [0.0052],\n",
      "        [0.0154],\n",
      "        [0.0220],\n",
      "        [0.0324],\n",
      "        [0.0394],\n",
      "        [0.0142],\n",
      "        [0.0576],\n",
      "        [0.0659],\n",
      "        [0.0654],\n",
      "        [0.0137],\n",
      "        [0.0356],\n",
      "        [0.0808],\n",
      "        [0.0909],\n",
      "        [0.0808],\n",
      "        [0.0516],\n",
      "        [0.0188],\n",
      "        [0.0230],\n",
      "        [0.0142],\n",
      "        [0.0404],\n",
      "        [0.0349],\n",
      "        [0.0528],\n",
      "        [0.0493],\n",
      "        [0.0342],\n",
      "        [0.0317],\n",
      "        [0.0425],\n",
      "        [0.0559],\n",
      "        [0.0617],\n",
      "        [0.0119],\n",
      "        [0.0110],\n",
      "        [0.0106],\n",
      "        [0.0534],\n",
      "        [0.0495],\n",
      "        [0.0203],\n",
      "        [0.0265],\n",
      "        [0.0383],\n",
      "        [0.0017],\n",
      "        [0.0099],\n",
      "        [0.0080],\n",
      "        [0.0317],\n",
      "        [0.0481],\n",
      "        [0.0699],\n",
      "        [0.0386],\n",
      "        [0.0506],\n",
      "        [0.0253],\n",
      "        [0.0570],\n",
      "        [0.1135],\n",
      "        [0.0976],\n",
      "        [0.0804],\n",
      "        [0.0707],\n",
      "        [0.0665],\n",
      "        [0.0438],\n",
      "        [0.1438],\n",
      "        [0.0242],\n",
      "        [0.0523],\n",
      "        [0.0437],\n",
      "        [0.0060],\n",
      "        [0.0079],\n",
      "        [0.0529],\n",
      "        [0.0371],\n",
      "        [0.0294],\n",
      "        [0.0442],\n",
      "        [0.0765],\n",
      "        [0.0879],\n",
      "        [0.0902],\n",
      "        [0.0867],\n",
      "        [0.1034],\n",
      "        [0.0791],\n",
      "        [0.0234],\n",
      "        [0.0040],\n",
      "        [0.0192],\n",
      "        [0.0212],\n",
      "        [0.0009],\n",
      "        [0.0405],\n",
      "        [0.0821],\n",
      "        [0.0387],\n",
      "        [0.1582],\n",
      "        [0.1992],\n",
      "        [0.2142],\n",
      "        [0.1579],\n",
      "        [0.1461],\n",
      "        [0.1133]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0437],\n",
      "        [    0.0268],\n",
      "        [    0.0231],\n",
      "        [    0.0003],\n",
      "        [    0.0092],\n",
      "        [    0.0062],\n",
      "        [    0.0036],\n",
      "        [    0.0103],\n",
      "        [    0.0201],\n",
      "        [    0.0077],\n",
      "        [    0.0063],\n",
      "        [    0.0038],\n",
      "        [    0.0025],\n",
      "        [    0.0018],\n",
      "        [    0.0142],\n",
      "        [    0.0254],\n",
      "        [    0.0367],\n",
      "        [    0.0378],\n",
      "        [    0.0182],\n",
      "        [    0.0634],\n",
      "        [    0.0722],\n",
      "        [    0.0722],\n",
      "        [    0.0198],\n",
      "        [    0.0303],\n",
      "        [    0.0761],\n",
      "        [    0.0864],\n",
      "        [    0.0762],\n",
      "        [    0.0471],\n",
      "        [    0.0136],\n",
      "        [    0.0170],\n",
      "        [    0.0208],\n",
      "        [    0.0328],\n",
      "        [    0.0274],\n",
      "        [    0.0452],\n",
      "        [    0.0419],\n",
      "        [    0.0260],\n",
      "        [    0.0231],\n",
      "        [    0.0346],\n",
      "        [    0.0480],\n",
      "        [    0.0539],\n",
      "        [    0.0045],\n",
      "        [    0.0051],\n",
      "        [    0.0165],\n",
      "        [    0.0596],\n",
      "        [    0.0552],\n",
      "        [    0.0252],\n",
      "        [    0.0313],\n",
      "        [    0.0333],\n",
      "        [    0.0065],\n",
      "        [    0.0049],\n",
      "        [    0.0128],\n",
      "        [    0.0361],\n",
      "        [    0.0516],\n",
      "        [    0.0730],\n",
      "        [    0.0407],\n",
      "        [    0.0522],\n",
      "        [    0.0267],\n",
      "        [    0.0553],\n",
      "        [    0.1111],\n",
      "        [    0.0948],\n",
      "        [    0.0775],\n",
      "        [    0.0666],\n",
      "        [    0.0614],\n",
      "        [    0.0367],\n",
      "        [    0.1514],\n",
      "        [    0.0322],\n",
      "        [    0.0595],\n",
      "        [    0.0514],\n",
      "        [    0.0001],\n",
      "        [    0.0019],\n",
      "        [    0.0464],\n",
      "        [    0.0315],\n",
      "        [    0.0244],\n",
      "        [    0.0391],\n",
      "        [    0.0710],\n",
      "        [    0.0821],\n",
      "        [    0.0845],\n",
      "        [    0.0814],\n",
      "        [    0.1006],\n",
      "        [    0.0774],\n",
      "        [    0.0221],\n",
      "        [    0.0029],\n",
      "        [    0.0201],\n",
      "        [    0.0204],\n",
      "        [    0.0006],\n",
      "        [    0.0405],\n",
      "        [    0.0811],\n",
      "        [    0.0366],\n",
      "        [    0.1544],\n",
      "        [    0.1922],\n",
      "        [    0.2054],\n",
      "        [    0.1480],\n",
      "        [    0.1350],\n",
      "        [    0.1005]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 95\n",
      "剩餘X 資料 torch.Size([282, 18])\n",
      "剩餘Y 資料 torch.Size([282, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7463])\n",
      "目前模型的Data狀態 torch.Size([95, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5233],\n",
      "        [0.4998],\n",
      "        [0.5284],\n",
      "        [0.5641],\n",
      "        [0.5682],\n",
      "        [0.5673],\n",
      "        [0.5594],\n",
      "        [0.5582],\n",
      "        [0.5466],\n",
      "        [0.5483],\n",
      "        [0.5430],\n",
      "        [0.5378],\n",
      "        [0.5304],\n",
      "        [0.5212],\n",
      "        [0.5553],\n",
      "        [0.5667],\n",
      "        [0.5618],\n",
      "        [0.5338],\n",
      "        [0.5859],\n",
      "        [0.8674],\n",
      "        [0.8858],\n",
      "        [0.9143],\n",
      "        [0.8645],\n",
      "        [0.8987],\n",
      "        [0.9060],\n",
      "        [0.8884],\n",
      "        [0.9232],\n",
      "        [0.9296],\n",
      "        [0.9620],\n",
      "        [0.9758],\n",
      "        [0.9998],\n",
      "        [0.9645],\n",
      "        [0.9560],\n",
      "        [0.9348],\n",
      "        [0.9255],\n",
      "        [0.9177],\n",
      "        [0.8659],\n",
      "        [0.8795],\n",
      "        [0.8886],\n",
      "        [0.8620],\n",
      "        [0.8488],\n",
      "        [0.8496],\n",
      "        [0.8619],\n",
      "        [0.8525],\n",
      "        [0.8617],\n",
      "        [0.8568],\n",
      "        [0.8350],\n",
      "        [0.8159],\n",
      "        [0.8360],\n",
      "        [0.8447],\n",
      "        [0.8171],\n",
      "        [0.8456],\n",
      "        [0.8716],\n",
      "        [0.8874],\n",
      "        [0.8807],\n",
      "        [0.8947],\n",
      "        [0.8902],\n",
      "        [0.8977],\n",
      "        [0.8889],\n",
      "        [0.8737],\n",
      "        [0.8907],\n",
      "        [0.9003],\n",
      "        [0.8907],\n",
      "        [0.8652],\n",
      "        [0.8593],\n",
      "        [0.8754],\n",
      "        [0.8892],\n",
      "        [0.8976],\n",
      "        [0.8526],\n",
      "        [0.8873],\n",
      "        [0.8515],\n",
      "        [0.8520],\n",
      "        [0.8430],\n",
      "        [0.8535],\n",
      "        [0.8386],\n",
      "        [0.8238],\n",
      "        [0.8355],\n",
      "        [0.8541],\n",
      "        [0.8588],\n",
      "        [0.8778],\n",
      "        [0.8982],\n",
      "        [0.8804],\n",
      "        [0.8818],\n",
      "        [0.8539],\n",
      "        [0.8362],\n",
      "        [0.8760],\n",
      "        [0.8747],\n",
      "        [0.8533],\n",
      "        [0.8583],\n",
      "        [0.8414],\n",
      "        [0.8638],\n",
      "        [0.8942],\n",
      "        [0.8805],\n",
      "        [0.8611],\n",
      "        [0.8386]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0437],\n",
      "        [    0.0268],\n",
      "        [    0.0231],\n",
      "        [    0.0003],\n",
      "        [    0.0092],\n",
      "        [    0.0062],\n",
      "        [    0.0036],\n",
      "        [    0.0103],\n",
      "        [    0.0201],\n",
      "        [    0.0077],\n",
      "        [    0.0063],\n",
      "        [    0.0038],\n",
      "        [    0.0025],\n",
      "        [    0.0018],\n",
      "        [    0.0142],\n",
      "        [    0.0254],\n",
      "        [    0.0367],\n",
      "        [    0.0378],\n",
      "        [    0.0182],\n",
      "        [    0.0634],\n",
      "        [    0.0722],\n",
      "        [    0.0722],\n",
      "        [    0.0198],\n",
      "        [    0.0303],\n",
      "        [    0.0761],\n",
      "        [    0.0864],\n",
      "        [    0.0762],\n",
      "        [    0.0471],\n",
      "        [    0.0136],\n",
      "        [    0.0170],\n",
      "        [    0.0208],\n",
      "        [    0.0328],\n",
      "        [    0.0274],\n",
      "        [    0.0452],\n",
      "        [    0.0419],\n",
      "        [    0.0260],\n",
      "        [    0.0231],\n",
      "        [    0.0346],\n",
      "        [    0.0480],\n",
      "        [    0.0539],\n",
      "        [    0.0045],\n",
      "        [    0.0051],\n",
      "        [    0.0165],\n",
      "        [    0.0596],\n",
      "        [    0.0552],\n",
      "        [    0.0252],\n",
      "        [    0.0313],\n",
      "        [    0.0333],\n",
      "        [    0.0065],\n",
      "        [    0.0049],\n",
      "        [    0.0128],\n",
      "        [    0.0361],\n",
      "        [    0.0516],\n",
      "        [    0.0730],\n",
      "        [    0.0407],\n",
      "        [    0.0522],\n",
      "        [    0.0267],\n",
      "        [    0.0553],\n",
      "        [    0.1111],\n",
      "        [    0.0948],\n",
      "        [    0.0775],\n",
      "        [    0.0666],\n",
      "        [    0.0614],\n",
      "        [    0.0367],\n",
      "        [    0.1514],\n",
      "        [    0.0322],\n",
      "        [    0.0595],\n",
      "        [    0.0514],\n",
      "        [    0.0001],\n",
      "        [    0.0019],\n",
      "        [    0.0464],\n",
      "        [    0.0315],\n",
      "        [    0.0244],\n",
      "        [    0.0391],\n",
      "        [    0.0710],\n",
      "        [    0.0821],\n",
      "        [    0.0845],\n",
      "        [    0.0814],\n",
      "        [    0.1006],\n",
      "        [    0.0774],\n",
      "        [    0.0221],\n",
      "        [    0.0029],\n",
      "        [    0.0201],\n",
      "        [    0.0204],\n",
      "        [    0.0006],\n",
      "        [    0.0405],\n",
      "        [    0.0811],\n",
      "        [    0.0366],\n",
      "        [    0.1544],\n",
      "        [    0.1922],\n",
      "        [    0.2054],\n",
      "        [    0.1480],\n",
      "        [    0.1350],\n",
      "        [    0.1005],\n",
      "        [    0.0923]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0514],\n",
      "        [0.0347],\n",
      "        [0.0297],\n",
      "        [0.0034],\n",
      "        [0.0094],\n",
      "        [0.0066],\n",
      "        [0.0037],\n",
      "        [0.0102],\n",
      "        [0.0199],\n",
      "        [0.0074],\n",
      "        [0.0057],\n",
      "        [0.0029],\n",
      "        [0.0032],\n",
      "        [0.0021],\n",
      "        [0.0158],\n",
      "        [0.0259],\n",
      "        [0.0379],\n",
      "        [0.0391],\n",
      "        [0.0182],\n",
      "        [0.0638],\n",
      "        [0.0732],\n",
      "        [0.0739],\n",
      "        [0.0210],\n",
      "        [0.0297],\n",
      "        [0.0762],\n",
      "        [0.0862],\n",
      "        [0.0758],\n",
      "        [0.0467],\n",
      "        [0.0125],\n",
      "        [0.0153],\n",
      "        [0.0228],\n",
      "        [0.0302],\n",
      "        [0.0249],\n",
      "        [0.0428],\n",
      "        [0.0395],\n",
      "        [0.0232],\n",
      "        [0.0201],\n",
      "        [0.0319],\n",
      "        [0.0454],\n",
      "        [0.0514],\n",
      "        [0.0024],\n",
      "        [0.0043],\n",
      "        [0.0175],\n",
      "        [0.0610],\n",
      "        [0.0562],\n",
      "        [0.0256],\n",
      "        [0.0318],\n",
      "        [0.0326],\n",
      "        [0.0072],\n",
      "        [0.0038],\n",
      "        [0.0137],\n",
      "        [0.0367],\n",
      "        [0.0515],\n",
      "        [0.0726],\n",
      "        [0.0393],\n",
      "        [0.0505],\n",
      "        [0.0248],\n",
      "        [0.0568],\n",
      "        [0.1121],\n",
      "        [0.0956],\n",
      "        [0.0780],\n",
      "        [0.0663],\n",
      "        [0.0603],\n",
      "        [0.0340],\n",
      "        [0.1541],\n",
      "        [0.0351],\n",
      "        [0.0620],\n",
      "        [0.0542],\n",
      "        [0.0015],\n",
      "        [0.0002],\n",
      "        [0.0442],\n",
      "        [0.0300],\n",
      "        [0.0235],\n",
      "        [0.0382],\n",
      "        [0.0701],\n",
      "        [0.0810],\n",
      "        [0.0834],\n",
      "        [0.0808],\n",
      "        [0.1021],\n",
      "        [0.0798],\n",
      "        [0.0248],\n",
      "        [0.0060],\n",
      "        [0.0169],\n",
      "        [0.0240],\n",
      "        [0.0041],\n",
      "        [0.0362],\n",
      "        [0.0758],\n",
      "        [0.0305],\n",
      "        [0.1469],\n",
      "        [0.1817],\n",
      "        [0.1933],\n",
      "        [0.1352],\n",
      "        [0.1210],\n",
      "        [0.0849],\n",
      "        [0.0763]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 96\n",
      "剩餘X 資料 torch.Size([281, 18])\n",
      "剩餘Y 資料 torch.Size([281, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7586])\n",
      "目前模型的Data狀態 torch.Size([96, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5155],\n",
      "        [0.4918],\n",
      "        [0.5217],\n",
      "        [0.5603],\n",
      "        [0.5684],\n",
      "        [0.5677],\n",
      "        [0.5595],\n",
      "        [0.5582],\n",
      "        [0.5463],\n",
      "        [0.5479],\n",
      "        [0.5424],\n",
      "        [0.5369],\n",
      "        [0.5297],\n",
      "        [0.5209],\n",
      "        [0.5538],\n",
      "        [0.5672],\n",
      "        [0.5629],\n",
      "        [0.5325],\n",
      "        [0.5860],\n",
      "        [0.8678],\n",
      "        [0.8868],\n",
      "        [0.9160],\n",
      "        [0.8657],\n",
      "        [0.8993],\n",
      "        [0.9059],\n",
      "        [0.8885],\n",
      "        [0.9236],\n",
      "        [0.9300],\n",
      "        [0.9630],\n",
      "        [0.9774],\n",
      "        [1.0018],\n",
      "        [0.9670],\n",
      "        [0.9584],\n",
      "        [0.9372],\n",
      "        [0.9279],\n",
      "        [0.9206],\n",
      "        [0.8689],\n",
      "        [0.8822],\n",
      "        [0.8912],\n",
      "        [0.8645],\n",
      "        [0.8509],\n",
      "        [0.8505],\n",
      "        [0.8630],\n",
      "        [0.8539],\n",
      "        [0.8627],\n",
      "        [0.8571],\n",
      "        [0.8355],\n",
      "        [0.8166],\n",
      "        [0.8367],\n",
      "        [0.8457],\n",
      "        [0.8179],\n",
      "        [0.8461],\n",
      "        [0.8715],\n",
      "        [0.8871],\n",
      "        [0.8793],\n",
      "        [0.8930],\n",
      "        [0.8883],\n",
      "        [0.8961],\n",
      "        [0.8879],\n",
      "        [0.8729],\n",
      "        [0.8902],\n",
      "        [0.9006],\n",
      "        [0.8918],\n",
      "        [0.8679],\n",
      "        [0.8620],\n",
      "        [0.8784],\n",
      "        [0.8917],\n",
      "        [0.9005],\n",
      "        [0.8539],\n",
      "        [0.8890],\n",
      "        [0.8537],\n",
      "        [0.8535],\n",
      "        [0.8439],\n",
      "        [0.8544],\n",
      "        [0.8395],\n",
      "        [0.8249],\n",
      "        [0.8365],\n",
      "        [0.8547],\n",
      "        [0.8573],\n",
      "        [0.8754],\n",
      "        [0.8955],\n",
      "        [0.8774],\n",
      "        [0.8786],\n",
      "        [0.8504],\n",
      "        [0.8315],\n",
      "        [0.8716],\n",
      "        [0.8694],\n",
      "        [0.8471],\n",
      "        [0.8507],\n",
      "        [0.8309],\n",
      "        [0.8518],\n",
      "        [0.8813],\n",
      "        [0.8665],\n",
      "        [0.8455],\n",
      "        [0.8226],\n",
      "        [0.7595]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0514],\n",
      "        [0.0347],\n",
      "        [0.0297],\n",
      "        [0.0034],\n",
      "        [0.0094],\n",
      "        [0.0066],\n",
      "        [0.0037],\n",
      "        [0.0102],\n",
      "        [0.0199],\n",
      "        [0.0074],\n",
      "        [0.0057],\n",
      "        [0.0029],\n",
      "        [0.0032],\n",
      "        [0.0021],\n",
      "        [0.0158],\n",
      "        [0.0259],\n",
      "        [0.0379],\n",
      "        [0.0391],\n",
      "        [0.0182],\n",
      "        [0.0638],\n",
      "        [0.0732],\n",
      "        [0.0739],\n",
      "        [0.0210],\n",
      "        [0.0297],\n",
      "        [0.0762],\n",
      "        [0.0862],\n",
      "        [0.0758],\n",
      "        [0.0467],\n",
      "        [0.0125],\n",
      "        [0.0153],\n",
      "        [0.0228],\n",
      "        [0.0302],\n",
      "        [0.0249],\n",
      "        [0.0428],\n",
      "        [0.0395],\n",
      "        [0.0232],\n",
      "        [0.0201],\n",
      "        [0.0319],\n",
      "        [0.0454],\n",
      "        [0.0514],\n",
      "        [0.0024],\n",
      "        [0.0043],\n",
      "        [0.0175],\n",
      "        [0.0610],\n",
      "        [0.0562],\n",
      "        [0.0256],\n",
      "        [0.0318],\n",
      "        [0.0326],\n",
      "        [0.0072],\n",
      "        [0.0038],\n",
      "        [0.0137],\n",
      "        [0.0367],\n",
      "        [0.0515],\n",
      "        [0.0726],\n",
      "        [0.0393],\n",
      "        [0.0505],\n",
      "        [0.0248],\n",
      "        [0.0568],\n",
      "        [0.1121],\n",
      "        [0.0956],\n",
      "        [0.0780],\n",
      "        [0.0663],\n",
      "        [0.0603],\n",
      "        [0.0340],\n",
      "        [0.1541],\n",
      "        [0.0351],\n",
      "        [0.0620],\n",
      "        [0.0542],\n",
      "        [0.0015],\n",
      "        [0.0002],\n",
      "        [0.0442],\n",
      "        [0.0300],\n",
      "        [0.0235],\n",
      "        [0.0382],\n",
      "        [0.0701],\n",
      "        [0.0810],\n",
      "        [0.0834],\n",
      "        [0.0808],\n",
      "        [0.1021],\n",
      "        [0.0798],\n",
      "        [0.0248],\n",
      "        [0.0060],\n",
      "        [0.0169],\n",
      "        [0.0240],\n",
      "        [0.0041],\n",
      "        [0.0362],\n",
      "        [0.0758],\n",
      "        [0.0305],\n",
      "        [0.1469],\n",
      "        [0.1817],\n",
      "        [0.1933],\n",
      "        [0.1352],\n",
      "        [0.1210],\n",
      "        [0.0849],\n",
      "        [0.0763],\n",
      "        [0.0009]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0579],\n",
      "        [0.0411],\n",
      "        [0.0347],\n",
      "        [0.0061],\n",
      "        [0.0100],\n",
      "        [0.0074],\n",
      "        [0.0041],\n",
      "        [0.0104],\n",
      "        [0.0200],\n",
      "        [0.0075],\n",
      "        [0.0057],\n",
      "        [0.0027],\n",
      "        [0.0033],\n",
      "        [0.0018],\n",
      "        [0.0165],\n",
      "        [0.0269],\n",
      "        [0.0392],\n",
      "        [0.0397],\n",
      "        [0.0178],\n",
      "        [0.0643],\n",
      "        [0.0745],\n",
      "        [0.0761],\n",
      "        [0.0225],\n",
      "        [0.0284],\n",
      "        [0.0754],\n",
      "        [0.0850],\n",
      "        [0.0741],\n",
      "        [0.0449],\n",
      "        [0.0101],\n",
      "        [0.0126],\n",
      "        [0.0257],\n",
      "        [0.0273],\n",
      "        [0.0222],\n",
      "        [0.0402],\n",
      "        [0.0368],\n",
      "        [0.0203],\n",
      "        [0.0176],\n",
      "        [0.0294],\n",
      "        [0.0428],\n",
      "        [0.0489],\n",
      "        [0.0003],\n",
      "        [0.0030],\n",
      "        [0.0192],\n",
      "        [0.0629],\n",
      "        [0.0578],\n",
      "        [0.0269],\n",
      "        [0.0333],\n",
      "        [0.0309],\n",
      "        [0.0090],\n",
      "        [0.0016],\n",
      "        [0.0156],\n",
      "        [0.0385],\n",
      "        [0.0531],\n",
      "        [0.0741],\n",
      "        [0.0397],\n",
      "        [0.0508],\n",
      "        [0.0249],\n",
      "        [0.0562],\n",
      "        [0.1112],\n",
      "        [0.0946],\n",
      "        [0.0767],\n",
      "        [0.0643],\n",
      "        [0.0579],\n",
      "        [0.0307],\n",
      "        [0.1570],\n",
      "        [0.0383],\n",
      "        [0.0649],\n",
      "        [0.0574],\n",
      "        [0.0034],\n",
      "        [0.0025],\n",
      "        [0.0410],\n",
      "        [0.0273],\n",
      "        [0.0216],\n",
      "        [0.0362],\n",
      "        [0.0683],\n",
      "        [0.0793],\n",
      "        [0.0818],\n",
      "        [0.0794],\n",
      "        [0.1024],\n",
      "        [0.0806],\n",
      "        [0.0258],\n",
      "        [0.0074],\n",
      "        [0.0153],\n",
      "        [0.0262],\n",
      "        [0.0076],\n",
      "        [0.0331],\n",
      "        [0.0720],\n",
      "        [0.0260],\n",
      "        [0.1414],\n",
      "        [0.1737],\n",
      "        [0.1840],\n",
      "        [0.1255],\n",
      "        [0.1103],\n",
      "        [0.0730],\n",
      "        [0.0639],\n",
      "        [0.0124]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 97\n",
      "剩餘X 資料 torch.Size([280, 18])\n",
      "剩餘Y 資料 torch.Size([280, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7218])\n",
      "目前模型的Data狀態 torch.Size([97, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5090],\n",
      "        [0.4854],\n",
      "        [0.5167],\n",
      "        [0.5576],\n",
      "        [0.5690],\n",
      "        [0.5685],\n",
      "        [0.5600],\n",
      "        [0.5584],\n",
      "        [0.5464],\n",
      "        [0.5480],\n",
      "        [0.5424],\n",
      "        [0.5367],\n",
      "        [0.5297],\n",
      "        [0.5212],\n",
      "        [0.5531],\n",
      "        [0.5682],\n",
      "        [0.5643],\n",
      "        [0.5319],\n",
      "        [0.5856],\n",
      "        [0.8683],\n",
      "        [0.8881],\n",
      "        [0.9183],\n",
      "        [0.8672],\n",
      "        [0.9005],\n",
      "        [0.9068],\n",
      "        [0.8897],\n",
      "        [0.9254],\n",
      "        [0.9318],\n",
      "        [0.9654],\n",
      "        [0.9801],\n",
      "        [1.0048],\n",
      "        [0.9699],\n",
      "        [0.9612],\n",
      "        [0.9398],\n",
      "        [0.9305],\n",
      "        [0.9235],\n",
      "        [0.8714],\n",
      "        [0.8847],\n",
      "        [0.8938],\n",
      "        [0.8671],\n",
      "        [0.8531],\n",
      "        [0.8518],\n",
      "        [0.8646],\n",
      "        [0.8558],\n",
      "        [0.8644],\n",
      "        [0.8584],\n",
      "        [0.8369],\n",
      "        [0.8183],\n",
      "        [0.8385],\n",
      "        [0.8480],\n",
      "        [0.8199],\n",
      "        [0.8479],\n",
      "        [0.8731],\n",
      "        [0.8886],\n",
      "        [0.8797],\n",
      "        [0.8934],\n",
      "        [0.8885],\n",
      "        [0.8968],\n",
      "        [0.8888],\n",
      "        [0.8739],\n",
      "        [0.8915],\n",
      "        [0.9026],\n",
      "        [0.8942],\n",
      "        [0.8711],\n",
      "        [0.8649],\n",
      "        [0.8816],\n",
      "        [0.8946],\n",
      "        [0.9037],\n",
      "        [0.8558],\n",
      "        [0.8917],\n",
      "        [0.8568],\n",
      "        [0.8561],\n",
      "        [0.8458],\n",
      "        [0.8564],\n",
      "        [0.8413],\n",
      "        [0.8266],\n",
      "        [0.8382],\n",
      "        [0.8560],\n",
      "        [0.8570],\n",
      "        [0.8746],\n",
      "        [0.8945],\n",
      "        [0.8759],\n",
      "        [0.8770],\n",
      "        [0.8482],\n",
      "        [0.8280],\n",
      "        [0.8686],\n",
      "        [0.8656],\n",
      "        [0.8427],\n",
      "        [0.8452],\n",
      "        [0.8229],\n",
      "        [0.8425],\n",
      "        [0.8716],\n",
      "        [0.8558],\n",
      "        [0.8336],\n",
      "        [0.8102],\n",
      "        [0.7462],\n",
      "        [0.7584]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0579],\n",
      "        [0.0411],\n",
      "        [0.0347],\n",
      "        [0.0061],\n",
      "        [0.0100],\n",
      "        [0.0074],\n",
      "        [0.0041],\n",
      "        [0.0104],\n",
      "        [0.0200],\n",
      "        [0.0075],\n",
      "        [0.0057],\n",
      "        [0.0027],\n",
      "        [0.0033],\n",
      "        [0.0018],\n",
      "        [0.0165],\n",
      "        [0.0269],\n",
      "        [0.0392],\n",
      "        [0.0397],\n",
      "        [0.0178],\n",
      "        [0.0643],\n",
      "        [0.0745],\n",
      "        [0.0761],\n",
      "        [0.0225],\n",
      "        [0.0284],\n",
      "        [0.0754],\n",
      "        [0.0850],\n",
      "        [0.0741],\n",
      "        [0.0449],\n",
      "        [0.0101],\n",
      "        [0.0126],\n",
      "        [0.0257],\n",
      "        [0.0273],\n",
      "        [0.0222],\n",
      "        [0.0402],\n",
      "        [0.0368],\n",
      "        [0.0203],\n",
      "        [0.0176],\n",
      "        [0.0294],\n",
      "        [0.0428],\n",
      "        [0.0489],\n",
      "        [0.0003],\n",
      "        [0.0030],\n",
      "        [0.0192],\n",
      "        [0.0629],\n",
      "        [0.0578],\n",
      "        [0.0269],\n",
      "        [0.0333],\n",
      "        [0.0309],\n",
      "        [0.0090],\n",
      "        [0.0016],\n",
      "        [0.0156],\n",
      "        [0.0385],\n",
      "        [0.0531],\n",
      "        [0.0741],\n",
      "        [0.0397],\n",
      "        [0.0508],\n",
      "        [0.0249],\n",
      "        [0.0562],\n",
      "        [0.1112],\n",
      "        [0.0946],\n",
      "        [0.0767],\n",
      "        [0.0643],\n",
      "        [0.0579],\n",
      "        [0.0307],\n",
      "        [0.1570],\n",
      "        [0.0383],\n",
      "        [0.0649],\n",
      "        [0.0574],\n",
      "        [0.0034],\n",
      "        [0.0025],\n",
      "        [0.0410],\n",
      "        [0.0273],\n",
      "        [0.0216],\n",
      "        [0.0362],\n",
      "        [0.0683],\n",
      "        [0.0793],\n",
      "        [0.0818],\n",
      "        [0.0794],\n",
      "        [0.1024],\n",
      "        [0.0806],\n",
      "        [0.0258],\n",
      "        [0.0074],\n",
      "        [0.0153],\n",
      "        [0.0262],\n",
      "        [0.0076],\n",
      "        [0.0331],\n",
      "        [0.0720],\n",
      "        [0.0260],\n",
      "        [0.1414],\n",
      "        [0.1737],\n",
      "        [0.1840],\n",
      "        [0.1255],\n",
      "        [0.1103],\n",
      "        [0.0730],\n",
      "        [0.0639],\n",
      "        [0.0124],\n",
      "        [0.0366]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0639],\n",
      "        [0.0467],\n",
      "        [0.0389],\n",
      "        [0.0085],\n",
      "        [0.0107],\n",
      "        [0.0083],\n",
      "        [0.0046],\n",
      "        [0.0107],\n",
      "        [0.0201],\n",
      "        [0.0077],\n",
      "        [0.0060],\n",
      "        [0.0028],\n",
      "        [0.0030],\n",
      "        [0.0013],\n",
      "        [0.0172],\n",
      "        [0.0277],\n",
      "        [0.0403],\n",
      "        [0.0402],\n",
      "        [0.0168],\n",
      "        [0.0640],\n",
      "        [0.0750],\n",
      "        [0.0776],\n",
      "        [0.0234],\n",
      "        [0.0278],\n",
      "        [0.0750],\n",
      "        [0.0842],\n",
      "        [0.0726],\n",
      "        [0.0434],\n",
      "        [0.0082],\n",
      "        [0.0105],\n",
      "        [0.0280],\n",
      "        [0.0253],\n",
      "        [0.0203],\n",
      "        [0.0385],\n",
      "        [0.0350],\n",
      "        [0.0183],\n",
      "        [0.0162],\n",
      "        [0.0278],\n",
      "        [0.0411],\n",
      "        [0.0472],\n",
      "        [0.0011],\n",
      "        [0.0023],\n",
      "        [0.0203],\n",
      "        [0.0643],\n",
      "        [0.0590],\n",
      "        [0.0278],\n",
      "        [0.0344],\n",
      "        [0.0295],\n",
      "        [0.0106],\n",
      "        [0.0004],\n",
      "        [0.0173],\n",
      "        [0.0401],\n",
      "        [0.0546],\n",
      "        [0.0757],\n",
      "        [0.0402],\n",
      "        [0.0514],\n",
      "        [0.0252],\n",
      "        [0.0555],\n",
      "        [0.1102],\n",
      "        [0.0937],\n",
      "        [0.0753],\n",
      "        [0.0625],\n",
      "        [0.0559],\n",
      "        [0.0281],\n",
      "        [0.1592],\n",
      "        [0.0407],\n",
      "        [0.0671],\n",
      "        [0.0599],\n",
      "        [0.0048],\n",
      "        [0.0050],\n",
      "        [0.0381],\n",
      "        [0.0249],\n",
      "        [0.0200],\n",
      "        [0.0345],\n",
      "        [0.0669],\n",
      "        [0.0781],\n",
      "        [0.0806],\n",
      "        [0.0785],\n",
      "        [0.1029],\n",
      "        [0.0816],\n",
      "        [0.0269],\n",
      "        [0.0089],\n",
      "        [0.0136],\n",
      "        [0.0286],\n",
      "        [0.0113],\n",
      "        [0.0298],\n",
      "        [0.0681],\n",
      "        [0.0216],\n",
      "        [0.1360],\n",
      "        [0.1660],\n",
      "        [0.1753],\n",
      "        [0.1165],\n",
      "        [0.1002],\n",
      "        [0.0621],\n",
      "        [0.0527],\n",
      "        [0.0245],\n",
      "        [0.0247]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 98\n",
      "剩餘X 資料 torch.Size([279, 18])\n",
      "剩餘Y 資料 torch.Size([279, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6630])\n",
      "目前模型的Data狀態 torch.Size([98, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5030],\n",
      "        [0.4798],\n",
      "        [0.5125],\n",
      "        [0.5553],\n",
      "        [0.5697],\n",
      "        [0.5693],\n",
      "        [0.5604],\n",
      "        [0.5586],\n",
      "        [0.5465],\n",
      "        [0.5483],\n",
      "        [0.5426],\n",
      "        [0.5368],\n",
      "        [0.5299],\n",
      "        [0.5218],\n",
      "        [0.5524],\n",
      "        [0.5690],\n",
      "        [0.5654],\n",
      "        [0.5314],\n",
      "        [0.5846],\n",
      "        [0.8679],\n",
      "        [0.8885],\n",
      "        [0.9197],\n",
      "        [0.8681],\n",
      "        [0.9012],\n",
      "        [0.9071],\n",
      "        [0.8905],\n",
      "        [0.9268],\n",
      "        [0.9333],\n",
      "        [0.9673],\n",
      "        [0.9822],\n",
      "        [1.0071],\n",
      "        [0.9720],\n",
      "        [0.9631],\n",
      "        [0.9415],\n",
      "        [0.9324],\n",
      "        [0.9254],\n",
      "        [0.8728],\n",
      "        [0.8863],\n",
      "        [0.8955],\n",
      "        [0.8687],\n",
      "        [0.8545],\n",
      "        [0.8525],\n",
      "        [0.8657],\n",
      "        [0.8571],\n",
      "        [0.8655],\n",
      "        [0.8593],\n",
      "        [0.8381],\n",
      "        [0.8196],\n",
      "        [0.8401],\n",
      "        [0.8500],\n",
      "        [0.8216],\n",
      "        [0.8496],\n",
      "        [0.8746],\n",
      "        [0.8902],\n",
      "        [0.8802],\n",
      "        [0.8939],\n",
      "        [0.8888],\n",
      "        [0.8975],\n",
      "        [0.8898],\n",
      "        [0.8748],\n",
      "        [0.8928],\n",
      "        [0.9045],\n",
      "        [0.8963],\n",
      "        [0.8738],\n",
      "        [0.8671],\n",
      "        [0.8840],\n",
      "        [0.8968],\n",
      "        [0.9062],\n",
      "        [0.8572],\n",
      "        [0.8942],\n",
      "        [0.8597],\n",
      "        [0.8586],\n",
      "        [0.8475],\n",
      "        [0.8581],\n",
      "        [0.8427],\n",
      "        [0.8278],\n",
      "        [0.8393],\n",
      "        [0.8570],\n",
      "        [0.8565],\n",
      "        [0.8737],\n",
      "        [0.8934],\n",
      "        [0.8744],\n",
      "        [0.8753],\n",
      "        [0.8458],\n",
      "        [0.8243],\n",
      "        [0.8653],\n",
      "        [0.8617],\n",
      "        [0.8382],\n",
      "        [0.8399],\n",
      "        [0.8152],\n",
      "        [0.8337],\n",
      "        [0.8626],\n",
      "        [0.8458],\n",
      "        [0.8227],\n",
      "        [0.7990],\n",
      "        [0.7341],\n",
      "        [0.7465],\n",
      "        [0.7383]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0639],\n",
      "        [0.0467],\n",
      "        [0.0389],\n",
      "        [0.0085],\n",
      "        [0.0107],\n",
      "        [0.0083],\n",
      "        [0.0046],\n",
      "        [0.0107],\n",
      "        [0.0201],\n",
      "        [0.0077],\n",
      "        [0.0060],\n",
      "        [0.0028],\n",
      "        [0.0030],\n",
      "        [0.0013],\n",
      "        [0.0172],\n",
      "        [0.0277],\n",
      "        [0.0403],\n",
      "        [0.0402],\n",
      "        [0.0168],\n",
      "        [0.0640],\n",
      "        [0.0750],\n",
      "        [0.0776],\n",
      "        [0.0234],\n",
      "        [0.0278],\n",
      "        [0.0750],\n",
      "        [0.0842],\n",
      "        [0.0726],\n",
      "        [0.0434],\n",
      "        [0.0082],\n",
      "        [0.0105],\n",
      "        [0.0280],\n",
      "        [0.0253],\n",
      "        [0.0203],\n",
      "        [0.0385],\n",
      "        [0.0350],\n",
      "        [0.0183],\n",
      "        [0.0162],\n",
      "        [0.0278],\n",
      "        [0.0411],\n",
      "        [0.0472],\n",
      "        [0.0011],\n",
      "        [0.0023],\n",
      "        [0.0203],\n",
      "        [0.0643],\n",
      "        [0.0590],\n",
      "        [0.0278],\n",
      "        [0.0344],\n",
      "        [0.0295],\n",
      "        [0.0106],\n",
      "        [0.0004],\n",
      "        [0.0173],\n",
      "        [0.0401],\n",
      "        [0.0546],\n",
      "        [0.0757],\n",
      "        [0.0402],\n",
      "        [0.0514],\n",
      "        [0.0252],\n",
      "        [0.0555],\n",
      "        [0.1102],\n",
      "        [0.0937],\n",
      "        [0.0753],\n",
      "        [0.0625],\n",
      "        [0.0559],\n",
      "        [0.0281],\n",
      "        [0.1592],\n",
      "        [0.0407],\n",
      "        [0.0671],\n",
      "        [0.0599],\n",
      "        [0.0048],\n",
      "        [0.0050],\n",
      "        [0.0381],\n",
      "        [0.0249],\n",
      "        [0.0200],\n",
      "        [0.0345],\n",
      "        [0.0669],\n",
      "        [0.0781],\n",
      "        [0.0806],\n",
      "        [0.0785],\n",
      "        [0.1029],\n",
      "        [0.0816],\n",
      "        [0.0269],\n",
      "        [0.0089],\n",
      "        [0.0136],\n",
      "        [0.0286],\n",
      "        [0.0113],\n",
      "        [0.0298],\n",
      "        [0.0681],\n",
      "        [0.0216],\n",
      "        [0.1360],\n",
      "        [0.1660],\n",
      "        [0.1753],\n",
      "        [0.1165],\n",
      "        [0.1002],\n",
      "        [0.0621],\n",
      "        [0.0527],\n",
      "        [0.0245],\n",
      "        [0.0247],\n",
      "        [0.0753]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0706],\n",
      "        [0.0527],\n",
      "        [0.0435],\n",
      "        [0.0115],\n",
      "        [0.0108],\n",
      "        [0.0085],\n",
      "        [0.0044],\n",
      "        [0.0103],\n",
      "        [0.0195],\n",
      "        [0.0073],\n",
      "        [0.0055],\n",
      "        [0.0022],\n",
      "        [0.0035],\n",
      "        [0.0014],\n",
      "        [0.0192],\n",
      "        [0.0270],\n",
      "        [0.0400],\n",
      "        [0.0419],\n",
      "        [0.0148],\n",
      "        [0.0622],\n",
      "        [0.0740],\n",
      "        [0.0775],\n",
      "        [0.0227],\n",
      "        [0.0286],\n",
      "        [0.0761],\n",
      "        [0.0849],\n",
      "        [0.0727],\n",
      "        [0.0435],\n",
      "        [0.0078],\n",
      "        [0.0100],\n",
      "        [0.0286],\n",
      "        [0.0248],\n",
      "        [0.0199],\n",
      "        [0.0383],\n",
      "        [0.0347],\n",
      "        [0.0179],\n",
      "        [0.0162],\n",
      "        [0.0276],\n",
      "        [0.0408],\n",
      "        [0.0469],\n",
      "        [0.0012],\n",
      "        [0.0028],\n",
      "        [0.0200],\n",
      "        [0.0642],\n",
      "        [0.0588],\n",
      "        [0.0275],\n",
      "        [0.0343],\n",
      "        [0.0295],\n",
      "        [0.0108],\n",
      "        [0.0011],\n",
      "        [0.0176],\n",
      "        [0.0403],\n",
      "        [0.0546],\n",
      "        [0.0757],\n",
      "        [0.0392],\n",
      "        [0.0504],\n",
      "        [0.0241],\n",
      "        [0.0563],\n",
      "        [0.1107],\n",
      "        [0.0942],\n",
      "        [0.0755],\n",
      "        [0.0622],\n",
      "        [0.0554],\n",
      "        [0.0271],\n",
      "        [0.1598],\n",
      "        [0.0416],\n",
      "        [0.0679],\n",
      "        [0.0609],\n",
      "        [0.0047],\n",
      "        [0.0061],\n",
      "        [0.0366],\n",
      "        [0.0240],\n",
      "        [0.0198],\n",
      "        [0.0344],\n",
      "        [0.0669],\n",
      "        [0.0783],\n",
      "        [0.0809],\n",
      "        [0.0789],\n",
      "        [0.1047],\n",
      "        [0.0839],\n",
      "        [0.0294],\n",
      "        [0.0118],\n",
      "        [0.0105],\n",
      "        [0.0323],\n",
      "        [0.0162],\n",
      "        [0.0253],\n",
      "        [0.0630],\n",
      "        [0.0159],\n",
      "        [0.1294],\n",
      "        [0.1571],\n",
      "        [0.1652],\n",
      "        [0.1061],\n",
      "        [0.0889],\n",
      "        [0.0500],\n",
      "        [0.0403],\n",
      "        [0.0377],\n",
      "        [0.0116],\n",
      "        [0.0622]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 99\n",
      "剩餘X 資料 torch.Size([278, 18])\n",
      "剩餘Y 資料 torch.Size([278, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4611])\n",
      "目前模型的Data狀態 torch.Size([99, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.4963],\n",
      "        [0.4738],\n",
      "        [0.5079],\n",
      "        [0.5522],\n",
      "        [0.5698],\n",
      "        [0.5695],\n",
      "        [0.5603],\n",
      "        [0.5583],\n",
      "        [0.5460],\n",
      "        [0.5478],\n",
      "        [0.5421],\n",
      "        [0.5362],\n",
      "        [0.5294],\n",
      "        [0.5216],\n",
      "        [0.5503],\n",
      "        [0.5683],\n",
      "        [0.5651],\n",
      "        [0.5297],\n",
      "        [0.5825],\n",
      "        [0.8661],\n",
      "        [0.8875],\n",
      "        [0.9196],\n",
      "        [0.8674],\n",
      "        [0.9004],\n",
      "        [0.9061],\n",
      "        [0.8899],\n",
      "        [0.9267],\n",
      "        [0.9332],\n",
      "        [0.9677],\n",
      "        [0.9827],\n",
      "        [1.0077],\n",
      "        [0.9725],\n",
      "        [0.9634],\n",
      "        [0.9417],\n",
      "        [0.9326],\n",
      "        [0.9259],\n",
      "        [0.8727],\n",
      "        [0.8865],\n",
      "        [0.8958],\n",
      "        [0.8690],\n",
      "        [0.8545],\n",
      "        [0.8519],\n",
      "        [0.8654],\n",
      "        [0.8571],\n",
      "        [0.8653],\n",
      "        [0.8590],\n",
      "        [0.8380],\n",
      "        [0.8197],\n",
      "        [0.8404],\n",
      "        [0.8507],\n",
      "        [0.8218],\n",
      "        [0.8498],\n",
      "        [0.8746],\n",
      "        [0.8902],\n",
      "        [0.8793],\n",
      "        [0.8929],\n",
      "        [0.8876],\n",
      "        [0.8967],\n",
      "        [0.8893],\n",
      "        [0.8742],\n",
      "        [0.8926],\n",
      "        [0.9048],\n",
      "        [0.8967],\n",
      "        [0.8748],\n",
      "        [0.8678],\n",
      "        [0.8849],\n",
      "        [0.8975],\n",
      "        [0.9071],\n",
      "        [0.8571],\n",
      "        [0.8953],\n",
      "        [0.8612],\n",
      "        [0.8595],\n",
      "        [0.8476],\n",
      "        [0.8582],\n",
      "        [0.8427],\n",
      "        [0.8276],\n",
      "        [0.8391],\n",
      "        [0.8566],\n",
      "        [0.8547],\n",
      "        [0.8714],\n",
      "        [0.8909],\n",
      "        [0.8715],\n",
      "        [0.8722],\n",
      "        [0.8421],\n",
      "        [0.8194],\n",
      "        [0.8608],\n",
      "        [0.8566],\n",
      "        [0.8326],\n",
      "        [0.8332],\n",
      "        [0.8063],\n",
      "        [0.8237],\n",
      "        [0.8522],\n",
      "        [0.8344],\n",
      "        [0.8106],\n",
      "        [0.7866],\n",
      "        [0.7209],\n",
      "        [0.7334],\n",
      "        [0.7252],\n",
      "        [0.7554]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0706],\n",
      "        [0.0527],\n",
      "        [0.0435],\n",
      "        [0.0115],\n",
      "        [0.0108],\n",
      "        [0.0085],\n",
      "        [0.0044],\n",
      "        [0.0103],\n",
      "        [0.0195],\n",
      "        [0.0073],\n",
      "        [0.0055],\n",
      "        [0.0022],\n",
      "        [0.0035],\n",
      "        [0.0014],\n",
      "        [0.0192],\n",
      "        [0.0270],\n",
      "        [0.0400],\n",
      "        [0.0419],\n",
      "        [0.0148],\n",
      "        [0.0622],\n",
      "        [0.0740],\n",
      "        [0.0775],\n",
      "        [0.0227],\n",
      "        [0.0286],\n",
      "        [0.0761],\n",
      "        [0.0849],\n",
      "        [0.0727],\n",
      "        [0.0435],\n",
      "        [0.0078],\n",
      "        [0.0100],\n",
      "        [0.0286],\n",
      "        [0.0248],\n",
      "        [0.0199],\n",
      "        [0.0383],\n",
      "        [0.0347],\n",
      "        [0.0179],\n",
      "        [0.0162],\n",
      "        [0.0276],\n",
      "        [0.0408],\n",
      "        [0.0469],\n",
      "        [0.0012],\n",
      "        [0.0028],\n",
      "        [0.0200],\n",
      "        [0.0642],\n",
      "        [0.0588],\n",
      "        [0.0275],\n",
      "        [0.0343],\n",
      "        [0.0295],\n",
      "        [0.0108],\n",
      "        [0.0011],\n",
      "        [0.0176],\n",
      "        [0.0403],\n",
      "        [0.0546],\n",
      "        [0.0757],\n",
      "        [0.0392],\n",
      "        [0.0504],\n",
      "        [0.0241],\n",
      "        [0.0563],\n",
      "        [0.1107],\n",
      "        [0.0942],\n",
      "        [0.0755],\n",
      "        [0.0622],\n",
      "        [0.0554],\n",
      "        [0.0271],\n",
      "        [0.1598],\n",
      "        [0.0416],\n",
      "        [0.0679],\n",
      "        [0.0609],\n",
      "        [0.0047],\n",
      "        [0.0061],\n",
      "        [0.0366],\n",
      "        [0.0240],\n",
      "        [0.0198],\n",
      "        [0.0344],\n",
      "        [0.0669],\n",
      "        [0.0783],\n",
      "        [0.0809],\n",
      "        [0.0789],\n",
      "        [0.1047],\n",
      "        [0.0839],\n",
      "        [0.0294],\n",
      "        [0.0118],\n",
      "        [0.0105],\n",
      "        [0.0323],\n",
      "        [0.0162],\n",
      "        [0.0253],\n",
      "        [0.0630],\n",
      "        [0.0159],\n",
      "        [0.1294],\n",
      "        [0.1571],\n",
      "        [0.1652],\n",
      "        [0.1061],\n",
      "        [0.0889],\n",
      "        [0.0500],\n",
      "        [0.0403],\n",
      "        [0.0377],\n",
      "        [0.0116],\n",
      "        [0.0622],\n",
      "        [0.2942]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 96\n",
      "Number of shrink: 32\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0863],\n",
      "        [0.0662],\n",
      "        [0.0547],\n",
      "        [0.0205],\n",
      "        [0.0073],\n",
      "        [0.0051],\n",
      "        [0.0006],\n",
      "        [0.0064],\n",
      "        [0.0154],\n",
      "        [0.0033],\n",
      "        [0.0014],\n",
      "        [0.0022],\n",
      "        [0.0077],\n",
      "        [0.0051],\n",
      "        [0.0237],\n",
      "        [0.0247],\n",
      "        [0.0384],\n",
      "        [0.0462],\n",
      "        [0.0090],\n",
      "        [0.0555],\n",
      "        [0.0686],\n",
      "        [0.0737],\n",
      "        [0.0178],\n",
      "        [0.0332],\n",
      "        [0.0808],\n",
      "        [0.0893],\n",
      "        [0.0762],\n",
      "        [0.0471],\n",
      "        [0.0108],\n",
      "        [0.0126],\n",
      "        [0.0265],\n",
      "        [0.0271],\n",
      "        [0.0224],\n",
      "        [0.0413],\n",
      "        [0.0378],\n",
      "        [0.0208],\n",
      "        [0.0199],\n",
      "        [0.0310],\n",
      "        [0.0439],\n",
      "        [0.0502],\n",
      "        [0.0025],\n",
      "        [0.0074],\n",
      "        [0.0160],\n",
      "        [0.0605],\n",
      "        [0.0550],\n",
      "        [0.0237],\n",
      "        [0.0308],\n",
      "        [0.0327],\n",
      "        [0.0082],\n",
      "        [0.0009],\n",
      "        [0.0148],\n",
      "        [0.0376],\n",
      "        [0.0516],\n",
      "        [0.0727],\n",
      "        [0.0349],\n",
      "        [0.0461],\n",
      "        [0.0194],\n",
      "        [0.0603],\n",
      "        [0.1145],\n",
      "        [0.0983],\n",
      "        [0.0791],\n",
      "        [0.0650],\n",
      "        [0.0582],\n",
      "        [0.0292],\n",
      "        [0.1573],\n",
      "        [0.0396],\n",
      "        [0.0658],\n",
      "        [0.0593],\n",
      "        [0.0016],\n",
      "        [0.0046],\n",
      "        [0.0379],\n",
      "        [0.0261],\n",
      "        [0.0230],\n",
      "        [0.0376],\n",
      "        [0.0706],\n",
      "        [0.0823],\n",
      "        [0.0847],\n",
      "        [0.0829],\n",
      "        [0.1112],\n",
      "        [0.0911],\n",
      "        [0.0367],\n",
      "        [0.0201],\n",
      "        [0.0018],\n",
      "        [0.0422],\n",
      "        [0.0280],\n",
      "        [0.0145],\n",
      "        [0.0514],\n",
      "        [0.0031],\n",
      "        [0.1151],\n",
      "        [0.1392],\n",
      "        [0.1458],\n",
      "        [0.0862],\n",
      "        [0.0676],\n",
      "        [0.0275],\n",
      "        [0.0173],\n",
      "        [0.0627],\n",
      "        [0.0133],\n",
      "        [0.0371],\n",
      "        [0.2696]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 13\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0860],\n",
      "        [0.0660],\n",
      "        [0.0544],\n",
      "        [0.0201],\n",
      "        [0.0076],\n",
      "        [0.0054],\n",
      "        [0.0009],\n",
      "        [0.0067],\n",
      "        [0.0157],\n",
      "        [0.0036],\n",
      "        [0.0017],\n",
      "        [0.0019],\n",
      "        [0.0074],\n",
      "        [0.0048],\n",
      "        [0.0234],\n",
      "        [0.0250],\n",
      "        [0.0387],\n",
      "        [0.0459],\n",
      "        [0.0093],\n",
      "        [0.0560],\n",
      "        [0.0691],\n",
      "        [0.0742],\n",
      "        [0.0183],\n",
      "        [0.0327],\n",
      "        [0.0803],\n",
      "        [0.0888],\n",
      "        [0.0757],\n",
      "        [0.0466],\n",
      "        [0.0102],\n",
      "        [0.0121],\n",
      "        [0.0271],\n",
      "        [0.0266],\n",
      "        [0.0219],\n",
      "        [0.0407],\n",
      "        [0.0373],\n",
      "        [0.0202],\n",
      "        [0.0194],\n",
      "        [0.0305],\n",
      "        [0.0434],\n",
      "        [0.0497],\n",
      "        [0.0020],\n",
      "        [0.0069],\n",
      "        [0.0165],\n",
      "        [0.0609],\n",
      "        [0.0555],\n",
      "        [0.0241],\n",
      "        [0.0312],\n",
      "        [0.0322],\n",
      "        [0.0087],\n",
      "        [0.0005],\n",
      "        [0.0152],\n",
      "        [0.0380],\n",
      "        [0.0521],\n",
      "        [0.0732],\n",
      "        [0.0353],\n",
      "        [0.0465],\n",
      "        [0.0199],\n",
      "        [0.0599],\n",
      "        [0.1141],\n",
      "        [0.0979],\n",
      "        [0.0786],\n",
      "        [0.0645],\n",
      "        [0.0577],\n",
      "        [0.0287],\n",
      "        [0.1578],\n",
      "        [0.0401],\n",
      "        [0.0663],\n",
      "        [0.0598],\n",
      "        [0.0020],\n",
      "        [0.0051],\n",
      "        [0.0375],\n",
      "        [0.0257],\n",
      "        [0.0225],\n",
      "        [0.0371],\n",
      "        [0.0702],\n",
      "        [0.0819],\n",
      "        [0.0842],\n",
      "        [0.0824],\n",
      "        [0.1108],\n",
      "        [0.0906],\n",
      "        [0.0363],\n",
      "        [0.0197],\n",
      "        [0.0023],\n",
      "        [0.0417],\n",
      "        [0.0275],\n",
      "        [0.0150],\n",
      "        [0.0519],\n",
      "        [0.0036],\n",
      "        [0.1156],\n",
      "        [0.1396],\n",
      "        [0.1462],\n",
      "        [0.0866],\n",
      "        [0.0680],\n",
      "        [0.0279],\n",
      "        [0.0177],\n",
      "        [0.0624],\n",
      "        [0.0130],\n",
      "        [0.0375],\n",
      "        [0.2700]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 100\n",
      "剩餘X 資料 torch.Size([277, 18])\n",
      "剩餘Y 資料 torch.Size([277, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6213])\n",
      "目前模型的Data狀態 torch.Size([100, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.4809],\n",
      "        [0.4606],\n",
      "        [0.4970],\n",
      "        [0.5436],\n",
      "        [0.5666],\n",
      "        [0.5665],\n",
      "        [0.5568],\n",
      "        [0.5547],\n",
      "        [0.5422],\n",
      "        [0.5442],\n",
      "        [0.5383],\n",
      "        [0.5321],\n",
      "        [0.5256],\n",
      "        [0.5182],\n",
      "        [0.5461],\n",
      "        [0.5663],\n",
      "        [0.5637],\n",
      "        [0.5257],\n",
      "        [0.5771],\n",
      "        [0.8600],\n",
      "        [0.8827],\n",
      "        [0.9163],\n",
      "        [0.8630],\n",
      "        [0.8962],\n",
      "        [0.9018],\n",
      "        [0.8859],\n",
      "        [0.9238],\n",
      "        [0.9301],\n",
      "        [0.9653],\n",
      "        [0.9807],\n",
      "        [1.0061],\n",
      "        [0.9707],\n",
      "        [0.9614],\n",
      "        [0.9393],\n",
      "        [0.9301],\n",
      "        [0.9235],\n",
      "        [0.8695],\n",
      "        [0.8836],\n",
      "        [0.8933],\n",
      "        [0.8662],\n",
      "        [0.8513],\n",
      "        [0.8479],\n",
      "        [0.8619],\n",
      "        [0.8538],\n",
      "        [0.8620],\n",
      "        [0.8557],\n",
      "        [0.8349],\n",
      "        [0.8170],\n",
      "        [0.8382],\n",
      "        [0.8491],\n",
      "        [0.8195],\n",
      "        [0.8474],\n",
      "        [0.8721],\n",
      "        [0.8876],\n",
      "        [0.8754],\n",
      "        [0.8891],\n",
      "        [0.8834],\n",
      "        [0.8931],\n",
      "        [0.8859],\n",
      "        [0.8706],\n",
      "        [0.8896],\n",
      "        [0.9024],\n",
      "        [0.8944],\n",
      "        [0.8732],\n",
      "        [0.8657],\n",
      "        [0.8834],\n",
      "        [0.8959],\n",
      "        [0.9061],\n",
      "        [0.8544],\n",
      "        [0.8943],\n",
      "        [0.8604],\n",
      "        [0.8578],\n",
      "        [0.8449],\n",
      "        [0.8555],\n",
      "        [0.8394],\n",
      "        [0.8241],\n",
      "        [0.8358],\n",
      "        [0.8530],\n",
      "        [0.8486],\n",
      "        [0.8646],\n",
      "        [0.8840],\n",
      "        [0.8637],\n",
      "        [0.8639],\n",
      "        [0.8327],\n",
      "        [0.8081],\n",
      "        [0.8504],\n",
      "        [0.8455],\n",
      "        [0.8202],\n",
      "        [0.8194],\n",
      "        [0.7888],\n",
      "        [0.8047],\n",
      "        [0.8328],\n",
      "        [0.8136],\n",
      "        [0.7885],\n",
      "        [0.7640],\n",
      "        [0.6962],\n",
      "        [0.7088],\n",
      "        [0.7005],\n",
      "        [0.7311],\n",
      "        [0.7259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0860],\n",
      "        [0.0660],\n",
      "        [0.0544],\n",
      "        [0.0201],\n",
      "        [0.0076],\n",
      "        [0.0054],\n",
      "        [0.0009],\n",
      "        [0.0067],\n",
      "        [0.0157],\n",
      "        [0.0036],\n",
      "        [0.0017],\n",
      "        [0.0019],\n",
      "        [0.0074],\n",
      "        [0.0048],\n",
      "        [0.0234],\n",
      "        [0.0250],\n",
      "        [0.0387],\n",
      "        [0.0459],\n",
      "        [0.0093],\n",
      "        [0.0560],\n",
      "        [0.0691],\n",
      "        [0.0742],\n",
      "        [0.0183],\n",
      "        [0.0327],\n",
      "        [0.0803],\n",
      "        [0.0888],\n",
      "        [0.0757],\n",
      "        [0.0466],\n",
      "        [0.0102],\n",
      "        [0.0121],\n",
      "        [0.0271],\n",
      "        [0.0266],\n",
      "        [0.0219],\n",
      "        [0.0407],\n",
      "        [0.0373],\n",
      "        [0.0202],\n",
      "        [0.0194],\n",
      "        [0.0305],\n",
      "        [0.0434],\n",
      "        [0.0497],\n",
      "        [0.0020],\n",
      "        [0.0069],\n",
      "        [0.0165],\n",
      "        [0.0609],\n",
      "        [0.0555],\n",
      "        [0.0241],\n",
      "        [0.0312],\n",
      "        [0.0322],\n",
      "        [0.0087],\n",
      "        [0.0005],\n",
      "        [0.0152],\n",
      "        [0.0380],\n",
      "        [0.0521],\n",
      "        [0.0732],\n",
      "        [0.0353],\n",
      "        [0.0465],\n",
      "        [0.0199],\n",
      "        [0.0599],\n",
      "        [0.1141],\n",
      "        [0.0979],\n",
      "        [0.0786],\n",
      "        [0.0645],\n",
      "        [0.0577],\n",
      "        [0.0287],\n",
      "        [0.1578],\n",
      "        [0.0401],\n",
      "        [0.0663],\n",
      "        [0.0598],\n",
      "        [0.0020],\n",
      "        [0.0051],\n",
      "        [0.0375],\n",
      "        [0.0257],\n",
      "        [0.0225],\n",
      "        [0.0371],\n",
      "        [0.0702],\n",
      "        [0.0819],\n",
      "        [0.0842],\n",
      "        [0.0824],\n",
      "        [0.1108],\n",
      "        [0.0906],\n",
      "        [0.0363],\n",
      "        [0.0197],\n",
      "        [0.0023],\n",
      "        [0.0417],\n",
      "        [0.0275],\n",
      "        [0.0150],\n",
      "        [0.0519],\n",
      "        [0.0036],\n",
      "        [0.1156],\n",
      "        [0.1396],\n",
      "        [0.1462],\n",
      "        [0.0866],\n",
      "        [0.0680],\n",
      "        [0.0279],\n",
      "        [0.0177],\n",
      "        [0.0624],\n",
      "        [0.0130],\n",
      "        [0.0375],\n",
      "        [0.2700],\n",
      "        [0.1045]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 6\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0860],\n",
      "        [0.0659],\n",
      "        [0.0544],\n",
      "        [0.0201],\n",
      "        [0.0077],\n",
      "        [0.0055],\n",
      "        [0.0010],\n",
      "        [0.0067],\n",
      "        [0.0158],\n",
      "        [0.0036],\n",
      "        [0.0017],\n",
      "        [0.0018],\n",
      "        [0.0073],\n",
      "        [0.0048],\n",
      "        [0.0234],\n",
      "        [0.0251],\n",
      "        [0.0387],\n",
      "        [0.0459],\n",
      "        [0.0094],\n",
      "        [0.0561],\n",
      "        [0.0692],\n",
      "        [0.0742],\n",
      "        [0.0183],\n",
      "        [0.0327],\n",
      "        [0.0803],\n",
      "        [0.0888],\n",
      "        [0.0756],\n",
      "        [0.0465],\n",
      "        [0.0102],\n",
      "        [0.0120],\n",
      "        [0.0271],\n",
      "        [0.0265],\n",
      "        [0.0218],\n",
      "        [0.0407],\n",
      "        [0.0372],\n",
      "        [0.0202],\n",
      "        [0.0194],\n",
      "        [0.0304],\n",
      "        [0.0433],\n",
      "        [0.0497],\n",
      "        [0.0020],\n",
      "        [0.0069],\n",
      "        [0.0165],\n",
      "        [0.0610],\n",
      "        [0.0555],\n",
      "        [0.0242],\n",
      "        [0.0313],\n",
      "        [0.0321],\n",
      "        [0.0087],\n",
      "        [0.0004],\n",
      "        [0.0153],\n",
      "        [0.0381],\n",
      "        [0.0521],\n",
      "        [0.0732],\n",
      "        [0.0354],\n",
      "        [0.0466],\n",
      "        [0.0199],\n",
      "        [0.0598],\n",
      "        [0.1140],\n",
      "        [0.0978],\n",
      "        [0.0785],\n",
      "        [0.0645],\n",
      "        [0.0577],\n",
      "        [0.0286],\n",
      "        [0.1579],\n",
      "        [0.0402],\n",
      "        [0.0663],\n",
      "        [0.0599],\n",
      "        [0.0021],\n",
      "        [0.0051],\n",
      "        [0.0374],\n",
      "        [0.0256],\n",
      "        [0.0225],\n",
      "        [0.0371],\n",
      "        [0.0701],\n",
      "        [0.0818],\n",
      "        [0.0842],\n",
      "        [0.0824],\n",
      "        [0.1107],\n",
      "        [0.0906],\n",
      "        [0.0362],\n",
      "        [0.0196],\n",
      "        [0.0023],\n",
      "        [0.0416],\n",
      "        [0.0275],\n",
      "        [0.0150],\n",
      "        [0.0519],\n",
      "        [0.0036],\n",
      "        [0.1156],\n",
      "        [0.1396],\n",
      "        [0.1462],\n",
      "        [0.0867],\n",
      "        [0.0681],\n",
      "        [0.0279],\n",
      "        [0.0177],\n",
      "        [0.0623],\n",
      "        [0.0129],\n",
      "        [0.0375],\n",
      "        [0.2700],\n",
      "        [0.1046]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 101\n",
      "剩餘X 資料 torch.Size([276, 18])\n",
      "剩餘Y 資料 torch.Size([276, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6143])\n",
      "目前模型的Data狀態 torch.Size([101, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.4809],\n",
      "        [0.4606],\n",
      "        [0.4970],\n",
      "        [0.5437],\n",
      "        [0.5667],\n",
      "        [0.5665],\n",
      "        [0.5568],\n",
      "        [0.5547],\n",
      "        [0.5422],\n",
      "        [0.5442],\n",
      "        [0.5384],\n",
      "        [0.5322],\n",
      "        [0.5256],\n",
      "        [0.5183],\n",
      "        [0.5462],\n",
      "        [0.5664],\n",
      "        [0.5638],\n",
      "        [0.5257],\n",
      "        [0.5771],\n",
      "        [0.8600],\n",
      "        [0.8827],\n",
      "        [0.9164],\n",
      "        [0.8630],\n",
      "        [0.8963],\n",
      "        [0.9018],\n",
      "        [0.8860],\n",
      "        [0.9238],\n",
      "        [0.9302],\n",
      "        [0.9653],\n",
      "        [0.9807],\n",
      "        [1.0062],\n",
      "        [0.9707],\n",
      "        [0.9615],\n",
      "        [0.9393],\n",
      "        [0.9301],\n",
      "        [0.9236],\n",
      "        [0.8696],\n",
      "        [0.8837],\n",
      "        [0.8933],\n",
      "        [0.8662],\n",
      "        [0.8514],\n",
      "        [0.8479],\n",
      "        [0.8619],\n",
      "        [0.8539],\n",
      "        [0.8621],\n",
      "        [0.8557],\n",
      "        [0.8349],\n",
      "        [0.8170],\n",
      "        [0.8382],\n",
      "        [0.8492],\n",
      "        [0.8196],\n",
      "        [0.8475],\n",
      "        [0.8721],\n",
      "        [0.8877],\n",
      "        [0.8754],\n",
      "        [0.8891],\n",
      "        [0.8835],\n",
      "        [0.8932],\n",
      "        [0.8860],\n",
      "        [0.8707],\n",
      "        [0.8896],\n",
      "        [0.9025],\n",
      "        [0.8945],\n",
      "        [0.8732],\n",
      "        [0.8658],\n",
      "        [0.8835],\n",
      "        [0.8960],\n",
      "        [0.9061],\n",
      "        [0.8545],\n",
      "        [0.8944],\n",
      "        [0.8604],\n",
      "        [0.8579],\n",
      "        [0.8449],\n",
      "        [0.8555],\n",
      "        [0.8395],\n",
      "        [0.8241],\n",
      "        [0.8358],\n",
      "        [0.8531],\n",
      "        [0.8487],\n",
      "        [0.8647],\n",
      "        [0.8841],\n",
      "        [0.8637],\n",
      "        [0.8640],\n",
      "        [0.8327],\n",
      "        [0.8082],\n",
      "        [0.8505],\n",
      "        [0.8455],\n",
      "        [0.8203],\n",
      "        [0.8194],\n",
      "        [0.7889],\n",
      "        [0.8047],\n",
      "        [0.8328],\n",
      "        [0.8136],\n",
      "        [0.7885],\n",
      "        [0.7640],\n",
      "        [0.6963],\n",
      "        [0.7089],\n",
      "        [0.7005],\n",
      "        [0.7311],\n",
      "        [0.7259],\n",
      "        [0.7019]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0860],\n",
      "        [0.0659],\n",
      "        [0.0544],\n",
      "        [0.0201],\n",
      "        [0.0077],\n",
      "        [0.0055],\n",
      "        [0.0010],\n",
      "        [0.0067],\n",
      "        [0.0158],\n",
      "        [0.0036],\n",
      "        [0.0017],\n",
      "        [0.0018],\n",
      "        [0.0073],\n",
      "        [0.0048],\n",
      "        [0.0234],\n",
      "        [0.0251],\n",
      "        [0.0387],\n",
      "        [0.0459],\n",
      "        [0.0094],\n",
      "        [0.0561],\n",
      "        [0.0692],\n",
      "        [0.0742],\n",
      "        [0.0183],\n",
      "        [0.0327],\n",
      "        [0.0803],\n",
      "        [0.0888],\n",
      "        [0.0756],\n",
      "        [0.0465],\n",
      "        [0.0102],\n",
      "        [0.0120],\n",
      "        [0.0271],\n",
      "        [0.0265],\n",
      "        [0.0218],\n",
      "        [0.0407],\n",
      "        [0.0372],\n",
      "        [0.0202],\n",
      "        [0.0194],\n",
      "        [0.0304],\n",
      "        [0.0433],\n",
      "        [0.0497],\n",
      "        [0.0020],\n",
      "        [0.0069],\n",
      "        [0.0165],\n",
      "        [0.0610],\n",
      "        [0.0555],\n",
      "        [0.0242],\n",
      "        [0.0313],\n",
      "        [0.0321],\n",
      "        [0.0087],\n",
      "        [0.0004],\n",
      "        [0.0153],\n",
      "        [0.0381],\n",
      "        [0.0521],\n",
      "        [0.0732],\n",
      "        [0.0354],\n",
      "        [0.0466],\n",
      "        [0.0199],\n",
      "        [0.0598],\n",
      "        [0.1140],\n",
      "        [0.0978],\n",
      "        [0.0785],\n",
      "        [0.0645],\n",
      "        [0.0577],\n",
      "        [0.0286],\n",
      "        [0.1579],\n",
      "        [0.0402],\n",
      "        [0.0663],\n",
      "        [0.0599],\n",
      "        [0.0021],\n",
      "        [0.0051],\n",
      "        [0.0374],\n",
      "        [0.0256],\n",
      "        [0.0225],\n",
      "        [0.0371],\n",
      "        [0.0701],\n",
      "        [0.0818],\n",
      "        [0.0842],\n",
      "        [0.0824],\n",
      "        [0.1107],\n",
      "        [0.0906],\n",
      "        [0.0362],\n",
      "        [0.0196],\n",
      "        [0.0023],\n",
      "        [0.0416],\n",
      "        [0.0275],\n",
      "        [0.0150],\n",
      "        [0.0519],\n",
      "        [0.0036],\n",
      "        [0.1156],\n",
      "        [0.1396],\n",
      "        [0.1462],\n",
      "        [0.0867],\n",
      "        [0.0681],\n",
      "        [0.0279],\n",
      "        [0.0177],\n",
      "        [0.0623],\n",
      "        [0.0129],\n",
      "        [0.0375],\n",
      "        [0.2700],\n",
      "        [0.1046],\n",
      "        [0.0876]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0932],\n",
      "        [    0.0712],\n",
      "        [    0.0576],\n",
      "        [    0.0213],\n",
      "        [    0.0108],\n",
      "        [    0.0087],\n",
      "        [    0.0037],\n",
      "        [    0.0094],\n",
      "        [    0.0181],\n",
      "        [    0.0059],\n",
      "        [    0.0038],\n",
      "        [    0.0002],\n",
      "        [    0.0057],\n",
      "        [    0.0028],\n",
      "        [    0.0230],\n",
      "        [    0.0272],\n",
      "        [    0.0415],\n",
      "        [    0.0451],\n",
      "        [    0.0100],\n",
      "        [    0.0595],\n",
      "        [    0.0738],\n",
      "        [    0.0800],\n",
      "        [    0.0226],\n",
      "        [    0.0277],\n",
      "        [    0.0752],\n",
      "        [    0.0841],\n",
      "        [    0.0699],\n",
      "        [    0.0410],\n",
      "        [    0.0038],\n",
      "        [    0.0051],\n",
      "        [    0.0347],\n",
      "        [    0.0190],\n",
      "        [    0.0146],\n",
      "        [    0.0339],\n",
      "        [    0.0308],\n",
      "        [    0.0134],\n",
      "        [    0.0136],\n",
      "        [    0.0245],\n",
      "        [    0.0371],\n",
      "        [    0.0439],\n",
      "        [    0.0034],\n",
      "        [    0.0021],\n",
      "        [    0.0217],\n",
      "        [    0.0662],\n",
      "        [    0.0608],\n",
      "        [    0.0295],\n",
      "        [    0.0364],\n",
      "        [    0.0271],\n",
      "        [    0.0143],\n",
      "        [    0.0056],\n",
      "        [    0.0204],\n",
      "        [    0.0435],\n",
      "        [    0.0574],\n",
      "        [    0.0785],\n",
      "        [    0.0397],\n",
      "        [    0.0509],\n",
      "        [    0.0240],\n",
      "        [    0.0553],\n",
      "        [    0.1094],\n",
      "        [    0.0934],\n",
      "        [    0.0737],\n",
      "        [    0.0588],\n",
      "        [    0.0520],\n",
      "        [    0.0225],\n",
      "        [    0.1640],\n",
      "        [    0.0471],\n",
      "        [    0.0732],\n",
      "        [    0.0672],\n",
      "        [    0.0077],\n",
      "        [    0.0122],\n",
      "        [    0.0306],\n",
      "        [    0.0195],\n",
      "        [    0.0173],\n",
      "        [    0.0318],\n",
      "        [    0.0652],\n",
      "        [    0.0770],\n",
      "        [    0.0791],\n",
      "        [    0.0773],\n",
      "        [    0.1076],\n",
      "        [    0.0880],\n",
      "        [    0.0336],\n",
      "        [    0.0179],\n",
      "        [    0.0038],\n",
      "        [    0.0412],\n",
      "        [    0.0284],\n",
      "        [    0.0152],\n",
      "        [    0.0513],\n",
      "        [    0.0017],\n",
      "        [    0.1124],\n",
      "        [    0.1334],\n",
      "        [    0.1389],\n",
      "        [    0.0792],\n",
      "        [    0.0594],\n",
      "        [    0.0181],\n",
      "        [    0.0075],\n",
      "        [    0.0750],\n",
      "        [    0.0254],\n",
      "        [    0.0247],\n",
      "        [    0.2578],\n",
      "        [    0.0914],\n",
      "        [    0.0738]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 102\n",
      "剩餘X 資料 torch.Size([275, 18])\n",
      "剩餘Y 資料 torch.Size([275, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6335])\n",
      "目前模型的Data狀態 torch.Size([102, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.4737],\n",
      "        [0.4553],\n",
      "        [0.4939],\n",
      "        [0.5424],\n",
      "        [0.5698],\n",
      "        [0.5697],\n",
      "        [0.5596],\n",
      "        [0.5573],\n",
      "        [0.5446],\n",
      "        [0.5465],\n",
      "        [0.5404],\n",
      "        [0.5338],\n",
      "        [0.5272],\n",
      "        [0.5203],\n",
      "        [0.5466],\n",
      "        [0.5685],\n",
      "        [0.5666],\n",
      "        [0.5265],\n",
      "        [0.5778],\n",
      "        [0.8634],\n",
      "        [0.8873],\n",
      "        [0.9222],\n",
      "        [0.8673],\n",
      "        [0.9013],\n",
      "        [0.9069],\n",
      "        [0.8907],\n",
      "        [0.9295],\n",
      "        [0.9357],\n",
      "        [0.9717],\n",
      "        [0.9876],\n",
      "        [1.0137],\n",
      "        [0.9782],\n",
      "        [0.9688],\n",
      "        [0.9462],\n",
      "        [0.9365],\n",
      "        [0.9304],\n",
      "        [0.8753],\n",
      "        [0.8896],\n",
      "        [0.8996],\n",
      "        [0.8720],\n",
      "        [0.8568],\n",
      "        [0.8526],\n",
      "        [0.8671],\n",
      "        [0.8591],\n",
      "        [0.8673],\n",
      "        [0.8610],\n",
      "        [0.8400],\n",
      "        [0.8221],\n",
      "        [0.8438],\n",
      "        [0.8551],\n",
      "        [0.8247],\n",
      "        [0.8529],\n",
      "        [0.8774],\n",
      "        [0.8930],\n",
      "        [0.8797],\n",
      "        [0.8934],\n",
      "        [0.8875],\n",
      "        [0.8977],\n",
      "        [0.8906],\n",
      "        [0.8751],\n",
      "        [0.8945],\n",
      "        [0.9081],\n",
      "        [0.9001],\n",
      "        [0.8793],\n",
      "        [0.8719],\n",
      "        [0.8904],\n",
      "        [0.9028],\n",
      "        [0.9135],\n",
      "        [0.8601],\n",
      "        [0.9015],\n",
      "        [0.8672],\n",
      "        [0.8639],\n",
      "        [0.8501],\n",
      "        [0.8608],\n",
      "        [0.8444],\n",
      "        [0.8289],\n",
      "        [0.8409],\n",
      "        [0.8582],\n",
      "        [0.8518],\n",
      "        [0.8673],\n",
      "        [0.8867],\n",
      "        [0.8654],\n",
      "        [0.8655],\n",
      "        [0.8332],\n",
      "        [0.8072],\n",
      "        [0.8506],\n",
      "        [0.8450],\n",
      "        [0.8184],\n",
      "        [0.8163],\n",
      "        [0.7826],\n",
      "        [0.7974],\n",
      "        [0.8253],\n",
      "        [0.8049],\n",
      "        [0.7787],\n",
      "        [0.7538],\n",
      "        [0.6836],\n",
      "        [0.6964],\n",
      "        [0.6878],\n",
      "        [0.7190],\n",
      "        [0.7128],\n",
      "        [0.6881],\n",
      "        [0.6606]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0932],\n",
      "        [    0.0712],\n",
      "        [    0.0576],\n",
      "        [    0.0213],\n",
      "        [    0.0108],\n",
      "        [    0.0087],\n",
      "        [    0.0037],\n",
      "        [    0.0094],\n",
      "        [    0.0181],\n",
      "        [    0.0059],\n",
      "        [    0.0038],\n",
      "        [    0.0002],\n",
      "        [    0.0057],\n",
      "        [    0.0028],\n",
      "        [    0.0230],\n",
      "        [    0.0272],\n",
      "        [    0.0415],\n",
      "        [    0.0451],\n",
      "        [    0.0100],\n",
      "        [    0.0595],\n",
      "        [    0.0738],\n",
      "        [    0.0800],\n",
      "        [    0.0226],\n",
      "        [    0.0277],\n",
      "        [    0.0752],\n",
      "        [    0.0841],\n",
      "        [    0.0699],\n",
      "        [    0.0410],\n",
      "        [    0.0038],\n",
      "        [    0.0051],\n",
      "        [    0.0347],\n",
      "        [    0.0190],\n",
      "        [    0.0146],\n",
      "        [    0.0339],\n",
      "        [    0.0308],\n",
      "        [    0.0134],\n",
      "        [    0.0136],\n",
      "        [    0.0245],\n",
      "        [    0.0371],\n",
      "        [    0.0439],\n",
      "        [    0.0034],\n",
      "        [    0.0021],\n",
      "        [    0.0217],\n",
      "        [    0.0662],\n",
      "        [    0.0608],\n",
      "        [    0.0295],\n",
      "        [    0.0364],\n",
      "        [    0.0271],\n",
      "        [    0.0143],\n",
      "        [    0.0056],\n",
      "        [    0.0204],\n",
      "        [    0.0435],\n",
      "        [    0.0574],\n",
      "        [    0.0785],\n",
      "        [    0.0397],\n",
      "        [    0.0509],\n",
      "        [    0.0240],\n",
      "        [    0.0553],\n",
      "        [    0.1094],\n",
      "        [    0.0934],\n",
      "        [    0.0737],\n",
      "        [    0.0588],\n",
      "        [    0.0520],\n",
      "        [    0.0225],\n",
      "        [    0.1640],\n",
      "        [    0.0471],\n",
      "        [    0.0732],\n",
      "        [    0.0672],\n",
      "        [    0.0077],\n",
      "        [    0.0122],\n",
      "        [    0.0306],\n",
      "        [    0.0195],\n",
      "        [    0.0173],\n",
      "        [    0.0318],\n",
      "        [    0.0652],\n",
      "        [    0.0770],\n",
      "        [    0.0791],\n",
      "        [    0.0773],\n",
      "        [    0.1076],\n",
      "        [    0.0880],\n",
      "        [    0.0336],\n",
      "        [    0.0179],\n",
      "        [    0.0038],\n",
      "        [    0.0412],\n",
      "        [    0.0284],\n",
      "        [    0.0152],\n",
      "        [    0.0513],\n",
      "        [    0.0017],\n",
      "        [    0.1124],\n",
      "        [    0.1334],\n",
      "        [    0.1389],\n",
      "        [    0.0792],\n",
      "        [    0.0594],\n",
      "        [    0.0181],\n",
      "        [    0.0075],\n",
      "        [    0.0750],\n",
      "        [    0.0254],\n",
      "        [    0.0247],\n",
      "        [    0.2578],\n",
      "        [    0.0914],\n",
      "        [    0.0738],\n",
      "        [    0.0271]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.1019],\n",
      "        [    0.0772],\n",
      "        [    0.0618],\n",
      "        [    0.0251],\n",
      "        [    0.0106],\n",
      "        [    0.0085],\n",
      "        [    0.0032],\n",
      "        [    0.0087],\n",
      "        [    0.0173],\n",
      "        [    0.0052],\n",
      "        [    0.0030],\n",
      "        [    0.0011],\n",
      "        [    0.0065],\n",
      "        [    0.0032],\n",
      "        [    0.0259],\n",
      "        [    0.0256],\n",
      "        [    0.0403],\n",
      "        [    0.0471],\n",
      "        [    0.0056],\n",
      "        [    0.0540],\n",
      "        [    0.0694],\n",
      "        [    0.0765],\n",
      "        [    0.0185],\n",
      "        [    0.0315],\n",
      "        [    0.0789],\n",
      "        [    0.0876],\n",
      "        [    0.0727],\n",
      "        [    0.0441],\n",
      "        [    0.0067],\n",
      "        [    0.0081],\n",
      "        [    0.0317],\n",
      "        [    0.0220],\n",
      "        [    0.0177],\n",
      "        [    0.0372],\n",
      "        [    0.0343],\n",
      "        [    0.0166],\n",
      "        [    0.0174],\n",
      "        [    0.0279],\n",
      "        [    0.0403],\n",
      "        [    0.0471],\n",
      "        [    0.0002],\n",
      "        [    0.0057],\n",
      "        [    0.0185],\n",
      "        [    0.0632],\n",
      "        [    0.0579],\n",
      "        [    0.0269],\n",
      "        [    0.0341],\n",
      "        [    0.0292],\n",
      "        [    0.0126],\n",
      "        [    0.0042],\n",
      "        [    0.0186],\n",
      "        [    0.0417],\n",
      "        [    0.0554],\n",
      "        [    0.0764],\n",
      "        [    0.0367],\n",
      "        [    0.0478],\n",
      "        [    0.0208],\n",
      "        [    0.0581],\n",
      "        [    0.1120],\n",
      "        [    0.0963],\n",
      "        [    0.0763],\n",
      "        [    0.0609],\n",
      "        [    0.0543],\n",
      "        [    0.0247],\n",
      "        [    0.1615],\n",
      "        [    0.0450],\n",
      "        [    0.0710],\n",
      "        [    0.0653],\n",
      "        [    0.0050],\n",
      "        [    0.0111],\n",
      "        [    0.0314],\n",
      "        [    0.0208],\n",
      "        [    0.0194],\n",
      "        [    0.0340],\n",
      "        [    0.0677],\n",
      "        [    0.0798],\n",
      "        [    0.0818],\n",
      "        [    0.0800],\n",
      "        [    0.1120],\n",
      "        [    0.0928],\n",
      "        [    0.0387],\n",
      "        [    0.0236],\n",
      "        [    0.0022],\n",
      "        [    0.0479],\n",
      "        [    0.0364],\n",
      "        [    0.0076],\n",
      "        [    0.0433],\n",
      "        [    0.0070],\n",
      "        [    0.1026],\n",
      "        [    0.1212],\n",
      "        [    0.1257],\n",
      "        [    0.0657],\n",
      "        [    0.0449],\n",
      "        [    0.0034],\n",
      "        [    0.0072],\n",
      "        [    0.0909],\n",
      "        [    0.0413],\n",
      "        [    0.0085],\n",
      "        [    0.2417],\n",
      "        [    0.0745],\n",
      "        [    0.0564],\n",
      "        [    0.0098]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 103\n",
      "剩餘X 資料 torch.Size([274, 18])\n",
      "剩餘Y 資料 torch.Size([274, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6553])\n",
      "目前模型的Data狀態 torch.Size([103, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.4650],\n",
      "        [0.4493],\n",
      "        [0.4896],\n",
      "        [0.5387],\n",
      "        [0.5696],\n",
      "        [0.5696],\n",
      "        [0.5590],\n",
      "        [0.5566],\n",
      "        [0.5437],\n",
      "        [0.5458],\n",
      "        [0.5397],\n",
      "        [0.5329],\n",
      "        [0.5264],\n",
      "        [0.5199],\n",
      "        [0.5437],\n",
      "        [0.5668],\n",
      "        [0.5653],\n",
      "        [0.5245],\n",
      "        [0.5733],\n",
      "        [0.8579],\n",
      "        [0.8829],\n",
      "        [0.9187],\n",
      "        [0.8631],\n",
      "        [0.8974],\n",
      "        [0.9032],\n",
      "        [0.8871],\n",
      "        [0.9267],\n",
      "        [0.9326],\n",
      "        [0.9688],\n",
      "        [0.9846],\n",
      "        [1.0107],\n",
      "        [0.9753],\n",
      "        [0.9656],\n",
      "        [0.9428],\n",
      "        [0.9331],\n",
      "        [0.9272],\n",
      "        [0.8716],\n",
      "        [0.8862],\n",
      "        [0.8964],\n",
      "        [0.8688],\n",
      "        [0.8535],\n",
      "        [0.8491],\n",
      "        [0.8639],\n",
      "        [0.8561],\n",
      "        [0.8644],\n",
      "        [0.8584],\n",
      "        [0.8378],\n",
      "        [0.8200],\n",
      "        [0.8421],\n",
      "        [0.8538],\n",
      "        [0.8229],\n",
      "        [0.8511],\n",
      "        [0.8754],\n",
      "        [0.8908],\n",
      "        [0.8768],\n",
      "        [0.8904],\n",
      "        [0.8844],\n",
      "        [0.8949],\n",
      "        [0.8880],\n",
      "        [0.8722],\n",
      "        [0.8919],\n",
      "        [0.9060],\n",
      "        [0.8978],\n",
      "        [0.8771],\n",
      "        [0.8694],\n",
      "        [0.8883],\n",
      "        [0.9007],\n",
      "        [0.9116],\n",
      "        [0.8574],\n",
      "        [0.9004],\n",
      "        [0.8665],\n",
      "        [0.8627],\n",
      "        [0.8480],\n",
      "        [0.8586],\n",
      "        [0.8419],\n",
      "        [0.8262],\n",
      "        [0.8382],\n",
      "        [0.8554],\n",
      "        [0.8474],\n",
      "        [0.8625],\n",
      "        [0.8816],\n",
      "        [0.8597],\n",
      "        [0.8595],\n",
      "        [0.8264],\n",
      "        [0.7992],\n",
      "        [0.8431],\n",
      "        [0.8369],\n",
      "        [0.8096],\n",
      "        [0.8065],\n",
      "        [0.7705],\n",
      "        [0.7842],\n",
      "        [0.8118],\n",
      "        [0.7904],\n",
      "        [0.7640],\n",
      "        [0.7391],\n",
      "        [0.6677],\n",
      "        [0.6804],\n",
      "        [0.6715],\n",
      "        [0.7028],\n",
      "        [0.6958],\n",
      "        [0.6707],\n",
      "        [0.6433],\n",
      "        [0.5931]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.1019],\n",
      "        [    0.0772],\n",
      "        [    0.0618],\n",
      "        [    0.0251],\n",
      "        [    0.0106],\n",
      "        [    0.0085],\n",
      "        [    0.0032],\n",
      "        [    0.0087],\n",
      "        [    0.0173],\n",
      "        [    0.0052],\n",
      "        [    0.0030],\n",
      "        [    0.0011],\n",
      "        [    0.0065],\n",
      "        [    0.0032],\n",
      "        [    0.0259],\n",
      "        [    0.0256],\n",
      "        [    0.0403],\n",
      "        [    0.0471],\n",
      "        [    0.0056],\n",
      "        [    0.0540],\n",
      "        [    0.0694],\n",
      "        [    0.0765],\n",
      "        [    0.0185],\n",
      "        [    0.0315],\n",
      "        [    0.0789],\n",
      "        [    0.0876],\n",
      "        [    0.0727],\n",
      "        [    0.0441],\n",
      "        [    0.0067],\n",
      "        [    0.0081],\n",
      "        [    0.0317],\n",
      "        [    0.0220],\n",
      "        [    0.0177],\n",
      "        [    0.0372],\n",
      "        [    0.0343],\n",
      "        [    0.0166],\n",
      "        [    0.0174],\n",
      "        [    0.0279],\n",
      "        [    0.0403],\n",
      "        [    0.0471],\n",
      "        [    0.0002],\n",
      "        [    0.0057],\n",
      "        [    0.0185],\n",
      "        [    0.0632],\n",
      "        [    0.0579],\n",
      "        [    0.0269],\n",
      "        [    0.0341],\n",
      "        [    0.0292],\n",
      "        [    0.0126],\n",
      "        [    0.0042],\n",
      "        [    0.0186],\n",
      "        [    0.0417],\n",
      "        [    0.0554],\n",
      "        [    0.0764],\n",
      "        [    0.0367],\n",
      "        [    0.0478],\n",
      "        [    0.0208],\n",
      "        [    0.0581],\n",
      "        [    0.1120],\n",
      "        [    0.0963],\n",
      "        [    0.0763],\n",
      "        [    0.0609],\n",
      "        [    0.0543],\n",
      "        [    0.0247],\n",
      "        [    0.1615],\n",
      "        [    0.0450],\n",
      "        [    0.0710],\n",
      "        [    0.0653],\n",
      "        [    0.0050],\n",
      "        [    0.0111],\n",
      "        [    0.0314],\n",
      "        [    0.0208],\n",
      "        [    0.0194],\n",
      "        [    0.0340],\n",
      "        [    0.0677],\n",
      "        [    0.0798],\n",
      "        [    0.0818],\n",
      "        [    0.0800],\n",
      "        [    0.1120],\n",
      "        [    0.0928],\n",
      "        [    0.0387],\n",
      "        [    0.0236],\n",
      "        [    0.0022],\n",
      "        [    0.0479],\n",
      "        [    0.0364],\n",
      "        [    0.0076],\n",
      "        [    0.0433],\n",
      "        [    0.0070],\n",
      "        [    0.1026],\n",
      "        [    0.1212],\n",
      "        [    0.1257],\n",
      "        [    0.0657],\n",
      "        [    0.0449],\n",
      "        [    0.0034],\n",
      "        [    0.0072],\n",
      "        [    0.0909],\n",
      "        [    0.0413],\n",
      "        [    0.0085],\n",
      "        [    0.2417],\n",
      "        [    0.0745],\n",
      "        [    0.0564],\n",
      "        [    0.0098],\n",
      "        [    0.0622]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.1003],\n",
      "        [0.0734],\n",
      "        [0.0570],\n",
      "        [0.0210],\n",
      "        [0.0167],\n",
      "        [0.0147],\n",
      "        [0.0090],\n",
      "        [0.0143],\n",
      "        [0.0226],\n",
      "        [0.0106],\n",
      "        [0.0086],\n",
      "        [0.0044],\n",
      "        [0.0011],\n",
      "        [0.0027],\n",
      "        [0.0241],\n",
      "        [0.0281],\n",
      "        [0.0430],\n",
      "        [0.0439],\n",
      "        [0.0063],\n",
      "        [0.0549],\n",
      "        [0.0709],\n",
      "        [0.0784],\n",
      "        [0.0201],\n",
      "        [0.0299],\n",
      "        [0.0772],\n",
      "        [0.0858],\n",
      "        [0.0707],\n",
      "        [0.0423],\n",
      "        [0.0049],\n",
      "        [0.0068],\n",
      "        [0.0328],\n",
      "        [0.0205],\n",
      "        [0.0165],\n",
      "        [0.0361],\n",
      "        [0.0330],\n",
      "        [0.0151],\n",
      "        [0.0159],\n",
      "        [0.0261],\n",
      "        [0.0386],\n",
      "        [0.0450],\n",
      "        [0.0024],\n",
      "        [0.0036],\n",
      "        [0.0207],\n",
      "        [0.0657],\n",
      "        [0.0603],\n",
      "        [0.0296],\n",
      "        [0.0371],\n",
      "        [0.0262],\n",
      "        [0.0157],\n",
      "        [0.0074],\n",
      "        [0.0216],\n",
      "        [0.0444],\n",
      "        [0.0580],\n",
      "        [0.0787],\n",
      "        [0.0385],\n",
      "        [0.0493],\n",
      "        [0.0223],\n",
      "        [0.0564],\n",
      "        [0.1101],\n",
      "        [0.0943],\n",
      "        [0.0743],\n",
      "        [0.0586],\n",
      "        [0.0522],\n",
      "        [0.0225],\n",
      "        [0.1636],\n",
      "        [0.0474],\n",
      "        [0.0732],\n",
      "        [0.0675],\n",
      "        [0.0072],\n",
      "        [0.0145],\n",
      "        [0.0275],\n",
      "        [0.0173],\n",
      "        [0.0165],\n",
      "        [0.0313],\n",
      "        [0.0650],\n",
      "        [0.0771],\n",
      "        [0.0791],\n",
      "        [0.0775],\n",
      "        [0.1104],\n",
      "        [0.0917],\n",
      "        [0.0381],\n",
      "        [0.0232],\n",
      "        [0.0019],\n",
      "        [0.0480],\n",
      "        [0.0370],\n",
      "        [0.0071],\n",
      "        [0.0424],\n",
      "        [0.0082],\n",
      "        [0.1007],\n",
      "        [0.1178],\n",
      "        [0.1215],\n",
      "        [0.0610],\n",
      "        [0.0398],\n",
      "        [0.0015],\n",
      "        [0.0118],\n",
      "        [0.0958],\n",
      "        [0.0465],\n",
      "        [0.0032],\n",
      "        [0.2362],\n",
      "        [0.0683],\n",
      "        [0.0500],\n",
      "        [0.0038],\n",
      "        [0.0676]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 104\n",
      "剩餘X 資料 torch.Size([273, 18])\n",
      "剩餘Y 資料 torch.Size([273, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6236])\n",
      "目前模型的Data狀態 torch.Size([104, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.4666],\n",
      "        [0.4531],\n",
      "        [0.4945],\n",
      "        [0.5428],\n",
      "        [0.5757],\n",
      "        [0.5757],\n",
      "        [0.5648],\n",
      "        [0.5622],\n",
      "        [0.5490],\n",
      "        [0.5512],\n",
      "        [0.5452],\n",
      "        [0.5384],\n",
      "        [0.5318],\n",
      "        [0.5257],\n",
      "        [0.5455],\n",
      "        [0.5694],\n",
      "        [0.5681],\n",
      "        [0.5277],\n",
      "        [0.5741],\n",
      "        [0.8589],\n",
      "        [0.8845],\n",
      "        [0.9205],\n",
      "        [0.8648],\n",
      "        [0.8991],\n",
      "        [0.9050],\n",
      "        [0.8889],\n",
      "        [0.9287],\n",
      "        [0.9344],\n",
      "        [0.9706],\n",
      "        [0.9860],\n",
      "        [1.0119],\n",
      "        [0.9768],\n",
      "        [0.9669],\n",
      "        [0.9440],\n",
      "        [0.9343],\n",
      "        [0.9287],\n",
      "        [0.8731],\n",
      "        [0.8880],\n",
      "        [0.8981],\n",
      "        [0.8709],\n",
      "        [0.8558],\n",
      "        [0.8511],\n",
      "        [0.8662],\n",
      "        [0.8585],\n",
      "        [0.8669],\n",
      "        [0.8612],\n",
      "        [0.8408],\n",
      "        [0.8230],\n",
      "        [0.8452],\n",
      "        [0.8569],\n",
      "        [0.8259],\n",
      "        [0.8539],\n",
      "        [0.8779],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8918],\n",
      "        [0.8859],\n",
      "        [0.8966],\n",
      "        [0.8899],\n",
      "        [0.8741],\n",
      "        [0.8939],\n",
      "        [0.9083],\n",
      "        [0.8999],\n",
      "        [0.8794],\n",
      "        [0.8715],\n",
      "        [0.8906],\n",
      "        [0.9028],\n",
      "        [0.9138],\n",
      "        [0.8596],\n",
      "        [0.9037],\n",
      "        [0.8704],\n",
      "        [0.8661],\n",
      "        [0.8509],\n",
      "        [0.8613],\n",
      "        [0.8446],\n",
      "        [0.8288],\n",
      "        [0.8409],\n",
      "        [0.8579],\n",
      "        [0.8489],\n",
      "        [0.8635],\n",
      "        [0.8822],\n",
      "        [0.8601],\n",
      "        [0.8597],\n",
      "        [0.8264],\n",
      "        [0.7986],\n",
      "        [0.8426],\n",
      "        [0.8360],\n",
      "        [0.8085],\n",
      "        [0.8046],\n",
      "        [0.7670],\n",
      "        [0.7799],\n",
      "        [0.8071],\n",
      "        [0.7853],\n",
      "        [0.7591],\n",
      "        [0.7345],\n",
      "        [0.6628],\n",
      "        [0.6753],\n",
      "        [0.6662],\n",
      "        [0.6973],\n",
      "        [0.6897],\n",
      "        [0.6644],\n",
      "        [0.6373],\n",
      "        [0.5877],\n",
      "        [0.5958]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.1003],\n",
      "        [0.0734],\n",
      "        [0.0570],\n",
      "        [0.0210],\n",
      "        [0.0167],\n",
      "        [0.0147],\n",
      "        [0.0090],\n",
      "        [0.0143],\n",
      "        [0.0226],\n",
      "        [0.0106],\n",
      "        [0.0086],\n",
      "        [0.0044],\n",
      "        [0.0011],\n",
      "        [0.0027],\n",
      "        [0.0241],\n",
      "        [0.0281],\n",
      "        [0.0430],\n",
      "        [0.0439],\n",
      "        [0.0063],\n",
      "        [0.0549],\n",
      "        [0.0709],\n",
      "        [0.0784],\n",
      "        [0.0201],\n",
      "        [0.0299],\n",
      "        [0.0772],\n",
      "        [0.0858],\n",
      "        [0.0707],\n",
      "        [0.0423],\n",
      "        [0.0049],\n",
      "        [0.0068],\n",
      "        [0.0328],\n",
      "        [0.0205],\n",
      "        [0.0165],\n",
      "        [0.0361],\n",
      "        [0.0330],\n",
      "        [0.0151],\n",
      "        [0.0159],\n",
      "        [0.0261],\n",
      "        [0.0386],\n",
      "        [0.0450],\n",
      "        [0.0024],\n",
      "        [0.0036],\n",
      "        [0.0207],\n",
      "        [0.0657],\n",
      "        [0.0603],\n",
      "        [0.0296],\n",
      "        [0.0371],\n",
      "        [0.0262],\n",
      "        [0.0157],\n",
      "        [0.0074],\n",
      "        [0.0216],\n",
      "        [0.0444],\n",
      "        [0.0580],\n",
      "        [0.0787],\n",
      "        [0.0385],\n",
      "        [0.0493],\n",
      "        [0.0223],\n",
      "        [0.0564],\n",
      "        [0.1101],\n",
      "        [0.0943],\n",
      "        [0.0743],\n",
      "        [0.0586],\n",
      "        [0.0522],\n",
      "        [0.0225],\n",
      "        [0.1636],\n",
      "        [0.0474],\n",
      "        [0.0732],\n",
      "        [0.0675],\n",
      "        [0.0072],\n",
      "        [0.0145],\n",
      "        [0.0275],\n",
      "        [0.0173],\n",
      "        [0.0165],\n",
      "        [0.0313],\n",
      "        [0.0650],\n",
      "        [0.0771],\n",
      "        [0.0791],\n",
      "        [0.0775],\n",
      "        [0.1104],\n",
      "        [0.0917],\n",
      "        [0.0381],\n",
      "        [0.0232],\n",
      "        [0.0019],\n",
      "        [0.0480],\n",
      "        [0.0370],\n",
      "        [0.0071],\n",
      "        [0.0424],\n",
      "        [0.0082],\n",
      "        [0.1007],\n",
      "        [0.1178],\n",
      "        [0.1215],\n",
      "        [0.0610],\n",
      "        [0.0398],\n",
      "        [0.0015],\n",
      "        [0.0118],\n",
      "        [0.0958],\n",
      "        [0.0465],\n",
      "        [0.0032],\n",
      "        [0.2362],\n",
      "        [0.0683],\n",
      "        [0.0500],\n",
      "        [0.0038],\n",
      "        [0.0676],\n",
      "        [0.0278]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.1011],\n",
      "        [0.0653],\n",
      "        [0.0549],\n",
      "        [0.0201],\n",
      "        [0.0190],\n",
      "        [0.0171],\n",
      "        [0.0110],\n",
      "        [0.0161],\n",
      "        [0.0241],\n",
      "        [0.0124],\n",
      "        [0.0107],\n",
      "        [0.0065],\n",
      "        [0.0011],\n",
      "        [0.0051],\n",
      "        [0.0240],\n",
      "        [0.0287],\n",
      "        [0.0436],\n",
      "        [0.0427],\n",
      "        [0.0037],\n",
      "        [0.0546],\n",
      "        [0.0714],\n",
      "        [0.0794],\n",
      "        [0.0207],\n",
      "        [0.0292],\n",
      "        [0.0763],\n",
      "        [0.0846],\n",
      "        [0.0691],\n",
      "        [0.0408],\n",
      "        [0.0035],\n",
      "        [0.0058],\n",
      "        [0.0334],\n",
      "        [0.0203],\n",
      "        [0.0165],\n",
      "        [0.0365],\n",
      "        [0.0331],\n",
      "        [0.0152],\n",
      "        [0.0165],\n",
      "        [0.0263],\n",
      "        [0.0388],\n",
      "        [0.0450],\n",
      "        [0.0027],\n",
      "        [0.0034],\n",
      "        [0.0214],\n",
      "        [0.0665],\n",
      "        [0.0612],\n",
      "        [0.0308],\n",
      "        [0.0387],\n",
      "        [0.0245],\n",
      "        [0.0176],\n",
      "        [0.0096],\n",
      "        [0.0235],\n",
      "        [0.0463],\n",
      "        [0.0600],\n",
      "        [0.0808],\n",
      "        [0.0398],\n",
      "        [0.0507],\n",
      "        [0.0236],\n",
      "        [0.0548],\n",
      "        [0.1083],\n",
      "        [0.0928],\n",
      "        [0.0725],\n",
      "        [0.0567],\n",
      "        [0.0506],\n",
      "        [0.0213],\n",
      "        [0.1642],\n",
      "        [0.0481],\n",
      "        [0.0739],\n",
      "        [0.0683],\n",
      "        [0.0080],\n",
      "        [0.0168],\n",
      "        [0.0246],\n",
      "        [0.0146],\n",
      "        [0.0143],\n",
      "        [0.0293],\n",
      "        [0.0633],\n",
      "        [0.0758],\n",
      "        [0.0777],\n",
      "        [0.0762],\n",
      "        [0.1098],\n",
      "        [0.0913],\n",
      "        [0.0381],\n",
      "        [0.0234],\n",
      "        [0.0022],\n",
      "        [0.0489],\n",
      "        [0.0389],\n",
      "        [0.0057],\n",
      "        [0.0407],\n",
      "        [0.0100],\n",
      "        [0.0986],\n",
      "        [0.1144],\n",
      "        [0.1176],\n",
      "        [0.0572],\n",
      "        [0.0356],\n",
      "        [0.0052],\n",
      "        [0.0152],\n",
      "        [0.0997],\n",
      "        [0.0505],\n",
      "        [0.0012],\n",
      "        [0.2317],\n",
      "        [0.0634],\n",
      "        [0.0447],\n",
      "        [0.0015],\n",
      "        [0.0729],\n",
      "        [0.0317]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 105\n",
      "剩餘X 資料 torch.Size([272, 18])\n",
      "剩餘Y 資料 torch.Size([272, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6611])\n",
      "目前模型的Data狀態 torch.Size([105, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.4658],\n",
      "        [0.4612],\n",
      "        [0.4966],\n",
      "        [0.5437],\n",
      "        [0.5780],\n",
      "        [0.5782],\n",
      "        [0.5668],\n",
      "        [0.5640],\n",
      "        [0.5505],\n",
      "        [0.5530],\n",
      "        [0.5473],\n",
      "        [0.5405],\n",
      "        [0.5341],\n",
      "        [0.5282],\n",
      "        [0.5456],\n",
      "        [0.5700],\n",
      "        [0.5687],\n",
      "        [0.5289],\n",
      "        [0.5715],\n",
      "        [0.8585],\n",
      "        [0.8849],\n",
      "        [0.9215],\n",
      "        [0.8654],\n",
      "        [0.8998],\n",
      "        [0.9058],\n",
      "        [0.8902],\n",
      "        [0.9304],\n",
      "        [0.9359],\n",
      "        [0.9720],\n",
      "        [0.9869],\n",
      "        [1.0125],\n",
      "        [0.9770],\n",
      "        [0.9668],\n",
      "        [0.9435],\n",
      "        [0.9342],\n",
      "        [0.9286],\n",
      "        [0.8724],\n",
      "        [0.8878],\n",
      "        [0.8979],\n",
      "        [0.8709],\n",
      "        [0.8560],\n",
      "        [0.8514],\n",
      "        [0.8668],\n",
      "        [0.8594],\n",
      "        [0.8677],\n",
      "        [0.8624],\n",
      "        [0.8423],\n",
      "        [0.8247],\n",
      "        [0.8472],\n",
      "        [0.8591],\n",
      "        [0.8278],\n",
      "        [0.8558],\n",
      "        [0.8800],\n",
      "        [0.8952],\n",
      "        [0.8798],\n",
      "        [0.8932],\n",
      "        [0.8872],\n",
      "        [0.8982],\n",
      "        [0.8917],\n",
      "        [0.8757],\n",
      "        [0.8957],\n",
      "        [0.9102],\n",
      "        [0.9015],\n",
      "        [0.8806],\n",
      "        [0.8721],\n",
      "        [0.8914],\n",
      "        [0.9036],\n",
      "        [0.9146],\n",
      "        [0.8604],\n",
      "        [0.9060],\n",
      "        [0.8733],\n",
      "        [0.8689],\n",
      "        [0.8531],\n",
      "        [0.8632],\n",
      "        [0.8463],\n",
      "        [0.8301],\n",
      "        [0.8423],\n",
      "        [0.8592],\n",
      "        [0.8496],\n",
      "        [0.8640],\n",
      "        [0.8822],\n",
      "        [0.8599],\n",
      "        [0.8595],\n",
      "        [0.8255],\n",
      "        [0.7968],\n",
      "        [0.8412],\n",
      "        [0.8344],\n",
      "        [0.8067],\n",
      "        [0.8025],\n",
      "        [0.7636],\n",
      "        [0.7761],\n",
      "        [0.8034],\n",
      "        [0.7811],\n",
      "        [0.7554],\n",
      "        [0.7311],\n",
      "        [0.6589],\n",
      "        [0.6713],\n",
      "        [0.6618],\n",
      "        [0.6928],\n",
      "        [0.6847],\n",
      "        [0.6591],\n",
      "        [0.6320],\n",
      "        [0.5824],\n",
      "        [0.5919],\n",
      "        [0.5449]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.1011],\n",
      "        [0.0653],\n",
      "        [0.0549],\n",
      "        [0.0201],\n",
      "        [0.0190],\n",
      "        [0.0171],\n",
      "        [0.0110],\n",
      "        [0.0161],\n",
      "        [0.0241],\n",
      "        [0.0124],\n",
      "        [0.0107],\n",
      "        [0.0065],\n",
      "        [0.0011],\n",
      "        [0.0051],\n",
      "        [0.0240],\n",
      "        [0.0287],\n",
      "        [0.0436],\n",
      "        [0.0427],\n",
      "        [0.0037],\n",
      "        [0.0546],\n",
      "        [0.0714],\n",
      "        [0.0794],\n",
      "        [0.0207],\n",
      "        [0.0292],\n",
      "        [0.0763],\n",
      "        [0.0846],\n",
      "        [0.0691],\n",
      "        [0.0408],\n",
      "        [0.0035],\n",
      "        [0.0058],\n",
      "        [0.0334],\n",
      "        [0.0203],\n",
      "        [0.0165],\n",
      "        [0.0365],\n",
      "        [0.0331],\n",
      "        [0.0152],\n",
      "        [0.0165],\n",
      "        [0.0263],\n",
      "        [0.0388],\n",
      "        [0.0450],\n",
      "        [0.0027],\n",
      "        [0.0034],\n",
      "        [0.0214],\n",
      "        [0.0665],\n",
      "        [0.0612],\n",
      "        [0.0308],\n",
      "        [0.0387],\n",
      "        [0.0245],\n",
      "        [0.0176],\n",
      "        [0.0096],\n",
      "        [0.0235],\n",
      "        [0.0463],\n",
      "        [0.0600],\n",
      "        [0.0808],\n",
      "        [0.0398],\n",
      "        [0.0507],\n",
      "        [0.0236],\n",
      "        [0.0548],\n",
      "        [0.1083],\n",
      "        [0.0928],\n",
      "        [0.0725],\n",
      "        [0.0567],\n",
      "        [0.0506],\n",
      "        [0.0213],\n",
      "        [0.1642],\n",
      "        [0.0481],\n",
      "        [0.0739],\n",
      "        [0.0683],\n",
      "        [0.0080],\n",
      "        [0.0168],\n",
      "        [0.0246],\n",
      "        [0.0146],\n",
      "        [0.0143],\n",
      "        [0.0293],\n",
      "        [0.0633],\n",
      "        [0.0758],\n",
      "        [0.0777],\n",
      "        [0.0762],\n",
      "        [0.1098],\n",
      "        [0.0913],\n",
      "        [0.0381],\n",
      "        [0.0234],\n",
      "        [0.0022],\n",
      "        [0.0489],\n",
      "        [0.0389],\n",
      "        [0.0057],\n",
      "        [0.0407],\n",
      "        [0.0100],\n",
      "        [0.0986],\n",
      "        [0.1144],\n",
      "        [0.1176],\n",
      "        [0.0572],\n",
      "        [0.0356],\n",
      "        [0.0052],\n",
      "        [0.0152],\n",
      "        [0.0997],\n",
      "        [0.0505],\n",
      "        [0.0012],\n",
      "        [0.2317],\n",
      "        [0.0634],\n",
      "        [0.0447],\n",
      "        [0.0015],\n",
      "        [0.0729],\n",
      "        [0.0317],\n",
      "        [0.1162]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0834],\n",
      "        [    0.0430],\n",
      "        [    0.0508],\n",
      "        [    0.0188],\n",
      "        [    0.0205],\n",
      "        [    0.0189],\n",
      "        [    0.0121],\n",
      "        [    0.0169],\n",
      "        [    0.0249],\n",
      "        [    0.0139],\n",
      "        [    0.0127],\n",
      "        [    0.0087],\n",
      "        [    0.0038],\n",
      "        [    0.0080],\n",
      "        [    0.0211],\n",
      "        [    0.0317],\n",
      "        [    0.0460],\n",
      "        [    0.0389],\n",
      "        [    0.0000],\n",
      "        [    0.0532],\n",
      "        [    0.0709],\n",
      "        [    0.0797],\n",
      "        [    0.0210],\n",
      "        [    0.0293],\n",
      "        [    0.0761],\n",
      "        [    0.0833],\n",
      "        [    0.0675],\n",
      "        [    0.0396],\n",
      "        [    0.0025],\n",
      "        [    0.0061],\n",
      "        [    0.0322],\n",
      "        [    0.0226],\n",
      "        [    0.0193],\n",
      "        [    0.0398],\n",
      "        [    0.0357],\n",
      "        [    0.0182],\n",
      "        [    0.0202],\n",
      "        [    0.0292],\n",
      "        [    0.0419],\n",
      "        [    0.0478],\n",
      "        [    0.0004],\n",
      "        [    0.0054],\n",
      "        [    0.0201],\n",
      "        [    0.0657],\n",
      "        [    0.0601],\n",
      "        [    0.0302],\n",
      "        [    0.0388],\n",
      "        [    0.0238],\n",
      "        [    0.0188],\n",
      "        [    0.0113],\n",
      "        [    0.0252],\n",
      "        [    0.0478],\n",
      "        [    0.0619],\n",
      "        [    0.0827],\n",
      "        [    0.0407],\n",
      "        [    0.0520],\n",
      "        [    0.0250],\n",
      "        [    0.0528],\n",
      "        [    0.1064],\n",
      "        [    0.0912],\n",
      "        [    0.0706],\n",
      "        [    0.0553],\n",
      "        [    0.0498],\n",
      "        [    0.0215],\n",
      "        [    0.1624],\n",
      "        [    0.0462],\n",
      "        [    0.0723],\n",
      "        [    0.0667],\n",
      "        [    0.0069],\n",
      "        [    0.0180],\n",
      "        [    0.0219],\n",
      "        [    0.0120],\n",
      "        [    0.0124],\n",
      "        [    0.0277],\n",
      "        [    0.0623],\n",
      "        [    0.0756],\n",
      "        [    0.0775],\n",
      "        [    0.0761],\n",
      "        [    0.1099],\n",
      "        [    0.0915],\n",
      "        [    0.0388],\n",
      "        [    0.0244],\n",
      "        [    0.0031],\n",
      "        [    0.0507],\n",
      "        [    0.0418],\n",
      "        [    0.0031],\n",
      "        [    0.0383],\n",
      "        [    0.0119],\n",
      "        [    0.0971],\n",
      "        [    0.1120],\n",
      "        [    0.1152],\n",
      "        [    0.0555],\n",
      "        [    0.0338],\n",
      "        [    0.0059],\n",
      "        [    0.0153],\n",
      "        [    0.0993],\n",
      "        [    0.0503],\n",
      "        [    0.0016],\n",
      "        [    0.2307],\n",
      "        [    0.0622],\n",
      "        [    0.0432],\n",
      "        [    0.0031],\n",
      "        [    0.0746],\n",
      "        [    0.0313],\n",
      "        [    0.1152]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 106\n",
      "剩餘X 資料 torch.Size([271, 18])\n",
      "剩餘Y 資料 torch.Size([271, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7168])\n",
      "目前模型的Data狀態 torch.Size([106, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.4835],\n",
      "        [0.4835],\n",
      "        [0.5006],\n",
      "        [0.5450],\n",
      "        [0.5795],\n",
      "        [0.5799],\n",
      "        [0.5680],\n",
      "        [0.5648],\n",
      "        [0.5513],\n",
      "        [0.5545],\n",
      "        [0.5493],\n",
      "        [0.5427],\n",
      "        [0.5368],\n",
      "        [0.5310],\n",
      "        [0.5484],\n",
      "        [0.5730],\n",
      "        [0.5710],\n",
      "        [0.5327],\n",
      "        [0.5678],\n",
      "        [0.8571],\n",
      "        [0.8844],\n",
      "        [0.9218],\n",
      "        [0.8657],\n",
      "        [0.8997],\n",
      "        [0.9060],\n",
      "        [0.8915],\n",
      "        [0.9319],\n",
      "        [0.9371],\n",
      "        [0.9730],\n",
      "        [0.9867],\n",
      "        [1.0112],\n",
      "        [0.9747],\n",
      "        [0.9641],\n",
      "        [0.9402],\n",
      "        [0.9316],\n",
      "        [0.9256],\n",
      "        [0.8687],\n",
      "        [0.8849],\n",
      "        [0.8947],\n",
      "        [0.8681],\n",
      "        [0.8538],\n",
      "        [0.8494],\n",
      "        [0.8656],\n",
      "        [0.8585],\n",
      "        [0.8666],\n",
      "        [0.8618],\n",
      "        [0.8425],\n",
      "        [0.8254],\n",
      "        [0.8483],\n",
      "        [0.8609],\n",
      "        [0.8294],\n",
      "        [0.8572],\n",
      "        [0.8818],\n",
      "        [0.8972],\n",
      "        [0.8808],\n",
      "        [0.8946],\n",
      "        [0.8885],\n",
      "        [0.9002],\n",
      "        [0.8936],\n",
      "        [0.8773],\n",
      "        [0.8976],\n",
      "        [0.9117],\n",
      "        [0.9023],\n",
      "        [0.8803],\n",
      "        [0.8703],\n",
      "        [0.8895],\n",
      "        [0.9019],\n",
      "        [0.9129],\n",
      "        [0.8593],\n",
      "        [0.9072],\n",
      "        [0.8759],\n",
      "        [0.8715],\n",
      "        [0.8550],\n",
      "        [0.8649],\n",
      "        [0.8473],\n",
      "        [0.8304],\n",
      "        [0.8425],\n",
      "        [0.8593],\n",
      "        [0.8495],\n",
      "        [0.8638],\n",
      "        [0.8815],\n",
      "        [0.8590],\n",
      "        [0.8585],\n",
      "        [0.8236],\n",
      "        [0.7938],\n",
      "        [0.8386],\n",
      "        [0.8319],\n",
      "        [0.8048],\n",
      "        [0.8010],\n",
      "        [0.7613],\n",
      "        [0.7737],\n",
      "        [0.8017],\n",
      "        [0.7793],\n",
      "        [0.7547],\n",
      "        [0.7310],\n",
      "        [0.6593],\n",
      "        [0.6715],\n",
      "        [0.6615],\n",
      "        [0.6919],\n",
      "        [0.6836],\n",
      "        [0.6575],\n",
      "        [0.6304],\n",
      "        [0.5807],\n",
      "        [0.5923],\n",
      "        [0.5459],\n",
      "        [0.5265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0834],\n",
      "        [    0.0430],\n",
      "        [    0.0508],\n",
      "        [    0.0188],\n",
      "        [    0.0205],\n",
      "        [    0.0189],\n",
      "        [    0.0121],\n",
      "        [    0.0169],\n",
      "        [    0.0249],\n",
      "        [    0.0139],\n",
      "        [    0.0127],\n",
      "        [    0.0087],\n",
      "        [    0.0038],\n",
      "        [    0.0080],\n",
      "        [    0.0211],\n",
      "        [    0.0317],\n",
      "        [    0.0460],\n",
      "        [    0.0389],\n",
      "        [    0.0000],\n",
      "        [    0.0532],\n",
      "        [    0.0709],\n",
      "        [    0.0797],\n",
      "        [    0.0210],\n",
      "        [    0.0293],\n",
      "        [    0.0761],\n",
      "        [    0.0833],\n",
      "        [    0.0675],\n",
      "        [    0.0396],\n",
      "        [    0.0025],\n",
      "        [    0.0061],\n",
      "        [    0.0322],\n",
      "        [    0.0226],\n",
      "        [    0.0193],\n",
      "        [    0.0398],\n",
      "        [    0.0357],\n",
      "        [    0.0182],\n",
      "        [    0.0202],\n",
      "        [    0.0292],\n",
      "        [    0.0419],\n",
      "        [    0.0478],\n",
      "        [    0.0004],\n",
      "        [    0.0054],\n",
      "        [    0.0201],\n",
      "        [    0.0657],\n",
      "        [    0.0601],\n",
      "        [    0.0302],\n",
      "        [    0.0388],\n",
      "        [    0.0238],\n",
      "        [    0.0188],\n",
      "        [    0.0113],\n",
      "        [    0.0252],\n",
      "        [    0.0478],\n",
      "        [    0.0619],\n",
      "        [    0.0827],\n",
      "        [    0.0407],\n",
      "        [    0.0520],\n",
      "        [    0.0250],\n",
      "        [    0.0528],\n",
      "        [    0.1064],\n",
      "        [    0.0912],\n",
      "        [    0.0706],\n",
      "        [    0.0553],\n",
      "        [    0.0498],\n",
      "        [    0.0215],\n",
      "        [    0.1624],\n",
      "        [    0.0462],\n",
      "        [    0.0723],\n",
      "        [    0.0667],\n",
      "        [    0.0069],\n",
      "        [    0.0180],\n",
      "        [    0.0219],\n",
      "        [    0.0120],\n",
      "        [    0.0124],\n",
      "        [    0.0277],\n",
      "        [    0.0623],\n",
      "        [    0.0756],\n",
      "        [    0.0775],\n",
      "        [    0.0761],\n",
      "        [    0.1099],\n",
      "        [    0.0915],\n",
      "        [    0.0388],\n",
      "        [    0.0244],\n",
      "        [    0.0031],\n",
      "        [    0.0507],\n",
      "        [    0.0418],\n",
      "        [    0.0031],\n",
      "        [    0.0383],\n",
      "        [    0.0119],\n",
      "        [    0.0971],\n",
      "        [    0.1120],\n",
      "        [    0.1152],\n",
      "        [    0.0555],\n",
      "        [    0.0338],\n",
      "        [    0.0059],\n",
      "        [    0.0153],\n",
      "        [    0.0993],\n",
      "        [    0.0503],\n",
      "        [    0.0016],\n",
      "        [    0.2307],\n",
      "        [    0.0622],\n",
      "        [    0.0432],\n",
      "        [    0.0031],\n",
      "        [    0.0746],\n",
      "        [    0.0313],\n",
      "        [    0.1152],\n",
      "        [    0.1903]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0575],\n",
      "        [    0.0171],\n",
      "        [    0.0397],\n",
      "        [    0.0113],\n",
      "        [    0.0258],\n",
      "        [    0.0245],\n",
      "        [    0.0173],\n",
      "        [    0.0216],\n",
      "        [    0.0295],\n",
      "        [    0.0194],\n",
      "        [    0.0188],\n",
      "        [    0.0153],\n",
      "        [    0.0107],\n",
      "        [    0.0150],\n",
      "        [    0.0136],\n",
      "        [    0.0390],\n",
      "        [    0.0522],\n",
      "        [    0.0308],\n",
      "        [    0.0007],\n",
      "        [    0.0574],\n",
      "        [    0.0756],\n",
      "        [    0.0847],\n",
      "        [    0.0266],\n",
      "        [    0.0248],\n",
      "        [    0.0716],\n",
      "        [    0.0772],\n",
      "        [    0.0615],\n",
      "        [    0.0337],\n",
      "        [    0.0027],\n",
      "        [    0.0025],\n",
      "        [    0.0341],\n",
      "        [    0.0218],\n",
      "        [    0.0192],\n",
      "        [    0.0403],\n",
      "        [    0.0352],\n",
      "        [    0.0181],\n",
      "        [    0.0206],\n",
      "        [    0.0288],\n",
      "        [    0.0422],\n",
      "        [    0.0473],\n",
      "        [    0.0015],\n",
      "        [    0.0041],\n",
      "        [    0.0222],\n",
      "        [    0.0682],\n",
      "        [    0.0622],\n",
      "        [    0.0322],\n",
      "        [    0.0416],\n",
      "        [    0.0204],\n",
      "        [    0.0224],\n",
      "        [    0.0153],\n",
      "        [    0.0294],\n",
      "        [    0.0517],\n",
      "        [    0.0661],\n",
      "        [    0.0871],\n",
      "        [    0.0438],\n",
      "        [    0.0555],\n",
      "        [    0.0284],\n",
      "        [    0.0488],\n",
      "        [    0.1021],\n",
      "        [    0.0871],\n",
      "        [    0.0664],\n",
      "        [    0.0517],\n",
      "        [    0.0468],\n",
      "        [    0.0197],\n",
      "        [    0.1624],\n",
      "        [    0.0457],\n",
      "        [    0.0720],\n",
      "        [    0.0663],\n",
      "        [    0.0077],\n",
      "        [    0.0207],\n",
      "        [    0.0172],\n",
      "        [    0.0066],\n",
      "        [    0.0078],\n",
      "        [    0.0235],\n",
      "        [    0.0584],\n",
      "        [    0.0725],\n",
      "        [    0.0746],\n",
      "        [    0.0734],\n",
      "        [    0.1065],\n",
      "        [    0.0880],\n",
      "        [    0.0363],\n",
      "        [    0.0216],\n",
      "        [    0.0002],\n",
      "        [    0.0483],\n",
      "        [    0.0400],\n",
      "        [    0.0054],\n",
      "        [    0.0409],\n",
      "        [    0.0079],\n",
      "        [    0.1018],\n",
      "        [    0.1165],\n",
      "        [    0.1200],\n",
      "        [    0.0612],\n",
      "        [    0.0398],\n",
      "        [    0.0016],\n",
      "        [    0.0069],\n",
      "        [    0.0890],\n",
      "        [    0.0400],\n",
      "        [    0.0083],\n",
      "        [    0.2394],\n",
      "        [    0.0711],\n",
      "        [    0.0518],\n",
      "        [    0.0054],\n",
      "        [    0.0657],\n",
      "        [    0.0201],\n",
      "        [    0.1023],\n",
      "        [    0.1767]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 107\n",
      "剩餘X 資料 torch.Size([270, 18])\n",
      "剩餘Y 資料 torch.Size([270, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7355])\n",
      "目前模型的Data狀態 torch.Size([107, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5094],\n",
      "        [0.5094],\n",
      "        [0.5118],\n",
      "        [0.5525],\n",
      "        [0.5848],\n",
      "        [0.5856],\n",
      "        [0.5731],\n",
      "        [0.5695],\n",
      "        [0.5559],\n",
      "        [0.5599],\n",
      "        [0.5554],\n",
      "        [0.5493],\n",
      "        [0.5437],\n",
      "        [0.5381],\n",
      "        [0.5560],\n",
      "        [0.5803],\n",
      "        [0.5773],\n",
      "        [0.5408],\n",
      "        [0.5685],\n",
      "        [0.8614],\n",
      "        [0.8892],\n",
      "        [0.9268],\n",
      "        [0.8713],\n",
      "        [0.9042],\n",
      "        [0.9105],\n",
      "        [0.8976],\n",
      "        [0.9379],\n",
      "        [0.9430],\n",
      "        [0.9782],\n",
      "        [0.9903],\n",
      "        [1.0132],\n",
      "        [0.9754],\n",
      "        [0.9642],\n",
      "        [0.9397],\n",
      "        [0.9321],\n",
      "        [0.9257],\n",
      "        [0.8684],\n",
      "        [0.8853],\n",
      "        [0.8945],\n",
      "        [0.8686],\n",
      "        [0.8549],\n",
      "        [0.8507],\n",
      "        [0.8676],\n",
      "        [0.8611],\n",
      "        [0.8688],\n",
      "        [0.8638],\n",
      "        [0.8453],\n",
      "        [0.8288],\n",
      "        [0.8520],\n",
      "        [0.8649],\n",
      "        [0.8336],\n",
      "        [0.8611],\n",
      "        [0.8861],\n",
      "        [0.9015],\n",
      "        [0.8838],\n",
      "        [0.8980],\n",
      "        [0.8920],\n",
      "        [0.9042],\n",
      "        [0.8979],\n",
      "        [0.8814],\n",
      "        [0.9018],\n",
      "        [0.9152],\n",
      "        [0.9053],\n",
      "        [0.8821],\n",
      "        [0.8703],\n",
      "        [0.8890],\n",
      "        [0.9017],\n",
      "        [0.9125],\n",
      "        [0.8601],\n",
      "        [0.9099],\n",
      "        [0.8807],\n",
      "        [0.8769],\n",
      "        [0.8596],\n",
      "        [0.8691],\n",
      "        [0.8512],\n",
      "        [0.8334],\n",
      "        [0.8453],\n",
      "        [0.8620],\n",
      "        [0.8529],\n",
      "        [0.8672],\n",
      "        [0.8840],\n",
      "        [0.8617],\n",
      "        [0.8615],\n",
      "        [0.8260],\n",
      "        [0.7957],\n",
      "        [0.8409],\n",
      "        [0.8345],\n",
      "        [0.8087],\n",
      "        [0.8057],\n",
      "        [0.7658],\n",
      "        [0.7785],\n",
      "        [0.8074],\n",
      "        [0.7853],\n",
      "        [0.7622],\n",
      "        [0.7394],\n",
      "        [0.6696],\n",
      "        [0.6818],\n",
      "        [0.6713],\n",
      "        [0.7006],\n",
      "        [0.6924],\n",
      "        [0.6661],\n",
      "        [0.6389],\n",
      "        [0.5896],\n",
      "        [0.6034],\n",
      "        [0.5588],\n",
      "        [0.5400],\n",
      "        [0.5417]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0575],\n",
      "        [    0.0171],\n",
      "        [    0.0397],\n",
      "        [    0.0113],\n",
      "        [    0.0258],\n",
      "        [    0.0245],\n",
      "        [    0.0173],\n",
      "        [    0.0216],\n",
      "        [    0.0295],\n",
      "        [    0.0194],\n",
      "        [    0.0188],\n",
      "        [    0.0153],\n",
      "        [    0.0107],\n",
      "        [    0.0150],\n",
      "        [    0.0136],\n",
      "        [    0.0390],\n",
      "        [    0.0522],\n",
      "        [    0.0308],\n",
      "        [    0.0007],\n",
      "        [    0.0574],\n",
      "        [    0.0756],\n",
      "        [    0.0847],\n",
      "        [    0.0266],\n",
      "        [    0.0248],\n",
      "        [    0.0716],\n",
      "        [    0.0772],\n",
      "        [    0.0615],\n",
      "        [    0.0337],\n",
      "        [    0.0027],\n",
      "        [    0.0025],\n",
      "        [    0.0341],\n",
      "        [    0.0218],\n",
      "        [    0.0192],\n",
      "        [    0.0403],\n",
      "        [    0.0352],\n",
      "        [    0.0181],\n",
      "        [    0.0206],\n",
      "        [    0.0288],\n",
      "        [    0.0422],\n",
      "        [    0.0473],\n",
      "        [    0.0015],\n",
      "        [    0.0041],\n",
      "        [    0.0222],\n",
      "        [    0.0682],\n",
      "        [    0.0622],\n",
      "        [    0.0322],\n",
      "        [    0.0416],\n",
      "        [    0.0204],\n",
      "        [    0.0224],\n",
      "        [    0.0153],\n",
      "        [    0.0294],\n",
      "        [    0.0517],\n",
      "        [    0.0661],\n",
      "        [    0.0871],\n",
      "        [    0.0438],\n",
      "        [    0.0555],\n",
      "        [    0.0284],\n",
      "        [    0.0488],\n",
      "        [    0.1021],\n",
      "        [    0.0871],\n",
      "        [    0.0664],\n",
      "        [    0.0517],\n",
      "        [    0.0468],\n",
      "        [    0.0197],\n",
      "        [    0.1624],\n",
      "        [    0.0457],\n",
      "        [    0.0720],\n",
      "        [    0.0663],\n",
      "        [    0.0077],\n",
      "        [    0.0207],\n",
      "        [    0.0172],\n",
      "        [    0.0066],\n",
      "        [    0.0078],\n",
      "        [    0.0235],\n",
      "        [    0.0584],\n",
      "        [    0.0725],\n",
      "        [    0.0746],\n",
      "        [    0.0734],\n",
      "        [    0.1065],\n",
      "        [    0.0880],\n",
      "        [    0.0363],\n",
      "        [    0.0216],\n",
      "        [    0.0002],\n",
      "        [    0.0483],\n",
      "        [    0.0400],\n",
      "        [    0.0054],\n",
      "        [    0.0409],\n",
      "        [    0.0079],\n",
      "        [    0.1018],\n",
      "        [    0.1165],\n",
      "        [    0.1200],\n",
      "        [    0.0612],\n",
      "        [    0.0398],\n",
      "        [    0.0016],\n",
      "        [    0.0069],\n",
      "        [    0.0890],\n",
      "        [    0.0400],\n",
      "        [    0.0083],\n",
      "        [    0.2394],\n",
      "        [    0.0711],\n",
      "        [    0.0518],\n",
      "        [    0.0054],\n",
      "        [    0.0657],\n",
      "        [    0.0201],\n",
      "        [    0.1023],\n",
      "        [    0.1767],\n",
      "        [    0.1938]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0405],\n",
      "        [    0.0001],\n",
      "        [    0.0250],\n",
      "        [    0.0063],\n",
      "        [    0.0276],\n",
      "        [    0.0266],\n",
      "        [    0.0189],\n",
      "        [    0.0228],\n",
      "        [    0.0305],\n",
      "        [    0.0212],\n",
      "        [    0.0213],\n",
      "        [    0.0183],\n",
      "        [    0.0140],\n",
      "        [    0.0184],\n",
      "        [    0.0100],\n",
      "        [    0.0424],\n",
      "        [    0.0545],\n",
      "        [    0.0271],\n",
      "        [    0.0005],\n",
      "        [    0.0596],\n",
      "        [    0.0779],\n",
      "        [    0.0867],\n",
      "        [    0.0296],\n",
      "        [    0.0233],\n",
      "        [    0.0704],\n",
      "        [    0.0744],\n",
      "        [    0.0592],\n",
      "        [    0.0313],\n",
      "        [    0.0044],\n",
      "        [    0.0024],\n",
      "        [    0.0326],\n",
      "        [    0.0242],\n",
      "        [    0.0223],\n",
      "        [    0.0439],\n",
      "        [    0.0378],\n",
      "        [    0.0210],\n",
      "        [    0.0233],\n",
      "        [    0.0311],\n",
      "        [    0.0451],\n",
      "        [    0.0495],\n",
      "        [    0.0001],\n",
      "        [    0.0055],\n",
      "        [    0.0211],\n",
      "        [    0.0676],\n",
      "        [    0.0611],\n",
      "        [    0.0305],\n",
      "        [    0.0406],\n",
      "        [    0.0210],\n",
      "        [    0.0218],\n",
      "        [    0.0148],\n",
      "        [    0.0291],\n",
      "        [    0.0510],\n",
      "        [    0.0657],\n",
      "        [    0.0867],\n",
      "        [    0.0422],\n",
      "        [    0.0540],\n",
      "        [    0.0272],\n",
      "        [    0.0498],\n",
      "        [    0.1026],\n",
      "        [    0.0874],\n",
      "        [    0.0668],\n",
      "        [    0.0527],\n",
      "        [    0.0481],\n",
      "        [    0.0218],\n",
      "        [    0.1587],\n",
      "        [    0.0414],\n",
      "        [    0.0678],\n",
      "        [    0.0617],\n",
      "        [    0.0044],\n",
      "        [    0.0188],\n",
      "        [    0.0170],\n",
      "        [    0.0058],\n",
      "        [    0.0076],\n",
      "        [    0.0236],\n",
      "        [    0.0586],\n",
      "        [    0.0733],\n",
      "        [    0.0757],\n",
      "        [    0.0747],\n",
      "        [    0.1067],\n",
      "        [    0.0881],\n",
      "        [    0.0375],\n",
      "        [    0.0223],\n",
      "        [    0.0005],\n",
      "        [    0.0487],\n",
      "        [    0.0404],\n",
      "        [    0.0053],\n",
      "        [    0.0413],\n",
      "        [    0.0061],\n",
      "        [    0.1045],\n",
      "        [    0.1193],\n",
      "        [    0.1231],\n",
      "        [    0.0650],\n",
      "        [    0.0440],\n",
      "        [    0.0070],\n",
      "        [    0.0003],\n",
      "        [    0.0797],\n",
      "        [    0.0309],\n",
      "        [    0.0172],\n",
      "        [    0.2472],\n",
      "        [    0.0792],\n",
      "        [    0.0599],\n",
      "        [    0.0135],\n",
      "        [    0.0569],\n",
      "        [    0.0094],\n",
      "        [    0.0894],\n",
      "        [    0.1628],\n",
      "        [    0.1810]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 108\n",
      "剩餘X 資料 torch.Size([269, 18])\n",
      "剩餘Y 資料 torch.Size([269, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7342])\n",
      "目前模型的Data狀態 torch.Size([108, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5264],\n",
      "        [0.5264],\n",
      "        [0.5264],\n",
      "        [0.5575],\n",
      "        [0.5866],\n",
      "        [0.5877],\n",
      "        [0.5748],\n",
      "        [0.5708],\n",
      "        [0.5569],\n",
      "        [0.5617],\n",
      "        [0.5580],\n",
      "        [0.5523],\n",
      "        [0.5469],\n",
      "        [0.5414],\n",
      "        [0.5596],\n",
      "        [0.5837],\n",
      "        [0.5796],\n",
      "        [0.5445],\n",
      "        [0.5673],\n",
      "        [0.8636],\n",
      "        [0.8914],\n",
      "        [0.9289],\n",
      "        [0.8743],\n",
      "        [0.9056],\n",
      "        [0.9117],\n",
      "        [0.9003],\n",
      "        [0.9402],\n",
      "        [0.9454],\n",
      "        [0.9799],\n",
      "        [0.9904],\n",
      "        [1.0117],\n",
      "        [0.9730],\n",
      "        [0.9611],\n",
      "        [0.9361],\n",
      "        [0.9296],\n",
      "        [0.9228],\n",
      "        [0.8657],\n",
      "        [0.8830],\n",
      "        [0.8915],\n",
      "        [0.8664],\n",
      "        [0.8534],\n",
      "        [0.8492],\n",
      "        [0.8666],\n",
      "        [0.8605],\n",
      "        [0.8676],\n",
      "        [0.8621],\n",
      "        [0.8443],\n",
      "        [0.8282],\n",
      "        [0.8513],\n",
      "        [0.8644],\n",
      "        [0.8334],\n",
      "        [0.8604],\n",
      "        [0.8856],\n",
      "        [0.9012],\n",
      "        [0.8822],\n",
      "        [0.8966],\n",
      "        [0.8907],\n",
      "        [0.9032],\n",
      "        [0.8974],\n",
      "        [0.8810],\n",
      "        [0.9013],\n",
      "        [0.9142],\n",
      "        [0.9040],\n",
      "        [0.8800],\n",
      "        [0.8666],\n",
      "        [0.8846],\n",
      "        [0.8974],\n",
      "        [0.9080],\n",
      "        [0.8568],\n",
      "        [0.9081],\n",
      "        [0.8808],\n",
      "        [0.8777],\n",
      "        [0.8598],\n",
      "        [0.8690],\n",
      "        [0.8510],\n",
      "        [0.8326],\n",
      "        [0.8443],\n",
      "        [0.8608],\n",
      "        [0.8527],\n",
      "        [0.8671],\n",
      "        [0.8828],\n",
      "        [0.8610],\n",
      "        [0.8611],\n",
      "        [0.8256],\n",
      "        [0.7953],\n",
      "        [0.8408],\n",
      "        [0.8349],\n",
      "        [0.8106],\n",
      "        [0.8083],\n",
      "        [0.7685],\n",
      "        [0.7816],\n",
      "        [0.8111],\n",
      "        [0.7895],\n",
      "        [0.7676],\n",
      "        [0.7460],\n",
      "        [0.6789],\n",
      "        [0.6909],\n",
      "        [0.6802],\n",
      "        [0.7083],\n",
      "        [0.7005],\n",
      "        [0.6742],\n",
      "        [0.6470],\n",
      "        [0.5984],\n",
      "        [0.6141],\n",
      "        [0.5716],\n",
      "        [0.5539],\n",
      "        [0.5545],\n",
      "        [0.5495]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0405],\n",
      "        [    0.0001],\n",
      "        [    0.0250],\n",
      "        [    0.0063],\n",
      "        [    0.0276],\n",
      "        [    0.0266],\n",
      "        [    0.0189],\n",
      "        [    0.0228],\n",
      "        [    0.0305],\n",
      "        [    0.0212],\n",
      "        [    0.0213],\n",
      "        [    0.0183],\n",
      "        [    0.0140],\n",
      "        [    0.0184],\n",
      "        [    0.0100],\n",
      "        [    0.0424],\n",
      "        [    0.0545],\n",
      "        [    0.0271],\n",
      "        [    0.0005],\n",
      "        [    0.0596],\n",
      "        [    0.0779],\n",
      "        [    0.0867],\n",
      "        [    0.0296],\n",
      "        [    0.0233],\n",
      "        [    0.0704],\n",
      "        [    0.0744],\n",
      "        [    0.0592],\n",
      "        [    0.0313],\n",
      "        [    0.0044],\n",
      "        [    0.0024],\n",
      "        [    0.0326],\n",
      "        [    0.0242],\n",
      "        [    0.0223],\n",
      "        [    0.0439],\n",
      "        [    0.0378],\n",
      "        [    0.0210],\n",
      "        [    0.0233],\n",
      "        [    0.0311],\n",
      "        [    0.0451],\n",
      "        [    0.0495],\n",
      "        [    0.0001],\n",
      "        [    0.0055],\n",
      "        [    0.0211],\n",
      "        [    0.0676],\n",
      "        [    0.0611],\n",
      "        [    0.0305],\n",
      "        [    0.0406],\n",
      "        [    0.0210],\n",
      "        [    0.0218],\n",
      "        [    0.0148],\n",
      "        [    0.0291],\n",
      "        [    0.0510],\n",
      "        [    0.0657],\n",
      "        [    0.0867],\n",
      "        [    0.0422],\n",
      "        [    0.0540],\n",
      "        [    0.0272],\n",
      "        [    0.0498],\n",
      "        [    0.1026],\n",
      "        [    0.0874],\n",
      "        [    0.0668],\n",
      "        [    0.0527],\n",
      "        [    0.0481],\n",
      "        [    0.0218],\n",
      "        [    0.1587],\n",
      "        [    0.0414],\n",
      "        [    0.0678],\n",
      "        [    0.0617],\n",
      "        [    0.0044],\n",
      "        [    0.0188],\n",
      "        [    0.0170],\n",
      "        [    0.0058],\n",
      "        [    0.0076],\n",
      "        [    0.0236],\n",
      "        [    0.0586],\n",
      "        [    0.0733],\n",
      "        [    0.0757],\n",
      "        [    0.0747],\n",
      "        [    0.1067],\n",
      "        [    0.0881],\n",
      "        [    0.0375],\n",
      "        [    0.0223],\n",
      "        [    0.0005],\n",
      "        [    0.0487],\n",
      "        [    0.0404],\n",
      "        [    0.0053],\n",
      "        [    0.0413],\n",
      "        [    0.0061],\n",
      "        [    0.1045],\n",
      "        [    0.1193],\n",
      "        [    0.1231],\n",
      "        [    0.0650],\n",
      "        [    0.0440],\n",
      "        [    0.0070],\n",
      "        [    0.0003],\n",
      "        [    0.0797],\n",
      "        [    0.0309],\n",
      "        [    0.0172],\n",
      "        [    0.2472],\n",
      "        [    0.0792],\n",
      "        [    0.0599],\n",
      "        [    0.0135],\n",
      "        [    0.0569],\n",
      "        [    0.0094],\n",
      "        [    0.0894],\n",
      "        [    0.1628],\n",
      "        [    0.1810],\n",
      "        [    0.1847]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0294],\n",
      "        [    0.0109],\n",
      "        [    0.0140],\n",
      "        [    0.0010],\n",
      "        [    0.0292],\n",
      "        [    0.0285],\n",
      "        [    0.0205],\n",
      "        [    0.0240],\n",
      "        [    0.0313],\n",
      "        [    0.0226],\n",
      "        [    0.0235],\n",
      "        [    0.0209],\n",
      "        [    0.0169],\n",
      "        [    0.0212],\n",
      "        [    0.0074],\n",
      "        [    0.0450],\n",
      "        [    0.0560],\n",
      "        [    0.0248],\n",
      "        [    0.0007],\n",
      "        [    0.0631],\n",
      "        [    0.0811],\n",
      "        [    0.0896],\n",
      "        [    0.0336],\n",
      "        [    0.0211],\n",
      "        [    0.0687],\n",
      "        [    0.0712],\n",
      "        [    0.0566],\n",
      "        [    0.0285],\n",
      "        [    0.0065],\n",
      "        [    0.0016],\n",
      "        [    0.0319],\n",
      "        [    0.0256],\n",
      "        [    0.0244],\n",
      "        [    0.0463],\n",
      "        [    0.0392],\n",
      "        [    0.0226],\n",
      "        [    0.0245],\n",
      "        [    0.0320],\n",
      "        [    0.0466],\n",
      "        [    0.0501],\n",
      "        [    0.0001],\n",
      "        [    0.0059],\n",
      "        [    0.0210],\n",
      "        [    0.0680],\n",
      "        [    0.0609],\n",
      "        [    0.0294],\n",
      "        [    0.0399],\n",
      "        [    0.0214],\n",
      "        [    0.0211],\n",
      "        [    0.0141],\n",
      "        [    0.0286],\n",
      "        [    0.0499],\n",
      "        [    0.0648],\n",
      "        [    0.0859],\n",
      "        [    0.0401],\n",
      "        [    0.0521],\n",
      "        [    0.0255],\n",
      "        [    0.0513],\n",
      "        [    0.1035],\n",
      "        [    0.0879],\n",
      "        [    0.0674],\n",
      "        [    0.0538],\n",
      "        [    0.0493],\n",
      "        [    0.0235],\n",
      "        [    0.1557],\n",
      "        [    0.0375],\n",
      "        [    0.0640],\n",
      "        [    0.0576],\n",
      "        [    0.0015],\n",
      "        [    0.0168],\n",
      "        [    0.0171],\n",
      "        [    0.0052],\n",
      "        [    0.0076],\n",
      "        [    0.0238],\n",
      "        [    0.0587],\n",
      "        [    0.0739],\n",
      "        [    0.0766],\n",
      "        [    0.0759],\n",
      "        [    0.1066],\n",
      "        [    0.0879],\n",
      "        [    0.0384],\n",
      "        [    0.0226],\n",
      "        [    0.0005],\n",
      "        [    0.0484],\n",
      "        [    0.0397],\n",
      "        [    0.0064],\n",
      "        [    0.0427],\n",
      "        [    0.0031],\n",
      "        [    0.1081],\n",
      "        [    0.1230],\n",
      "        [    0.1272],\n",
      "        [    0.0695],\n",
      "        [    0.0490],\n",
      "        [    0.0129],\n",
      "        [    0.0065],\n",
      "        [    0.0700],\n",
      "        [    0.0212],\n",
      "        [    0.0269],\n",
      "        [    0.2558],\n",
      "        [    0.0883],\n",
      "        [    0.0691],\n",
      "        [    0.0227],\n",
      "        [    0.0469],\n",
      "        [    0.0022],\n",
      "        [    0.0755],\n",
      "        [    0.1478],\n",
      "        [    0.1668],\n",
      "        [    0.1707]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 109\n",
      "剩餘X 資料 torch.Size([268, 18])\n",
      "剩餘Y 資料 torch.Size([268, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7118])\n",
      "目前模型的Data狀態 torch.Size([109, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5375],\n",
      "        [0.5375],\n",
      "        [0.5375],\n",
      "        [0.5628],\n",
      "        [0.5882],\n",
      "        [0.5896],\n",
      "        [0.5764],\n",
      "        [0.5720],\n",
      "        [0.5578],\n",
      "        [0.5632],\n",
      "        [0.5601],\n",
      "        [0.5549],\n",
      "        [0.5498],\n",
      "        [0.5442],\n",
      "        [0.5621],\n",
      "        [0.5863],\n",
      "        [0.5811],\n",
      "        [0.5469],\n",
      "        [0.5670],\n",
      "        [0.8671],\n",
      "        [0.8947],\n",
      "        [0.9318],\n",
      "        [0.8783],\n",
      "        [0.9079],\n",
      "        [0.9135],\n",
      "        [0.9035],\n",
      "        [0.9428],\n",
      "        [0.9482],\n",
      "        [0.9821],\n",
      "        [0.9911],\n",
      "        [1.0109],\n",
      "        [0.9716],\n",
      "        [0.9590],\n",
      "        [0.9337],\n",
      "        [0.9282],\n",
      "        [0.9212],\n",
      "        [0.8645],\n",
      "        [0.8821],\n",
      "        [0.8900],\n",
      "        [0.8658],\n",
      "        [0.8534],\n",
      "        [0.8489],\n",
      "        [0.8665],\n",
      "        [0.8609],\n",
      "        [0.8674],\n",
      "        [0.8609],\n",
      "        [0.8436],\n",
      "        [0.8278],\n",
      "        [0.8506],\n",
      "        [0.8637],\n",
      "        [0.8329],\n",
      "        [0.8594],\n",
      "        [0.8848],\n",
      "        [0.9004],\n",
      "        [0.8802],\n",
      "        [0.8947],\n",
      "        [0.8891],\n",
      "        [0.9017],\n",
      "        [0.8965],\n",
      "        [0.8806],\n",
      "        [0.9007],\n",
      "        [0.9132],\n",
      "        [0.9028],\n",
      "        [0.8784],\n",
      "        [0.8637],\n",
      "        [0.8808],\n",
      "        [0.8937],\n",
      "        [0.9038],\n",
      "        [0.8539],\n",
      "        [0.9060],\n",
      "        [0.8807],\n",
      "        [0.8783],\n",
      "        [0.8598],\n",
      "        [0.8688],\n",
      "        [0.8509],\n",
      "        [0.8320],\n",
      "        [0.8434],\n",
      "        [0.8596],\n",
      "        [0.8528],\n",
      "        [0.8673],\n",
      "        [0.8819],\n",
      "        [0.8608],\n",
      "        [0.8612],\n",
      "        [0.8259],\n",
      "        [0.7960],\n",
      "        [0.8419],\n",
      "        [0.8363],\n",
      "        [0.8136],\n",
      "        [0.8120],\n",
      "        [0.7723],\n",
      "        [0.7856],\n",
      "        [0.8156],\n",
      "        [0.7945],\n",
      "        [0.7735],\n",
      "        [0.7528],\n",
      "        [0.6886],\n",
      "        [0.7006],\n",
      "        [0.6899],\n",
      "        [0.7170],\n",
      "        [0.7096],\n",
      "        [0.6835],\n",
      "        [0.6562],\n",
      "        [0.6084],\n",
      "        [0.6257],\n",
      "        [0.5855],\n",
      "        [0.5690],\n",
      "        [0.5687],\n",
      "        [0.5635],\n",
      "        [0.5892]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0294],\n",
      "        [    0.0109],\n",
      "        [    0.0140],\n",
      "        [    0.0010],\n",
      "        [    0.0292],\n",
      "        [    0.0285],\n",
      "        [    0.0205],\n",
      "        [    0.0240],\n",
      "        [    0.0313],\n",
      "        [    0.0226],\n",
      "        [    0.0235],\n",
      "        [    0.0209],\n",
      "        [    0.0169],\n",
      "        [    0.0212],\n",
      "        [    0.0074],\n",
      "        [    0.0450],\n",
      "        [    0.0560],\n",
      "        [    0.0248],\n",
      "        [    0.0007],\n",
      "        [    0.0631],\n",
      "        [    0.0811],\n",
      "        [    0.0896],\n",
      "        [    0.0336],\n",
      "        [    0.0211],\n",
      "        [    0.0687],\n",
      "        [    0.0712],\n",
      "        [    0.0566],\n",
      "        [    0.0285],\n",
      "        [    0.0065],\n",
      "        [    0.0016],\n",
      "        [    0.0319],\n",
      "        [    0.0256],\n",
      "        [    0.0244],\n",
      "        [    0.0463],\n",
      "        [    0.0392],\n",
      "        [    0.0226],\n",
      "        [    0.0245],\n",
      "        [    0.0320],\n",
      "        [    0.0466],\n",
      "        [    0.0501],\n",
      "        [    0.0001],\n",
      "        [    0.0059],\n",
      "        [    0.0210],\n",
      "        [    0.0680],\n",
      "        [    0.0609],\n",
      "        [    0.0294],\n",
      "        [    0.0399],\n",
      "        [    0.0214],\n",
      "        [    0.0211],\n",
      "        [    0.0141],\n",
      "        [    0.0286],\n",
      "        [    0.0499],\n",
      "        [    0.0648],\n",
      "        [    0.0859],\n",
      "        [    0.0401],\n",
      "        [    0.0521],\n",
      "        [    0.0255],\n",
      "        [    0.0513],\n",
      "        [    0.1035],\n",
      "        [    0.0879],\n",
      "        [    0.0674],\n",
      "        [    0.0538],\n",
      "        [    0.0493],\n",
      "        [    0.0235],\n",
      "        [    0.1557],\n",
      "        [    0.0375],\n",
      "        [    0.0640],\n",
      "        [    0.0576],\n",
      "        [    0.0015],\n",
      "        [    0.0168],\n",
      "        [    0.0171],\n",
      "        [    0.0052],\n",
      "        [    0.0076],\n",
      "        [    0.0238],\n",
      "        [    0.0587],\n",
      "        [    0.0739],\n",
      "        [    0.0766],\n",
      "        [    0.0759],\n",
      "        [    0.1066],\n",
      "        [    0.0879],\n",
      "        [    0.0384],\n",
      "        [    0.0226],\n",
      "        [    0.0005],\n",
      "        [    0.0484],\n",
      "        [    0.0397],\n",
      "        [    0.0064],\n",
      "        [    0.0427],\n",
      "        [    0.0031],\n",
      "        [    0.1081],\n",
      "        [    0.1230],\n",
      "        [    0.1272],\n",
      "        [    0.0695],\n",
      "        [    0.0490],\n",
      "        [    0.0129],\n",
      "        [    0.0065],\n",
      "        [    0.0700],\n",
      "        [    0.0212],\n",
      "        [    0.0269],\n",
      "        [    0.2558],\n",
      "        [    0.0883],\n",
      "        [    0.0691],\n",
      "        [    0.0227],\n",
      "        [    0.0469],\n",
      "        [    0.0022],\n",
      "        [    0.0755],\n",
      "        [    0.1478],\n",
      "        [    0.1668],\n",
      "        [    0.1707],\n",
      "        [    0.1226]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0244],\n",
      "        [    0.0160],\n",
      "        [    0.0089],\n",
      "        [    0.0001],\n",
      "        [    0.0270],\n",
      "        [    0.0265],\n",
      "        [    0.0182],\n",
      "        [    0.0213],\n",
      "        [    0.0282],\n",
      "        [    0.0201],\n",
      "        [    0.0217],\n",
      "        [    0.0196],\n",
      "        [    0.0157],\n",
      "        [    0.0198],\n",
      "        [    0.0090],\n",
      "        [    0.0436],\n",
      "        [    0.0537],\n",
      "        [    0.0267],\n",
      "        [    0.0045],\n",
      "        [    0.0633],\n",
      "        [    0.0812],\n",
      "        [    0.0895],\n",
      "        [    0.0343],\n",
      "        [    0.0219],\n",
      "        [    0.0699],\n",
      "        [    0.0712],\n",
      "        [    0.0569],\n",
      "        [    0.0284],\n",
      "        [    0.0061],\n",
      "        [    0.0033],\n",
      "        [    0.0290],\n",
      "        [    0.0294],\n",
      "        [    0.0288],\n",
      "        [    0.0511],\n",
      "        [    0.0429],\n",
      "        [    0.0267],\n",
      "        [    0.0282],\n",
      "        [    0.0353],\n",
      "        [    0.0505],\n",
      "        [    0.0532],\n",
      "        [    0.0025],\n",
      "        [    0.0088],\n",
      "        [    0.0183],\n",
      "        [    0.0656],\n",
      "        [    0.0580],\n",
      "        [    0.0255],\n",
      "        [    0.0364],\n",
      "        [    0.0247],\n",
      "        [    0.0176],\n",
      "        [    0.0106],\n",
      "        [    0.0252],\n",
      "        [    0.0461],\n",
      "        [    0.0612],\n",
      "        [    0.0825],\n",
      "        [    0.0354],\n",
      "        [    0.0477],\n",
      "        [    0.0213],\n",
      "        [    0.0553],\n",
      "        [    0.1070],\n",
      "        [    0.0910],\n",
      "        [    0.0705],\n",
      "        [    0.0573],\n",
      "        [    0.0529],\n",
      "        [    0.0276],\n",
      "        [    0.1503],\n",
      "        [    0.0313],\n",
      "        [    0.0579],\n",
      "        [    0.0511],\n",
      "        [    0.0040],\n",
      "        [    0.0123],\n",
      "        [    0.0201],\n",
      "        [    0.0074],\n",
      "        [    0.0106],\n",
      "        [    0.0269],\n",
      "        [    0.0618],\n",
      "        [    0.0776],\n",
      "        [    0.0805],\n",
      "        [    0.0800],\n",
      "        [    0.1096],\n",
      "        [    0.0908],\n",
      "        [    0.0422],\n",
      "        [    0.0258],\n",
      "        [    0.0035],\n",
      "        [    0.0514],\n",
      "        [    0.0423],\n",
      "        [    0.0042],\n",
      "        [    0.0408],\n",
      "        [    0.0035],\n",
      "        [    0.1082],\n",
      "        [    0.1230],\n",
      "        [    0.1274],\n",
      "        [    0.0701],\n",
      "        [    0.0500],\n",
      "        [    0.0145],\n",
      "        [    0.0088],\n",
      "        [    0.0652],\n",
      "        [    0.0164],\n",
      "        [    0.0318],\n",
      "        [    0.2598],\n",
      "        [    0.0927],\n",
      "        [    0.0736],\n",
      "        [    0.0271],\n",
      "        [    0.0420],\n",
      "        [    0.0086],\n",
      "        [    0.0671],\n",
      "        [    0.1383],\n",
      "        [    0.1580],\n",
      "        [    0.1621],\n",
      "        [    0.1143]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 110\n",
      "剩餘X 資料 torch.Size([267, 18])\n",
      "剩餘Y 資料 torch.Size([267, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7034])\n",
      "目前模型的Data狀態 torch.Size([110, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5425],\n",
      "        [0.5425],\n",
      "        [0.5425],\n",
      "        [0.5638],\n",
      "        [0.5860],\n",
      "        [0.5875],\n",
      "        [0.5740],\n",
      "        [0.5693],\n",
      "        [0.5546],\n",
      "        [0.5606],\n",
      "        [0.5583],\n",
      "        [0.5536],\n",
      "        [0.5486],\n",
      "        [0.5428],\n",
      "        [0.5606],\n",
      "        [0.5849],\n",
      "        [0.5787],\n",
      "        [0.5449],\n",
      "        [0.5633],\n",
      "        [0.8673],\n",
      "        [0.8948],\n",
      "        [0.9317],\n",
      "        [0.8789],\n",
      "        [0.9071],\n",
      "        [0.9122],\n",
      "        [0.9036],\n",
      "        [0.9425],\n",
      "        [0.9483],\n",
      "        [0.9817],\n",
      "        [0.9894],\n",
      "        [1.0080],\n",
      "        [0.9679],\n",
      "        [0.9545],\n",
      "        [0.9289],\n",
      "        [0.9244],\n",
      "        [0.9171],\n",
      "        [0.8608],\n",
      "        [0.8788],\n",
      "        [0.8862],\n",
      "        [0.8627],\n",
      "        [0.8509],\n",
      "        [0.8460],\n",
      "        [0.8637],\n",
      "        [0.8585],\n",
      "        [0.8645],\n",
      "        [0.8570],\n",
      "        [0.8401],\n",
      "        [0.8245],\n",
      "        [0.8472],\n",
      "        [0.8602],\n",
      "        [0.8294],\n",
      "        [0.8555],\n",
      "        [0.8811],\n",
      "        [0.8969],\n",
      "        [0.8754],\n",
      "        [0.8902],\n",
      "        [0.8848],\n",
      "        [0.8977],\n",
      "        [0.8930],\n",
      "        [0.8774],\n",
      "        [0.8976],\n",
      "        [0.9097],\n",
      "        [0.8992],\n",
      "        [0.8742],\n",
      "        [0.8582],\n",
      "        [0.8746],\n",
      "        [0.8876],\n",
      "        [0.8974],\n",
      "        [0.8484],\n",
      "        [0.9015],\n",
      "        [0.8778],\n",
      "        [0.8760],\n",
      "        [0.8568],\n",
      "        [0.8657],\n",
      "        [0.8477],\n",
      "        [0.8283],\n",
      "        [0.8394],\n",
      "        [0.8554],\n",
      "        [0.8498],\n",
      "        [0.8645],\n",
      "        [0.8781],\n",
      "        [0.8575],\n",
      "        [0.8582],\n",
      "        [0.8230],\n",
      "        [0.7933],\n",
      "        [0.8397],\n",
      "        [0.8345],\n",
      "        [0.8131],\n",
      "        [0.8120],\n",
      "        [0.7722],\n",
      "        [0.7858],\n",
      "        [0.8163],\n",
      "        [0.7955],\n",
      "        [0.7751],\n",
      "        [0.7551],\n",
      "        [0.6934],\n",
      "        [0.7054],\n",
      "        [0.6948],\n",
      "        [0.7210],\n",
      "        [0.7141],\n",
      "        [0.6880],\n",
      "        [0.6606],\n",
      "        [0.6133],\n",
      "        [0.6322],\n",
      "        [0.5939],\n",
      "        [0.5784],\n",
      "        [0.5775],\n",
      "        [0.5721],\n",
      "        [0.5975],\n",
      "        [0.6292]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0244],\n",
      "        [    0.0160],\n",
      "        [    0.0089],\n",
      "        [    0.0001],\n",
      "        [    0.0270],\n",
      "        [    0.0265],\n",
      "        [    0.0182],\n",
      "        [    0.0213],\n",
      "        [    0.0282],\n",
      "        [    0.0201],\n",
      "        [    0.0217],\n",
      "        [    0.0196],\n",
      "        [    0.0157],\n",
      "        [    0.0198],\n",
      "        [    0.0090],\n",
      "        [    0.0436],\n",
      "        [    0.0537],\n",
      "        [    0.0267],\n",
      "        [    0.0045],\n",
      "        [    0.0633],\n",
      "        [    0.0812],\n",
      "        [    0.0895],\n",
      "        [    0.0343],\n",
      "        [    0.0219],\n",
      "        [    0.0699],\n",
      "        [    0.0712],\n",
      "        [    0.0569],\n",
      "        [    0.0284],\n",
      "        [    0.0061],\n",
      "        [    0.0033],\n",
      "        [    0.0290],\n",
      "        [    0.0294],\n",
      "        [    0.0288],\n",
      "        [    0.0511],\n",
      "        [    0.0429],\n",
      "        [    0.0267],\n",
      "        [    0.0282],\n",
      "        [    0.0353],\n",
      "        [    0.0505],\n",
      "        [    0.0532],\n",
      "        [    0.0025],\n",
      "        [    0.0088],\n",
      "        [    0.0183],\n",
      "        [    0.0656],\n",
      "        [    0.0580],\n",
      "        [    0.0255],\n",
      "        [    0.0364],\n",
      "        [    0.0247],\n",
      "        [    0.0176],\n",
      "        [    0.0106],\n",
      "        [    0.0252],\n",
      "        [    0.0461],\n",
      "        [    0.0612],\n",
      "        [    0.0825],\n",
      "        [    0.0354],\n",
      "        [    0.0477],\n",
      "        [    0.0213],\n",
      "        [    0.0553],\n",
      "        [    0.1070],\n",
      "        [    0.0910],\n",
      "        [    0.0705],\n",
      "        [    0.0573],\n",
      "        [    0.0529],\n",
      "        [    0.0276],\n",
      "        [    0.1503],\n",
      "        [    0.0313],\n",
      "        [    0.0579],\n",
      "        [    0.0511],\n",
      "        [    0.0040],\n",
      "        [    0.0123],\n",
      "        [    0.0201],\n",
      "        [    0.0074],\n",
      "        [    0.0106],\n",
      "        [    0.0269],\n",
      "        [    0.0618],\n",
      "        [    0.0776],\n",
      "        [    0.0805],\n",
      "        [    0.0800],\n",
      "        [    0.1096],\n",
      "        [    0.0908],\n",
      "        [    0.0422],\n",
      "        [    0.0258],\n",
      "        [    0.0035],\n",
      "        [    0.0514],\n",
      "        [    0.0423],\n",
      "        [    0.0042],\n",
      "        [    0.0408],\n",
      "        [    0.0035],\n",
      "        [    0.1082],\n",
      "        [    0.1230],\n",
      "        [    0.1274],\n",
      "        [    0.0701],\n",
      "        [    0.0500],\n",
      "        [    0.0145],\n",
      "        [    0.0088],\n",
      "        [    0.0652],\n",
      "        [    0.0164],\n",
      "        [    0.0318],\n",
      "        [    0.2598],\n",
      "        [    0.0927],\n",
      "        [    0.0736],\n",
      "        [    0.0271],\n",
      "        [    0.0420],\n",
      "        [    0.0086],\n",
      "        [    0.0671],\n",
      "        [    0.1383],\n",
      "        [    0.1580],\n",
      "        [    0.1621],\n",
      "        [    0.1143],\n",
      "        [    0.0742]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0233],\n",
      "        [0.0171],\n",
      "        [0.0078],\n",
      "        [0.0018],\n",
      "        [0.0262],\n",
      "        [0.0259],\n",
      "        [0.0173],\n",
      "        [0.0201],\n",
      "        [0.0264],\n",
      "        [0.0187],\n",
      "        [0.0209],\n",
      "        [0.0191],\n",
      "        [0.0152],\n",
      "        [0.0206],\n",
      "        [0.0103],\n",
      "        [0.0428],\n",
      "        [0.0520],\n",
      "        [0.0280],\n",
      "        [0.0064],\n",
      "        [0.0661],\n",
      "        [0.0840],\n",
      "        [0.0924],\n",
      "        [0.0374],\n",
      "        [0.0199],\n",
      "        [0.0684],\n",
      "        [0.0687],\n",
      "        [0.0545],\n",
      "        [0.0255],\n",
      "        [0.0089],\n",
      "        [0.0016],\n",
      "        [0.0299],\n",
      "        [0.0292],\n",
      "        [0.0293],\n",
      "        [0.0519],\n",
      "        [0.0430],\n",
      "        [0.0268],\n",
      "        [0.0283],\n",
      "        [0.0350],\n",
      "        [0.0506],\n",
      "        [0.0528],\n",
      "        [0.0017],\n",
      "        [0.0085],\n",
      "        [0.0188],\n",
      "        [0.0664],\n",
      "        [0.0583],\n",
      "        [0.0247],\n",
      "        [0.0358],\n",
      "        [0.0254],\n",
      "        [0.0169],\n",
      "        [0.0099],\n",
      "        [0.0242],\n",
      "        [0.0449],\n",
      "        [0.0601],\n",
      "        [0.0817],\n",
      "        [0.0334],\n",
      "        [0.0458],\n",
      "        [0.0197],\n",
      "        [0.0568],\n",
      "        [0.1079],\n",
      "        [0.0915],\n",
      "        [0.0709],\n",
      "        [0.0578],\n",
      "        [0.0534],\n",
      "        [0.0285],\n",
      "        [0.1484],\n",
      "        [0.0287],\n",
      "        [0.0555],\n",
      "        [0.0484],\n",
      "        [0.0065],\n",
      "        [0.0108],\n",
      "        [0.0202],\n",
      "        [0.0071],\n",
      "        [0.0111],\n",
      "        [0.0274],\n",
      "        [0.0623],\n",
      "        [0.0786],\n",
      "        [0.0817],\n",
      "        [0.0814],\n",
      "        [0.1100],\n",
      "        [0.0910],\n",
      "        [0.0431],\n",
      "        [0.0265],\n",
      "        [0.0039],\n",
      "        [0.0518],\n",
      "        [0.0426],\n",
      "        [0.0046],\n",
      "        [0.0414],\n",
      "        [0.0019],\n",
      "        [0.1101],\n",
      "        [0.1243],\n",
      "        [0.1288],\n",
      "        [0.0720],\n",
      "        [0.0518],\n",
      "        [0.0165],\n",
      "        [0.0113],\n",
      "        [0.0608],\n",
      "        [0.0120],\n",
      "        [0.0363],\n",
      "        [0.2639],\n",
      "        [0.0970],\n",
      "        [0.0779],\n",
      "        [0.0310],\n",
      "        [0.0378],\n",
      "        [0.0143],\n",
      "        [0.0600],\n",
      "        [0.1305],\n",
      "        [0.1505],\n",
      "        [0.1548],\n",
      "        [0.1070],\n",
      "        [0.0672]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 111\n",
      "剩餘X 資料 torch.Size([266, 18])\n",
      "剩餘Y 資料 torch.Size([266, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6914])\n",
      "目前模型的Data狀態 torch.Size([111, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5436],\n",
      "        [0.5436],\n",
      "        [0.5436],\n",
      "        [0.5656],\n",
      "        [0.5852],\n",
      "        [0.5870],\n",
      "        [0.5731],\n",
      "        [0.5680],\n",
      "        [0.5528],\n",
      "        [0.5592],\n",
      "        [0.5575],\n",
      "        [0.5531],\n",
      "        [0.5482],\n",
      "        [0.5436],\n",
      "        [0.5593],\n",
      "        [0.5841],\n",
      "        [0.5771],\n",
      "        [0.5436],\n",
      "        [0.5614],\n",
      "        [0.8701],\n",
      "        [0.8976],\n",
      "        [0.9345],\n",
      "        [0.8821],\n",
      "        [0.9090],\n",
      "        [0.9137],\n",
      "        [0.9061],\n",
      "        [0.9449],\n",
      "        [0.9512],\n",
      "        [0.9844],\n",
      "        [0.9912],\n",
      "        [1.0089],\n",
      "        [0.9680],\n",
      "        [0.9540],\n",
      "        [0.9281],\n",
      "        [0.9244],\n",
      "        [0.9170],\n",
      "        [0.8607],\n",
      "        [0.8791],\n",
      "        [0.8861],\n",
      "        [0.8631],\n",
      "        [0.8517],\n",
      "        [0.8462],\n",
      "        [0.8642],\n",
      "        [0.8592],\n",
      "        [0.8648],\n",
      "        [0.8563],\n",
      "        [0.8394],\n",
      "        [0.8238],\n",
      "        [0.8464],\n",
      "        [0.8595],\n",
      "        [0.8285],\n",
      "        [0.8543],\n",
      "        [0.8801],\n",
      "        [0.8961],\n",
      "        [0.8734],\n",
      "        [0.8884],\n",
      "        [0.8832],\n",
      "        [0.8962],\n",
      "        [0.8921],\n",
      "        [0.8769],\n",
      "        [0.8972],\n",
      "        [0.9091],\n",
      "        [0.8987],\n",
      "        [0.8733],\n",
      "        [0.8563],\n",
      "        [0.8720],\n",
      "        [0.8851],\n",
      "        [0.8946],\n",
      "        [0.8460],\n",
      "        [0.9001],\n",
      "        [0.8776],\n",
      "        [0.8763],\n",
      "        [0.8564],\n",
      "        [0.8652],\n",
      "        [0.8473],\n",
      "        [0.8274],\n",
      "        [0.8382],\n",
      "        [0.8541],\n",
      "        [0.8494],\n",
      "        [0.8643],\n",
      "        [0.8771],\n",
      "        [0.8568],\n",
      "        [0.8578],\n",
      "        [0.8226],\n",
      "        [0.7931],\n",
      "        [0.8401],\n",
      "        [0.8350],\n",
      "        [0.8147],\n",
      "        [0.8139],\n",
      "        [0.7736],\n",
      "        [0.7873],\n",
      "        [0.8181],\n",
      "        [0.7973],\n",
      "        [0.7771],\n",
      "        [0.7576],\n",
      "        [0.6978],\n",
      "        [0.7098],\n",
      "        [0.6993],\n",
      "        [0.7250],\n",
      "        [0.7184],\n",
      "        [0.6922],\n",
      "        [0.6645],\n",
      "        [0.6175],\n",
      "        [0.6379],\n",
      "        [0.6011],\n",
      "        [0.5863],\n",
      "        [0.5850],\n",
      "        [0.5795],\n",
      "        [0.6047],\n",
      "        [0.6362],\n",
      "        [0.6136]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0233],\n",
      "        [0.0171],\n",
      "        [0.0078],\n",
      "        [0.0018],\n",
      "        [0.0262],\n",
      "        [0.0259],\n",
      "        [0.0173],\n",
      "        [0.0201],\n",
      "        [0.0264],\n",
      "        [0.0187],\n",
      "        [0.0209],\n",
      "        [0.0191],\n",
      "        [0.0152],\n",
      "        [0.0206],\n",
      "        [0.0103],\n",
      "        [0.0428],\n",
      "        [0.0520],\n",
      "        [0.0280],\n",
      "        [0.0064],\n",
      "        [0.0661],\n",
      "        [0.0840],\n",
      "        [0.0924],\n",
      "        [0.0374],\n",
      "        [0.0199],\n",
      "        [0.0684],\n",
      "        [0.0687],\n",
      "        [0.0545],\n",
      "        [0.0255],\n",
      "        [0.0089],\n",
      "        [0.0016],\n",
      "        [0.0299],\n",
      "        [0.0292],\n",
      "        [0.0293],\n",
      "        [0.0519],\n",
      "        [0.0430],\n",
      "        [0.0268],\n",
      "        [0.0283],\n",
      "        [0.0350],\n",
      "        [0.0506],\n",
      "        [0.0528],\n",
      "        [0.0017],\n",
      "        [0.0085],\n",
      "        [0.0188],\n",
      "        [0.0664],\n",
      "        [0.0583],\n",
      "        [0.0247],\n",
      "        [0.0358],\n",
      "        [0.0254],\n",
      "        [0.0169],\n",
      "        [0.0099],\n",
      "        [0.0242],\n",
      "        [0.0449],\n",
      "        [0.0601],\n",
      "        [0.0817],\n",
      "        [0.0334],\n",
      "        [0.0458],\n",
      "        [0.0197],\n",
      "        [0.0568],\n",
      "        [0.1079],\n",
      "        [0.0915],\n",
      "        [0.0709],\n",
      "        [0.0578],\n",
      "        [0.0534],\n",
      "        [0.0285],\n",
      "        [0.1484],\n",
      "        [0.0287],\n",
      "        [0.0555],\n",
      "        [0.0484],\n",
      "        [0.0065],\n",
      "        [0.0108],\n",
      "        [0.0202],\n",
      "        [0.0071],\n",
      "        [0.0111],\n",
      "        [0.0274],\n",
      "        [0.0623],\n",
      "        [0.0786],\n",
      "        [0.0817],\n",
      "        [0.0814],\n",
      "        [0.1100],\n",
      "        [0.0910],\n",
      "        [0.0431],\n",
      "        [0.0265],\n",
      "        [0.0039],\n",
      "        [0.0518],\n",
      "        [0.0426],\n",
      "        [0.0046],\n",
      "        [0.0414],\n",
      "        [0.0019],\n",
      "        [0.1101],\n",
      "        [0.1243],\n",
      "        [0.1288],\n",
      "        [0.0720],\n",
      "        [0.0518],\n",
      "        [0.0165],\n",
      "        [0.0113],\n",
      "        [0.0608],\n",
      "        [0.0120],\n",
      "        [0.0363],\n",
      "        [0.2639],\n",
      "        [0.0970],\n",
      "        [0.0779],\n",
      "        [0.0310],\n",
      "        [0.0378],\n",
      "        [0.0143],\n",
      "        [0.0600],\n",
      "        [0.1305],\n",
      "        [0.1505],\n",
      "        [0.1548],\n",
      "        [0.1070],\n",
      "        [0.0672],\n",
      "        [0.0778]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0199],\n",
      "        [0.0205],\n",
      "        [0.0044],\n",
      "        [0.0053],\n",
      "        [0.0274],\n",
      "        [0.0273],\n",
      "        [0.0183],\n",
      "        [0.0207],\n",
      "        [0.0264],\n",
      "        [0.0191],\n",
      "        [0.0219],\n",
      "        [0.0205],\n",
      "        [0.0166],\n",
      "        [0.0240],\n",
      "        [0.0113],\n",
      "        [0.0422],\n",
      "        [0.0507],\n",
      "        [0.0246],\n",
      "        [0.0074],\n",
      "        [0.0704],\n",
      "        [0.0885],\n",
      "        [0.0970],\n",
      "        [0.0421],\n",
      "        [0.0163],\n",
      "        [0.0651],\n",
      "        [0.0643],\n",
      "        [0.0500],\n",
      "        [0.0205],\n",
      "        [0.0139],\n",
      "        [0.0025],\n",
      "        [0.0331],\n",
      "        [0.0268],\n",
      "        [0.0275],\n",
      "        [0.0504],\n",
      "        [0.0407],\n",
      "        [0.0247],\n",
      "        [0.0262],\n",
      "        [0.0325],\n",
      "        [0.0484],\n",
      "        [0.0501],\n",
      "        [0.0013],\n",
      "        [0.0060],\n",
      "        [0.0216],\n",
      "        [0.0694],\n",
      "        [0.0609],\n",
      "        [0.0264],\n",
      "        [0.0376],\n",
      "        [0.0237],\n",
      "        [0.0185],\n",
      "        [0.0115],\n",
      "        [0.0256],\n",
      "        [0.0461],\n",
      "        [0.0616],\n",
      "        [0.0835],\n",
      "        [0.0339],\n",
      "        [0.0466],\n",
      "        [0.0206],\n",
      "        [0.0556],\n",
      "        [0.1062],\n",
      "        [0.0895],\n",
      "        [0.0687],\n",
      "        [0.0556],\n",
      "        [0.0512],\n",
      "        [0.0269],\n",
      "        [0.1489],\n",
      "        [0.0287],\n",
      "        [0.0557],\n",
      "        [0.0483],\n",
      "        [0.0064],\n",
      "        [0.0121],\n",
      "        [0.0178],\n",
      "        [0.0043],\n",
      "        [0.0090],\n",
      "        [0.0254],\n",
      "        [0.0603],\n",
      "        [0.0771],\n",
      "        [0.0806],\n",
      "        [0.0803],\n",
      "        [0.1081],\n",
      "        [0.0888],\n",
      "        [0.0417],\n",
      "        [0.0247],\n",
      "        [0.0019],\n",
      "        [0.0499],\n",
      "        [0.0407],\n",
      "        [0.0071],\n",
      "        [0.0440],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1275],\n",
      "        [0.1321],\n",
      "        [0.0756],\n",
      "        [0.0553],\n",
      "        [0.0200],\n",
      "        [0.0153],\n",
      "        [0.0552],\n",
      "        [0.0063],\n",
      "        [0.0421],\n",
      "        [0.2693],\n",
      "        [0.1027],\n",
      "        [0.0834],\n",
      "        [0.0361],\n",
      "        [0.0328],\n",
      "        [0.0208],\n",
      "        [0.0521],\n",
      "        [0.1220],\n",
      "        [0.1424],\n",
      "        [0.1468],\n",
      "        [0.0990],\n",
      "        [0.0593],\n",
      "        [0.0699]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 112\n",
      "剩餘X 資料 torch.Size([265, 18])\n",
      "剩餘Y 資料 torch.Size([265, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7056])\n",
      "目前模型的Data狀態 torch.Size([112, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5470],\n",
      "        [0.5470],\n",
      "        [0.5470],\n",
      "        [0.5691],\n",
      "        [0.5864],\n",
      "        [0.5883],\n",
      "        [0.5741],\n",
      "        [0.5686],\n",
      "        [0.5528],\n",
      "        [0.5597],\n",
      "        [0.5585],\n",
      "        [0.5545],\n",
      "        [0.5495],\n",
      "        [0.5470],\n",
      "        [0.5582],\n",
      "        [0.5835],\n",
      "        [0.5758],\n",
      "        [0.5470],\n",
      "        [0.5603],\n",
      "        [0.8744],\n",
      "        [0.9020],\n",
      "        [0.9391],\n",
      "        [0.8868],\n",
      "        [0.9127],\n",
      "        [0.9170],\n",
      "        [0.9104],\n",
      "        [0.9494],\n",
      "        [0.9562],\n",
      "        [0.9894],\n",
      "        [0.9952],\n",
      "        [1.0122],\n",
      "        [0.9704],\n",
      "        [0.9558],\n",
      "        [0.9297],\n",
      "        [0.9267],\n",
      "        [0.9191],\n",
      "        [0.8627],\n",
      "        [0.8816],\n",
      "        [0.8883],\n",
      "        [0.8658],\n",
      "        [0.8547],\n",
      "        [0.8488],\n",
      "        [0.8670],\n",
      "        [0.8623],\n",
      "        [0.8674],\n",
      "        [0.8579],\n",
      "        [0.8413],\n",
      "        [0.8254],\n",
      "        [0.8480],\n",
      "        [0.8611],\n",
      "        [0.8299],\n",
      "        [0.8555],\n",
      "        [0.8816],\n",
      "        [0.8979],\n",
      "        [0.8739],\n",
      "        [0.8891],\n",
      "        [0.8842],\n",
      "        [0.8974],\n",
      "        [0.8938],\n",
      "        [0.8790],\n",
      "        [0.8995],\n",
      "        [0.9114],\n",
      "        [0.9009],\n",
      "        [0.8750],\n",
      "        [0.8568],\n",
      "        [0.8720],\n",
      "        [0.8853],\n",
      "        [0.8945],\n",
      "        [0.8460],\n",
      "        [0.9013],\n",
      "        [0.8800],\n",
      "        [0.8792],\n",
      "        [0.8584],\n",
      "        [0.8671],\n",
      "        [0.8492],\n",
      "        [0.8288],\n",
      "        [0.8394],\n",
      "        [0.8551],\n",
      "        [0.8513],\n",
      "        [0.8665],\n",
      "        [0.8786],\n",
      "        [0.8586],\n",
      "        [0.8597],\n",
      "        [0.8244],\n",
      "        [0.7950],\n",
      "        [0.8425],\n",
      "        [0.8376],\n",
      "        [0.8183],\n",
      "        [0.8176],\n",
      "        [0.7767],\n",
      "        [0.7905],\n",
      "        [0.8217],\n",
      "        [0.8008],\n",
      "        [0.7806],\n",
      "        [0.7616],\n",
      "        [0.7034],\n",
      "        [0.7155],\n",
      "        [0.7051],\n",
      "        [0.7304],\n",
      "        [0.7240],\n",
      "        [0.6977],\n",
      "        [0.6696],\n",
      "        [0.6225],\n",
      "        [0.6444],\n",
      "        [0.6089],\n",
      "        [0.5947],\n",
      "        [0.5931],\n",
      "        [0.5875],\n",
      "        [0.6127],\n",
      "        [0.6441],\n",
      "        [0.6215],\n",
      "        [0.5979]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0199],\n",
      "        [0.0205],\n",
      "        [0.0044],\n",
      "        [0.0053],\n",
      "        [0.0274],\n",
      "        [0.0273],\n",
      "        [0.0183],\n",
      "        [0.0207],\n",
      "        [0.0264],\n",
      "        [0.0191],\n",
      "        [0.0219],\n",
      "        [0.0205],\n",
      "        [0.0166],\n",
      "        [0.0240],\n",
      "        [0.0113],\n",
      "        [0.0422],\n",
      "        [0.0507],\n",
      "        [0.0246],\n",
      "        [0.0074],\n",
      "        [0.0704],\n",
      "        [0.0885],\n",
      "        [0.0970],\n",
      "        [0.0421],\n",
      "        [0.0163],\n",
      "        [0.0651],\n",
      "        [0.0643],\n",
      "        [0.0500],\n",
      "        [0.0205],\n",
      "        [0.0139],\n",
      "        [0.0025],\n",
      "        [0.0331],\n",
      "        [0.0268],\n",
      "        [0.0275],\n",
      "        [0.0504],\n",
      "        [0.0407],\n",
      "        [0.0247],\n",
      "        [0.0262],\n",
      "        [0.0325],\n",
      "        [0.0484],\n",
      "        [0.0501],\n",
      "        [0.0013],\n",
      "        [0.0060],\n",
      "        [0.0216],\n",
      "        [0.0694],\n",
      "        [0.0609],\n",
      "        [0.0264],\n",
      "        [0.0376],\n",
      "        [0.0237],\n",
      "        [0.0185],\n",
      "        [0.0115],\n",
      "        [0.0256],\n",
      "        [0.0461],\n",
      "        [0.0616],\n",
      "        [0.0835],\n",
      "        [0.0339],\n",
      "        [0.0466],\n",
      "        [0.0206],\n",
      "        [0.0556],\n",
      "        [0.1062],\n",
      "        [0.0895],\n",
      "        [0.0687],\n",
      "        [0.0556],\n",
      "        [0.0512],\n",
      "        [0.0269],\n",
      "        [0.1489],\n",
      "        [0.0287],\n",
      "        [0.0557],\n",
      "        [0.0483],\n",
      "        [0.0064],\n",
      "        [0.0121],\n",
      "        [0.0178],\n",
      "        [0.0043],\n",
      "        [0.0090],\n",
      "        [0.0254],\n",
      "        [0.0603],\n",
      "        [0.0771],\n",
      "        [0.0806],\n",
      "        [0.0803],\n",
      "        [0.1081],\n",
      "        [0.0888],\n",
      "        [0.0417],\n",
      "        [0.0247],\n",
      "        [0.0019],\n",
      "        [0.0499],\n",
      "        [0.0407],\n",
      "        [0.0071],\n",
      "        [0.0440],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1275],\n",
      "        [0.1321],\n",
      "        [0.0756],\n",
      "        [0.0553],\n",
      "        [0.0200],\n",
      "        [0.0153],\n",
      "        [0.0552],\n",
      "        [0.0063],\n",
      "        [0.0421],\n",
      "        [0.2693],\n",
      "        [0.1027],\n",
      "        [0.0834],\n",
      "        [0.0361],\n",
      "        [0.0328],\n",
      "        [0.0208],\n",
      "        [0.0521],\n",
      "        [0.1220],\n",
      "        [0.1424],\n",
      "        [0.1468],\n",
      "        [0.0990],\n",
      "        [0.0593],\n",
      "        [0.0699],\n",
      "        [0.1077]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 35\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0064],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0657],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0277],\n",
      "        [0.0284],\n",
      "        [0.0512],\n",
      "        [0.0414],\n",
      "        [0.0254],\n",
      "        [0.0267],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0063],\n",
      "        [0.0212],\n",
      "        [0.0691],\n",
      "        [0.0605],\n",
      "        [0.0259],\n",
      "        [0.0372],\n",
      "        [0.0241],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0455],\n",
      "        [0.0611],\n",
      "        [0.0828],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0279],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0184],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0260],\n",
      "        [0.0608],\n",
      "        [0.0776],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0502],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0554],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0055],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0579],\n",
      "        [0.0683],\n",
      "        [0.1062]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 113\n",
      "剩餘X 資料 torch.Size([264, 18])\n",
      "剩餘Y 資料 torch.Size([264, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7161])\n",
      "目前模型的Data狀態 torch.Size([113, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5890],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5588],\n",
      "        [0.5840],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5609],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9386],\n",
      "        [0.8866],\n",
      "        [0.9122],\n",
      "        [0.9165],\n",
      "        [0.9100],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0112],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9288],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8606],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8810],\n",
      "        [0.8973],\n",
      "        [0.8732],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8989],\n",
      "        [0.9107],\n",
      "        [0.9003],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8845],\n",
      "        [0.8936],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8787],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8389],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8593],\n",
      "        [0.8242],\n",
      "        [0.7948],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8176],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6143],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0064],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0657],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0277],\n",
      "        [0.0284],\n",
      "        [0.0512],\n",
      "        [0.0414],\n",
      "        [0.0254],\n",
      "        [0.0267],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0063],\n",
      "        [0.0212],\n",
      "        [0.0691],\n",
      "        [0.0605],\n",
      "        [0.0259],\n",
      "        [0.0372],\n",
      "        [0.0241],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0455],\n",
      "        [0.0611],\n",
      "        [0.0828],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0279],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0184],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0260],\n",
      "        [0.0608],\n",
      "        [0.0776],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0502],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0554],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0055],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0579],\n",
      "        [0.0683],\n",
      "        [0.1062],\n",
      "        [0.1314]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 4\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 114\n",
      "剩餘X 資料 torch.Size([263, 18])\n",
      "剩餘Y 資料 torch.Size([263, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7078])\n",
      "目前模型的Data狀態 torch.Size([114, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 115\n",
      "剩餘X 資料 torch.Size([262, 18])\n",
      "剩餘Y 資料 torch.Size([262, 1])\n",
      "現在要進去模型的數據，y= tensor([0.7050])\n",
      "目前模型的Data狀態 torch.Size([115, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 116\n",
      "剩餘X 資料 torch.Size([261, 18])\n",
      "剩餘Y 資料 torch.Size([261, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6950])\n",
      "目前模型的Data狀態 torch.Size([116, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 117\n",
      "剩餘X 資料 torch.Size([260, 18])\n",
      "剩餘Y 資料 torch.Size([260, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6835])\n",
      "目前模型的Data狀態 torch.Size([117, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 118\n",
      "剩餘X 資料 torch.Size([259, 18])\n",
      "剩餘Y 資料 torch.Size([259, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6772])\n",
      "目前模型的Data狀態 torch.Size([118, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 119\n",
      "剩餘X 資料 torch.Size([258, 18])\n",
      "剩餘Y 資料 torch.Size([258, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6597])\n",
      "目前模型的Data狀態 torch.Size([119, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 120\n",
      "剩餘X 資料 torch.Size([257, 18])\n",
      "剩餘Y 資料 torch.Size([257, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6353])\n",
      "目前模型的Data狀態 torch.Size([120, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 121\n",
      "剩餘X 資料 torch.Size([256, 18])\n",
      "剩餘Y 資料 torch.Size([256, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6474])\n",
      "目前模型的Data狀態 torch.Size([121, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 122\n",
      "剩餘X 資料 torch.Size([255, 18])\n",
      "剩餘Y 資料 torch.Size([255, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6412])\n",
      "目前模型的Data狀態 torch.Size([122, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 123\n",
      "剩餘X 資料 torch.Size([254, 18])\n",
      "剩餘Y 資料 torch.Size([254, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6591])\n",
      "目前模型的Data狀態 torch.Size([123, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 124\n",
      "剩餘X 資料 torch.Size([253, 18])\n",
      "剩餘Y 資料 torch.Size([253, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6590])\n",
      "目前模型的Data狀態 torch.Size([124, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 125\n",
      "剩餘X 資料 torch.Size([252, 18])\n",
      "剩餘Y 資料 torch.Size([252, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6794])\n",
      "目前模型的Data狀態 torch.Size([125, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 126\n",
      "剩餘X 資料 torch.Size([251, 18])\n",
      "剩餘Y 資料 torch.Size([251, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6966])\n",
      "目前模型的Data狀態 torch.Size([126, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 127\n",
      "剩餘X 資料 torch.Size([250, 18])\n",
      "剩餘Y 資料 torch.Size([250, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6907])\n",
      "目前模型的Data狀態 torch.Size([127, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 128\n",
      "剩餘X 資料 torch.Size([249, 18])\n",
      "剩餘Y 資料 torch.Size([249, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6893])\n",
      "目前模型的Data狀態 torch.Size([128, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 129\n",
      "剩餘X 資料 torch.Size([248, 18])\n",
      "剩餘Y 資料 torch.Size([248, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6720])\n",
      "目前模型的Data狀態 torch.Size([129, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 130\n",
      "剩餘X 資料 torch.Size([247, 18])\n",
      "剩餘Y 資料 torch.Size([247, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6416])\n",
      "目前模型的Data狀態 torch.Size([130, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 131\n",
      "剩餘X 資料 torch.Size([246, 18])\n",
      "剩餘Y 資料 torch.Size([246, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6454])\n",
      "目前模型的Data狀態 torch.Size([131, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 132\n",
      "剩餘X 資料 torch.Size([245, 18])\n",
      "剩餘Y 資料 torch.Size([245, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6364])\n",
      "目前模型的Data狀態 torch.Size([132, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 133\n",
      "剩餘X 資料 torch.Size([244, 18])\n",
      "剩餘Y 資料 torch.Size([244, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6360])\n",
      "目前模型的Data狀態 torch.Size([133, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 134\n",
      "剩餘X 資料 torch.Size([243, 18])\n",
      "剩餘Y 資料 torch.Size([243, 1])\n",
      "現在要進去模型的數據，y= tensor([0.5888])\n",
      "目前模型的Data狀態 torch.Size([134, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 135\n",
      "剩餘X 資料 torch.Size([242, 18])\n",
      "剩餘Y 資料 torch.Size([242, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4205])\n",
      "目前模型的Data狀態 torch.Size([135, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 136\n",
      "剩餘X 資料 torch.Size([241, 18])\n",
      "剩餘Y 資料 torch.Size([241, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4237])\n",
      "目前模型的Data狀態 torch.Size([136, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 137\n",
      "剩餘X 資料 torch.Size([240, 18])\n",
      "剩餘Y 資料 torch.Size([240, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4569])\n",
      "目前模型的Data狀態 torch.Size([137, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 138\n",
      "剩餘X 資料 torch.Size([239, 18])\n",
      "剩餘Y 資料 torch.Size([239, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4953])\n",
      "目前模型的Data狀態 torch.Size([138, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 139\n",
      "剩餘X 資料 torch.Size([238, 18])\n",
      "剩餘Y 資料 torch.Size([238, 1])\n",
      "現在要進去模型的數據，y= tensor([0.5114])\n",
      "目前模型的Data狀態 torch.Size([139, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 140\n",
      "剩餘X 資料 torch.Size([237, 18])\n",
      "剩餘Y 資料 torch.Size([237, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6105])\n",
      "目前模型的Data狀態 torch.Size([140, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 141\n",
      "剩餘X 資料 torch.Size([236, 18])\n",
      "剩餘Y 資料 torch.Size([236, 1])\n",
      "現在要進去模型的數據，y= tensor([0.5851])\n",
      "目前模型的Data狀態 torch.Size([141, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 142\n",
      "剩餘X 資料 torch.Size([235, 18])\n",
      "剩餘Y 資料 torch.Size([235, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6239])\n",
      "目前模型的Data狀態 torch.Size([142, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 143\n",
      "剩餘X 資料 torch.Size([234, 18])\n",
      "剩餘Y 資料 torch.Size([234, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6171])\n",
      "目前模型的Data狀態 torch.Size([143, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 144\n",
      "剩餘X 資料 torch.Size([233, 18])\n",
      "剩餘Y 資料 torch.Size([233, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6187])\n",
      "目前模型的Data狀態 torch.Size([144, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 145\n",
      "剩餘X 資料 torch.Size([232, 18])\n",
      "剩餘Y 資料 torch.Size([232, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6108])\n",
      "目前模型的Data狀態 torch.Size([145, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 146\n",
      "剩餘X 資料 torch.Size([231, 18])\n",
      "剩餘Y 資料 torch.Size([231, 1])\n",
      "現在要進去模型的數據，y= tensor([0.5807])\n",
      "目前模型的Data狀態 torch.Size([146, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 147\n",
      "剩餘X 資料 torch.Size([230, 18])\n",
      "剩餘Y 資料 torch.Size([230, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6306])\n",
      "目前模型的Data狀態 torch.Size([147, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 148\n",
      "剩餘X 資料 torch.Size([229, 18])\n",
      "剩餘Y 資料 torch.Size([229, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6767])\n",
      "目前模型的Data狀態 torch.Size([148, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 149\n",
      "剩餘X 資料 torch.Size([228, 18])\n",
      "剩餘Y 資料 torch.Size([228, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6717])\n",
      "目前模型的Data狀態 torch.Size([149, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 150\n",
      "剩餘X 資料 torch.Size([227, 18])\n",
      "剩餘Y 資料 torch.Size([227, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6430])\n",
      "目前模型的Data狀態 torch.Size([150, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 151\n",
      "剩餘X 資料 torch.Size([226, 18])\n",
      "剩餘Y 資料 torch.Size([226, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6216])\n",
      "目前模型的Data狀態 torch.Size([151, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 152\n",
      "剩餘X 資料 torch.Size([225, 18])\n",
      "剩餘Y 資料 torch.Size([225, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6333])\n",
      "目前模型的Data狀態 torch.Size([152, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 153\n",
      "剩餘X 資料 torch.Size([224, 18])\n",
      "剩餘Y 資料 torch.Size([224, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6286])\n",
      "目前模型的Data狀態 torch.Size([153, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 154\n",
      "剩餘X 資料 torch.Size([223, 18])\n",
      "剩餘Y 資料 torch.Size([223, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6070])\n",
      "目前模型的Data狀態 torch.Size([154, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 155\n",
      "剩餘X 資料 torch.Size([222, 18])\n",
      "剩餘Y 資料 torch.Size([222, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6166])\n",
      "目前模型的Data狀態 torch.Size([155, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 156\n",
      "剩餘X 資料 torch.Size([221, 18])\n",
      "剩餘Y 資料 torch.Size([221, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6439])\n",
      "目前模型的Data狀態 torch.Size([156, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 157\n",
      "剩餘X 資料 torch.Size([220, 18])\n",
      "剩餘Y 資料 torch.Size([220, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6278])\n",
      "目前模型的Data狀態 torch.Size([157, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 158\n",
      "剩餘X 資料 torch.Size([219, 18])\n",
      "剩餘Y 資料 torch.Size([219, 1])\n",
      "現在要進去模型的數據，y= tensor([0.6072])\n",
      "目前模型的Data狀態 torch.Size([158, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 159\n",
      "剩餘X 資料 torch.Size([218, 18])\n",
      "剩餘Y 資料 torch.Size([218, 1])\n",
      "現在要進去模型的數據，y= tensor([0.5907])\n",
      "目前模型的Data狀態 torch.Size([159, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 160\n",
      "剩餘X 資料 torch.Size([217, 18])\n",
      "剩餘Y 資料 torch.Size([217, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4709])\n",
      "目前模型的Data狀態 torch.Size([160, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 161\n",
      "剩餘X 資料 torch.Size([216, 18])\n",
      "剩餘Y 資料 torch.Size([216, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4872])\n",
      "目前模型的Data狀態 torch.Size([161, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 162\n",
      "剩餘X 資料 torch.Size([215, 18])\n",
      "剩餘Y 資料 torch.Size([215, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4740])\n",
      "目前模型的Data狀態 torch.Size([162, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 163\n",
      "剩餘X 資料 torch.Size([214, 18])\n",
      "剩餘Y 資料 torch.Size([214, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4719])\n",
      "目前模型的Data狀態 torch.Size([163, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 164\n",
      "剩餘X 資料 torch.Size([213, 18])\n",
      "剩餘Y 資料 torch.Size([213, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4646])\n",
      "目前模型的Data狀態 torch.Size([164, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 165\n",
      "剩餘X 資料 torch.Size([212, 18])\n",
      "剩餘Y 資料 torch.Size([212, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4404])\n",
      "目前模型的Data狀態 torch.Size([165, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833],\n",
      "        [0.1074]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833],\n",
      "        [0.1074]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 166\n",
      "剩餘X 資料 torch.Size([211, 18])\n",
      "剩餘Y 資料 torch.Size([211, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3264])\n",
      "目前模型的Data狀態 torch.Size([166, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833],\n",
      "        [0.1074],\n",
      "        [0.2215]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833],\n",
      "        [0.1074],\n",
      "        [0.2215]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 167\n",
      "剩餘X 資料 torch.Size([210, 18])\n",
      "剩餘Y 資料 torch.Size([210, 1])\n",
      "現在要進去模型的數據，y= tensor([0.2868])\n",
      "目前模型的Data狀態 torch.Size([167, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833],\n",
      "        [0.1074],\n",
      "        [0.2215],\n",
      "        [0.2611]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833],\n",
      "        [0.1074],\n",
      "        [0.2215],\n",
      "        [0.2611]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 168\n",
      "剩餘X 資料 torch.Size([209, 18])\n",
      "剩餘Y 資料 torch.Size([209, 1])\n",
      "現在要進去模型的數據，y= tensor([0.2274])\n",
      "目前模型的Data狀態 torch.Size([168, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5891],\n",
      "        [0.5748],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8742],\n",
      "        [0.9017],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9123],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8655],\n",
      "        [0.8544],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8671],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8251],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8811],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8967],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9108],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8937],\n",
      "        [0.8453],\n",
      "        [0.9005],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8666],\n",
      "        [0.8488],\n",
      "        [0.8284],\n",
      "        [0.8390],\n",
      "        [0.8546],\n",
      "        [0.8509],\n",
      "        [0.8661],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8594],\n",
      "        [0.8242],\n",
      "        [0.7949],\n",
      "        [0.8423],\n",
      "        [0.8374],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8218],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6236],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5850],\n",
      "        [0.5942],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6157],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5975],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833],\n",
      "        [0.1074],\n",
      "        [0.2215],\n",
      "        [0.2611],\n",
      "        [0.3204]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 5559\n",
      "Number of shrink: 2849\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0213],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0281],\n",
      "        [0.0280],\n",
      "        [0.0190],\n",
      "        [0.0214],\n",
      "        [0.0271],\n",
      "        [0.0198],\n",
      "        [0.0227],\n",
      "        [0.0214],\n",
      "        [0.0175],\n",
      "        [0.0248],\n",
      "        [0.0107],\n",
      "        [0.0428],\n",
      "        [0.0512],\n",
      "        [0.0238],\n",
      "        [0.0068],\n",
      "        [0.0702],\n",
      "        [0.0882],\n",
      "        [0.0965],\n",
      "        [0.0420],\n",
      "        [0.0167],\n",
      "        [0.0656],\n",
      "        [0.0647],\n",
      "        [0.0505],\n",
      "        [0.0209],\n",
      "        [0.0133],\n",
      "        [0.0017],\n",
      "        [0.0322],\n",
      "        [0.0276],\n",
      "        [0.0284],\n",
      "        [0.0511],\n",
      "        [0.0413],\n",
      "        [0.0254],\n",
      "        [0.0266],\n",
      "        [0.0329],\n",
      "        [0.0489],\n",
      "        [0.0504],\n",
      "        [0.0011],\n",
      "        [0.0062],\n",
      "        [0.0213],\n",
      "        [0.0692],\n",
      "        [0.0605],\n",
      "        [0.0260],\n",
      "        [0.0373],\n",
      "        [0.0240],\n",
      "        [0.0181],\n",
      "        [0.0111],\n",
      "        [0.0252],\n",
      "        [0.0456],\n",
      "        [0.0611],\n",
      "        [0.0829],\n",
      "        [0.0332],\n",
      "        [0.0459],\n",
      "        [0.0200],\n",
      "        [0.0563],\n",
      "        [0.1068],\n",
      "        [0.0900],\n",
      "        [0.0692],\n",
      "        [0.0562],\n",
      "        [0.0518],\n",
      "        [0.0274],\n",
      "        [0.1483],\n",
      "        [0.0280],\n",
      "        [0.0549],\n",
      "        [0.0474],\n",
      "        [0.0071],\n",
      "        [0.0113],\n",
      "        [0.0183],\n",
      "        [0.0047],\n",
      "        [0.0095],\n",
      "        [0.0259],\n",
      "        [0.0608],\n",
      "        [0.0775],\n",
      "        [0.0810],\n",
      "        [0.0809],\n",
      "        [0.1085],\n",
      "        [0.0892],\n",
      "        [0.0422],\n",
      "        [0.0251],\n",
      "        [0.0023],\n",
      "        [0.0501],\n",
      "        [0.0408],\n",
      "        [0.0068],\n",
      "        [0.0438],\n",
      "        [0.0016],\n",
      "        [0.1138],\n",
      "        [0.1277],\n",
      "        [0.1322],\n",
      "        [0.0756],\n",
      "        [0.0555],\n",
      "        [0.0202],\n",
      "        [0.0156],\n",
      "        [0.0543],\n",
      "        [0.0054],\n",
      "        [0.0430],\n",
      "        [0.2700],\n",
      "        [0.1035],\n",
      "        [0.0843],\n",
      "        [0.0371],\n",
      "        [0.0317],\n",
      "        [0.0220],\n",
      "        [0.0506],\n",
      "        [0.1203],\n",
      "        [0.1407],\n",
      "        [0.1451],\n",
      "        [0.0974],\n",
      "        [0.0578],\n",
      "        [0.0683],\n",
      "        [0.1061],\n",
      "        [0.1314],\n",
      "        [0.1435],\n",
      "        [0.1305],\n",
      "        [0.0999],\n",
      "        [0.0985],\n",
      "        [0.0829],\n",
      "        [0.0848],\n",
      "        [0.0875],\n",
      "        [0.0996],\n",
      "        [0.0933],\n",
      "        [0.1113],\n",
      "        [0.1112],\n",
      "        [0.1316],\n",
      "        [0.1488],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1242],\n",
      "        [0.0937],\n",
      "        [0.0976],\n",
      "        [0.0886],\n",
      "        [0.0882],\n",
      "        [0.0410],\n",
      "        [0.1273],\n",
      "        [0.1241],\n",
      "        [0.0909],\n",
      "        [0.0525],\n",
      "        [0.0365],\n",
      "        [0.0605],\n",
      "        [0.0208],\n",
      "        [0.0760],\n",
      "        [0.0693],\n",
      "        [0.0613],\n",
      "        [0.0498],\n",
      "        [0.0005],\n",
      "        [0.0148],\n",
      "        [0.0369],\n",
      "        [0.0521],\n",
      "        [0.0198],\n",
      "        [0.0240],\n",
      "        [0.0437],\n",
      "        [0.0519],\n",
      "        [0.0354],\n",
      "        [0.0379],\n",
      "        [0.0431],\n",
      "        [0.0329],\n",
      "        [0.0259],\n",
      "        [0.0049],\n",
      "        [0.0769],\n",
      "        [0.0606],\n",
      "        [0.0739],\n",
      "        [0.0759],\n",
      "        [0.0833],\n",
      "        [0.1074],\n",
      "        [0.2215],\n",
      "        [0.2611],\n",
      "        [0.3204]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[167,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0191],\n",
      "        [    0.0213],\n",
      "        [    0.0036],\n",
      "        [    0.0064],\n",
      "        [    0.0281],\n",
      "        [    0.0280],\n",
      "        [    0.0190],\n",
      "        [    0.0214],\n",
      "        [    0.0271],\n",
      "        [    0.0198],\n",
      "        [    0.0227],\n",
      "        [    0.0214],\n",
      "        [    0.0175],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0702],\n",
      "        [    0.0881],\n",
      "        [    0.0965],\n",
      "        [    0.0420],\n",
      "        [    0.0168],\n",
      "        [    0.0656],\n",
      "        [    0.0647],\n",
      "        [    0.0505],\n",
      "        [    0.0209],\n",
      "        [    0.0133],\n",
      "        [    0.0017],\n",
      "        [    0.0322],\n",
      "        [    0.0276],\n",
      "        [    0.0284],\n",
      "        [    0.0511],\n",
      "        [    0.0413],\n",
      "        [    0.0254],\n",
      "        [    0.0266],\n",
      "        [    0.0329],\n",
      "        [    0.0489],\n",
      "        [    0.0503],\n",
      "        [    0.0011],\n",
      "        [    0.0062],\n",
      "        [    0.0212],\n",
      "        [    0.0692],\n",
      "        [    0.0605],\n",
      "        [    0.0260],\n",
      "        [    0.0372],\n",
      "        [    0.0240],\n",
      "        [    0.0181],\n",
      "        [    0.0111],\n",
      "        [    0.0252],\n",
      "        [    0.0455],\n",
      "        [    0.0611],\n",
      "        [    0.0829],\n",
      "        [    0.0332],\n",
      "        [    0.0459],\n",
      "        [    0.0200],\n",
      "        [    0.0564],\n",
      "        [    0.1068],\n",
      "        [    0.0899],\n",
      "        [    0.0692],\n",
      "        [    0.0562],\n",
      "        [    0.0518],\n",
      "        [    0.0274],\n",
      "        [    0.1483],\n",
      "        [    0.0280],\n",
      "        [    0.0550],\n",
      "        [    0.0474],\n",
      "        [    0.0071],\n",
      "        [    0.0114],\n",
      "        [    0.0184],\n",
      "        [    0.0047],\n",
      "        [    0.0095],\n",
      "        [    0.0259],\n",
      "        [    0.0607],\n",
      "        [    0.0775],\n",
      "        [    0.0810],\n",
      "        [    0.0809],\n",
      "        [    0.1085],\n",
      "        [    0.0893],\n",
      "        [    0.0422],\n",
      "        [    0.0251],\n",
      "        [    0.0023],\n",
      "        [    0.0502],\n",
      "        [    0.0407],\n",
      "        [    0.0068],\n",
      "        [    0.0439],\n",
      "        [    0.0016],\n",
      "        [    0.1138],\n",
      "        [    0.1277],\n",
      "        [    0.1322],\n",
      "        [    0.0756],\n",
      "        [    0.0555],\n",
      "        [    0.0202],\n",
      "        [    0.0156],\n",
      "        [    0.0543],\n",
      "        [    0.0054],\n",
      "        [    0.0430],\n",
      "        [    0.2700],\n",
      "        [    0.1035],\n",
      "        [    0.0843],\n",
      "        [    0.0371],\n",
      "        [    0.0316],\n",
      "        [    0.0220],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1407],\n",
      "        [    0.1450],\n",
      "        [    0.0974],\n",
      "        [    0.0579],\n",
      "        [    0.0683],\n",
      "        [    0.1062],\n",
      "        [    0.1314],\n",
      "        [    0.1435],\n",
      "        [    0.1305],\n",
      "        [    0.0999],\n",
      "        [    0.0985],\n",
      "        [    0.0829],\n",
      "        [    0.0848],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1488],\n",
      "        [    0.1429],\n",
      "        [    0.1414],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0909],\n",
      "        [    0.0525],\n",
      "        [    0.0365],\n",
      "        [    0.0605],\n",
      "        [    0.0208],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0613],\n",
      "        [    0.0498],\n",
      "        [    0.0005],\n",
      "        [    0.0148],\n",
      "        [    0.0370],\n",
      "        [    0.0521],\n",
      "        [    0.0198],\n",
      "        [    0.0240],\n",
      "        [    0.0437],\n",
      "        [    0.0519],\n",
      "        [    0.0355],\n",
      "        [    0.0379],\n",
      "        [    0.0431],\n",
      "        [    0.0329],\n",
      "        [    0.0259],\n",
      "        [    0.0049],\n",
      "        [    0.0769],\n",
      "        [    0.0606],\n",
      "        [    0.0739],\n",
      "        [    0.0759],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 2\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0191],\n",
      "        [    0.0213],\n",
      "        [    0.0036],\n",
      "        [    0.0064],\n",
      "        [    0.0281],\n",
      "        [    0.0280],\n",
      "        [    0.0190],\n",
      "        [    0.0214],\n",
      "        [    0.0271],\n",
      "        [    0.0198],\n",
      "        [    0.0227],\n",
      "        [    0.0214],\n",
      "        [    0.0175],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0702],\n",
      "        [    0.0881],\n",
      "        [    0.0965],\n",
      "        [    0.0420],\n",
      "        [    0.0168],\n",
      "        [    0.0656],\n",
      "        [    0.0647],\n",
      "        [    0.0505],\n",
      "        [    0.0209],\n",
      "        [    0.0133],\n",
      "        [    0.0017],\n",
      "        [    0.0322],\n",
      "        [    0.0276],\n",
      "        [    0.0284],\n",
      "        [    0.0511],\n",
      "        [    0.0413],\n",
      "        [    0.0254],\n",
      "        [    0.0266],\n",
      "        [    0.0329],\n",
      "        [    0.0489],\n",
      "        [    0.0503],\n",
      "        [    0.0011],\n",
      "        [    0.0062],\n",
      "        [    0.0212],\n",
      "        [    0.0692],\n",
      "        [    0.0605],\n",
      "        [    0.0260],\n",
      "        [    0.0372],\n",
      "        [    0.0240],\n",
      "        [    0.0181],\n",
      "        [    0.0111],\n",
      "        [    0.0252],\n",
      "        [    0.0455],\n",
      "        [    0.0611],\n",
      "        [    0.0829],\n",
      "        [    0.0332],\n",
      "        [    0.0459],\n",
      "        [    0.0200],\n",
      "        [    0.0564],\n",
      "        [    0.1068],\n",
      "        [    0.0899],\n",
      "        [    0.0692],\n",
      "        [    0.0562],\n",
      "        [    0.0518],\n",
      "        [    0.0274],\n",
      "        [    0.1483],\n",
      "        [    0.0280],\n",
      "        [    0.0550],\n",
      "        [    0.0474],\n",
      "        [    0.0071],\n",
      "        [    0.0114],\n",
      "        [    0.0184],\n",
      "        [    0.0047],\n",
      "        [    0.0095],\n",
      "        [    0.0259],\n",
      "        [    0.0607],\n",
      "        [    0.0775],\n",
      "        [    0.0810],\n",
      "        [    0.0809],\n",
      "        [    0.1085],\n",
      "        [    0.0893],\n",
      "        [    0.0422],\n",
      "        [    0.0251],\n",
      "        [    0.0023],\n",
      "        [    0.0502],\n",
      "        [    0.0407],\n",
      "        [    0.0068],\n",
      "        [    0.0439],\n",
      "        [    0.0016],\n",
      "        [    0.1138],\n",
      "        [    0.1277],\n",
      "        [    0.1322],\n",
      "        [    0.0756],\n",
      "        [    0.0555],\n",
      "        [    0.0202],\n",
      "        [    0.0156],\n",
      "        [    0.0543],\n",
      "        [    0.0054],\n",
      "        [    0.0430],\n",
      "        [    0.2700],\n",
      "        [    0.1035],\n",
      "        [    0.0843],\n",
      "        [    0.0371],\n",
      "        [    0.0316],\n",
      "        [    0.0220],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1407],\n",
      "        [    0.1450],\n",
      "        [    0.0974],\n",
      "        [    0.0579],\n",
      "        [    0.0683],\n",
      "        [    0.1062],\n",
      "        [    0.1314],\n",
      "        [    0.1435],\n",
      "        [    0.1305],\n",
      "        [    0.0999],\n",
      "        [    0.0985],\n",
      "        [    0.0829],\n",
      "        [    0.0848],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1488],\n",
      "        [    0.1429],\n",
      "        [    0.1414],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0909],\n",
      "        [    0.0525],\n",
      "        [    0.0365],\n",
      "        [    0.0605],\n",
      "        [    0.0208],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0613],\n",
      "        [    0.0498],\n",
      "        [    0.0005],\n",
      "        [    0.0148],\n",
      "        [    0.0370],\n",
      "        [    0.0521],\n",
      "        [    0.0198],\n",
      "        [    0.0240],\n",
      "        [    0.0437],\n",
      "        [    0.0519],\n",
      "        [    0.0355],\n",
      "        [    0.0379],\n",
      "        [    0.0431],\n",
      "        [    0.0329],\n",
      "        [    0.0259],\n",
      "        [    0.0049],\n",
      "        [    0.0769],\n",
      "        [    0.0606],\n",
      "        [    0.0739],\n",
      "        [    0.0759],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 169\n",
      "剩餘X 資料 torch.Size([208, 18])\n",
      "剩餘Y 資料 torch.Size([208, 1])\n",
      "現在要進去模型的數據，y= tensor([0.2649])\n",
      "目前模型的Data狀態 torch.Size([169, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5702],\n",
      "        [0.5871],\n",
      "        [0.5890],\n",
      "        [0.5749],\n",
      "        [0.5694],\n",
      "        [0.5535],\n",
      "        [0.5604],\n",
      "        [0.5593],\n",
      "        [0.5554],\n",
      "        [0.5504],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5609],\n",
      "        [0.8742],\n",
      "        [0.9016],\n",
      "        [0.9387],\n",
      "        [0.8867],\n",
      "        [0.9122],\n",
      "        [0.9165],\n",
      "        [0.9101],\n",
      "        [0.9489],\n",
      "        [0.9558],\n",
      "        [0.9888],\n",
      "        [0.9945],\n",
      "        [1.0113],\n",
      "        [0.9696],\n",
      "        [0.9550],\n",
      "        [0.9289],\n",
      "        [0.9260],\n",
      "        [0.9184],\n",
      "        [0.8623],\n",
      "        [0.8812],\n",
      "        [0.8878],\n",
      "        [0.8656],\n",
      "        [0.8545],\n",
      "        [0.8485],\n",
      "        [0.8667],\n",
      "        [0.8620],\n",
      "        [0.8670],\n",
      "        [0.8575],\n",
      "        [0.8409],\n",
      "        [0.8252],\n",
      "        [0.8476],\n",
      "        [0.8607],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8810],\n",
      "        [0.8973],\n",
      "        [0.8733],\n",
      "        [0.8884],\n",
      "        [0.8835],\n",
      "        [0.8966],\n",
      "        [0.8932],\n",
      "        [0.8785],\n",
      "        [0.8990],\n",
      "        [0.9107],\n",
      "        [0.9004],\n",
      "        [0.8744],\n",
      "        [0.8562],\n",
      "        [0.8712],\n",
      "        [0.8846],\n",
      "        [0.8936],\n",
      "        [0.8453],\n",
      "        [0.9006],\n",
      "        [0.8795],\n",
      "        [0.8788],\n",
      "        [0.8579],\n",
      "        [0.8667],\n",
      "        [0.8488],\n",
      "        [0.8285],\n",
      "        [0.8390],\n",
      "        [0.8545],\n",
      "        [0.8509],\n",
      "        [0.8660],\n",
      "        [0.8781],\n",
      "        [0.8582],\n",
      "        [0.8593],\n",
      "        [0.8242],\n",
      "        [0.7950],\n",
      "        [0.8423],\n",
      "        [0.8375],\n",
      "        [0.8183],\n",
      "        [0.8177],\n",
      "        [0.7769],\n",
      "        [0.7907],\n",
      "        [0.8217],\n",
      "        [0.8010],\n",
      "        [0.7808],\n",
      "        [0.7619],\n",
      "        [0.7043],\n",
      "        [0.7163],\n",
      "        [0.7060],\n",
      "        [0.7311],\n",
      "        [0.7248],\n",
      "        [0.6986],\n",
      "        [0.6706],\n",
      "        [0.6237],\n",
      "        [0.6456],\n",
      "        [0.6105],\n",
      "        [0.5965],\n",
      "        [0.5948],\n",
      "        [0.5892],\n",
      "        [0.6144],\n",
      "        [0.6455],\n",
      "        [0.6231],\n",
      "        [0.5995],\n",
      "        [0.5847],\n",
      "        [0.5643],\n",
      "        [0.5745],\n",
      "        [0.5951],\n",
      "        [0.5851],\n",
      "        [0.5943],\n",
      "        [0.5750],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5643],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5574],\n",
      "        [0.5609],\n",
      "        [0.5812],\n",
      "        [0.6158],\n",
      "        [0.6398],\n",
      "        [0.6196],\n",
      "        [0.6232],\n",
      "        [0.5976],\n",
      "        [0.5896],\n",
      "        [0.5767],\n",
      "        [0.5715],\n",
      "        [0.5787],\n",
      "        [0.6009],\n",
      "        [0.5949],\n",
      "        [0.5814],\n",
      "        [0.5858],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.2275],\n",
      "        [0.5528]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0191],\n",
      "        [    0.0213],\n",
      "        [    0.0036],\n",
      "        [    0.0064],\n",
      "        [    0.0281],\n",
      "        [    0.0280],\n",
      "        [    0.0190],\n",
      "        [    0.0214],\n",
      "        [    0.0271],\n",
      "        [    0.0198],\n",
      "        [    0.0227],\n",
      "        [    0.0214],\n",
      "        [    0.0175],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0702],\n",
      "        [    0.0881],\n",
      "        [    0.0965],\n",
      "        [    0.0420],\n",
      "        [    0.0168],\n",
      "        [    0.0656],\n",
      "        [    0.0647],\n",
      "        [    0.0505],\n",
      "        [    0.0209],\n",
      "        [    0.0133],\n",
      "        [    0.0017],\n",
      "        [    0.0322],\n",
      "        [    0.0276],\n",
      "        [    0.0284],\n",
      "        [    0.0511],\n",
      "        [    0.0413],\n",
      "        [    0.0254],\n",
      "        [    0.0266],\n",
      "        [    0.0329],\n",
      "        [    0.0489],\n",
      "        [    0.0503],\n",
      "        [    0.0011],\n",
      "        [    0.0062],\n",
      "        [    0.0212],\n",
      "        [    0.0692],\n",
      "        [    0.0605],\n",
      "        [    0.0260],\n",
      "        [    0.0372],\n",
      "        [    0.0240],\n",
      "        [    0.0181],\n",
      "        [    0.0111],\n",
      "        [    0.0252],\n",
      "        [    0.0455],\n",
      "        [    0.0611],\n",
      "        [    0.0829],\n",
      "        [    0.0332],\n",
      "        [    0.0459],\n",
      "        [    0.0200],\n",
      "        [    0.0564],\n",
      "        [    0.1068],\n",
      "        [    0.0899],\n",
      "        [    0.0692],\n",
      "        [    0.0562],\n",
      "        [    0.0518],\n",
      "        [    0.0274],\n",
      "        [    0.1483],\n",
      "        [    0.0280],\n",
      "        [    0.0550],\n",
      "        [    0.0474],\n",
      "        [    0.0071],\n",
      "        [    0.0114],\n",
      "        [    0.0184],\n",
      "        [    0.0047],\n",
      "        [    0.0095],\n",
      "        [    0.0259],\n",
      "        [    0.0607],\n",
      "        [    0.0775],\n",
      "        [    0.0810],\n",
      "        [    0.0809],\n",
      "        [    0.1085],\n",
      "        [    0.0893],\n",
      "        [    0.0422],\n",
      "        [    0.0251],\n",
      "        [    0.0023],\n",
      "        [    0.0502],\n",
      "        [    0.0407],\n",
      "        [    0.0068],\n",
      "        [    0.0439],\n",
      "        [    0.0016],\n",
      "        [    0.1138],\n",
      "        [    0.1277],\n",
      "        [    0.1322],\n",
      "        [    0.0756],\n",
      "        [    0.0555],\n",
      "        [    0.0202],\n",
      "        [    0.0156],\n",
      "        [    0.0543],\n",
      "        [    0.0054],\n",
      "        [    0.0430],\n",
      "        [    0.2700],\n",
      "        [    0.1035],\n",
      "        [    0.0843],\n",
      "        [    0.0371],\n",
      "        [    0.0316],\n",
      "        [    0.0220],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1407],\n",
      "        [    0.1450],\n",
      "        [    0.0974],\n",
      "        [    0.0579],\n",
      "        [    0.0683],\n",
      "        [    0.1062],\n",
      "        [    0.1314],\n",
      "        [    0.1435],\n",
      "        [    0.1305],\n",
      "        [    0.0999],\n",
      "        [    0.0985],\n",
      "        [    0.0829],\n",
      "        [    0.0848],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1488],\n",
      "        [    0.1429],\n",
      "        [    0.1414],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0909],\n",
      "        [    0.0525],\n",
      "        [    0.0365],\n",
      "        [    0.0605],\n",
      "        [    0.0208],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0613],\n",
      "        [    0.0498],\n",
      "        [    0.0005],\n",
      "        [    0.0148],\n",
      "        [    0.0370],\n",
      "        [    0.0521],\n",
      "        [    0.0198],\n",
      "        [    0.0240],\n",
      "        [    0.0437],\n",
      "        [    0.0519],\n",
      "        [    0.0355],\n",
      "        [    0.0379],\n",
      "        [    0.0431],\n",
      "        [    0.0329],\n",
      "        [    0.0259],\n",
      "        [    0.0049],\n",
      "        [    0.0769],\n",
      "        [    0.0606],\n",
      "        [    0.0739],\n",
      "        [    0.0759],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.2878]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 89\n",
      "Number of shrink: 52\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0191],\n",
      "        [    0.0213],\n",
      "        [    0.0036],\n",
      "        [    0.0064],\n",
      "        [    0.0281],\n",
      "        [    0.0280],\n",
      "        [    0.0190],\n",
      "        [    0.0214],\n",
      "        [    0.0271],\n",
      "        [    0.0198],\n",
      "        [    0.0227],\n",
      "        [    0.0214],\n",
      "        [    0.0175],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0702],\n",
      "        [    0.0881],\n",
      "        [    0.0965],\n",
      "        [    0.0420],\n",
      "        [    0.0168],\n",
      "        [    0.0656],\n",
      "        [    0.0647],\n",
      "        [    0.0505],\n",
      "        [    0.0209],\n",
      "        [    0.0133],\n",
      "        [    0.0017],\n",
      "        [    0.0322],\n",
      "        [    0.0276],\n",
      "        [    0.0284],\n",
      "        [    0.0511],\n",
      "        [    0.0413],\n",
      "        [    0.0254],\n",
      "        [    0.0266],\n",
      "        [    0.0329],\n",
      "        [    0.0489],\n",
      "        [    0.0503],\n",
      "        [    0.0011],\n",
      "        [    0.0062],\n",
      "        [    0.0212],\n",
      "        [    0.0692],\n",
      "        [    0.0605],\n",
      "        [    0.0260],\n",
      "        [    0.0372],\n",
      "        [    0.0240],\n",
      "        [    0.0181],\n",
      "        [    0.0111],\n",
      "        [    0.0252],\n",
      "        [    0.0455],\n",
      "        [    0.0611],\n",
      "        [    0.0829],\n",
      "        [    0.0332],\n",
      "        [    0.0459],\n",
      "        [    0.0200],\n",
      "        [    0.0564],\n",
      "        [    0.1068],\n",
      "        [    0.0899],\n",
      "        [    0.0692],\n",
      "        [    0.0562],\n",
      "        [    0.0518],\n",
      "        [    0.0274],\n",
      "        [    0.1483],\n",
      "        [    0.0280],\n",
      "        [    0.0550],\n",
      "        [    0.0474],\n",
      "        [    0.0071],\n",
      "        [    0.0114],\n",
      "        [    0.0184],\n",
      "        [    0.0047],\n",
      "        [    0.0095],\n",
      "        [    0.0259],\n",
      "        [    0.0607],\n",
      "        [    0.0775],\n",
      "        [    0.0810],\n",
      "        [    0.0809],\n",
      "        [    0.1085],\n",
      "        [    0.0893],\n",
      "        [    0.0422],\n",
      "        [    0.0251],\n",
      "        [    0.0023],\n",
      "        [    0.0502],\n",
      "        [    0.0407],\n",
      "        [    0.0068],\n",
      "        [    0.0439],\n",
      "        [    0.0016],\n",
      "        [    0.1138],\n",
      "        [    0.1277],\n",
      "        [    0.1322],\n",
      "        [    0.0756],\n",
      "        [    0.0555],\n",
      "        [    0.0202],\n",
      "        [    0.0156],\n",
      "        [    0.0543],\n",
      "        [    0.0054],\n",
      "        [    0.0430],\n",
      "        [    0.2700],\n",
      "        [    0.1035],\n",
      "        [    0.0843],\n",
      "        [    0.0371],\n",
      "        [    0.0316],\n",
      "        [    0.0220],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1407],\n",
      "        [    0.1450],\n",
      "        [    0.0974],\n",
      "        [    0.0579],\n",
      "        [    0.0683],\n",
      "        [    0.1062],\n",
      "        [    0.1314],\n",
      "        [    0.1435],\n",
      "        [    0.1305],\n",
      "        [    0.0999],\n",
      "        [    0.0985],\n",
      "        [    0.0829],\n",
      "        [    0.0848],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1488],\n",
      "        [    0.1429],\n",
      "        [    0.1414],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0909],\n",
      "        [    0.0525],\n",
      "        [    0.0365],\n",
      "        [    0.0605],\n",
      "        [    0.0208],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0613],\n",
      "        [    0.0498],\n",
      "        [    0.0005],\n",
      "        [    0.0148],\n",
      "        [    0.0370],\n",
      "        [    0.0521],\n",
      "        [    0.0198],\n",
      "        [    0.0240],\n",
      "        [    0.0437],\n",
      "        [    0.0519],\n",
      "        [    0.0355],\n",
      "        [    0.0379],\n",
      "        [    0.0431],\n",
      "        [    0.0329],\n",
      "        [    0.0259],\n",
      "        [    0.0049],\n",
      "        [    0.0769],\n",
      "        [    0.0606],\n",
      "        [    0.0739],\n",
      "        [    0.0759],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.2878]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[168,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0214],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0953],\n",
      "        [    0.0430],\n",
      "        [    0.0179],\n",
      "        [    0.0642],\n",
      "        [    0.0636],\n",
      "        [    0.0492],\n",
      "        [    0.0216],\n",
      "        [    0.0127],\n",
      "        [    0.0023],\n",
      "        [    0.0336],\n",
      "        [    0.0266],\n",
      "        [    0.0293],\n",
      "        [    0.0523],\n",
      "        [    0.0406],\n",
      "        [    0.0249],\n",
      "        [    0.0257],\n",
      "        [    0.0342],\n",
      "        [    0.0480],\n",
      "        [    0.0517],\n",
      "        [    0.0021],\n",
      "        [    0.0071],\n",
      "        [    0.0217],\n",
      "        [    0.0704],\n",
      "        [    0.0596],\n",
      "        [    0.0268],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0112],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0565],\n",
      "        [    0.1070],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0508],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0463],\n",
      "        [    0.0058],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0095],\n",
      "        [    0.0259],\n",
      "        [    0.0620],\n",
      "        [    0.0768],\n",
      "        [    0.0821],\n",
      "        [    0.0800],\n",
      "        [    0.1098],\n",
      "        [    0.0900],\n",
      "        [    0.0434],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0511],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0027],\n",
      "        [    0.1125],\n",
      "        [    0.1276],\n",
      "        [    0.1320],\n",
      "        [    0.0756],\n",
      "        [    0.0557],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1204],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0973],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0846],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1112],\n",
      "        [    0.1316],\n",
      "        [    0.1485],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0909],\n",
      "        [    0.0525],\n",
      "        [    0.0365],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 24\n",
      "Number of shrink: 19\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 7\n",
      "Reorganizing result: The final number of neuro is  7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0214],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0953],\n",
      "        [    0.0430],\n",
      "        [    0.0179],\n",
      "        [    0.0642],\n",
      "        [    0.0636],\n",
      "        [    0.0492],\n",
      "        [    0.0216],\n",
      "        [    0.0127],\n",
      "        [    0.0023],\n",
      "        [    0.0336],\n",
      "        [    0.0266],\n",
      "        [    0.0293],\n",
      "        [    0.0523],\n",
      "        [    0.0406],\n",
      "        [    0.0249],\n",
      "        [    0.0257],\n",
      "        [    0.0342],\n",
      "        [    0.0480],\n",
      "        [    0.0517],\n",
      "        [    0.0021],\n",
      "        [    0.0071],\n",
      "        [    0.0217],\n",
      "        [    0.0704],\n",
      "        [    0.0596],\n",
      "        [    0.0268],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0112],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0565],\n",
      "        [    0.1070],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0508],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0463],\n",
      "        [    0.0058],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0095],\n",
      "        [    0.0259],\n",
      "        [    0.0620],\n",
      "        [    0.0768],\n",
      "        [    0.0821],\n",
      "        [    0.0800],\n",
      "        [    0.1098],\n",
      "        [    0.0900],\n",
      "        [    0.0434],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0511],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0027],\n",
      "        [    0.1125],\n",
      "        [    0.1276],\n",
      "        [    0.1320],\n",
      "        [    0.0756],\n",
      "        [    0.0557],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1204],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0973],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0846],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1112],\n",
      "        [    0.1316],\n",
      "        [    0.1485],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0909],\n",
      "        [    0.0525],\n",
      "        [    0.0365],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
      "        7], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 170\n",
      "剩餘X 資料 torch.Size([207, 18])\n",
      "剩餘Y 資料 torch.Size([207, 1])\n",
      "現在要進去模型的數據，y= tensor([0.2675])\n",
      "目前模型的Data狀態 torch.Size([170, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5888],\n",
      "        [0.5747],\n",
      "        [0.5693],\n",
      "        [0.5534],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8877],\n",
      "        [0.9111],\n",
      "        [0.9179],\n",
      "        [0.9111],\n",
      "        [0.9502],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9277],\n",
      "        [0.9267],\n",
      "        [0.9189],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8642],\n",
      "        [0.8554],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8418],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8838],\n",
      "        [0.8965],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9013],\n",
      "        [0.8750],\n",
      "        [0.8554],\n",
      "        [0.8720],\n",
      "        [0.8857],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8579],\n",
      "        [0.8667],\n",
      "        [0.8476],\n",
      "        [0.8291],\n",
      "        [0.8379],\n",
      "        [0.8554],\n",
      "        [0.8496],\n",
      "        [0.8652],\n",
      "        [0.8769],\n",
      "        [0.8574],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7939],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8193],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7905],\n",
      "        [0.8217],\n",
      "        [0.8012],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7309],\n",
      "        [0.7246],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6001],\n",
      "        [0.5844],\n",
      "        [0.5644],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5766],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6010],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2274],\n",
      "        [0.2660],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0214],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0953],\n",
      "        [    0.0430],\n",
      "        [    0.0179],\n",
      "        [    0.0642],\n",
      "        [    0.0636],\n",
      "        [    0.0492],\n",
      "        [    0.0216],\n",
      "        [    0.0127],\n",
      "        [    0.0023],\n",
      "        [    0.0336],\n",
      "        [    0.0266],\n",
      "        [    0.0293],\n",
      "        [    0.0523],\n",
      "        [    0.0406],\n",
      "        [    0.0249],\n",
      "        [    0.0257],\n",
      "        [    0.0342],\n",
      "        [    0.0480],\n",
      "        [    0.0517],\n",
      "        [    0.0021],\n",
      "        [    0.0071],\n",
      "        [    0.0217],\n",
      "        [    0.0704],\n",
      "        [    0.0596],\n",
      "        [    0.0268],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0112],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0565],\n",
      "        [    0.1070],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0508],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0463],\n",
      "        [    0.0058],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0095],\n",
      "        [    0.0259],\n",
      "        [    0.0620],\n",
      "        [    0.0768],\n",
      "        [    0.0821],\n",
      "        [    0.0800],\n",
      "        [    0.1098],\n",
      "        [    0.0900],\n",
      "        [    0.0434],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0511],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0027],\n",
      "        [    0.1125],\n",
      "        [    0.1276],\n",
      "        [    0.1320],\n",
      "        [    0.0756],\n",
      "        [    0.0557],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1204],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0973],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0846],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1112],\n",
      "        [    0.1316],\n",
      "        [    0.1485],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0909],\n",
      "        [    0.0525],\n",
      "        [    0.0365],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.2804]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0214],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0953],\n",
      "        [    0.0430],\n",
      "        [    0.0179],\n",
      "        [    0.0642],\n",
      "        [    0.0636],\n",
      "        [    0.0492],\n",
      "        [    0.0216],\n",
      "        [    0.0127],\n",
      "        [    0.0023],\n",
      "        [    0.0336],\n",
      "        [    0.0266],\n",
      "        [    0.0293],\n",
      "        [    0.0523],\n",
      "        [    0.0406],\n",
      "        [    0.0249],\n",
      "        [    0.0257],\n",
      "        [    0.0342],\n",
      "        [    0.0480],\n",
      "        [    0.0517],\n",
      "        [    0.0021],\n",
      "        [    0.0071],\n",
      "        [    0.0217],\n",
      "        [    0.0704],\n",
      "        [    0.0596],\n",
      "        [    0.0268],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0112],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0565],\n",
      "        [    0.1070],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0508],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0463],\n",
      "        [    0.0058],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0095],\n",
      "        [    0.0259],\n",
      "        [    0.0620],\n",
      "        [    0.0768],\n",
      "        [    0.0821],\n",
      "        [    0.0800],\n",
      "        [    0.1098],\n",
      "        [    0.0900],\n",
      "        [    0.0434],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0511],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0027],\n",
      "        [    0.1125],\n",
      "        [    0.1276],\n",
      "        [    0.1320],\n",
      "        [    0.0756],\n",
      "        [    0.0557],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1204],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0973],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0846],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1112],\n",
      "        [    0.1316],\n",
      "        [    0.1485],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0909],\n",
      "        [    0.0525],\n",
      "        [    0.0365],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.2804]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[169,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 171\n",
      "剩餘X 資料 torch.Size([206, 18])\n",
      "剩餘Y 資料 torch.Size([206, 1])\n",
      "現在要進去模型的數據，y= tensor([0.2910])\n",
      "目前模型的Data狀態 torch.Size([171, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 172\n",
      "剩餘X 資料 torch.Size([205, 18])\n",
      "剩餘Y 資料 torch.Size([205, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3027])\n",
      "目前模型的Data狀態 torch.Size([172, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 173\n",
      "剩餘X 資料 torch.Size([204, 18])\n",
      "剩餘Y 資料 torch.Size([204, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3192])\n",
      "目前模型的Data狀態 torch.Size([173, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 174\n",
      "剩餘X 資料 torch.Size([203, 18])\n",
      "剩餘Y 資料 torch.Size([203, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3078])\n",
      "目前模型的Data狀態 torch.Size([174, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 175\n",
      "剩餘X 資料 torch.Size([202, 18])\n",
      "剩餘Y 資料 torch.Size([202, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3071])\n",
      "目前模型的Data狀態 torch.Size([175, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 176\n",
      "剩餘X 資料 torch.Size([201, 18])\n",
      "剩餘Y 資料 torch.Size([201, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3579])\n",
      "目前模型的Data狀態 torch.Size([176, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 177\n",
      "剩餘X 資料 torch.Size([200, 18])\n",
      "剩餘Y 資料 torch.Size([200, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3580])\n",
      "目前模型的Data狀態 torch.Size([177, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 178\n",
      "剩餘X 資料 torch.Size([199, 18])\n",
      "剩餘Y 資料 torch.Size([199, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3587])\n",
      "目前模型的Data狀態 torch.Size([178, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 179\n",
      "剩餘X 資料 torch.Size([198, 18])\n",
      "剩餘Y 資料 torch.Size([198, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3586])\n",
      "目前模型的Data狀態 torch.Size([179, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 180\n",
      "剩餘X 資料 torch.Size([197, 18])\n",
      "剩餘Y 資料 torch.Size([197, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3635])\n",
      "目前模型的Data狀態 torch.Size([180, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 181\n",
      "剩餘X 資料 torch.Size([196, 18])\n",
      "剩餘Y 資料 torch.Size([196, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3911])\n",
      "目前模型的Data狀態 torch.Size([181, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 182\n",
      "剩餘X 資料 torch.Size([195, 18])\n",
      "剩餘Y 資料 torch.Size([195, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4510])\n",
      "目前模型的Data狀態 torch.Size([182, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 183\n",
      "剩餘X 資料 torch.Size([194, 18])\n",
      "剩餘Y 資料 torch.Size([194, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4522])\n",
      "目前模型的Data狀態 torch.Size([183, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 343\n",
      "Number of shrink: 157\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 184\n",
      "剩餘X 資料 torch.Size([193, 18])\n",
      "剩餘Y 資料 torch.Size([193, 1])\n",
      "現在要進去模型的數據，y= tensor([0.4365])\n",
      "目前模型的Data狀態 torch.Size([184, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 343\n",
      "Number of shrink: 157\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 185\n",
      "剩餘X 資料 torch.Size([192, 18])\n",
      "剩餘Y 資料 torch.Size([192, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3989])\n",
      "目前模型的Data狀態 torch.Size([185, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 343\n",
      "Number of shrink: 157\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 186\n",
      "剩餘X 資料 torch.Size([191, 18])\n",
      "剩餘Y 資料 torch.Size([191, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3645])\n",
      "目前模型的Data狀態 torch.Size([186, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 343\n",
      "Number of shrink: 157\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 187\n",
      "剩餘X 資料 torch.Size([190, 18])\n",
      "剩餘Y 資料 torch.Size([190, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3543])\n",
      "目前模型的Data狀態 torch.Size([187, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 342\n",
      "Number of shrink: 158\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 188\n",
      "剩餘X 資料 torch.Size([189, 18])\n",
      "剩餘Y 資料 torch.Size([189, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3142])\n",
      "目前模型的Data狀態 torch.Size([188, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 189\n",
      "剩餘X 資料 torch.Size([188, 18])\n",
      "剩餘Y 資料 torch.Size([188, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3114])\n",
      "目前模型的Data狀態 torch.Size([189, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 190\n",
      "剩餘X 資料 torch.Size([187, 18])\n",
      "剩餘Y 資料 torch.Size([187, 1])\n",
      "現在要進去模型的數據，y= tensor([0.3253])\n",
      "目前模型的Data狀態 torch.Size([190, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 191\n",
      "剩餘X 資料 torch.Size([186, 18])\n",
      "剩餘Y 資料 torch.Size([186, 1])\n",
      "現在要進去模型的數據，y= tensor([0.2710])\n",
      "目前模型的Data狀態 torch.Size([191, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.2768]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0900],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.2768]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[190,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 22\n",
      "Number of shrink: 18\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 328\n",
      "Number of shrink: 172\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 328\n",
      "Number of shrink: 172\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 13\n",
      "Reorganizing result: The final number of neuro is  13\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 13], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 192\n",
      "剩餘X 資料 torch.Size([185, 18])\n",
      "剩餘Y 資料 torch.Size([185, 1])\n",
      "現在要進去模型的數據，y= tensor([0.2622])\n",
      "目前模型的Data狀態 torch.Size([192, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5595],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9023],\n",
      "        [0.9375],\n",
      "        [0.8876],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9501],\n",
      "        [0.9550],\n",
      "        [0.9883],\n",
      "        [0.9951],\n",
      "        [1.0127],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9267],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8886],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8672],\n",
      "        [0.8633],\n",
      "        [0.8662],\n",
      "        [0.8584],\n",
      "        [0.8417],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8296],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8974],\n",
      "        [0.8735],\n",
      "        [0.8886],\n",
      "        [0.8837],\n",
      "        [0.8964],\n",
      "        [0.8930],\n",
      "        [0.8784],\n",
      "        [0.8989],\n",
      "        [0.9106],\n",
      "        [0.9014],\n",
      "        [0.8749],\n",
      "        [0.8554],\n",
      "        [0.8721],\n",
      "        [0.8858],\n",
      "        [0.8925],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8666],\n",
      "        [0.8476],\n",
      "        [0.8290],\n",
      "        [0.8379],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8651],\n",
      "        [0.8770],\n",
      "        [0.8573],\n",
      "        [0.8603],\n",
      "        [0.8232],\n",
      "        [0.7940],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7768],\n",
      "        [0.7904],\n",
      "        [0.8218],\n",
      "        [0.8013],\n",
      "        [0.7807],\n",
      "        [0.7622],\n",
      "        [0.7046],\n",
      "        [0.7168],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7246],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6000],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5976],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5810],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2275],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.2710],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.0000],\n",
      "        [    0.2856]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0213],\n",
      "        [    0.0270],\n",
      "        [    0.0199],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0176],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0068],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0954],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0493],\n",
      "        [    0.0217],\n",
      "        [    0.0128],\n",
      "        [    0.0023],\n",
      "        [    0.0337],\n",
      "        [    0.0266],\n",
      "        [    0.0292],\n",
      "        [    0.0524],\n",
      "        [    0.0406],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0597],\n",
      "        [    0.0269],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0113],\n",
      "        [    0.0253],\n",
      "        [    0.0455],\n",
      "        [    0.0609],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0461],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1070],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0507],\n",
      "        [    0.0269],\n",
      "        [    0.1475],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0057],\n",
      "        [    0.0102],\n",
      "        [    0.0185],\n",
      "        [    0.0046],\n",
      "        [    0.0096],\n",
      "        [    0.0260],\n",
      "        [    0.0620],\n",
      "        [    0.0769],\n",
      "        [    0.0821],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0901],\n",
      "        [    0.0433],\n",
      "        [    0.0260],\n",
      "        [    0.0013],\n",
      "        [    0.0512],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0026],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1320],\n",
      "        [    0.0757],\n",
      "        [    0.0558],\n",
      "        [    0.0201],\n",
      "        [    0.0159],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0972],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1316],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0999],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0933],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0881],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0605],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0692],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0149],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0240],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0429],\n",
      "        [    0.0331],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.0000],\n",
      "        [    0.2856]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[191,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0214],\n",
      "        [    0.0270],\n",
      "        [    0.0200],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0175],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0067],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0953],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0492],\n",
      "        [    0.0216],\n",
      "        [    0.0129],\n",
      "        [    0.0024],\n",
      "        [    0.0337],\n",
      "        [    0.0265],\n",
      "        [    0.0293],\n",
      "        [    0.0524],\n",
      "        [    0.0405],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0598],\n",
      "        [    0.0268],\n",
      "        [    0.0380],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0112],\n",
      "        [    0.0252],\n",
      "        [    0.0455],\n",
      "        [    0.0608],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0462],\n",
      "        [    0.0202],\n",
      "        [    0.0565],\n",
      "        [    0.1069],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0508],\n",
      "        [    0.0270],\n",
      "        [    0.1474],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0102],\n",
      "        [    0.0184],\n",
      "        [    0.0046],\n",
      "        [    0.0097],\n",
      "        [    0.0259],\n",
      "        [    0.0619],\n",
      "        [    0.0770],\n",
      "        [    0.0822],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0900],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0025],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1319],\n",
      "        [    0.0756],\n",
      "        [    0.0557],\n",
      "        [    0.0200],\n",
      "        [    0.0158],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0973],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1317],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0934],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0604],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0148],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0239],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0428],\n",
      "        [    0.0330],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.0000],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 14\n",
      "Number of shrink: 14\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 328\n",
      "Number of shrink: 172\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 328\n",
      "Number of shrink: 172\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 16\n",
      "Reorganizing result: The final number of neuro is  16\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0214],\n",
      "        [    0.0270],\n",
      "        [    0.0200],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0175],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0067],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0953],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0492],\n",
      "        [    0.0216],\n",
      "        [    0.0129],\n",
      "        [    0.0024],\n",
      "        [    0.0337],\n",
      "        [    0.0265],\n",
      "        [    0.0293],\n",
      "        [    0.0524],\n",
      "        [    0.0405],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0598],\n",
      "        [    0.0268],\n",
      "        [    0.0380],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0112],\n",
      "        [    0.0252],\n",
      "        [    0.0455],\n",
      "        [    0.0608],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0462],\n",
      "        [    0.0202],\n",
      "        [    0.0565],\n",
      "        [    0.1069],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0508],\n",
      "        [    0.0270],\n",
      "        [    0.1474],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0102],\n",
      "        [    0.0184],\n",
      "        [    0.0046],\n",
      "        [    0.0097],\n",
      "        [    0.0259],\n",
      "        [    0.0619],\n",
      "        [    0.0770],\n",
      "        [    0.0822],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0900],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0025],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1319],\n",
      "        [    0.0756],\n",
      "        [    0.0557],\n",
      "        [    0.0200],\n",
      "        [    0.0158],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0973],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1317],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0934],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0604],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0148],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0239],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0428],\n",
      "        [    0.0330],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.0000],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 13, 16], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 193\n",
      "剩餘X 資料 torch.Size([184, 18])\n",
      "剩餘Y 資料 torch.Size([184, 1])\n",
      "現在要進去模型的數據，y= tensor([0.2201])\n",
      "目前模型的Data狀態 torch.Size([193, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5473],\n",
      "        [0.5479],\n",
      "        [0.5480],\n",
      "        [0.5698],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5746],\n",
      "        [0.5693],\n",
      "        [0.5535],\n",
      "        [0.5605],\n",
      "        [0.5596],\n",
      "        [0.5554],\n",
      "        [0.5505],\n",
      "        [0.5479],\n",
      "        [0.5589],\n",
      "        [0.5841],\n",
      "        [0.5762],\n",
      "        [0.5478],\n",
      "        [0.5610],\n",
      "        [0.8750],\n",
      "        [0.9024],\n",
      "        [0.9375],\n",
      "        [0.8875],\n",
      "        [0.9112],\n",
      "        [0.9179],\n",
      "        [0.9110],\n",
      "        [0.9502],\n",
      "        [0.9550],\n",
      "        [0.9884],\n",
      "        [0.9951],\n",
      "        [1.0128],\n",
      "        [0.9707],\n",
      "        [0.9541],\n",
      "        [0.9276],\n",
      "        [0.9268],\n",
      "        [0.9190],\n",
      "        [0.8633],\n",
      "        [0.8799],\n",
      "        [0.8885],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8673],\n",
      "        [0.8633],\n",
      "        [0.8663],\n",
      "        [0.8584],\n",
      "        [0.8416],\n",
      "        [0.8257],\n",
      "        [0.8476],\n",
      "        [0.8608],\n",
      "        [0.8295],\n",
      "        [0.8550],\n",
      "        [0.8808],\n",
      "        [0.8975],\n",
      "        [0.8736],\n",
      "        [0.8887],\n",
      "        [0.8837],\n",
      "        [0.8965],\n",
      "        [0.8931],\n",
      "        [0.8783],\n",
      "        [0.8989],\n",
      "        [0.9107],\n",
      "        [0.9013],\n",
      "        [0.8748],\n",
      "        [0.8553],\n",
      "        [0.8721],\n",
      "        [0.8857],\n",
      "        [0.8924],\n",
      "        [0.8467],\n",
      "        [0.8994],\n",
      "        [0.8794],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8667],\n",
      "        [0.8477],\n",
      "        [0.8290],\n",
      "        [0.8378],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8652],\n",
      "        [0.8770],\n",
      "        [0.8574],\n",
      "        [0.8604],\n",
      "        [0.8231],\n",
      "        [0.7939],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8192],\n",
      "        [0.8164],\n",
      "        [0.7767],\n",
      "        [0.7904],\n",
      "        [0.8217],\n",
      "        [0.8012],\n",
      "        [0.7806],\n",
      "        [0.7621],\n",
      "        [0.7046],\n",
      "        [0.7167],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6235],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5964],\n",
      "        [0.5947],\n",
      "        [0.5891],\n",
      "        [0.6145],\n",
      "        [0.6455],\n",
      "        [0.6230],\n",
      "        [0.6001],\n",
      "        [0.5844],\n",
      "        [0.5645],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5849],\n",
      "        [0.5937],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5478],\n",
      "        [0.5481],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5500],\n",
      "        [0.5642],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5573],\n",
      "        [0.5610],\n",
      "        [0.5810],\n",
      "        [0.6157],\n",
      "        [0.6396],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5977],\n",
      "        [0.5898],\n",
      "        [0.5767],\n",
      "        [0.5713],\n",
      "        [0.5786],\n",
      "        [0.6011],\n",
      "        [0.5947],\n",
      "        [0.5811],\n",
      "        [0.5854],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.5479],\n",
      "        [0.2274],\n",
      "        [0.2660],\n",
      "        [0.2676],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.2710],\n",
      "        [0.2622],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0214],\n",
      "        [    0.0270],\n",
      "        [    0.0200],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0175],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0067],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0953],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0492],\n",
      "        [    0.0216],\n",
      "        [    0.0129],\n",
      "        [    0.0024],\n",
      "        [    0.0337],\n",
      "        [    0.0265],\n",
      "        [    0.0293],\n",
      "        [    0.0524],\n",
      "        [    0.0405],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0598],\n",
      "        [    0.0268],\n",
      "        [    0.0380],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0112],\n",
      "        [    0.0252],\n",
      "        [    0.0455],\n",
      "        [    0.0608],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0462],\n",
      "        [    0.0202],\n",
      "        [    0.0565],\n",
      "        [    0.1069],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0508],\n",
      "        [    0.0270],\n",
      "        [    0.1474],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0102],\n",
      "        [    0.0184],\n",
      "        [    0.0046],\n",
      "        [    0.0097],\n",
      "        [    0.0259],\n",
      "        [    0.0619],\n",
      "        [    0.0770],\n",
      "        [    0.0822],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0900],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0025],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1319],\n",
      "        [    0.0756],\n",
      "        [    0.0557],\n",
      "        [    0.0200],\n",
      "        [    0.0158],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0973],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1317],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0934],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0604],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0148],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0239],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0428],\n",
      "        [    0.0330],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.3277]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0196],\n",
      "        [    0.0213],\n",
      "        [    0.0034],\n",
      "        [    0.0060],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0188],\n",
      "        [    0.0214],\n",
      "        [    0.0270],\n",
      "        [    0.0200],\n",
      "        [    0.0229],\n",
      "        [    0.0214],\n",
      "        [    0.0175],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0428],\n",
      "        [    0.0512],\n",
      "        [    0.0238],\n",
      "        [    0.0067],\n",
      "        [    0.0710],\n",
      "        [    0.0888],\n",
      "        [    0.0953],\n",
      "        [    0.0429],\n",
      "        [    0.0178],\n",
      "        [    0.0642],\n",
      "        [    0.0637],\n",
      "        [    0.0492],\n",
      "        [    0.0216],\n",
      "        [    0.0129],\n",
      "        [    0.0024],\n",
      "        [    0.0337],\n",
      "        [    0.0265],\n",
      "        [    0.0293],\n",
      "        [    0.0524],\n",
      "        [    0.0405],\n",
      "        [    0.0248],\n",
      "        [    0.0256],\n",
      "        [    0.0342],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0218],\n",
      "        [    0.0704],\n",
      "        [    0.0598],\n",
      "        [    0.0268],\n",
      "        [    0.0380],\n",
      "        [    0.0235],\n",
      "        [    0.0181],\n",
      "        [    0.0112],\n",
      "        [    0.0252],\n",
      "        [    0.0455],\n",
      "        [    0.0608],\n",
      "        [    0.0830],\n",
      "        [    0.0335],\n",
      "        [    0.0462],\n",
      "        [    0.0202],\n",
      "        [    0.0565],\n",
      "        [    0.1069],\n",
      "        [    0.0901],\n",
      "        [    0.0693],\n",
      "        [    0.0563],\n",
      "        [    0.0508],\n",
      "        [    0.0270],\n",
      "        [    0.1474],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0102],\n",
      "        [    0.0184],\n",
      "        [    0.0046],\n",
      "        [    0.0097],\n",
      "        [    0.0259],\n",
      "        [    0.0619],\n",
      "        [    0.0770],\n",
      "        [    0.0822],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0900],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0025],\n",
      "        [    0.1126],\n",
      "        [    0.1275],\n",
      "        [    0.1319],\n",
      "        [    0.0756],\n",
      "        [    0.0557],\n",
      "        [    0.0200],\n",
      "        [    0.0158],\n",
      "        [    0.0540],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0318],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1203],\n",
      "        [    0.1408],\n",
      "        [    0.1452],\n",
      "        [    0.0973],\n",
      "        [    0.0579],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1317],\n",
      "        [    0.1433],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0986],\n",
      "        [    0.0834],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0934],\n",
      "        [    0.1113],\n",
      "        [    0.1111],\n",
      "        [    0.1316],\n",
      "        [    0.1486],\n",
      "        [    0.1429],\n",
      "        [    0.1412],\n",
      "        [    0.1242],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0882],\n",
      "        [    0.0410],\n",
      "        [    0.1273],\n",
      "        [    0.1241],\n",
      "        [    0.0910],\n",
      "        [    0.0525],\n",
      "        [    0.0364],\n",
      "        [    0.0604],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0614],\n",
      "        [    0.0497],\n",
      "        [    0.0003],\n",
      "        [    0.0148],\n",
      "        [    0.0371],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0239],\n",
      "        [    0.0435],\n",
      "        [    0.0520],\n",
      "        [    0.0357],\n",
      "        [    0.0380],\n",
      "        [    0.0428],\n",
      "        [    0.0330],\n",
      "        [    0.0262],\n",
      "        [    0.0053],\n",
      "        [    0.0769],\n",
      "        [    0.0605],\n",
      "        [    0.0739],\n",
      "        [    0.0758],\n",
      "        [    0.0833],\n",
      "        [    0.1074],\n",
      "        [    0.2215],\n",
      "        [    0.2611],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2336],\n",
      "        [    0.2364],\n",
      "        [    0.2226],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.3277]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[192,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0201],\n",
      "        [    0.0218],\n",
      "        [    0.0034],\n",
      "        [    0.0065],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0183],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0197],\n",
      "        [    0.0234],\n",
      "        [    0.0214],\n",
      "        [    0.0168],\n",
      "        [    0.0251],\n",
      "        [    0.0108],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0067],\n",
      "        [    0.0720],\n",
      "        [    0.0898],\n",
      "        [    0.0943],\n",
      "        [    0.0419],\n",
      "        [    0.0168],\n",
      "        [    0.0652],\n",
      "        [    0.0647],\n",
      "        [    0.0483],\n",
      "        [    0.0226],\n",
      "        [    0.0109],\n",
      "        [    0.0034],\n",
      "        [    0.0347],\n",
      "        [    0.0265],\n",
      "        [    0.0312],\n",
      "        [    0.0514],\n",
      "        [    0.0405],\n",
      "        [    0.0238],\n",
      "        [    0.0237],\n",
      "        [    0.0352],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0228],\n",
      "        [    0.0704],\n",
      "        [    0.0598],\n",
      "        [    0.0268],\n",
      "        [    0.0380],\n",
      "        [    0.0226],\n",
      "        [    0.0176],\n",
      "        [    0.0117],\n",
      "        [    0.0257],\n",
      "        [    0.0460],\n",
      "        [    0.0608],\n",
      "        [    0.0835],\n",
      "        [    0.0340],\n",
      "        [    0.0447],\n",
      "        [    0.0197],\n",
      "        [    0.0575],\n",
      "        [    0.1084],\n",
      "        [    0.0897],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0498],\n",
      "        [    0.0260],\n",
      "        [    0.1474],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0112],\n",
      "        [    0.0174],\n",
      "        [    0.0051],\n",
      "        [    0.0097],\n",
      "        [    0.0254],\n",
      "        [    0.0619],\n",
      "        [    0.0760],\n",
      "        [    0.0822],\n",
      "        [    0.0790],\n",
      "        [    0.1089],\n",
      "        [    0.0910],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0091],\n",
      "        [    0.0433],\n",
      "        [    0.0016],\n",
      "        [    0.1126],\n",
      "        [    0.1280],\n",
      "        [    0.1319],\n",
      "        [    0.0751],\n",
      "        [    0.0547],\n",
      "        [    0.0200],\n",
      "        [    0.0144],\n",
      "        [    0.0535],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0313],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1198],\n",
      "        [    0.1410],\n",
      "        [    0.1449],\n",
      "        [    0.0970],\n",
      "        [    0.0583],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1312],\n",
      "        [    0.1423],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0991],\n",
      "        [    0.0830],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.1001],\n",
      "        [    0.0934],\n",
      "        [    0.1113],\n",
      "        [    0.1116],\n",
      "        [    0.1321],\n",
      "        [    0.1483],\n",
      "        [    0.1427],\n",
      "        [    0.1412],\n",
      "        [    0.1244],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0877],\n",
      "        [    0.0408],\n",
      "        [    0.1273],\n",
      "        [    0.1246],\n",
      "        [    0.0910],\n",
      "        [    0.0530],\n",
      "        [    0.0367],\n",
      "        [    0.0602],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0616],\n",
      "        [    0.0502],\n",
      "        [    0.0013],\n",
      "        [    0.0148],\n",
      "        [    0.0376],\n",
      "        [    0.0516],\n",
      "        [    0.0190],\n",
      "        [    0.0239],\n",
      "        [    0.0435],\n",
      "        [    0.0515],\n",
      "        [    0.0362],\n",
      "        [    0.0380],\n",
      "        [    0.0424],\n",
      "        [    0.0326],\n",
      "        [    0.0257],\n",
      "        [    0.0057],\n",
      "        [    0.0776],\n",
      "        [    0.0603],\n",
      "        [    0.0740],\n",
      "        [    0.0755],\n",
      "        [    0.0837],\n",
      "        [    0.1071],\n",
      "        [    0.2214],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2363],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 8\n",
      "Number of shrink: 11\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 314\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 328\n",
      "Number of shrink: 172\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 327\n",
      "Number of shrink: 173\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 19\n",
      "Reorganizing result: The final number of neuro is  19\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0201],\n",
      "        [    0.0218],\n",
      "        [    0.0034],\n",
      "        [    0.0065],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0183],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0197],\n",
      "        [    0.0234],\n",
      "        [    0.0214],\n",
      "        [    0.0168],\n",
      "        [    0.0251],\n",
      "        [    0.0108],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0067],\n",
      "        [    0.0720],\n",
      "        [    0.0898],\n",
      "        [    0.0943],\n",
      "        [    0.0419],\n",
      "        [    0.0168],\n",
      "        [    0.0652],\n",
      "        [    0.0647],\n",
      "        [    0.0483],\n",
      "        [    0.0226],\n",
      "        [    0.0109],\n",
      "        [    0.0034],\n",
      "        [    0.0347],\n",
      "        [    0.0265],\n",
      "        [    0.0312],\n",
      "        [    0.0514],\n",
      "        [    0.0405],\n",
      "        [    0.0238],\n",
      "        [    0.0237],\n",
      "        [    0.0352],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0228],\n",
      "        [    0.0704],\n",
      "        [    0.0598],\n",
      "        [    0.0268],\n",
      "        [    0.0380],\n",
      "        [    0.0226],\n",
      "        [    0.0176],\n",
      "        [    0.0117],\n",
      "        [    0.0257],\n",
      "        [    0.0460],\n",
      "        [    0.0608],\n",
      "        [    0.0835],\n",
      "        [    0.0340],\n",
      "        [    0.0447],\n",
      "        [    0.0197],\n",
      "        [    0.0575],\n",
      "        [    0.1084],\n",
      "        [    0.0897],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0498],\n",
      "        [    0.0260],\n",
      "        [    0.1474],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0112],\n",
      "        [    0.0174],\n",
      "        [    0.0051],\n",
      "        [    0.0097],\n",
      "        [    0.0254],\n",
      "        [    0.0619],\n",
      "        [    0.0760],\n",
      "        [    0.0822],\n",
      "        [    0.0790],\n",
      "        [    0.1089],\n",
      "        [    0.0910],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0091],\n",
      "        [    0.0433],\n",
      "        [    0.0016],\n",
      "        [    0.1126],\n",
      "        [    0.1280],\n",
      "        [    0.1319],\n",
      "        [    0.0751],\n",
      "        [    0.0547],\n",
      "        [    0.0200],\n",
      "        [    0.0144],\n",
      "        [    0.0535],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0313],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1198],\n",
      "        [    0.1410],\n",
      "        [    0.1449],\n",
      "        [    0.0970],\n",
      "        [    0.0583],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1312],\n",
      "        [    0.1423],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0991],\n",
      "        [    0.0830],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.1001],\n",
      "        [    0.0934],\n",
      "        [    0.1113],\n",
      "        [    0.1116],\n",
      "        [    0.1321],\n",
      "        [    0.1483],\n",
      "        [    0.1427],\n",
      "        [    0.1412],\n",
      "        [    0.1244],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0877],\n",
      "        [    0.0408],\n",
      "        [    0.1273],\n",
      "        [    0.1246],\n",
      "        [    0.0910],\n",
      "        [    0.0530],\n",
      "        [    0.0367],\n",
      "        [    0.0602],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0616],\n",
      "        [    0.0502],\n",
      "        [    0.0013],\n",
      "        [    0.0148],\n",
      "        [    0.0376],\n",
      "        [    0.0516],\n",
      "        [    0.0190],\n",
      "        [    0.0239],\n",
      "        [    0.0435],\n",
      "        [    0.0515],\n",
      "        [    0.0362],\n",
      "        [    0.0380],\n",
      "        [    0.0424],\n",
      "        [    0.0326],\n",
      "        [    0.0257],\n",
      "        [    0.0057],\n",
      "        [    0.0776],\n",
      "        [    0.0603],\n",
      "        [    0.0740],\n",
      "        [    0.0755],\n",
      "        [    0.0837],\n",
      "        [    0.1071],\n",
      "        [    0.2214],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2363],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 13, 16, 19], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 194\n",
      "剩餘X 資料 torch.Size([183, 18])\n",
      "剩餘Y 資料 torch.Size([183, 1])\n",
      "現在要進去模型的數據，y= tensor([0.1909])\n",
      "目前模型的Data狀態 torch.Size([194, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5468],\n",
      "        [0.5483],\n",
      "        [0.5480],\n",
      "        [0.5703],\n",
      "        [0.5869],\n",
      "        [0.5889],\n",
      "        [0.5741],\n",
      "        [0.5698],\n",
      "        [0.5542],\n",
      "        [0.5603],\n",
      "        [0.5601],\n",
      "        [0.5554],\n",
      "        [0.5497],\n",
      "        [0.5481],\n",
      "        [0.5588],\n",
      "        [0.5840],\n",
      "        [0.5761],\n",
      "        [0.5477],\n",
      "        [0.5610],\n",
      "        [0.8759],\n",
      "        [0.9034],\n",
      "        [0.9365],\n",
      "        [0.8866],\n",
      "        [0.9121],\n",
      "        [0.9169],\n",
      "        [0.9101],\n",
      "        [0.9511],\n",
      "        [0.9541],\n",
      "        [0.9864],\n",
      "        [0.9961],\n",
      "        [1.0138],\n",
      "        [0.9707],\n",
      "        [0.9521],\n",
      "        [0.9286],\n",
      "        [0.9268],\n",
      "        [0.9200],\n",
      "        [0.8653],\n",
      "        [0.8789],\n",
      "        [0.8885],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8683],\n",
      "        [0.8633],\n",
      "        [0.8663],\n",
      "        [0.8584],\n",
      "        [0.8416],\n",
      "        [0.8266],\n",
      "        [0.8471],\n",
      "        [0.8613],\n",
      "        [0.8300],\n",
      "        [0.8554],\n",
      "        [0.8808],\n",
      "        [0.8980],\n",
      "        [0.8741],\n",
      "        [0.8872],\n",
      "        [0.8832],\n",
      "        [0.8955],\n",
      "        [0.8916],\n",
      "        [0.8788],\n",
      "        [0.8989],\n",
      "        [0.9112],\n",
      "        [0.9023],\n",
      "        [0.8758],\n",
      "        [0.8553],\n",
      "        [0.8721],\n",
      "        [0.8857],\n",
      "        [0.8924],\n",
      "        [0.8467],\n",
      "        [0.9004],\n",
      "        [0.8804],\n",
      "        [0.8784],\n",
      "        [0.8578],\n",
      "        [0.8672],\n",
      "        [0.8477],\n",
      "        [0.8299],\n",
      "        [0.8378],\n",
      "        [0.8565],\n",
      "        [0.8504],\n",
      "        [0.8642],\n",
      "        [0.8770],\n",
      "        [0.8574],\n",
      "        [0.8604],\n",
      "        [0.8231],\n",
      "        [0.7939],\n",
      "        [0.8446],\n",
      "        [0.8369],\n",
      "        [0.8182],\n",
      "        [0.8164],\n",
      "        [0.7772],\n",
      "        [0.7904],\n",
      "        [0.8213],\n",
      "        [0.8003],\n",
      "        [0.7806],\n",
      "        [0.7607],\n",
      "        [0.7050],\n",
      "        [0.7167],\n",
      "        [0.7060],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6987],\n",
      "        [0.6704],\n",
      "        [0.6240],\n",
      "        [0.6457],\n",
      "        [0.6106],\n",
      "        [0.5969],\n",
      "        [0.5945],\n",
      "        [0.5893],\n",
      "        [0.6147],\n",
      "        [0.6450],\n",
      "        [0.6230],\n",
      "        [0.6001],\n",
      "        [0.5849],\n",
      "        [0.5654],\n",
      "        [0.5747],\n",
      "        [0.5952],\n",
      "        [0.5844],\n",
      "        [0.5942],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5473],\n",
      "        [0.5478],\n",
      "        [0.5479],\n",
      "        [0.5474],\n",
      "        [0.5473],\n",
      "        [0.5482],\n",
      "        [0.5481],\n",
      "        [0.5481],\n",
      "        [0.5476],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5483],\n",
      "        [0.5481],\n",
      "        [0.5478],\n",
      "        [0.5483],\n",
      "        [0.5479],\n",
      "        [0.5483],\n",
      "        [0.5480],\n",
      "        [0.5503],\n",
      "        [0.5642],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5571],\n",
      "        [0.5605],\n",
      "        [0.5820],\n",
      "        [0.6157],\n",
      "        [0.6391],\n",
      "        [0.6201],\n",
      "        [0.6240],\n",
      "        [0.5977],\n",
      "        [0.5898],\n",
      "        [0.5771],\n",
      "        [0.5708],\n",
      "        [0.5786],\n",
      "        [0.6016],\n",
      "        [0.5952],\n",
      "        [0.5815],\n",
      "        [0.5849],\n",
      "        [0.5486],\n",
      "        [0.5476],\n",
      "        [0.5479],\n",
      "        [0.5474],\n",
      "        [0.5482],\n",
      "        [0.5475],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.2274],\n",
      "        [0.2659],\n",
      "        [0.2674],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5477],\n",
      "        [0.5477],\n",
      "        [0.2710],\n",
      "        [0.2622],\n",
      "        [0.2214],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0201],\n",
      "        [    0.0218],\n",
      "        [    0.0034],\n",
      "        [    0.0065],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0183],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0197],\n",
      "        [    0.0234],\n",
      "        [    0.0214],\n",
      "        [    0.0168],\n",
      "        [    0.0251],\n",
      "        [    0.0108],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0067],\n",
      "        [    0.0720],\n",
      "        [    0.0898],\n",
      "        [    0.0943],\n",
      "        [    0.0419],\n",
      "        [    0.0168],\n",
      "        [    0.0652],\n",
      "        [    0.0647],\n",
      "        [    0.0483],\n",
      "        [    0.0226],\n",
      "        [    0.0109],\n",
      "        [    0.0034],\n",
      "        [    0.0347],\n",
      "        [    0.0265],\n",
      "        [    0.0312],\n",
      "        [    0.0514],\n",
      "        [    0.0405],\n",
      "        [    0.0238],\n",
      "        [    0.0237],\n",
      "        [    0.0352],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0228],\n",
      "        [    0.0704],\n",
      "        [    0.0598],\n",
      "        [    0.0268],\n",
      "        [    0.0380],\n",
      "        [    0.0226],\n",
      "        [    0.0176],\n",
      "        [    0.0117],\n",
      "        [    0.0257],\n",
      "        [    0.0460],\n",
      "        [    0.0608],\n",
      "        [    0.0835],\n",
      "        [    0.0340],\n",
      "        [    0.0447],\n",
      "        [    0.0197],\n",
      "        [    0.0575],\n",
      "        [    0.1084],\n",
      "        [    0.0897],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0498],\n",
      "        [    0.0260],\n",
      "        [    0.1474],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0112],\n",
      "        [    0.0174],\n",
      "        [    0.0051],\n",
      "        [    0.0097],\n",
      "        [    0.0254],\n",
      "        [    0.0619],\n",
      "        [    0.0760],\n",
      "        [    0.0822],\n",
      "        [    0.0790],\n",
      "        [    0.1089],\n",
      "        [    0.0910],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0091],\n",
      "        [    0.0433],\n",
      "        [    0.0016],\n",
      "        [    0.1126],\n",
      "        [    0.1280],\n",
      "        [    0.1319],\n",
      "        [    0.0751],\n",
      "        [    0.0547],\n",
      "        [    0.0200],\n",
      "        [    0.0144],\n",
      "        [    0.0535],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0313],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1198],\n",
      "        [    0.1410],\n",
      "        [    0.1449],\n",
      "        [    0.0970],\n",
      "        [    0.0583],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1312],\n",
      "        [    0.1423],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0991],\n",
      "        [    0.0830],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.1001],\n",
      "        [    0.0934],\n",
      "        [    0.1113],\n",
      "        [    0.1116],\n",
      "        [    0.1321],\n",
      "        [    0.1483],\n",
      "        [    0.1427],\n",
      "        [    0.1412],\n",
      "        [    0.1244],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0877],\n",
      "        [    0.0408],\n",
      "        [    0.1273],\n",
      "        [    0.1246],\n",
      "        [    0.0910],\n",
      "        [    0.0530],\n",
      "        [    0.0367],\n",
      "        [    0.0602],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0616],\n",
      "        [    0.0502],\n",
      "        [    0.0013],\n",
      "        [    0.0148],\n",
      "        [    0.0376],\n",
      "        [    0.0516],\n",
      "        [    0.0190],\n",
      "        [    0.0239],\n",
      "        [    0.0435],\n",
      "        [    0.0515],\n",
      "        [    0.0362],\n",
      "        [    0.0380],\n",
      "        [    0.0424],\n",
      "        [    0.0326],\n",
      "        [    0.0257],\n",
      "        [    0.0057],\n",
      "        [    0.0776],\n",
      "        [    0.0603],\n",
      "        [    0.0740],\n",
      "        [    0.0755],\n",
      "        [    0.0837],\n",
      "        [    0.1071],\n",
      "        [    0.2214],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2363],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.3569]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0201],\n",
      "        [    0.0218],\n",
      "        [    0.0034],\n",
      "        [    0.0065],\n",
      "        [    0.0279],\n",
      "        [    0.0278],\n",
      "        [    0.0183],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0197],\n",
      "        [    0.0234],\n",
      "        [    0.0214],\n",
      "        [    0.0168],\n",
      "        [    0.0251],\n",
      "        [    0.0108],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0067],\n",
      "        [    0.0720],\n",
      "        [    0.0898],\n",
      "        [    0.0943],\n",
      "        [    0.0419],\n",
      "        [    0.0168],\n",
      "        [    0.0652],\n",
      "        [    0.0647],\n",
      "        [    0.0483],\n",
      "        [    0.0226],\n",
      "        [    0.0109],\n",
      "        [    0.0034],\n",
      "        [    0.0347],\n",
      "        [    0.0265],\n",
      "        [    0.0312],\n",
      "        [    0.0514],\n",
      "        [    0.0405],\n",
      "        [    0.0238],\n",
      "        [    0.0237],\n",
      "        [    0.0352],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0228],\n",
      "        [    0.0704],\n",
      "        [    0.0598],\n",
      "        [    0.0268],\n",
      "        [    0.0380],\n",
      "        [    0.0226],\n",
      "        [    0.0176],\n",
      "        [    0.0117],\n",
      "        [    0.0257],\n",
      "        [    0.0460],\n",
      "        [    0.0608],\n",
      "        [    0.0835],\n",
      "        [    0.0340],\n",
      "        [    0.0447],\n",
      "        [    0.0197],\n",
      "        [    0.0575],\n",
      "        [    0.1084],\n",
      "        [    0.0897],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0498],\n",
      "        [    0.0260],\n",
      "        [    0.1474],\n",
      "        [    0.0288],\n",
      "        [    0.0561],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0112],\n",
      "        [    0.0174],\n",
      "        [    0.0051],\n",
      "        [    0.0097],\n",
      "        [    0.0254],\n",
      "        [    0.0619],\n",
      "        [    0.0760],\n",
      "        [    0.0822],\n",
      "        [    0.0790],\n",
      "        [    0.1089],\n",
      "        [    0.0910],\n",
      "        [    0.0433],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0513],\n",
      "        [    0.0417],\n",
      "        [    0.0091],\n",
      "        [    0.0433],\n",
      "        [    0.0016],\n",
      "        [    0.1126],\n",
      "        [    0.1280],\n",
      "        [    0.1319],\n",
      "        [    0.0751],\n",
      "        [    0.0547],\n",
      "        [    0.0200],\n",
      "        [    0.0144],\n",
      "        [    0.0535],\n",
      "        [    0.0050],\n",
      "        [    0.0430],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0844],\n",
      "        [    0.0369],\n",
      "        [    0.0313],\n",
      "        [    0.0221],\n",
      "        [    0.0505],\n",
      "        [    0.1198],\n",
      "        [    0.1410],\n",
      "        [    0.1449],\n",
      "        [    0.0970],\n",
      "        [    0.0583],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1312],\n",
      "        [    0.1423],\n",
      "        [    0.1303],\n",
      "        [    0.0998],\n",
      "        [    0.0991],\n",
      "        [    0.0830],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.1001],\n",
      "        [    0.0934],\n",
      "        [    0.1113],\n",
      "        [    0.1116],\n",
      "        [    0.1321],\n",
      "        [    0.1483],\n",
      "        [    0.1427],\n",
      "        [    0.1412],\n",
      "        [    0.1244],\n",
      "        [    0.0937],\n",
      "        [    0.0976],\n",
      "        [    0.0886],\n",
      "        [    0.0877],\n",
      "        [    0.0408],\n",
      "        [    0.1273],\n",
      "        [    0.1246],\n",
      "        [    0.0910],\n",
      "        [    0.0530],\n",
      "        [    0.0367],\n",
      "        [    0.0602],\n",
      "        [    0.0209],\n",
      "        [    0.0760],\n",
      "        [    0.0693],\n",
      "        [    0.0616],\n",
      "        [    0.0502],\n",
      "        [    0.0013],\n",
      "        [    0.0148],\n",
      "        [    0.0376],\n",
      "        [    0.0516],\n",
      "        [    0.0190],\n",
      "        [    0.0239],\n",
      "        [    0.0435],\n",
      "        [    0.0515],\n",
      "        [    0.0362],\n",
      "        [    0.0380],\n",
      "        [    0.0424],\n",
      "        [    0.0326],\n",
      "        [    0.0257],\n",
      "        [    0.0057],\n",
      "        [    0.0776],\n",
      "        [    0.0603],\n",
      "        [    0.0740],\n",
      "        [    0.0755],\n",
      "        [    0.0837],\n",
      "        [    0.1071],\n",
      "        [    0.2214],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2363],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.3569]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[193,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0201],\n",
      "        [    0.0221],\n",
      "        [    0.0034],\n",
      "        [    0.0065],\n",
      "        [    0.0279],\n",
      "        [    0.0273],\n",
      "        [    0.0183],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0195],\n",
      "        [    0.0234],\n",
      "        [    0.0211],\n",
      "        [    0.0170],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0072],\n",
      "        [    0.0739],\n",
      "        [    0.0898],\n",
      "        [    0.0943],\n",
      "        [    0.0419],\n",
      "        [    0.0159],\n",
      "        [    0.0652],\n",
      "        [    0.0647],\n",
      "        [    0.0483],\n",
      "        [    0.0226],\n",
      "        [    0.0109],\n",
      "        [    0.0043],\n",
      "        [    0.0347],\n",
      "        [    0.0255],\n",
      "        [    0.0312],\n",
      "        [    0.0514],\n",
      "        [    0.0415],\n",
      "        [    0.0238],\n",
      "        [    0.0237],\n",
      "        [    0.0352],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0238],\n",
      "        [    0.0704],\n",
      "        [    0.0588],\n",
      "        [    0.0268],\n",
      "        [    0.0370],\n",
      "        [    0.0231],\n",
      "        [    0.0186],\n",
      "        [    0.0122],\n",
      "        [    0.0257],\n",
      "        [    0.0460],\n",
      "        [    0.0613],\n",
      "        [    0.0835],\n",
      "        [    0.0340],\n",
      "        [    0.0447],\n",
      "        [    0.0202],\n",
      "        [    0.0570],\n",
      "        [    0.1079],\n",
      "        [    0.0892],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0498],\n",
      "        [    0.0260],\n",
      "        [    0.1484],\n",
      "        [    0.0278],\n",
      "        [    0.0570],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0112],\n",
      "        [    0.0174],\n",
      "        [    0.0046],\n",
      "        [    0.0097],\n",
      "        [    0.0249],\n",
      "        [    0.0609],\n",
      "        [    0.0760],\n",
      "        [    0.0832],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0920],\n",
      "        [    0.0423],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0522],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0006],\n",
      "        [    0.1126],\n",
      "        [    0.1280],\n",
      "        [    0.1314],\n",
      "        [    0.0751],\n",
      "        [    0.0543],\n",
      "        [    0.0200],\n",
      "        [    0.0139],\n",
      "        [    0.0531],\n",
      "        [    0.0055],\n",
      "        [    0.0425],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0839],\n",
      "        [    0.0374],\n",
      "        [    0.0313],\n",
      "        [    0.0224],\n",
      "        [    0.0503],\n",
      "        [    0.1201],\n",
      "        [    0.1408],\n",
      "        [    0.1449],\n",
      "        [    0.0968],\n",
      "        [    0.0583],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1317],\n",
      "        [    0.1418],\n",
      "        [    0.1298],\n",
      "        [    0.1003],\n",
      "        [    0.0986],\n",
      "        [    0.0830],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0934],\n",
      "        [    0.1108],\n",
      "        [    0.1111],\n",
      "        [    0.1319],\n",
      "        [    0.1483],\n",
      "        [    0.1427],\n",
      "        [    0.1412],\n",
      "        [    0.1244],\n",
      "        [    0.0937],\n",
      "        [    0.0971],\n",
      "        [    0.0886],\n",
      "        [    0.0877],\n",
      "        [    0.0408],\n",
      "        [    0.1278],\n",
      "        [    0.1246],\n",
      "        [    0.0913],\n",
      "        [    0.0532],\n",
      "        [    0.0367],\n",
      "        [    0.0602],\n",
      "        [    0.0209],\n",
      "        [    0.0762],\n",
      "        [    0.0690],\n",
      "        [    0.0614],\n",
      "        [    0.0507],\n",
      "        [    0.0018],\n",
      "        [    0.0153],\n",
      "        [    0.0381],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0244],\n",
      "        [    0.0440],\n",
      "        [    0.0520],\n",
      "        [    0.0362],\n",
      "        [    0.0384],\n",
      "        [    0.0424],\n",
      "        [    0.0321],\n",
      "        [    0.0262],\n",
      "        [    0.0062],\n",
      "        [    0.0776],\n",
      "        [    0.0605],\n",
      "        [    0.0740],\n",
      "        [    0.0755],\n",
      "        [    0.0837],\n",
      "        [    0.1071],\n",
      "        [    0.2215],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2363],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 10\n",
      "Number of shrink: 12\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 327\n",
      "Number of shrink: 173\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 328\n",
      "Number of shrink: 172\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 327\n",
      "Number of shrink: 173\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 22\n",
      "Reorganizing result: The final number of neuro is  22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0201],\n",
      "        [    0.0221],\n",
      "        [    0.0034],\n",
      "        [    0.0065],\n",
      "        [    0.0279],\n",
      "        [    0.0273],\n",
      "        [    0.0183],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0195],\n",
      "        [    0.0234],\n",
      "        [    0.0211],\n",
      "        [    0.0170],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0072],\n",
      "        [    0.0739],\n",
      "        [    0.0898],\n",
      "        [    0.0943],\n",
      "        [    0.0419],\n",
      "        [    0.0159],\n",
      "        [    0.0652],\n",
      "        [    0.0647],\n",
      "        [    0.0483],\n",
      "        [    0.0226],\n",
      "        [    0.0109],\n",
      "        [    0.0043],\n",
      "        [    0.0347],\n",
      "        [    0.0255],\n",
      "        [    0.0312],\n",
      "        [    0.0514],\n",
      "        [    0.0415],\n",
      "        [    0.0238],\n",
      "        [    0.0237],\n",
      "        [    0.0352],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0238],\n",
      "        [    0.0704],\n",
      "        [    0.0588],\n",
      "        [    0.0268],\n",
      "        [    0.0370],\n",
      "        [    0.0231],\n",
      "        [    0.0186],\n",
      "        [    0.0122],\n",
      "        [    0.0257],\n",
      "        [    0.0460],\n",
      "        [    0.0613],\n",
      "        [    0.0835],\n",
      "        [    0.0340],\n",
      "        [    0.0447],\n",
      "        [    0.0202],\n",
      "        [    0.0570],\n",
      "        [    0.1079],\n",
      "        [    0.0892],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0498],\n",
      "        [    0.0260],\n",
      "        [    0.1484],\n",
      "        [    0.0278],\n",
      "        [    0.0570],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0112],\n",
      "        [    0.0174],\n",
      "        [    0.0046],\n",
      "        [    0.0097],\n",
      "        [    0.0249],\n",
      "        [    0.0609],\n",
      "        [    0.0760],\n",
      "        [    0.0832],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0920],\n",
      "        [    0.0423],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0522],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0006],\n",
      "        [    0.1126],\n",
      "        [    0.1280],\n",
      "        [    0.1314],\n",
      "        [    0.0751],\n",
      "        [    0.0543],\n",
      "        [    0.0200],\n",
      "        [    0.0139],\n",
      "        [    0.0531],\n",
      "        [    0.0055],\n",
      "        [    0.0425],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0839],\n",
      "        [    0.0374],\n",
      "        [    0.0313],\n",
      "        [    0.0224],\n",
      "        [    0.0503],\n",
      "        [    0.1201],\n",
      "        [    0.1408],\n",
      "        [    0.1449],\n",
      "        [    0.0968],\n",
      "        [    0.0583],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1317],\n",
      "        [    0.1418],\n",
      "        [    0.1298],\n",
      "        [    0.1003],\n",
      "        [    0.0986],\n",
      "        [    0.0830],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0934],\n",
      "        [    0.1108],\n",
      "        [    0.1111],\n",
      "        [    0.1319],\n",
      "        [    0.1483],\n",
      "        [    0.1427],\n",
      "        [    0.1412],\n",
      "        [    0.1244],\n",
      "        [    0.0937],\n",
      "        [    0.0971],\n",
      "        [    0.0886],\n",
      "        [    0.0877],\n",
      "        [    0.0408],\n",
      "        [    0.1278],\n",
      "        [    0.1246],\n",
      "        [    0.0913],\n",
      "        [    0.0532],\n",
      "        [    0.0367],\n",
      "        [    0.0602],\n",
      "        [    0.0209],\n",
      "        [    0.0762],\n",
      "        [    0.0690],\n",
      "        [    0.0614],\n",
      "        [    0.0507],\n",
      "        [    0.0018],\n",
      "        [    0.0153],\n",
      "        [    0.0381],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0244],\n",
      "        [    0.0440],\n",
      "        [    0.0520],\n",
      "        [    0.0362],\n",
      "        [    0.0384],\n",
      "        [    0.0424],\n",
      "        [    0.0321],\n",
      "        [    0.0262],\n",
      "        [    0.0062],\n",
      "        [    0.0776],\n",
      "        [    0.0605],\n",
      "        [    0.0740],\n",
      "        [    0.0755],\n",
      "        [    0.0837],\n",
      "        [    0.1071],\n",
      "        [    0.2215],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2363],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 13, 16, 19, 22],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 195\n",
      "剩餘X 資料 torch.Size([182, 18])\n",
      "剩餘Y 資料 torch.Size([182, 1])\n",
      "現在要進去模型的數據，y= tensor([0.1627])\n",
      "目前模型的Data狀態 torch.Size([195, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5468],\n",
      "        [0.5486],\n",
      "        [0.5480],\n",
      "        [0.5703],\n",
      "        [0.5869],\n",
      "        [0.5884],\n",
      "        [0.5741],\n",
      "        [0.5698],\n",
      "        [0.5542],\n",
      "        [0.5601],\n",
      "        [0.5601],\n",
      "        [0.5551],\n",
      "        [0.5500],\n",
      "        [0.5479],\n",
      "        [0.5588],\n",
      "        [0.5840],\n",
      "        [0.5761],\n",
      "        [0.5477],\n",
      "        [0.5605],\n",
      "        [0.8779],\n",
      "        [0.9034],\n",
      "        [0.9365],\n",
      "        [0.8866],\n",
      "        [0.9131],\n",
      "        [0.9169],\n",
      "        [0.9101],\n",
      "        [0.9511],\n",
      "        [0.9541],\n",
      "        [0.9864],\n",
      "        [0.9971],\n",
      "        [1.0138],\n",
      "        [0.9717],\n",
      "        [0.9521],\n",
      "        [0.9286],\n",
      "        [0.9258],\n",
      "        [0.9200],\n",
      "        [0.8653],\n",
      "        [0.8789],\n",
      "        [0.8885],\n",
      "        [0.8643],\n",
      "        [0.8555],\n",
      "        [0.8476],\n",
      "        [0.8692],\n",
      "        [0.8633],\n",
      "        [0.8653],\n",
      "        [0.8584],\n",
      "        [0.8407],\n",
      "        [0.8261],\n",
      "        [0.8481],\n",
      "        [0.8618],\n",
      "        [0.8300],\n",
      "        [0.8554],\n",
      "        [0.8813],\n",
      "        [0.8980],\n",
      "        [0.8741],\n",
      "        [0.8872],\n",
      "        [0.8837],\n",
      "        [0.8960],\n",
      "        [0.8921],\n",
      "        [0.8793],\n",
      "        [0.8989],\n",
      "        [0.9112],\n",
      "        [0.9023],\n",
      "        [0.8758],\n",
      "        [0.8563],\n",
      "        [0.8711],\n",
      "        [0.8867],\n",
      "        [0.8924],\n",
      "        [0.8467],\n",
      "        [0.9004],\n",
      "        [0.8804],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8676],\n",
      "        [0.8487],\n",
      "        [0.8299],\n",
      "        [0.8368],\n",
      "        [0.8555],\n",
      "        [0.8495],\n",
      "        [0.8633],\n",
      "        [0.8780],\n",
      "        [0.8574],\n",
      "        [0.8604],\n",
      "        [0.8221],\n",
      "        [0.7939],\n",
      "        [0.8437],\n",
      "        [0.8369],\n",
      "        [0.8172],\n",
      "        [0.8164],\n",
      "        [0.7772],\n",
      "        [0.7899],\n",
      "        [0.8213],\n",
      "        [0.7998],\n",
      "        [0.7806],\n",
      "        [0.7602],\n",
      "        [0.7055],\n",
      "        [0.7162],\n",
      "        [0.7055],\n",
      "        [0.7310],\n",
      "        [0.7245],\n",
      "        [0.6982],\n",
      "        [0.6709],\n",
      "        [0.6240],\n",
      "        [0.6459],\n",
      "        [0.6108],\n",
      "        [0.5967],\n",
      "        [0.5947],\n",
      "        [0.5893],\n",
      "        [0.6150],\n",
      "        [0.6450],\n",
      "        [0.6230],\n",
      "        [0.6001],\n",
      "        [0.5844],\n",
      "        [0.5659],\n",
      "        [0.5752],\n",
      "        [0.5947],\n",
      "        [0.5849],\n",
      "        [0.5942],\n",
      "        [0.5752],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5483],\n",
      "        [0.5479],\n",
      "        [0.5475],\n",
      "        [0.5482],\n",
      "        [0.5481],\n",
      "        [0.5481],\n",
      "        [0.5476],\n",
      "        [0.5479],\n",
      "        [0.5483],\n",
      "        [0.5478],\n",
      "        [0.5483],\n",
      "        [0.5481],\n",
      "        [0.5483],\n",
      "        [0.5483],\n",
      "        [0.5481],\n",
      "        [0.5486],\n",
      "        [0.5480],\n",
      "        [0.5503],\n",
      "        [0.5642],\n",
      "        [0.5476],\n",
      "        [0.5480],\n",
      "        [0.5573],\n",
      "        [0.5601],\n",
      "        [0.5825],\n",
      "        [0.6152],\n",
      "        [0.6386],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5972],\n",
      "        [0.5893],\n",
      "        [0.5767],\n",
      "        [0.5708],\n",
      "        [0.5781],\n",
      "        [0.6016],\n",
      "        [0.5957],\n",
      "        [0.5811],\n",
      "        [0.5844],\n",
      "        [0.5486],\n",
      "        [0.5477],\n",
      "        [0.5479],\n",
      "        [0.5474],\n",
      "        [0.5482],\n",
      "        [0.5475],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.2274],\n",
      "        [0.2660],\n",
      "        [0.2675],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5477],\n",
      "        [0.5477],\n",
      "        [0.2710],\n",
      "        [0.2622],\n",
      "        [0.2214],\n",
      "        [0.1909],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0201],\n",
      "        [    0.0221],\n",
      "        [    0.0034],\n",
      "        [    0.0065],\n",
      "        [    0.0279],\n",
      "        [    0.0273],\n",
      "        [    0.0183],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0195],\n",
      "        [    0.0234],\n",
      "        [    0.0211],\n",
      "        [    0.0170],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0072],\n",
      "        [    0.0739],\n",
      "        [    0.0898],\n",
      "        [    0.0943],\n",
      "        [    0.0419],\n",
      "        [    0.0159],\n",
      "        [    0.0652],\n",
      "        [    0.0647],\n",
      "        [    0.0483],\n",
      "        [    0.0226],\n",
      "        [    0.0109],\n",
      "        [    0.0043],\n",
      "        [    0.0347],\n",
      "        [    0.0255],\n",
      "        [    0.0312],\n",
      "        [    0.0514],\n",
      "        [    0.0415],\n",
      "        [    0.0238],\n",
      "        [    0.0237],\n",
      "        [    0.0352],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0238],\n",
      "        [    0.0704],\n",
      "        [    0.0588],\n",
      "        [    0.0268],\n",
      "        [    0.0370],\n",
      "        [    0.0231],\n",
      "        [    0.0186],\n",
      "        [    0.0122],\n",
      "        [    0.0257],\n",
      "        [    0.0460],\n",
      "        [    0.0613],\n",
      "        [    0.0835],\n",
      "        [    0.0340],\n",
      "        [    0.0447],\n",
      "        [    0.0202],\n",
      "        [    0.0570],\n",
      "        [    0.1079],\n",
      "        [    0.0892],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0498],\n",
      "        [    0.0260],\n",
      "        [    0.1484],\n",
      "        [    0.0278],\n",
      "        [    0.0570],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0112],\n",
      "        [    0.0174],\n",
      "        [    0.0046],\n",
      "        [    0.0097],\n",
      "        [    0.0249],\n",
      "        [    0.0609],\n",
      "        [    0.0760],\n",
      "        [    0.0832],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0920],\n",
      "        [    0.0423],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0522],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0006],\n",
      "        [    0.1126],\n",
      "        [    0.1280],\n",
      "        [    0.1314],\n",
      "        [    0.0751],\n",
      "        [    0.0543],\n",
      "        [    0.0200],\n",
      "        [    0.0139],\n",
      "        [    0.0531],\n",
      "        [    0.0055],\n",
      "        [    0.0425],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0839],\n",
      "        [    0.0374],\n",
      "        [    0.0313],\n",
      "        [    0.0224],\n",
      "        [    0.0503],\n",
      "        [    0.1201],\n",
      "        [    0.1408],\n",
      "        [    0.1449],\n",
      "        [    0.0968],\n",
      "        [    0.0583],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1317],\n",
      "        [    0.1418],\n",
      "        [    0.1298],\n",
      "        [    0.1003],\n",
      "        [    0.0986],\n",
      "        [    0.0830],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0934],\n",
      "        [    0.1108],\n",
      "        [    0.1111],\n",
      "        [    0.1319],\n",
      "        [    0.1483],\n",
      "        [    0.1427],\n",
      "        [    0.1412],\n",
      "        [    0.1244],\n",
      "        [    0.0937],\n",
      "        [    0.0971],\n",
      "        [    0.0886],\n",
      "        [    0.0877],\n",
      "        [    0.0408],\n",
      "        [    0.1278],\n",
      "        [    0.1246],\n",
      "        [    0.0913],\n",
      "        [    0.0532],\n",
      "        [    0.0367],\n",
      "        [    0.0602],\n",
      "        [    0.0209],\n",
      "        [    0.0762],\n",
      "        [    0.0690],\n",
      "        [    0.0614],\n",
      "        [    0.0507],\n",
      "        [    0.0018],\n",
      "        [    0.0153],\n",
      "        [    0.0381],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0244],\n",
      "        [    0.0440],\n",
      "        [    0.0520],\n",
      "        [    0.0362],\n",
      "        [    0.0384],\n",
      "        [    0.0424],\n",
      "        [    0.0321],\n",
      "        [    0.0262],\n",
      "        [    0.0062],\n",
      "        [    0.0776],\n",
      "        [    0.0605],\n",
      "        [    0.0740],\n",
      "        [    0.0755],\n",
      "        [    0.0837],\n",
      "        [    0.1071],\n",
      "        [    0.2215],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2363],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0000],\n",
      "        [    0.3851]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0201],\n",
      "        [    0.0221],\n",
      "        [    0.0034],\n",
      "        [    0.0065],\n",
      "        [    0.0279],\n",
      "        [    0.0273],\n",
      "        [    0.0183],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0195],\n",
      "        [    0.0234],\n",
      "        [    0.0211],\n",
      "        [    0.0170],\n",
      "        [    0.0248],\n",
      "        [    0.0107],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0072],\n",
      "        [    0.0739],\n",
      "        [    0.0898],\n",
      "        [    0.0943],\n",
      "        [    0.0419],\n",
      "        [    0.0159],\n",
      "        [    0.0652],\n",
      "        [    0.0647],\n",
      "        [    0.0483],\n",
      "        [    0.0226],\n",
      "        [    0.0109],\n",
      "        [    0.0043],\n",
      "        [    0.0347],\n",
      "        [    0.0255],\n",
      "        [    0.0312],\n",
      "        [    0.0514],\n",
      "        [    0.0415],\n",
      "        [    0.0238],\n",
      "        [    0.0237],\n",
      "        [    0.0352],\n",
      "        [    0.0481],\n",
      "        [    0.0516],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0238],\n",
      "        [    0.0704],\n",
      "        [    0.0588],\n",
      "        [    0.0268],\n",
      "        [    0.0370],\n",
      "        [    0.0231],\n",
      "        [    0.0186],\n",
      "        [    0.0122],\n",
      "        [    0.0257],\n",
      "        [    0.0460],\n",
      "        [    0.0613],\n",
      "        [    0.0835],\n",
      "        [    0.0340],\n",
      "        [    0.0447],\n",
      "        [    0.0202],\n",
      "        [    0.0570],\n",
      "        [    0.1079],\n",
      "        [    0.0892],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0498],\n",
      "        [    0.0260],\n",
      "        [    0.1484],\n",
      "        [    0.0278],\n",
      "        [    0.0570],\n",
      "        [    0.0462],\n",
      "        [    0.0058],\n",
      "        [    0.0112],\n",
      "        [    0.0174],\n",
      "        [    0.0046],\n",
      "        [    0.0097],\n",
      "        [    0.0249],\n",
      "        [    0.0609],\n",
      "        [    0.0760],\n",
      "        [    0.0832],\n",
      "        [    0.0799],\n",
      "        [    0.1099],\n",
      "        [    0.0920],\n",
      "        [    0.0423],\n",
      "        [    0.0259],\n",
      "        [    0.0013],\n",
      "        [    0.0522],\n",
      "        [    0.0417],\n",
      "        [    0.0082],\n",
      "        [    0.0433],\n",
      "        [    0.0006],\n",
      "        [    0.1126],\n",
      "        [    0.1280],\n",
      "        [    0.1314],\n",
      "        [    0.0751],\n",
      "        [    0.0543],\n",
      "        [    0.0200],\n",
      "        [    0.0139],\n",
      "        [    0.0531],\n",
      "        [    0.0055],\n",
      "        [    0.0425],\n",
      "        [    0.2698],\n",
      "        [    0.1032],\n",
      "        [    0.0839],\n",
      "        [    0.0374],\n",
      "        [    0.0313],\n",
      "        [    0.0224],\n",
      "        [    0.0503],\n",
      "        [    0.1201],\n",
      "        [    0.1408],\n",
      "        [    0.1449],\n",
      "        [    0.0968],\n",
      "        [    0.0583],\n",
      "        [    0.0684],\n",
      "        [    0.1056],\n",
      "        [    0.1317],\n",
      "        [    0.1418],\n",
      "        [    0.1298],\n",
      "        [    0.1003],\n",
      "        [    0.0986],\n",
      "        [    0.0830],\n",
      "        [    0.0845],\n",
      "        [    0.0875],\n",
      "        [    0.0996],\n",
      "        [    0.0934],\n",
      "        [    0.1108],\n",
      "        [    0.1111],\n",
      "        [    0.1319],\n",
      "        [    0.1483],\n",
      "        [    0.1427],\n",
      "        [    0.1412],\n",
      "        [    0.1244],\n",
      "        [    0.0937],\n",
      "        [    0.0971],\n",
      "        [    0.0886],\n",
      "        [    0.0877],\n",
      "        [    0.0408],\n",
      "        [    0.1278],\n",
      "        [    0.1246],\n",
      "        [    0.0913],\n",
      "        [    0.0532],\n",
      "        [    0.0367],\n",
      "        [    0.0602],\n",
      "        [    0.0209],\n",
      "        [    0.0762],\n",
      "        [    0.0690],\n",
      "        [    0.0614],\n",
      "        [    0.0507],\n",
      "        [    0.0018],\n",
      "        [    0.0153],\n",
      "        [    0.0381],\n",
      "        [    0.0521],\n",
      "        [    0.0195],\n",
      "        [    0.0244],\n",
      "        [    0.0440],\n",
      "        [    0.0520],\n",
      "        [    0.0362],\n",
      "        [    0.0384],\n",
      "        [    0.0424],\n",
      "        [    0.0321],\n",
      "        [    0.0262],\n",
      "        [    0.0062],\n",
      "        [    0.0776],\n",
      "        [    0.0605],\n",
      "        [    0.0740],\n",
      "        [    0.0755],\n",
      "        [    0.0837],\n",
      "        [    0.1071],\n",
      "        [    0.2215],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2363],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0000],\n",
      "        [    0.3851]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[194,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0199],\n",
      "        [    0.0221],\n",
      "        [    0.0034],\n",
      "        [    0.0063],\n",
      "        [    0.0280],\n",
      "        [    0.0276],\n",
      "        [    0.0182],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0194],\n",
      "        [    0.0234],\n",
      "        [    0.0212],\n",
      "        [    0.0171],\n",
      "        [    0.0249],\n",
      "        [    0.0107],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0072],\n",
      "        [    0.0736],\n",
      "        [    0.0896],\n",
      "        [    0.0942],\n",
      "        [    0.0417],\n",
      "        [    0.0155],\n",
      "        [    0.0653],\n",
      "        [    0.0650],\n",
      "        [    0.0486],\n",
      "        [    0.0230],\n",
      "        [    0.0108],\n",
      "        [    0.0041],\n",
      "        [    0.0348],\n",
      "        [    0.0254],\n",
      "        [    0.0313],\n",
      "        [    0.0511],\n",
      "        [    0.0420],\n",
      "        [    0.0237],\n",
      "        [    0.0233],\n",
      "        [    0.0350],\n",
      "        [    0.0481],\n",
      "        [    0.0521],\n",
      "        [    0.0021],\n",
      "        [    0.0071],\n",
      "        [    0.0240],\n",
      "        [    0.0703],\n",
      "        [    0.0591],\n",
      "        [    0.0271],\n",
      "        [    0.0370],\n",
      "        [    0.0235],\n",
      "        [    0.0189],\n",
      "        [    0.0121],\n",
      "        [    0.0256],\n",
      "        [    0.0459],\n",
      "        [    0.0616],\n",
      "        [    0.0833],\n",
      "        [    0.0341],\n",
      "        [    0.0449],\n",
      "        [    0.0202],\n",
      "        [    0.0569],\n",
      "        [    0.1082],\n",
      "        [    0.0892],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0495],\n",
      "        [    0.0257],\n",
      "        [    0.1479],\n",
      "        [    0.0274],\n",
      "        [    0.0571],\n",
      "        [    0.0465],\n",
      "        [    0.0058],\n",
      "        [    0.0107],\n",
      "        [    0.0177],\n",
      "        [    0.0045],\n",
      "        [    0.0097],\n",
      "        [    0.0249],\n",
      "        [    0.0607],\n",
      "        [    0.0757],\n",
      "        [    0.0832],\n",
      "        [    0.0804],\n",
      "        [    0.1099],\n",
      "        [    0.0918],\n",
      "        [    0.0422],\n",
      "        [    0.0258],\n",
      "        [    0.0016],\n",
      "        [    0.0525],\n",
      "        [    0.0415],\n",
      "        [    0.0082],\n",
      "        [    0.0430],\n",
      "        [    0.0010],\n",
      "        [    0.1131],\n",
      "        [    0.1275],\n",
      "        [    0.1311],\n",
      "        [    0.0752],\n",
      "        [    0.0540],\n",
      "        [    0.0200],\n",
      "        [    0.0138],\n",
      "        [    0.0529],\n",
      "        [    0.0058],\n",
      "        [    0.0425],\n",
      "        [    0.2697],\n",
      "        [    0.1030],\n",
      "        [    0.0838],\n",
      "        [    0.0373],\n",
      "        [    0.0311],\n",
      "        [    0.0221],\n",
      "        [    0.0501],\n",
      "        [    0.1200],\n",
      "        [    0.1407],\n",
      "        [    0.1449],\n",
      "        [    0.0967],\n",
      "        [    0.0583],\n",
      "        [    0.0687],\n",
      "        [    0.1054],\n",
      "        [    0.1319],\n",
      "        [    0.1418],\n",
      "        [    0.1300],\n",
      "        [    0.1005],\n",
      "        [    0.0985],\n",
      "        [    0.0828],\n",
      "        [    0.0847],\n",
      "        [    0.0878],\n",
      "        [    0.0996],\n",
      "        [    0.0932],\n",
      "        [    0.1106],\n",
      "        [    0.1113],\n",
      "        [    0.1318],\n",
      "        [    0.1483],\n",
      "        [    0.1426],\n",
      "        [    0.1414],\n",
      "        [    0.1245],\n",
      "        [    0.0938],\n",
      "        [    0.0970],\n",
      "        [    0.0884],\n",
      "        [    0.0875],\n",
      "        [    0.0409],\n",
      "        [    0.1280],\n",
      "        [    0.1244],\n",
      "        [    0.0913],\n",
      "        [    0.0531],\n",
      "        [    0.0367],\n",
      "        [    0.0603],\n",
      "        [    0.0208],\n",
      "        [    0.0763],\n",
      "        [    0.0691],\n",
      "        [    0.0614],\n",
      "        [    0.0508],\n",
      "        [    0.0016],\n",
      "        [    0.0153],\n",
      "        [    0.0378],\n",
      "        [    0.0521],\n",
      "        [    0.0194],\n",
      "        [    0.0243],\n",
      "        [    0.0439],\n",
      "        [    0.0521],\n",
      "        [    0.0363],\n",
      "        [    0.0387],\n",
      "        [    0.0422],\n",
      "        [    0.0323],\n",
      "        [    0.0262],\n",
      "        [    0.0064],\n",
      "        [    0.0776],\n",
      "        [    0.0604],\n",
      "        [    0.0741],\n",
      "        [    0.0756],\n",
      "        [    0.0836],\n",
      "        [    0.1071],\n",
      "        [    0.2215],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2362],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0000],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 8\n",
      "Number of shrink: 11\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 265\n",
      "Number of shrink: 142\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 328\n",
      "Number of shrink: 172\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 308\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 23 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 24 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 25 / 25\n",
      "Reorganizing result: The final number of neuro is  25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0199],\n",
      "        [    0.0221],\n",
      "        [    0.0034],\n",
      "        [    0.0063],\n",
      "        [    0.0280],\n",
      "        [    0.0276],\n",
      "        [    0.0182],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0194],\n",
      "        [    0.0234],\n",
      "        [    0.0212],\n",
      "        [    0.0171],\n",
      "        [    0.0249],\n",
      "        [    0.0107],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0072],\n",
      "        [    0.0736],\n",
      "        [    0.0896],\n",
      "        [    0.0942],\n",
      "        [    0.0417],\n",
      "        [    0.0155],\n",
      "        [    0.0653],\n",
      "        [    0.0650],\n",
      "        [    0.0486],\n",
      "        [    0.0230],\n",
      "        [    0.0108],\n",
      "        [    0.0041],\n",
      "        [    0.0348],\n",
      "        [    0.0254],\n",
      "        [    0.0313],\n",
      "        [    0.0511],\n",
      "        [    0.0420],\n",
      "        [    0.0237],\n",
      "        [    0.0233],\n",
      "        [    0.0350],\n",
      "        [    0.0481],\n",
      "        [    0.0521],\n",
      "        [    0.0021],\n",
      "        [    0.0071],\n",
      "        [    0.0240],\n",
      "        [    0.0703],\n",
      "        [    0.0591],\n",
      "        [    0.0271],\n",
      "        [    0.0370],\n",
      "        [    0.0235],\n",
      "        [    0.0189],\n",
      "        [    0.0121],\n",
      "        [    0.0256],\n",
      "        [    0.0459],\n",
      "        [    0.0616],\n",
      "        [    0.0833],\n",
      "        [    0.0341],\n",
      "        [    0.0449],\n",
      "        [    0.0202],\n",
      "        [    0.0569],\n",
      "        [    0.1082],\n",
      "        [    0.0892],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0495],\n",
      "        [    0.0257],\n",
      "        [    0.1479],\n",
      "        [    0.0274],\n",
      "        [    0.0571],\n",
      "        [    0.0465],\n",
      "        [    0.0058],\n",
      "        [    0.0107],\n",
      "        [    0.0177],\n",
      "        [    0.0045],\n",
      "        [    0.0097],\n",
      "        [    0.0249],\n",
      "        [    0.0607],\n",
      "        [    0.0757],\n",
      "        [    0.0832],\n",
      "        [    0.0804],\n",
      "        [    0.1099],\n",
      "        [    0.0918],\n",
      "        [    0.0422],\n",
      "        [    0.0258],\n",
      "        [    0.0016],\n",
      "        [    0.0525],\n",
      "        [    0.0415],\n",
      "        [    0.0082],\n",
      "        [    0.0430],\n",
      "        [    0.0010],\n",
      "        [    0.1131],\n",
      "        [    0.1275],\n",
      "        [    0.1311],\n",
      "        [    0.0752],\n",
      "        [    0.0540],\n",
      "        [    0.0200],\n",
      "        [    0.0138],\n",
      "        [    0.0529],\n",
      "        [    0.0058],\n",
      "        [    0.0425],\n",
      "        [    0.2697],\n",
      "        [    0.1030],\n",
      "        [    0.0838],\n",
      "        [    0.0373],\n",
      "        [    0.0311],\n",
      "        [    0.0221],\n",
      "        [    0.0501],\n",
      "        [    0.1200],\n",
      "        [    0.1407],\n",
      "        [    0.1449],\n",
      "        [    0.0967],\n",
      "        [    0.0583],\n",
      "        [    0.0687],\n",
      "        [    0.1054],\n",
      "        [    0.1319],\n",
      "        [    0.1418],\n",
      "        [    0.1300],\n",
      "        [    0.1005],\n",
      "        [    0.0985],\n",
      "        [    0.0828],\n",
      "        [    0.0847],\n",
      "        [    0.0878],\n",
      "        [    0.0996],\n",
      "        [    0.0932],\n",
      "        [    0.1106],\n",
      "        [    0.1113],\n",
      "        [    0.1318],\n",
      "        [    0.1483],\n",
      "        [    0.1426],\n",
      "        [    0.1414],\n",
      "        [    0.1245],\n",
      "        [    0.0938],\n",
      "        [    0.0970],\n",
      "        [    0.0884],\n",
      "        [    0.0875],\n",
      "        [    0.0409],\n",
      "        [    0.1280],\n",
      "        [    0.1244],\n",
      "        [    0.0913],\n",
      "        [    0.0531],\n",
      "        [    0.0367],\n",
      "        [    0.0603],\n",
      "        [    0.0208],\n",
      "        [    0.0763],\n",
      "        [    0.0691],\n",
      "        [    0.0614],\n",
      "        [    0.0508],\n",
      "        [    0.0016],\n",
      "        [    0.0153],\n",
      "        [    0.0378],\n",
      "        [    0.0521],\n",
      "        [    0.0194],\n",
      "        [    0.0243],\n",
      "        [    0.0439],\n",
      "        [    0.0521],\n",
      "        [    0.0363],\n",
      "        [    0.0387],\n",
      "        [    0.0422],\n",
      "        [    0.0323],\n",
      "        [    0.0262],\n",
      "        [    0.0064],\n",
      "        [    0.0776],\n",
      "        [    0.0604],\n",
      "        [    0.0741],\n",
      "        [    0.0756],\n",
      "        [    0.0836],\n",
      "        [    0.1071],\n",
      "        [    0.2215],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2362],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0000],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  4,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 13, 16, 19, 22, 25],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 196\n",
      "剩餘X 資料 torch.Size([181, 18])\n",
      "剩餘Y 資料 torch.Size([181, 1])\n",
      "現在要進去模型的數據，y= tensor([0.1876])\n",
      "目前模型的Data狀態 torch.Size([196, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.5470],\n",
      "        [0.5486],\n",
      "        [0.5480],\n",
      "        [0.5700],\n",
      "        [0.5870],\n",
      "        [0.5886],\n",
      "        [0.5740],\n",
      "        [0.5699],\n",
      "        [0.5542],\n",
      "        [0.5600],\n",
      "        [0.5600],\n",
      "        [0.5552],\n",
      "        [0.5501],\n",
      "        [0.5480],\n",
      "        [0.5588],\n",
      "        [0.5839],\n",
      "        [0.5761],\n",
      "        [0.5477],\n",
      "        [0.5606],\n",
      "        [0.8775],\n",
      "        [0.9031],\n",
      "        [0.9363],\n",
      "        [0.8864],\n",
      "        [0.9134],\n",
      "        [0.9168],\n",
      "        [0.9098],\n",
      "        [0.9508],\n",
      "        [0.9536],\n",
      "        [0.9863],\n",
      "        [0.9969],\n",
      "        [1.0139],\n",
      "        [0.9718],\n",
      "        [0.9521],\n",
      "        [0.9289],\n",
      "        [0.9253],\n",
      "        [0.9201],\n",
      "        [0.8656],\n",
      "        [0.8791],\n",
      "        [0.8885],\n",
      "        [0.8638],\n",
      "        [0.8554],\n",
      "        [0.8476],\n",
      "        [0.8694],\n",
      "        [0.8632],\n",
      "        [0.8656],\n",
      "        [0.8587],\n",
      "        [0.8407],\n",
      "        [0.8257],\n",
      "        [0.8484],\n",
      "        [0.8617],\n",
      "        [0.8299],\n",
      "        [0.8553],\n",
      "        [0.8816],\n",
      "        [0.8978],\n",
      "        [0.8742],\n",
      "        [0.8874],\n",
      "        [0.8837],\n",
      "        [0.8961],\n",
      "        [0.8918],\n",
      "        [0.8792],\n",
      "        [0.8988],\n",
      "        [0.9111],\n",
      "        [0.9027],\n",
      "        [0.8761],\n",
      "        [0.8558],\n",
      "        [0.8706],\n",
      "        [0.8868],\n",
      "        [0.8928],\n",
      "        [0.8467],\n",
      "        [0.8999],\n",
      "        [0.8802],\n",
      "        [0.8789],\n",
      "        [0.8578],\n",
      "        [0.8677],\n",
      "        [0.8489],\n",
      "        [0.8302],\n",
      "        [0.8368],\n",
      "        [0.8551],\n",
      "        [0.8495],\n",
      "        [0.8635],\n",
      "        [0.8781],\n",
      "        [0.8575],\n",
      "        [0.8601],\n",
      "        [0.8218],\n",
      "        [0.7942],\n",
      "        [0.8437],\n",
      "        [0.8366],\n",
      "        [0.8177],\n",
      "        [0.8169],\n",
      "        [0.7767],\n",
      "        [0.7896],\n",
      "        [0.8213],\n",
      "        [0.7995],\n",
      "        [0.7806],\n",
      "        [0.7601],\n",
      "        [0.7057],\n",
      "        [0.7160],\n",
      "        [0.7055],\n",
      "        [0.7309],\n",
      "        [0.7244],\n",
      "        [0.6981],\n",
      "        [0.6708],\n",
      "        [0.6242],\n",
      "        [0.6457],\n",
      "        [0.6110],\n",
      "        [0.5968],\n",
      "        [0.5948],\n",
      "        [0.5894],\n",
      "        [0.6151],\n",
      "        [0.6451],\n",
      "        [0.6227],\n",
      "        [0.6002],\n",
      "        [0.5842],\n",
      "        [0.5659],\n",
      "        [0.5750],\n",
      "        [0.5945],\n",
      "        [0.5851],\n",
      "        [0.5944],\n",
      "        [0.5750],\n",
      "        [0.5475],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5485],\n",
      "        [0.5477],\n",
      "        [0.5476],\n",
      "        [0.5483],\n",
      "        [0.5482],\n",
      "        [0.5479],\n",
      "        [0.5475],\n",
      "        [0.5477],\n",
      "        [0.5484],\n",
      "        [0.5479],\n",
      "        [0.5485],\n",
      "        [0.5479],\n",
      "        [0.5485],\n",
      "        [0.5481],\n",
      "        [0.5481],\n",
      "        [0.5484],\n",
      "        [0.5481],\n",
      "        [0.5502],\n",
      "        [0.5643],\n",
      "        [0.5476],\n",
      "        [0.5480],\n",
      "        [0.5573],\n",
      "        [0.5600],\n",
      "        [0.5822],\n",
      "        [0.6153],\n",
      "        [0.6389],\n",
      "        [0.6196],\n",
      "        [0.6235],\n",
      "        [0.5973],\n",
      "        [0.5894],\n",
      "        [0.5765],\n",
      "        [0.5707],\n",
      "        [0.5779],\n",
      "        [0.6017],\n",
      "        [0.5955],\n",
      "        [0.5811],\n",
      "        [0.5843],\n",
      "        [0.5485],\n",
      "        [0.5477],\n",
      "        [0.5480],\n",
      "        [0.5475],\n",
      "        [0.5482],\n",
      "        [0.5475],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.2274],\n",
      "        [0.2660],\n",
      "        [0.2675],\n",
      "        [0.5479],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5671],\n",
      "        [0.5551],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5478],\n",
      "        [0.5477],\n",
      "        [0.5477],\n",
      "        [0.5477],\n",
      "        [0.2710],\n",
      "        [0.2622],\n",
      "        [0.2214],\n",
      "        [0.1909],\n",
      "        [0.1628],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0199],\n",
      "        [    0.0221],\n",
      "        [    0.0034],\n",
      "        [    0.0063],\n",
      "        [    0.0280],\n",
      "        [    0.0276],\n",
      "        [    0.0182],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0194],\n",
      "        [    0.0234],\n",
      "        [    0.0212],\n",
      "        [    0.0171],\n",
      "        [    0.0249],\n",
      "        [    0.0107],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0072],\n",
      "        [    0.0736],\n",
      "        [    0.0896],\n",
      "        [    0.0942],\n",
      "        [    0.0417],\n",
      "        [    0.0155],\n",
      "        [    0.0653],\n",
      "        [    0.0650],\n",
      "        [    0.0486],\n",
      "        [    0.0230],\n",
      "        [    0.0108],\n",
      "        [    0.0041],\n",
      "        [    0.0348],\n",
      "        [    0.0254],\n",
      "        [    0.0313],\n",
      "        [    0.0511],\n",
      "        [    0.0420],\n",
      "        [    0.0237],\n",
      "        [    0.0233],\n",
      "        [    0.0350],\n",
      "        [    0.0481],\n",
      "        [    0.0521],\n",
      "        [    0.0021],\n",
      "        [    0.0071],\n",
      "        [    0.0240],\n",
      "        [    0.0703],\n",
      "        [    0.0591],\n",
      "        [    0.0271],\n",
      "        [    0.0370],\n",
      "        [    0.0235],\n",
      "        [    0.0189],\n",
      "        [    0.0121],\n",
      "        [    0.0256],\n",
      "        [    0.0459],\n",
      "        [    0.0616],\n",
      "        [    0.0833],\n",
      "        [    0.0341],\n",
      "        [    0.0449],\n",
      "        [    0.0202],\n",
      "        [    0.0569],\n",
      "        [    0.1082],\n",
      "        [    0.0892],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0495],\n",
      "        [    0.0257],\n",
      "        [    0.1479],\n",
      "        [    0.0274],\n",
      "        [    0.0571],\n",
      "        [    0.0465],\n",
      "        [    0.0058],\n",
      "        [    0.0107],\n",
      "        [    0.0177],\n",
      "        [    0.0045],\n",
      "        [    0.0097],\n",
      "        [    0.0249],\n",
      "        [    0.0607],\n",
      "        [    0.0757],\n",
      "        [    0.0832],\n",
      "        [    0.0804],\n",
      "        [    0.1099],\n",
      "        [    0.0918],\n",
      "        [    0.0422],\n",
      "        [    0.0258],\n",
      "        [    0.0016],\n",
      "        [    0.0525],\n",
      "        [    0.0415],\n",
      "        [    0.0082],\n",
      "        [    0.0430],\n",
      "        [    0.0010],\n",
      "        [    0.1131],\n",
      "        [    0.1275],\n",
      "        [    0.1311],\n",
      "        [    0.0752],\n",
      "        [    0.0540],\n",
      "        [    0.0200],\n",
      "        [    0.0138],\n",
      "        [    0.0529],\n",
      "        [    0.0058],\n",
      "        [    0.0425],\n",
      "        [    0.2697],\n",
      "        [    0.1030],\n",
      "        [    0.0838],\n",
      "        [    0.0373],\n",
      "        [    0.0311],\n",
      "        [    0.0221],\n",
      "        [    0.0501],\n",
      "        [    0.1200],\n",
      "        [    0.1407],\n",
      "        [    0.1449],\n",
      "        [    0.0967],\n",
      "        [    0.0583],\n",
      "        [    0.0687],\n",
      "        [    0.1054],\n",
      "        [    0.1319],\n",
      "        [    0.1418],\n",
      "        [    0.1300],\n",
      "        [    0.1005],\n",
      "        [    0.0985],\n",
      "        [    0.0828],\n",
      "        [    0.0847],\n",
      "        [    0.0878],\n",
      "        [    0.0996],\n",
      "        [    0.0932],\n",
      "        [    0.1106],\n",
      "        [    0.1113],\n",
      "        [    0.1318],\n",
      "        [    0.1483],\n",
      "        [    0.1426],\n",
      "        [    0.1414],\n",
      "        [    0.1245],\n",
      "        [    0.0938],\n",
      "        [    0.0970],\n",
      "        [    0.0884],\n",
      "        [    0.0875],\n",
      "        [    0.0409],\n",
      "        [    0.1280],\n",
      "        [    0.1244],\n",
      "        [    0.0913],\n",
      "        [    0.0531],\n",
      "        [    0.0367],\n",
      "        [    0.0603],\n",
      "        [    0.0208],\n",
      "        [    0.0763],\n",
      "        [    0.0691],\n",
      "        [    0.0614],\n",
      "        [    0.0508],\n",
      "        [    0.0016],\n",
      "        [    0.0153],\n",
      "        [    0.0378],\n",
      "        [    0.0521],\n",
      "        [    0.0194],\n",
      "        [    0.0243],\n",
      "        [    0.0439],\n",
      "        [    0.0521],\n",
      "        [    0.0363],\n",
      "        [    0.0387],\n",
      "        [    0.0422],\n",
      "        [    0.0323],\n",
      "        [    0.0262],\n",
      "        [    0.0064],\n",
      "        [    0.0776],\n",
      "        [    0.0604],\n",
      "        [    0.0741],\n",
      "        [    0.0756],\n",
      "        [    0.0836],\n",
      "        [    0.1071],\n",
      "        [    0.2215],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2362],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.3602]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "Loss值\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0199],\n",
      "        [    0.0221],\n",
      "        [    0.0034],\n",
      "        [    0.0063],\n",
      "        [    0.0280],\n",
      "        [    0.0276],\n",
      "        [    0.0182],\n",
      "        [    0.0219],\n",
      "        [    0.0278],\n",
      "        [    0.0194],\n",
      "        [    0.0234],\n",
      "        [    0.0212],\n",
      "        [    0.0171],\n",
      "        [    0.0249],\n",
      "        [    0.0107],\n",
      "        [    0.0427],\n",
      "        [    0.0511],\n",
      "        [    0.0239],\n",
      "        [    0.0072],\n",
      "        [    0.0736],\n",
      "        [    0.0896],\n",
      "        [    0.0942],\n",
      "        [    0.0417],\n",
      "        [    0.0155],\n",
      "        [    0.0653],\n",
      "        [    0.0650],\n",
      "        [    0.0486],\n",
      "        [    0.0230],\n",
      "        [    0.0108],\n",
      "        [    0.0041],\n",
      "        [    0.0348],\n",
      "        [    0.0254],\n",
      "        [    0.0313],\n",
      "        [    0.0511],\n",
      "        [    0.0420],\n",
      "        [    0.0237],\n",
      "        [    0.0233],\n",
      "        [    0.0350],\n",
      "        [    0.0481],\n",
      "        [    0.0521],\n",
      "        [    0.0021],\n",
      "        [    0.0071],\n",
      "        [    0.0240],\n",
      "        [    0.0703],\n",
      "        [    0.0591],\n",
      "        [    0.0271],\n",
      "        [    0.0370],\n",
      "        [    0.0235],\n",
      "        [    0.0189],\n",
      "        [    0.0121],\n",
      "        [    0.0256],\n",
      "        [    0.0459],\n",
      "        [    0.0616],\n",
      "        [    0.0833],\n",
      "        [    0.0341],\n",
      "        [    0.0449],\n",
      "        [    0.0202],\n",
      "        [    0.0569],\n",
      "        [    0.1082],\n",
      "        [    0.0892],\n",
      "        [    0.0693],\n",
      "        [    0.0558],\n",
      "        [    0.0495],\n",
      "        [    0.0257],\n",
      "        [    0.1479],\n",
      "        [    0.0274],\n",
      "        [    0.0571],\n",
      "        [    0.0465],\n",
      "        [    0.0058],\n",
      "        [    0.0107],\n",
      "        [    0.0177],\n",
      "        [    0.0045],\n",
      "        [    0.0097],\n",
      "        [    0.0249],\n",
      "        [    0.0607],\n",
      "        [    0.0757],\n",
      "        [    0.0832],\n",
      "        [    0.0804],\n",
      "        [    0.1099],\n",
      "        [    0.0918],\n",
      "        [    0.0422],\n",
      "        [    0.0258],\n",
      "        [    0.0016],\n",
      "        [    0.0525],\n",
      "        [    0.0415],\n",
      "        [    0.0082],\n",
      "        [    0.0430],\n",
      "        [    0.0010],\n",
      "        [    0.1131],\n",
      "        [    0.1275],\n",
      "        [    0.1311],\n",
      "        [    0.0752],\n",
      "        [    0.0540],\n",
      "        [    0.0200],\n",
      "        [    0.0138],\n",
      "        [    0.0529],\n",
      "        [    0.0058],\n",
      "        [    0.0425],\n",
      "        [    0.2697],\n",
      "        [    0.1030],\n",
      "        [    0.0838],\n",
      "        [    0.0373],\n",
      "        [    0.0311],\n",
      "        [    0.0221],\n",
      "        [    0.0501],\n",
      "        [    0.1200],\n",
      "        [    0.1407],\n",
      "        [    0.1449],\n",
      "        [    0.0967],\n",
      "        [    0.0583],\n",
      "        [    0.0687],\n",
      "        [    0.1054],\n",
      "        [    0.1319],\n",
      "        [    0.1418],\n",
      "        [    0.1300],\n",
      "        [    0.1005],\n",
      "        [    0.0985],\n",
      "        [    0.0828],\n",
      "        [    0.0847],\n",
      "        [    0.0878],\n",
      "        [    0.0996],\n",
      "        [    0.0932],\n",
      "        [    0.1106],\n",
      "        [    0.1113],\n",
      "        [    0.1318],\n",
      "        [    0.1483],\n",
      "        [    0.1426],\n",
      "        [    0.1414],\n",
      "        [    0.1245],\n",
      "        [    0.0938],\n",
      "        [    0.0970],\n",
      "        [    0.0884],\n",
      "        [    0.0875],\n",
      "        [    0.0409],\n",
      "        [    0.1280],\n",
      "        [    0.1244],\n",
      "        [    0.0913],\n",
      "        [    0.0531],\n",
      "        [    0.0367],\n",
      "        [    0.0603],\n",
      "        [    0.0208],\n",
      "        [    0.0763],\n",
      "        [    0.0691],\n",
      "        [    0.0614],\n",
      "        [    0.0508],\n",
      "        [    0.0016],\n",
      "        [    0.0153],\n",
      "        [    0.0378],\n",
      "        [    0.0521],\n",
      "        [    0.0194],\n",
      "        [    0.0243],\n",
      "        [    0.0439],\n",
      "        [    0.0521],\n",
      "        [    0.0363],\n",
      "        [    0.0387],\n",
      "        [    0.0422],\n",
      "        [    0.0323],\n",
      "        [    0.0262],\n",
      "        [    0.0064],\n",
      "        [    0.0776],\n",
      "        [    0.0604],\n",
      "        [    0.0741],\n",
      "        [    0.0756],\n",
      "        [    0.0836],\n",
      "        [    0.1071],\n",
      "        [    0.2215],\n",
      "        [    0.2610],\n",
      "        [    0.0001],\n",
      "        [    0.0010],\n",
      "        [    0.0000],\n",
      "        [    0.2570],\n",
      "        [    0.2451],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1899],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1041],\n",
      "        [    0.0956],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1833],\n",
      "        [    0.1935],\n",
      "        [    0.2335],\n",
      "        [    0.2362],\n",
      "        [    0.2224],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0012],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.3602]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.27\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[195,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0206],\n",
      "        [    0.0219],\n",
      "        [    0.0035],\n",
      "        [    0.0065],\n",
      "        [    0.0268],\n",
      "        [    0.0275],\n",
      "        [    0.0182],\n",
      "        [    0.0216],\n",
      "        [    0.0274],\n",
      "        [    0.0189],\n",
      "        [    0.0239],\n",
      "        [    0.0211],\n",
      "        [    0.0166],\n",
      "        [    0.0245],\n",
      "        [    0.0108],\n",
      "        [    0.0425],\n",
      "        [    0.0509],\n",
      "        [    0.0237],\n",
      "        [    0.0081],\n",
      "        [    0.0739],\n",
      "        [    0.0881],\n",
      "        [    0.0967],\n",
      "        [    0.0427],\n",
      "        [    0.0168],\n",
      "        [    0.0646],\n",
      "        [    0.0638],\n",
      "        [    0.0474],\n",
      "        [    0.0243],\n",
      "        [    0.0100],\n",
      "        [    0.0017],\n",
      "        [    0.0355],\n",
      "        [    0.0323],\n",
      "        [    0.0354],\n",
      "        [    0.0556],\n",
      "        [    0.0457],\n",
      "        [    0.0205],\n",
      "        [    0.0220],\n",
      "        [    0.0389],\n",
      "        [    0.0505],\n",
      "        [    0.0483],\n",
      "        [    0.0042],\n",
      "        [    0.0088],\n",
      "        [    0.0246],\n",
      "        [    0.0724],\n",
      "        [    0.0613],\n",
      "        [    0.0268],\n",
      "        [    0.0364],\n",
      "        [    0.0222],\n",
      "        [    0.0195],\n",
      "        [    0.0119],\n",
      "        [    0.0260],\n",
      "        [    0.0460],\n",
      "        [    0.0626],\n",
      "        [    0.0830],\n",
      "        [    0.0338],\n",
      "        [    0.0456],\n",
      "        [    0.0202],\n",
      "        [    0.0566],\n",
      "        [    0.1075],\n",
      "        [    0.0892],\n",
      "        [    0.0691],\n",
      "        [    0.0561],\n",
      "        [    0.0488],\n",
      "        [    0.0253],\n",
      "        [    0.1478],\n",
      "        [    0.0242],\n",
      "        [    0.0561],\n",
      "        [    0.0476],\n",
      "        [    0.0049],\n",
      "        [    0.0105],\n",
      "        [    0.0179],\n",
      "        [    0.0045],\n",
      "        [    0.0095],\n",
      "        [    0.0244],\n",
      "        [    0.0609],\n",
      "        [    0.0760],\n",
      "        [    0.0836],\n",
      "        [    0.0807],\n",
      "        [    0.1111],\n",
      "        [    0.0910],\n",
      "        [    0.0433],\n",
      "        [    0.0246],\n",
      "        [    0.0018],\n",
      "        [    0.0525],\n",
      "        [    0.0431],\n",
      "        [    0.0099],\n",
      "        [    0.0422],\n",
      "        [    0.0007],\n",
      "        [    0.1123],\n",
      "        [    0.1272],\n",
      "        [    0.1318],\n",
      "        [    0.0746],\n",
      "        [    0.0550],\n",
      "        [    0.0194],\n",
      "        [    0.0136],\n",
      "        [    0.0525],\n",
      "        [    0.0053],\n",
      "        [    0.0428],\n",
      "        [    0.2687],\n",
      "        [    0.1029],\n",
      "        [    0.0850],\n",
      "        [    0.0369],\n",
      "        [    0.0310],\n",
      "        [    0.0228],\n",
      "        [    0.0503],\n",
      "        [    0.1208],\n",
      "        [    0.1398],\n",
      "        [    0.1455],\n",
      "        [    0.0958],\n",
      "        [    0.0579],\n",
      "        [    0.0694],\n",
      "        [    0.1049],\n",
      "        [    0.1303],\n",
      "        [    0.1427],\n",
      "        [    0.1309],\n",
      "        [    0.1006],\n",
      "        [    0.0974],\n",
      "        [    0.0831],\n",
      "        [    0.0847],\n",
      "        [    0.0879],\n",
      "        [    0.0994],\n",
      "        [    0.0942],\n",
      "        [    0.1106],\n",
      "        [    0.1119],\n",
      "        [    0.1330],\n",
      "        [    0.1469],\n",
      "        [    0.1432],\n",
      "        [    0.1403],\n",
      "        [    0.1246],\n",
      "        [    0.0946],\n",
      "        [    0.0977],\n",
      "        [    0.0895],\n",
      "        [    0.0878],\n",
      "        [    0.0418],\n",
      "        [    0.1293],\n",
      "        [    0.1238],\n",
      "        [    0.0912],\n",
      "        [    0.0518],\n",
      "        [    0.0366],\n",
      "        [    0.0600],\n",
      "        [    0.0207],\n",
      "        [    0.0758],\n",
      "        [    0.0694],\n",
      "        [    0.0617],\n",
      "        [    0.0497],\n",
      "        [    0.0002],\n",
      "        [    0.0143],\n",
      "        [    0.0380],\n",
      "        [    0.0516],\n",
      "        [    0.0186],\n",
      "        [    0.0243],\n",
      "        [    0.0442],\n",
      "        [    0.0508],\n",
      "        [    0.0364],\n",
      "        [    0.0394],\n",
      "        [    0.0422],\n",
      "        [    0.0321],\n",
      "        [    0.0269],\n",
      "        [    0.0061],\n",
      "        [    0.0778],\n",
      "        [    0.0607],\n",
      "        [    0.0738],\n",
      "        [    0.0751],\n",
      "        [    0.0838],\n",
      "        [    0.1068],\n",
      "        [    0.2217],\n",
      "        [    0.2609],\n",
      "        [    0.0005],\n",
      "        [    0.0013],\n",
      "        [    0.0001],\n",
      "        [    0.2569],\n",
      "        [    0.2453],\n",
      "        [    0.2286],\n",
      "        [    0.2400],\n",
      "        [    0.2407],\n",
      "        [    0.1900],\n",
      "        [    0.1898],\n",
      "        [    0.1891],\n",
      "        [    0.1893],\n",
      "        [    0.1844],\n",
      "        [    0.1760],\n",
      "        [    0.1040],\n",
      "        [    0.0955],\n",
      "        [    0.1113],\n",
      "        [    0.1489],\n",
      "        [    0.1832],\n",
      "        [    0.1934],\n",
      "        [    0.2334],\n",
      "        [    0.2359],\n",
      "        [    0.2222],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0013],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0003]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.27\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.27\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 8\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 165\n",
      "Number of shrink: 91\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 327\n",
      "Number of shrink: 173\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 163\n",
      "Number of shrink: 90\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 23 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 24 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 25 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 26 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 27 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.27\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.27\n"
     ]
    }
   ],
   "source": [
    "evaluation_table_train = pd.DataFrame(columns=[\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "evaluation_table_test = pd.DataFrame(columns=[\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "    \n",
    "x_data, y_data= get_data(4)\n",
    "x_data = sc.fit_transform(x_data)\n",
    "y_data = sc.fit_transform(y_data[:,3].reshape(-1,1))\n",
    "threshold_for_error = 7000/(sc.data_max_-sc.data_min_)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## Record the number of each step\n",
    "nb_step4 = 0\n",
    "nb_step6_1 = 0\n",
    "nb_step6_2 = 0\n",
    "\n",
    "\n",
    "x_train = x_data[:int(x_data.shape[0]*0.8)]\n",
    "x_test = x_data[int(x_data.shape[0]*0.8):]\n",
    "y_train = y_data[:int(y_data.shape[0]*0.8)]\n",
    "y_test = y_data[int(y_data.shape[0]*0.8):]\n",
    "\n",
    "x_train_scaled = torch.FloatTensor(x_train)\n",
    "x_test_scaled = torch.FloatTensor(x_test)\n",
    "y_train_scaled = torch.FloatTensor(y_train)\n",
    "y_test = sc.inverse_transform(y_test)\n",
    "\n",
    "lower = torch.mean(y_train_scaled)-0.1*torch.std(y_train_scaled)\n",
    "upper = torch.mean(y_train_scaled)+0.1*torch.std(y_train_scaled)\n",
    "nonoutlier_index = torch.nonzero((y_train_scaled[:,0]>lower)&(y_train_scaled[:,0]<upper), as_tuple =False).reshape([-1])\n",
    "print(\"初始值候選人\",nonoutlier_index.shape)\n",
    "initial_x = x_train_scaled[nonoutlier_index[:19]]\n",
    "initial_y = y_train_scaled[nonoutlier_index[:19]]\n",
    "\n",
    "x_train_scaled = np.delete(x_train_scaled, nonoutlier_index[:19], 0)\n",
    "y_train_scaled = np.delete(y_train_scaled, nonoutlier_index[:19], 0)\n",
    "\n",
    "network = Network(1,initial_x,initial_y)\n",
    "\n",
    "network.nb_node_acceptable = torch.IntTensor([1 for _ in range(initial_x.shape[0])])\n",
    "network.threshold_for_error = round(threshold_for_error[0],2)\n",
    "\n",
    "initializing(network, initial_x, initial_y)\n",
    "\n",
    "print(\"<<Initializing後看一下差異>>\")\n",
    "yo,loss = network.forward()\n",
    "print(torch.abs(network.y-yo))\n",
    "print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "\n",
    "remainder =  x_train_scaled.shape[0]\n",
    "nb_step4 += initial_x.shape[0]\n",
    "\n",
    "for i in range(remainder):\n",
    "\n",
    "    \n",
    "    print(\"現在訓練到第幾筆資料: %d\"%(i+x_train_scaled.shape[1]+2))\n",
    "\n",
    "    print(\"剩餘X 資料\",x_train_scaled.shape)\n",
    "    print(\"剩餘Y 資料\",y_train_scaled.shape)\n",
    "\n",
    "#     sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "    ## Add new data for training\n",
    "    print(\"現在要進去模型的數據，y=\",y_train_scaled[0].data)        \n",
    "    network.addData(x_train_scaled[0], y_train_scaled[0])\n",
    "    print(\"目前模型的Data狀態\",network.y.shape)\n",
    "    x_train_scaled = x_train_scaled[1:]\n",
    "    y_train_scaled = y_train_scaled[1:]\n",
    "\n",
    "    yo,loss = network.forward()\n",
    "    print(\"<<預測值>>\")\n",
    "    print(yo)\n",
    "    print(\"<<差異>>\")\n",
    "    print(torch.abs(yo-network.y))\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    print(\"Loss值\")\n",
    "    print(loss)\n",
    "\n",
    "    pre_network = copy.deepcopy(network)\n",
    "\n",
    "    if not torch.all(torch.abs(network.y-yo)<=network.threshold_for_error):\n",
    "        \n",
    "        network.acceptable = False\n",
    "        network = matching(network)\n",
    "\n",
    "        print(\"<<Matching後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "\n",
    "        if network.acceptable == False:\n",
    "\n",
    "            network = copy.deepcopy(pre_network)\n",
    "            cramming(network)\n",
    "\n",
    "            if network.acceptable == False:\n",
    "                sys.exit(\"Cramming failed.\")  \n",
    "\n",
    "            print(\"<<Cramming後看一下差異>>\")\n",
    "            yo,loss = network.forward()\n",
    "            print(torch.abs(yo-network.y))\n",
    "            print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "            nb_step6_2 += 1\n",
    "\n",
    "        else:\n",
    "            nb_step6_1 += 1\n",
    "\n",
    "    else:\n",
    "        nb_step4 += 1\n",
    "\n",
    "    network = reorganizing(network)\n",
    "    print(\"<<Reorganizing後看一下差異>>\")\n",
    "    yo,loss = network.forward()\n",
    "    print(torch.abs(yo-network.y))\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "\n",
    "    network.nb_node_acceptable = torch.cat([network.nb_node_acceptable, torch.IntTensor([network.linear1.bias.data.shape[0]])],0)\n",
    "    print(\"看一下 hidden node\")\n",
    "    print(network.nb_node_acceptable)\n",
    "\n",
    "    print(\"使用裝置\",(list(network.parameters())[0].device))\n",
    "    print(\"-\"*90)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"<<The performance>>\")\n",
    "evaluation_table_train, evaluation_table_test = validation(network, nb_step4, nb_step6_1, nb_step6_2, x_train_scaled, y_train_scaled,x_test_scaled, y_test, start, end,evaluation_table_train,evaluation_table_test)\n",
    "\n",
    "evaluation_table_train.to_csv(\"evaluation_table_train.csv\",index=False)\n",
    "evaluation_table_test.to_csv(\"evaluation_table_inferencing.csv\",index=False)\n",
    "\n",
    "print(\"花費時間(s)\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
